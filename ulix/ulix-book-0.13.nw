\documentclass[a4paper,twoside,open=right,numbers=noenddot,DIV=13,BCOR=8.25mm]{scrreprt}
% document needs TeXlive 2013
% compile with xelatex

% ULIX v. 0.13, September 2015
% 
% Copyright (c) 2008-2015 Felix Freiling, University of Erlangen-Nürnberg, Germany
% Copyright (c) 2011-2015 Hans-Georg Eßer, University of Erlangen-Nürnberg, Germany
% 
% This program is free software: you can redistribute it and/or modify it under 
% the terms of the GNU General Public License as published by the Free Software 
% Foundation, either version 3 of the License, or (at your option) any later version.
% 
% This program is distributed in the hope that it will be useful, but WITHOUT ANY 
% WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A 
% PARTICULAR PURPOSE.  See the GNU General Public License for more details.
% 
% You should have received a copy of the GNU General Public License along with this 
% program.  If not, see http://www.gnu.org/licenses/ .

\usepackage[usenames,xetex]{xcolor}
\usepackage{soul} % for highlighting
\usepackage{mathspec}
\usepackage{xltxtra}
\setmainfont[Mapping=tex-text]{Linux Libertine O}
\setmathsfont(Digits,Latin,Greek)[Numbers={Lining,Proportional}]{Linux Libertine O}

\definecolor{DarkBlue}{rgb}{0.3,0.3,1.0}
\setmonofont[FakeStretch=.9,Scale=MatchLowercase]{Menlo}
\setsansfont[Mapping=tex-text,Scale=MatchLowercase]{Linux Biolinum O}

\usepackage[Q=yes,pverb-linebreak=yes,pverb-linebreakchar={$\lnot$}]{examplep}% \Q command
\usepackage{scrpage2}

\newcommand{\parttocpagebreak}{} % for minitoc page breaks
\newcommand{\parttocenlarge}{}   % for minitoc enlargethispage
\usepackage{tocloft}
\usepackage[k-tight]{minitoc}
\newcommand\hgepolylof[1]{\mtcpolymlof{\vspace{2mm}#1}{}{}{#1}}  % force 2mm after previous partlof entry
\newcommand\hgepolylot[1]{\mtcpolymlot{\vspace{2mm}#1}{}{}{#1}}  % force 2mm after previous partlot entry
% my modification of minitoc, dirty hack that adds a \contentsline{chapter}{\pagebreak}...
\makeatletter
\long\def\PTC@test#1#2#3#4#5#6\PTC@{%
  \ifx#1\contentsline
    \let\mtc@string\string
    \PTC@contentsline{#2}{#3}{#4}{#5}%
    \let\mtc@string\relax
  \else\ifx#1\parttocpagebreak
    \let\mtc@string\string
    \PTC@contentsline{chapter}{\pagebreak}{}{}%
    \let\mtc@string\relax
  \else\ifx#1\parttocenlarge
    \let\mtc@string\string
    \PTC@contentsline{chapter}{\protect\enlargethispage{1cm}}{}{}%
    \let\mtc@string\relax
  \else\ifx#1\@input
     \edef\PTC@list{\PTC@list#2\relax}%
  \else\ifx#1\partend
     \immediate\closeout\tf@mtc
     \immediate\openout\tf@mtc=\jobname.mtc
  \else\ifx#1\partbegin
     \addtocounter{ptc}{-1}%
  \fi\fi\fi\fi\fi\fi
  \ifeof\@inputcheck\expandafter\PTC@toc
  \else\expandafter\PTC@read\fi}%
\makeatother



\usepackage{microtype}  % optischer Randausgleich
\usepackage{bchart}
\usepackage{multicol}
\usepackage{adjmulticol}
\usepackage{enumitem} % modify itemize env.
\setlist[itemize]{leftmargin=20pt,topsep=5pt,parsep=5pt,itemsep=-2pt,label={\Large\green\textbullet}}
\setlist[enumerate]{leftmargin=20pt,topsep=5pt,parsep=5pt,itemsep=-2pt}

\usepackage{ragged2e,array,longtable}
\usepackage{bytefield}

% Babel tip: http://tex.stackexchange.com/questions/27198/babel-adding-ngerman-s-language-shorthands-to-english-as-the-main-document-lan
% "= : Trennung
% "- : weiches Trennzeichen
% Beispiel: Das Ulix"=Be"-triebs"-sys"-tem
\usepackage[ngerman,english]{babel}
\useshorthands{"}
\addto\extrasenglish{\languageshorthands{ngerman}}

\usepackage{pdfpages}

% note: http://stackoverflow.com/questions/2625714/linebreak-in-url-with-bibtex-and-hyperref-package
% url must come before hyperref, noweb
\usepackage[hyphens]{url}
\usepackage[breaklinks,hidelinks]{hyperref}
\usepackage{noweb}
\usepackage[latin1]{inputenc}
\usepackage{graphicx,boxedminipage,a4wide}
\noweboptions{english,externalindex,longchunks,hideunuseddefs,subscriptquotedidents}
% fix for empty pages after code chunks
% found in FAQ, http://www.cs.tufts.edu/~nr/noweb/FAQ.html
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par

% Noweb margin tags on left/right margins (twoside)
\renewcommand{\nwmargintag}[1]{\marginnote{{\small [}#1{\small ]}}}
\newcommand{\marginhl}[1]{\marginnote{#1}}

\usepackage{fancyvrb} %  Verbatim statt verbatim
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{baselinestretch=.9}

\usepackage{marginnote}  % Randnoten
\renewcommand*{\marginfont}{\sffamily\noindent}


%%% Chapter headings
\usepackage[sf]{titlesec}
\titleformat{\section}[hang]{\LARGE\sffamily\bfseries}{\thetitle}{12pt}{}
\titleformat{\subsection}[hang]{\Large\sffamily\bfseries}{\thetitle}{12pt}{}
\titleformat{\subsubsection}[hang]{\large\sffamily\bfseries}{\thetitle}{12pt}{}
\titleformat{\paragraph}[hang]{\fontsize{13pt}{13pt}\sffamily}{\thetitle}{12pt}{}

% abstände: Einzug, abstand darüber, abstand darunter
\titlespacing{\paragraph}{0pt}{6pt}{0pt}

%Etwas aufwendiger für die Kapitelüberschriften:
\titleformat{\chapter}[display]
{\filleft\fontsize{30pt}{36pt}\selectfont\sffamily} %Huge ist die Größe für Titeltext und Nummer
{\fontsize{120pt}{100pt}\selectfont\thechapter}
{-2ex} %is vertical space in [display] mode
%Platz vor dem ganzen Krempel
{\vspace{0.5ex}} %1ex ist die Höhe von x im aktuellen Font
%Platz danach
[\vspace{0.5ex}]
% 

% replace "->" in listings with nicer arrow
\def\ARROW{\begingroup\maybehbox\bgroup\setupmodname\It$-\hspace{-2.35mm}-\!\!\!$\egroup\endgroup>}

\usepackage{listings}
\usepackage{type1cm} % beliebig skalierbare Fonts, z. B. \fontsize{3.32}{4}


%%% escaping < <:
%%% add a @ character in front of < <
%%% like this:
%%%    @<<  or   @>>

\definecolor{LinkColor}{rgb}{0.18,0,0.44}
\hypersetup{
  pdfauthor={Hans-Georg Eßer},
  pdftitle={Design, Implementation and Evaluation of the ULIX-i386 Teaching Operating System}%,
  %colorlinks=true,
  %urlcolor=blue,
  %linkcolor=LinkColor
}


% relax noweb's page breaking rules (taken from Noweb FAQ) at
% http://www.eecs.harvard.edu/~nr/noweb/FAQ.html
\def\nwendcode{\endtrivlist \endgroup}
\let\nwdocspar=\par

\setlength{\cftchapnumwidth}{1.1cm}

\setlength{\cftsecnumwidth}{1.5cm}
\setlength{\cftsecindent}{1.1cm}

\setlength{\cftsubsecnumwidth}{1.6cm}
\setlength{\cftsubsecindent}{2.6cm}       % 1.2.3

\setlength{\cftsubsubsecnumwidth}{1.6cm}
\setlength{\cftsubsubsecindent}{4.2cm}   % 1.2.3.4

% prepare for index generation
\usepackage{makeidx}
\usepackage[columns=2]{idxlayout}
\makeindex

% Changes to the Index layout
\makeatletter
\patchcmd{\theindex}{%
  \begin{multicols}{\theidxcols}%
}{%
  \small%
  \columnseprule=.4pt%
  \begin{adjmulticols}{2}{0cm}{-2.92cm}%
}{}{}
\patchcmd{\endtheindex}{%
  \end{multicols}%
}{%
  \end{adjmulticols}%
}{}{}
\makeatother

\setcounter{secnumdepth}{4}   % until 1.2.3.4

\newcommand{\eg}{e.\,g.}
\newtheorem{definition}{Definition}

% some typesetting for identifiers in formulas:
\newcommand{\id}[1]{\textit{#1}}

% registers such as ECX, EDX etc.: italics
\newcommand{\register}[1]{\texttt{\textsl{#1}}}

% for indexing (definitions from Felix)
% plain index, additional term to be added (does not appear in text)
\newcommand{\pindex}[1]{\index{#1}}
% like plain index, term is sorted according to first argument but
% typeset as second argument (example: \pcindex{TeX}{\TeX{}})
\newcommand{\pcindex}[2]{\index{#1@#2}}
% verbatim index, term appears in index and in text as is
\newcommand{\vindex}[1]{#1\index{#1}}
% tt index, term appears in index in \tt font
\newcommand{\tindex}[1]{\index{#1@\texttt{#1}}}
% Intel index
\newcommand{\intelindex}[1]{\index{Intel x86 architecture!#1}}
% Syscall index
\newcommand{\syscallindex}[1]{\index{#1 system call@\texttt{#1} system call}\index{system call!#1@\texttt{#1}}}
% TCB index
\newcommand{\tcbindex}[1]{\index{thread control block!#1}}
%


%\newcommand{\dindex}[1]{\index{#1|blueindex}}  % diss index
\newcommand{\dindex}[1]{}  % NO diss index

\newcommand{\blueindex}[1]{{\lblue{}\emph{#1}\black{}}}    % helper for blue diss index
\newcommand{\Index}[1]{#1\index{#1}}
\newcommand{\BIndex}[1]{#1\index{#1|textbf}}
\newcommand{\UIndex}[1]{#1\index{#1|underline}}
\newcommand{\bindex}[1]{\index{#1|textbf}}
\newcommand{\uindex}[1]{\index{#1|underline}}
%
% indicate where work needs to be done
\newenvironment{work}{\noindent\begin{boxedminipage}{\textwidth}}{\end{boxedminipage}}

\newenvironment{goingwhere}%
{\columnsep=7mm%
\vspace{-3mm}%
\begin{multicols}{2}%
\marginnote{\textbf{Going\\ where?}}%
\large\sf%
\noindent%
}%
{\end{multicols}
}%



\newenvironment{ind}[1]%
{\begin{list}{}%
{\setlength{\leftmargin}{#1}\setlength{\rightmargin}{#1}}%
\item[]%
}
{\end{list}}
\newcommand\none{${}^{}$}


\newcommand{\Ulix}{\textsc{Ulix}}
\newcommand{\UlixI}{\textsc{Ulix}}

\newcommand{\shellcmd}[1]{{\tt #1}}

\newcommand{\codesymbol}{*}
\newcommand{\codesection}[1]{\section{#1\codesymbol{}}}

% colors:
%\definecolor{black}{rgb}{0,0,0}
\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{green}{rgb}{0,0.5,0}
\definecolor{red}{rgb}{1.0,0,0}
\definecolor{orange}{rgb}{1,0.5,0}
\newcommand\blue{\color{darkblue}}
\newcommand\green{\color{green}}
\newcommand\Green[1]{\textcolor{green}{#1}}

%% mark Felix' code?
%\newcommand\felix{\color{blue}}
\newcommand\felix{}
%%
\newcommand\lblue{\color{blue}}
\newcommand\black{\color{black}}
\newcommand\red{\color{red}}
\newcommand\Red[1]{\textcolor{red}{#1}}
\newcommand\orange{\color{orange}}
\newcommand\Orange[1]{\textcolor{orange}{#1}}
\newcommand\lightblue{\color{blue}}
\newcommand\Lightblue[1]{\textcolor{blue}{#1}}

% Kommentar: Kasten, rot
\newcommand\comment[1]{
  \noindent
  \begin{boxedminipage}{\textwidth}
  \red{}#1\black{}
  \end{boxedminipage}
}

% proper footnotes:
\deffootnote[1.5em]{1.5em}{1em} {\textsuperscript{\thefootnotemark}\,\,\,}

% part numbering: A, B, ...
\renewcommand*{\thepart}{\Alph{part}}
\renewcommand*{\thepart}{}  % remove "A", "B" etc.
\renewcommand{\partname}{}  % remove "Part"

% hex addresses such as C000.0000: Courier font, small, 0x prefix
\newcommand\hexaddr[1]{{\tt 0x#1}}
\newcommand\hex[1]{{\tt 0x#1}}
\newcommand\hexrange[2]{{\tt 0x#1}\,--\,{\tt 0x#2}}
\newcommand\bin[1]{{\tt #1}${}_b$}
\newcommand\oct[1]{{\tt #1}${}_o$}

% hyphenations
\hyphenation{de-pen-ding}
\hyphenation{Spei-cher}
\hyphenation{Tech-ni-sche}
\hyphenation{hand-ler}
\hyphenation{hand-lers}
\hyphenation{inode}
\hyphenation{inodes}
\hyphenation{un-der-stan-ding}
\hyphenation{wai-ting}
\hyphenation{se-ma-phore}
\hyphenation{se-ma-phores}

% page layout
% DIV=13
%\setlength\paperwidth{597.50793pt}       % width: A4 paper -1cm
\setlength\paperwidth{18.5cm}             % width: 18.5 cm (US textbook)
%\setlength\paperheight{845.04694pt}  % height: A4 paper -3cm
\setlength\paperheight{23.1cm}            % height: 23.1 cm (US textbook)
%%\setlength\paperwidth{20.350cm}            % width: 18.5 cm x 1.1 (US textbook)
%%\setlength\paperheight{25.41cm}           % height: 23.1 cm x 1.1 (US textbook)

\setlength\textwidth{441.56494pt}
\setlength\evensidemargin{16.043pt}
%\setlength\oddsidemargin{-4.63998pt}
\setlength\oddsidemargin{-18pt}
\setlength\textheight{650.20029pt}
\setlength\topmargin{-44.6664pt}
\setlength\headheight{17.0pt}
\setlength\headsep{20.40001pt}
\setlength\topskip{11.0pt}
\setlength\footskip{25pt}
\setlength\baselineskip{13.6pt}


% mehr Rand
\addtolength{\marginparwidth}{40pt}
\addtolength{\marginparsep}{5pt}
\addtolength{\textwidth}{-45pt}
\addtolength{\evensidemargin}{45pt}
%\addtolength{\oddsidemargin}{0pt}

\usepackage[strict]{changepage}  % change page layout

%%% package needed for my diss.ist index style
\usepackage{needspace}
\def\lneed#1{\needspace{#1\baselineskip}}


\usepackage{blowup}
%\blowUp{paper={18.5cm,23.1cm}}
\blowUp{paper=x0.9}


%----------------------------------------------------------------------


\begin{document}

\setkomafont{pagehead}{\normalfont\sffamily}
\setkomafont{pagefoot}{\normalfont\sffamily}
\setkomafont{pagenumber}{\normalfont\sffamily}

% trim=left bottom right top,clip
% offset: right, up
\includepdf[width=22cm,offset=5mm -15mm]{pics/unix-plate/titlepage-book.pdf}
\cleardoublepage

%\changetext{⟨text height⟩}{⟨text width⟩}{⟨even-side margin⟩} {⟨odd-side margin⟩}{⟨column sep.⟩}
\changetext{-2cm}{}{}{}{}

\renewcommand{\partname}{}
%\part[The \Ulix{} Book]{%
\part*{%
\thispagestyle{empty}
The Design and \\
Implementation \\
of the \\[.5cm]
\includegraphics[width=6cm]{pics/ULIX-Logo3.png}\\
Operating System \\[1.5cm] 
 \quad \Large{Hans-Georg Eßer, {\felix Felix C.\ Freiling}%
}}
\label{part:ulixbook}

\setcounter{chapter}{0}
\ohead{\pagemark}

\renewcommand{\ptifont}{\huge\bfseries\sffamily}
\mtcsetdepth{parttoc}{4}   % for part II TOC
\mtcsetrules{parttoc}{off} % no rules before/after TOC
\mtcsetrules{partlof}{off} % no rules before/after TOC
\mtcsetrules{partlot}{off} % no rules before/after TOC

\pagenumbering{arabic}
\setcounter{page}{1}

\pagestyle{scrheadings}
\ihead{\headmark}
\ohead{\pagemark}
%\setheadwidth[0pt]{textwithmarginpar}
\setheadwidth[0pt]{480pt}
\setfootwidth[0pt]{480pt}
\ofoot{}
\setkomafont{pagenumber}{\normalfont\rmfamily\bf}
\setheadtopline{1pt}
\setheadsepline{.3pt}
\setfootsepline{.3pt}[\vspace{3mm}]% move bottom line 3mm down
\renewcommand*{\chapterpagestyle}{empty}



\pagestyle{scrheadings}
\chapter*{Foreword}
\addcontentsline{toc}{chapter}{Foreword}

Welcome to the \Ulix{} book. If you want to discover how precisely a modern operating system performs its multitasking magic, you've probably found the right textbook. On the next 600 pages you can read about the implementation of \Ulix{}\index{Ulix}, a Unix-like system, and while you read the chapters which are organized along similar topics as those of most operating system textbooks, you will see the \emph{full} implementation. We left out nothing, the whole code is there (actually: the book \emph{is} the code, but more about that later), and you can read it step by step with each implementation part shown where it makes sense---which is very different from just providing a collection of source code files.

If you're already familiar with other operating system texts, you will notice that this book tends to be more practical. We often discuss only one solution to a problem (where other books mention a variety and sometimes give a qualified comparison of several techniques). We do not completely ignore alternative approaches, but since we give helpful explanations of all the code parts, we tend to write more about our solutions than about the ones which we did not choose for the \Ulix{} kernel.

Writing this book was a fun experience, because for us, the authors, it meant learning a lot as we went along with the implementation and documentation task. While previous exposure to theoretical books on operating system principles was certainly helpful for deciding \emph{what} to implement, it did not help a lot with the question of \emph{how} to do it. Many technical references and some online tutorials for OS development beginners were useful (and much needed) in order to overcome the numerous challenges which the \Ulix{} development encompassed. We hope that you will find reading our book as pleasant and instructive as we found writing it, and we encourage you to try your own experiments with kernel development: The book provides several exercises in which you can modify or add to the \Ulix{} code.

Our overall hope is that you will find this book helpful and that it takes you on a journey that intensifies your knowledge of OS internals and the necessary hardware-related details. After reading, let us know if we've met your expectations ($\rightarrow$ {\tt feedback@ulixos.org}).

\begin{flushright}
Hans-Georg Eßer \\
Felix C.\ Freiling \\[2mm]
Erlangen, September 2015
\end{flushright}


\pagebreak

\thispagestyle{empty}

% font: http://www.dafont.com/afl-font-pespaye-no.font?l[]=10&l[]=1&text=This+page+intentionally+left+blank
\begin{figure}[h!]
\hspace{1cm}
\vspace{-1cm}
\includegraphics[width=.5\textwidth]{pics/intentionally-left-blank.png}
\end{figure}

\def\ptifont{\vspace{2.5cm}\hspace{3.2cm}\hfill\sffamily\fontsize{30pt}{36pt}\selectfont}
\def\mtcgapafterheads{-4.8cm}
\tightmtctrue
\cleardoublepage
\pagestyle{scrheadings}
{
\renewcommand{\MakeUppercase}[1]{#1}% write "Table of Contents", not "TABLE OF..."
\renewcommand{\afterpartlof}{}
\renewcommand{\beforepartlot}{\vspace{-1cm}}
\setlength{\cftchapnumwidth}{20pt}
\setlength{\cftsecindent}{20pt}
\setlength{\cftsecnumwidth}{30pt}
\setlength{\cftsubsecindent}{50pt}
\setlength{\cftsubsecnumwidth}{40pt}
\setlength{\cftsubsubsecindent}{90pt}
\setlength{\cftsubsubsecnumwidth}{45pt}

\lehead{\leftmark}  % Chapter auf geraden Seiten (links) in Kopfzeile
\rohead{\rightmark} % Section auf ungeraden Seiten (rechts) in Kopfzeile
\ofoot{}

\makeatletter
\renewcommand{\tableofcontents}[1][Table of Contents]{%
  \chapter*{#1}
  \pagestyle{scrheadings}
  \thispagestyle{empty}
  \lehead{\bfseries\pagemark}
  \rehead{Contents}
  \lohead{Contents}
  \rohead{\bfseries\pagemark}
%  \begin{multicols}{2}
    \@starttoc{toc}
%  \end{multicols}
}
\makeatother

\tableofcontents[Table of Contents]




\cleardoublepage
\pagestyle{scrheadings}

\addcontentsline{toc}{chapter}{List of Figures}
\setlength{\cftfignumwidth}{1.2cm}
\renewcommand\listfigurename{\protect\raggedleft\normalfont\sffamily\fontsize{30pt}{36pt}\selectfont List of Figures\\ }
\lehead{\bfseries\pagemark}
\rehead{Figures}
\lohead{Figures}
\rohead{\bfseries\pagemark}
\thispagestyle{empty}
\listoffigures

\mtcsetfeature{partlot}{pagestyle}% 

\pagebreak
\addcontentsline{toc}{chapter}{List of Tables}
\renewcommand\listtablename{\protect\raggedleft\normalfont\sffamily\fontsize{30pt}{36pt}\selectfont List of Tables \\}
\setlength{\cfttabnumwidth}{1.2cm}
\thispagestyle{scrheadings}
\listoftables
}



\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{17}
\pagestyle{scrheadings}
\ihead{\headmark}
\ohead{\pagemark}
\automark[section]{chapter}
\chapter{Introduction}

%+FELIX
\felix
Operating systems are an important part of computing. They mediate between the complex intricacies of modern hardware and the abstract needs of users and applications. Also, operating systems are one of the oldest research areas in computer science. Moreover, the topic is one of the core subjects in academic computer science curricula. So there are many books and other teaching resources available.

Because of the wealth of material and the practical appeal of the topic, operating systems are a fun subject to teach which can also make it an enjoyable course for students. As regular instructors of two of these courses we have learned that one of the key aspects of a good operating systems course is to discuss and analyze real operating systems, i.\,e., operating systems that work in practice and can actually be used by people. To this end, open source systems like FreeBSD\index{FreeBSD operating system}\marginnote{FreeBSD, Linux} and Linux\index{Linux} have established themselves as good objects of study because they have commercial value and their source code can be accessed and scrutinized by lecturers and students in course.

Unfortunately, it is hard to use the source code of such ``real'' systems directly and extensively in class. One main reason is the complexity of the code. Operating systems naturally have to deal with details of the underlying hardware. If a system is designed to be portable, the source code must cater for multiple computer architectures, which makes it even more complex. \black For example, at the time of writing this book, the current Linux\index{Linux} version 3.14.5\footnote{\url{https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.14.5.tar.gz}} had 29 subfolders in the \verb#linux-3.14.5/arch/# directory which contained the specific code files for those architectures.

\begin{verbatim}
$ cd ~/Downloads/linux-3.14.5/arch/
$ find . -type d -maxdepth 1 -mindepth 1 | sed -e 's/\.\///' | column -c160
alpha   blackfin   ia64        mips       s390      um
arc     c6x        m32r        mn10300    score     unicore32
arm     cris       m68k        openrisc   sh        x86
arm64   frv        metag       parisc     sparc     xtensa
avr32   hexagon    microblaze  powerpc    tile
\end{verbatim}

\noindent
While not all platforms are supported equally well, in same cases there is a tremendous amount of platform-specific code as the following examples demonstrate which show the lines of code of source files in the \verb#x86#, \verb#ia64#, \verb#alpha# and \verb#powerpc# subdirectories:

\begin{verbatim}
$ for arch in x86 ia64 alpha powerpc; do printf "%8s" $arch:; \
> find $arch/ -type f | xargs cat | wc -l; done
    x86:  318881
   ia64:  115179
  alpha:   62383
powerpc:  439961
\end{verbatim}

\felix
\noindent
Furthermore, modern operating systems usually offer an increasing number of features which must all be expressed by code. Another reason for the complexity of operating systems code is that practical operating systems must be extremely efficient. Every instruction cycle and memory cell used by the operating system cannot be used by the applications and their users. That is why operating systems code is often highly optimized. There are many other reasons that prevent instructors from showing real source code in class.

In our view the most important reason for not using real code directly in class is that operating systems have not been written with a human reader in mind, especially non-expert readers like students of operating systems classes who want to learn the basics of the area.
\black
Even when this is not the case and an operating system was developed 
for teaching purposes, such as the Minix\index{Minix!operating system}\marginnote{Minix} operating system, it is often a tough task to browse through the complete source code that is split into several separate files and is ordered according to constraints of the programming language. 

That is precisely where our approach differs: You can read this book from front to back and discover the theory and the implementation of the shown principles in the source code of the \Ulix{} operating system that serves as an example.
\felix


\section{Literate Programming}
\label{sec:exposition}

When we write software, do we really think about a human reader?  The
harder we try, the more we feel constrained by the programming tools
available. When writing a complex piece of code, wouldn't you
sometimes like to include a figure into the code to explain the
complex interactions of variables? Or when you implement an algorithm
from a textbook, wouldn't you like to give an automatic reference to
this book in the source code? Or when one part of the code is similar
to another part because you used the same idea, wouldn't you like to
use automatic cross-referencing between these two parts?  And aren't
you bored of writing all these comment signs (like \texttt{//} in C or
Java) all the time (or worse, aligning the stars when using
\texttt{/*} and \texttt{*/})? If you have ever felt such a desire, you
are ready for \vindex{literate programming}.

Literate programming\index{literate programming} is a programming technique originally developed
by Donald E.\ Knuth\pindex{Knuth, Donald E.} to write the
\TeX{}\pcindex{TeX}{\TeX{}}\marginhl{\TeX{}} typesetting system. The source code of
\TeX{} appeared 1986 as a book called ``\TeX\ -- The Program''
\cite{Knuth:1986:TTP}. Reading that book is an entirely different
experience from reading ``normal'' source code.  It contains the
\emph{entire} source code, not just important excerpts, and it is
\emph{real} code that was compiled into the original version of the
typesetting program.

\black
With literate programming there is a conceptual change in the programming approach: Here, documentation comes first. A literate program is basically a text describing the program, and the actual code is inserted in the documentation, thus reversing the normal ordering.
So instead of classically documenting code as in the following example:

{%\small
\begin{verbatim}
  // This function takes an argument, squares it, and adds the constant 42.
  int square_and_add (x) {
    const int add = 42;     // declare the constant
    x = x*x;                // square x
    return x + add;         // calculate sum, return result
  }
\end{verbatim}
}

\noindent
a literate programming\index{literate programming!example} version of the same code might look like this:

\begin{ind}{4mm}
%\small
\noindent
We will write a function \verb#square_and_add# which takes an argument \verb#x#, squares it and adds some constant. Squaring a variable is just a multiplication of the value with itself:

\noindent
$\langle$\emph{\normalfont\it square}  \verb#x#$\rangle \equiv$\\
\none\quad\verb#x = x*x;#

\noindent\index{$\langle$ (begin chunk name; output version)}\index{$\rangle$ (end chunk name; output version)}%
With this knowledge we can implement the function:

\noindent
$\langle$\emph{\normalfont\it function implementation}$\rangle \equiv$\\
\none\quad\verb#int square_and_add (x) {#\\
\none\quad\quad$\langle$\emph{\normalfont\it declare constant} \verb#add#$\rangle$\\
\none\quad\quad$\langle$\emph{\normalfont\it square} \verb#x#$\rangle$\\
\none\quad\quad\verb#return x + add;#\\
\none\quad\verb#}#

\noindent
Now, what's left is to decide on the constant \verb#add#---we pick 42:

\noindent
$\langle$\emph{\normalfont\it declare constant}  \verb#add#$\rangle \equiv$\\
\none\quad\verb#const int add = 42;#

This is an implementation of the function $f: x \mapsto x^2 + 42$.
\end{ind}

\noindent
Note how the function definition uses two code chunks\index{code chunk}: one that was presented \emph{before} the function and another one which came \emph{after} the function. Literate programming makes the developer independent of any specific ordering of code fragments which the language may demand, e.\,g. the declaration of variables before their first use. Also, both top-down and bottom-up styles of programming are possible and can be combined.

\felix

Following the idea of literate programming, this book is a
book for students. Its source code can be used to generate
executable code (for the \Ulix{}\marginhl{\Ulix{}} operating system)  
\emph{and} a \LaTeX{} file that can be typeset to an
introductory text on operating systems (this book). 

\black
When you look at the source file [[ulix-book.nw]] from which this book was created, you will see how code chunks are declared: The chunk name is always put between {\tt @<<}\index{\textless\textless\ (begin chunk name; input version)} and {\tt @>>{}=}\index{\textgreater\textgreater\ (end chunk name; input version)}, then follows the code which is terminated with a \verb#@#\index{"@ (end of code chunk)} character on a single line. When referencing a code chunk the same syntax (without the equals sign) is used. So for example, in order to declare the $\langle$\emph{\normalfont\it function implementation}$\rangle$ chunk from above, the following lines are needed:\\[-3mm]
\vspace{3mm}%

\noindent
{\tt
@<<function implementation@>>{}= \\
int square\_and\_add (x) \verb#{# \\
\none\quad  @<<declare constant add@>> \\
\none\quad  @<<square x@>> \\
\none\quad  return x + add; \\
\verb#}# \\
@@
}
\vspace{3mm}%

\noindent
Chunks may also be continued, i.\,e., some pages (or even chapters) after
the initial definition of a code chunk it is ``defined again.'' That does
not replace the original definition, but add to it. In the source file this
is done by simply writing
\vspace{3mm}%

\noindent
{\tt
@<<function implementation@>>{}= \\
... \\
@@
}
\vspace{3mm}%

\noindent
again (with additional code lines inside), but in the PDF version the
representation of a continued code chunk looks slightly different: Instead
of \\[-2mm]

\noindent
$\langle$\emph{\normalfont\it function implementation}$\rangle \equiv$\\[-2mm]

\noindent
it will look like this:\\[-2mm]

\noindent\index{$+\equiv$ (continuation of chunk)}%
$\langle$\emph{\normalfont\it function implementation}$\rangle +\!\equiv$\\[-2mm]

\noindent
with a $+\!\equiv$ sign that indicates the \emph{continuation}\index{code chunk!continuation}\index{continuation (of a code chunk)}---similarly to C's
[[+=]] operator that also has an ``add to'' meaning (e.\,g.\ [[x+=5;]]
means: add 5 to the value of \verb#x#).


\section{The \Ulix{} Operating System}

Throughout this book we present the whole source code of the \Ulix{}
operating system. That encompasses the kernel but also the user mode
library which application developers must use in order to interface
with kernel functions. The book does not show source code for (all) the
applications.


\felix
\subsection{The Name of the Game}

The name \Ulix{}\index{Ulix} is intentionally similar to the name Unix\index{Unix}. This is meant
to imply that the code is influenced a lot by things we have seen in
Unix/Linux style operating systems. The focus on Unix is solely based
in the past experiences of the authors, it is in no way intended to
imply that Unix is better or worse than other operating systems.

The choice of the letter ``\textsc{l}'' in \Ulix{} is supposed to concisely
express that the system is meant for \emph{learning} and teaching
operating systems. Besides, the name \Ulix{} is one of the few
four-letter abbreviations that do not seem to have been chosen for
other software systems yet. Furthermore, \Ulix{} is probably the first
operating system that is written as a literate program, and so
\Ulix{} can also stand for ``literate Unix''.




\subsection{Design Principles of \Ulix{}}
\label{sec:design:principles}

The following principles have determined the design of \Ulix{}\index{Ulix!design principles}:
%
\begin{itemize}

\item \Ulix{} is for \emph{learning and teaching} principles of
  operating systems in a course. \Ulix{} should never be a practical
  system in the sense that it can be used to run real applications.

\item Nevertheless, \Ulix{} should be a \emph{real} operating system,
  i.\,e., the code should be executable on some well-defined computer
  architecture. If necessary, it should be possible to port \Ulix{} to
  other platforms, but portability is not a core requirement of
  \Ulix{}.

\item The design and implementation of \Ulix{} should be governed by the
  principle of \emph{simplicity}, avoiding optimizations, focusing on
  understandable and correct code.

\item It should be possible to use the source code \emph{directly} in
  class. The source code should be written with the human reader in
  mind.

\end{itemize}

\noindent
Given the above design principles, one point should be clear---but is
important enough to mention it anyway: While trying to be \emph{real},
\Ulix{} is not \emph{practical}, i.\,e., we disclaim any fitness for
practical use. On the one hand, the code is not guaranteed to be free
of programming errors. On the other hand, the performance of \Ulix{}
is such that it will not achieve any required quality of service in
practice. \Ulix{} is \emph{purely} for learning. The path chosen is
the one of simplicity. So when you have read this book, you will have
a fairly good idea of how \Ulix{} works, but only a
faint idea of how operating systems work in general. Therefore, this
book is not (and never will be) a replacement for the available excellent general
textbooks on operating systems.

\black
\subsection{\Ulix{} Features}

\index{Ulix!features}Some of the words in the following feature list may not make sense to you right now, but if you already have some knowledge of operating system principles, this gives you an idea of what kind of content to expect in the book. If you are familiar with some Unix system as a user or administrator, at least most of the application programs mentioned in the following paragraph should be well-known.

\Ulix{} is a classical Unix-like operating system which features processes with separate address spaces, threads, paging, a virtual filesystem (currently supporting floppies and hard disks, with Minix as the primary filesystem) and synchronization via kernel mutexes and semaphores. It has a preemptive scheduler (implementing a simple Round Robin strategy) and allows for the integration of new interrupt and system call handlers at runtime. \Ulix{} supports up to ten text mode terminals. It works on 32-bit Intel-compatible CPUs and provides system calls (via the classical \verb#int 0x80#) and corresponding user mode library functions which are compatible to other Unix systems, e.\,g.\ \verb!fork!, \verb!execv!, \verb!exit!, \verb!waitpid!, \verb#signal#, and \verb#kill# for process control, some of the \verb!pthread_*! and \verb!pthread_mutex_*! functions for thread control \cite{IEEE:1995:IITa}, \verb!open!, \verb!read!, \verb!write!, \verb#lseek# and \verb#close# for file access, \verb#brk# for dynamic memory (heap) management etc. There are also a few user mode programs (\verb#cat#, \verb#chgrp#, \verb#chown#, \verb#chmod#, \verb#clear#, \verb#cp#, \verb#df#, \verb#diff#, \verb#free#, \verb#grep#, \verb#hexdump#, \verb#kill#, \verb#ls#, \verb#man#, \verb#mkdir#, \verb#ps#, \verb#readelf#, \verb#rm#, \verb#rmdir#, \verb#stat#, \verb#sync#, \verb#touch#, \verb#vi# and \verb#wc#), and some more commands are implemented as shell built-ins of the \Ulix{} shell \verb#sh#, e.\,g.\ \verb#cd# and \verb#pwd#.

A login mechanism asks for user name and password and checks these against entries in \path!/etc/passwd! (where the passwords are stored in plaintext and world-readable since hashing and encryption are not available in \Ulix{}), and authenticated users can only access files for which they have the required access permissions. Also, signaling other processes via the \verb#kill# function or program requires the user to own the targeted process (or have administrator privileges).

Redirection of standard input, standard output and standard error are supported via closing one of the file descriptors 0, 1 or 2 and opening a new file (which will reuse that descriptor). The shell understands the [[<]], [[>]] and [[2>]] syntax for starting programs with redirections, and it can also use the feature to execute shell script files (via [[sh <script.sh]]).

\Ulix{} uses a buffer cache for disk read and write operations so that repeated access to the same data on disk is faster than first access. A [[swapper]] process runs in the background and checks whether physical memory fills up too much: if so, it will pick parts of memory and write them to disk in order to increase the available memory. If such a ``paged-out'' memory area is accessed later, it will be ``paged in'' again before the program that wants to use it can continue.

The system can be run inside a virtual machine using \verb#qemu# and it writes a kernel log to a (virtual) serial port; you can save this output in a file for later analysis. The simple shell can launch user mode programs (which need to be compiled outside \Ulix{}). Such programs are stored using the ELF executable format \cite{ELF-Spec:1995}. \Ulix{} expects to have 64 MByte of RAM and maps that physical RAM to a fixed address space region for easy access to the physical memory. POSIX threads are somewhat limited in that each thread has a fixed-size stack (whereas the primary or only thread has a stack which automatically increases its size as needed).


\felix
\section{Tools}
\label{sec:tools}

The original goal was to write a book like ``\TeX{} -- The Program''
\cite{Knuth:1986:TTP} with pretty-printed sourcecode and extensive
automatic cross-references and indexes (especially the famous
\vindex{mini indexes} on right-hand pages).  This can be achieved
using the Knuth/Levy
\pindex{Knuth, Donald E.}%
\vindex{CWEB} documentation tool
\cite{cweb:homepage,cweb:2001} that also has hypertext extensions.
Mini indexes can be generated by an extension called \vindex{CTWILL}
\cite{Knuth:1993:MIF} that is the program used to generate the source
of ``\TeX{} -- The Program''. However, the CWEB
family of tools is restricted to \TeX{} as typesetting language which
we wanted to avoid in favour of \LaTeX{}.  While there exists an
experimental adaption of CWEB for \LaTeX{} by Joachim
Schrod\pindex{Schrod, Joachim} \cite{cweb-latex}, CWEB is also
restricted to the \vindex{C programming language}, so more than one
language (e.\,g.\ C code, assembler code and configuration
files) cannot be handled.

\black
For this book we decided to use Norman Ramsey's\index{Ramsey, Norman} \verb#noweb# 
\marginnote{\tt noweb}\index{noweb} tool \cite{Ramsey:1994:noweb} which combines 
a simple syntax with language independency: it uses 
\LaTeX{}\marginhl{\LaTeX\ } (or alternatively HTML)
as input and output format for the documentation. There are also
several extensions which add pretty-printing and indexing.

The main source for the book is one huge \LaTeX{}\pcindex{LaTeX}{\LaTeX{}} file that serves
as input to the \verb#noweb# tool chain. The program \verb#noweave#
\marginhl{\tt noweave}\tindex{noweave}
converts it into a classical \LaTeX{} file that can then be
processed as usual; for this book we chose the \XeLaTeX{} 
\marginhl{\XeLaTeX\ } variant
\cite{XeLaTeX:web}\pcindex{XeLaTeX}{\XeLaTeX{}}
of \LaTeX{} because it handles UTF-8-encoded input files and 
provides better options for font selection. Together with standard
\LaTeX{} tools (\verb#bibtex# and \verb#makeindex#) it produces the
PDF file that you're currently reading in the PDF viewer or as
a printed copy.

The other part of the \verb#noweb# tool chain generates the \UlixI{} 
source code files: \verb#notangle# \marginnote{\tt notangle}\tindex{notangle}
extracts code chunks and saves them in source files which will
then be compiled or assembled with the GNU C compiler \verb#gcc# and the
\verb#nasm# \marginhl{{\tt gcc}, {\tt nasm}} assembler.

Figure \ref{img:noweb-tool-chain} shows a simplified view of the
build process for both the book as well as the kernel, the user mode
library and a sample application. We will give a detailed description
in Chapter~\ref{chap:ulix:build-process}.

\begin{figure}[b!]
\centering
\includegraphics[width=14.1cm]{pics/noweb.pdf}
\caption[Noweb tools extract source code and documentation.]{Using the Noweb tool chain it is possible to generate this book and also the \UlixI{} kernel binary and other system files.}
\label{img:noweb-tool-chain}
\end{figure}


\felix




\section{Copying}
\label{sec:copying}

\black
\Ulix{} is Free Software\marginhl{Free Software}, following the definition 
of this term that was coined by the Free Software Foundation\index{Free Software Foundation} (FSF). 
\index{Ulix!copyright}
\felix You can copy and browse the
code and compile it into any form you like. If you find bugs in the
source code, please drop us a message so that we can fix the bug in the
next iteration of the software.
Similar to \TeX{}, \Ulix{} is meant to
eventually become a stable platform that does not evolve anymore,
i.\,e., we will eventually stop issuing new releases. 
That's why we retain
the entire copyright that must be mentioned in all files associated
with the system. If you think that \Ulix{} should be fundamentally
changed, become more efficient etc., you can take the code but should
call the resulting system something other than ``\Ulix{}''.
\black

%nouse
<<copyright notice>>=
/*
Copyright (c) 2008-2015 Felix Freiling, University of Erlangen-Nürnberg, Germany
Copyright (c) 2011-2015 Hans-Georg Eßer, University of Erlangen-Nürnberg, Germany

This program is free software: you can redistribute it and/or modify it under 
the terms of the GNU General Public License as published by the Free Software 
Foundation, either version 3 of the License, or (at your option) any later version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY 
WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A 
PARTICULAR PURPOSE.  See the GNU General Public License for more details.

You should have received a copy of the GNU General Public License along with this 
program.  If not, see <http://www.gnu.org/licenses/>.                            */
@

\noindent
You can find version 3 of the GPL\index{GPL (GNU General Public License)} at the end of the book.


\section{Notation}

In this section we describe the various conventions used throughout the book.

\subsection{Numbers and Units}

This book makes heavy use of hexadecimal numbers and (less often)
octal and binary numbers. We expect readers to be familiar with
these positional numeral systems with bases 16, 8 and 2.

\begin{itemize}
\item Hexadecimal\index{hexadecimal numbers}\index{numbers!hexadecimal}\marginhl{hexadecimal} numbers such as \hex{AB12CD34} will appear with a
monospaced font and a \verb#0x# prefix\index{0x prefix@\texttt{0x} prefix} (since that is the notation
also used in C). Sometimes we will insert a dot in the middle
(\hex{AB12.CD34}) to improve readability.

\item Octal\index{octal numbers}\index{numbers!octal}\marginhl{octal} numbers such as \oct{56701} also use the monospaced
font but have a small ${}_o$ index at the end to indicate that the
octal system is used. C uses a different notation: every number
which starts with a zero is considered to be an octal number which
sometimes causes problems for readers who are not familiar with
this convention.

\item We write binary\index{binary numbers}\index{numbers!binary}\marginhl{binary} numbers like \bin{100101} in a similar
fashion, but with a ${}_b$ index at the end. Standard C has no way
to express binary numbers, but the GNU C compiler allows the
non-standard syntax \verb#0b100101# (with a \verb#0b# prefix\index{0b prefix@\texttt{0b} prefix},
similar to the \verb#0x# prefix for hexadecimal numbers).
\end{itemize}

We often discuss kilobytes\index{kilobyte}\index{KByte}\marginnote{kilobyte\\ megabyte}, megabytes\index{megabyte}\index{MByte} (or rarely gigabytes\index{gigabyte}\index{GByte}) when talking about memory or disk areas and filesizes. When we do so, we use the historical meanings as displayed in Table \ref{table:units-kilo-mega}. Note that most newer books use the reformed interpretation according to which kilo-, mega- and gigabytes refer to powers of 1000 of bytes, which is more consistent with other uses of ``kilo'' and ``mega'' like, for example, kilometers and megatonnes. The new terms for the old units are ``kibibyte\index{kibibyte}'', ``mebibyte\index{mebibyte}'', ``gibibyte\index{gibibyte}'' etc. \cite{iec-2000-si}.

However, having a special unit name for 1000 bytes or a million bytes is quite useless since these sizes have no meaning: 1000 is not a power of 2 (but $1000 = 2^3 \times 5^3$), and everything in the hardware is organized by powers of 2. That is why we have decided to stick with the classical meanings even though they are considered wrong by today's standards. If you're already used to the new notation, please replace any occurrence of ``kilobyte'' with ``kibibyte'', ``megabyte'' with ``mebibyte'' etc.

Note also that the often-used term ``1.44 megabyte floppy disk'' makes no sense at all, because such a floppy stores 2880 sectors each of which is 512 bytes large. Thus, the disk size is 1440 KByte which are 1.40625 MByte. When using the new terms the size could be expressed as 1474.56 kB or 1.47456 MB, and none of those numbers should lead to ``1.44''---you can only arrive there by mixing the old and the new terminology and claiming that a megabyte was $1000 \times 1024$ bytes.


\begin{table}[h!]
\renewcommand{\arraystretch}{1.3}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Unit} & \textbf{Abbreviation} & \textbf{Size in bytes} & \textbf{hexadecimal}\\
\hline
Kilobyte (``Kibibyte'') & KByte & $2^{10} = 1\,024^1 = 1\,024$        & \hex{00000400} \\
Megabyte (``Mebibyte'') & MByte & $2^{20} = 1\,024^2 = 1\,048\,576$     & \hex{00100000} \\
Gigabyte (``Gibibyte'') & GByte & $2^{30} = 1\,024^3 = 1\,073\,741\,824$  & \hex{40000000} \\
\hline
``New Kilobyte''        & kB    & $1\,000^1 = 1\,000$                 & \hex{000003E8} \\
``New Megabyte''        & MB    & $1\,000^2 = 1\,000\,000$              & \hex{000F4240} \\
``New Gigabyte''        & GB    & $1\,000^3 = 1\,000\,000\,000$           & \hex{3B9ACA00} \\
\hline
\end{tabular}
\caption[\hgepolylot{Definition of ``kilobyte'', ``megabyte'' and ``gigabyte''.}]{In this book we use the classical meanings of ``kilobyte'', ``megabyte'' and ``gigabyte''.}
\label{table:units-kilo-mega}
\end{table}

For comparison, we have added the new interpretations to the table; especially when looking at the hexadecimal representations you can see that these units do not occur in practical settings.


\subsection{Identifiers}

Names of variables, functions, constants and other code elements that appear in a regular paragraph also use the monospaced font, and we sometimes add round brackets to a function name when we want to emphasize that it is the name of a function. So you may find references to ``the [[read_file]] function'' or simply to ``[[read_file()]]''. When a variable or function is declared or defined in a code chunk, there will often be a suffix which indicates the page number where the definition can be found, e.\,g. for the [[readblock_hd]] function.

Some functions appear to exist twice: once inside the kernel, and once in the user mode library which applications must link to access those kernel functions. An example is the \verb#open# function which opens a file. Surely, the kernel needs a way to open files, and applications also have that need. While both functions will never appear in the same context, they do appear in this same book which contains cross references to the place where a function was defined. Thus, using the same name would cause some confusion, so we use slightly different names in the kernel by adding a [[u_]] prefix\marginhl{[[u_]] prefix} to the name. The kernel uses the [[u_open]] function, and the user mode library provides an [[open]] function.

Constants (defined via the pre-processor's \verb!#define! macro) use all-upper-case names and underscores as word separators, for example [[MEM_SIZE]].

\subsection{Margin Notes}

You will have noticed already that the page margin sometimes contains a few words, for example, in the above paragraphs, there's a ``[[u_]] prefix'' margin note\index{margin note}. These notes are helpful in two ways: when you thumb through the pages of the book, you can quickly identify key words, and when you have looked up a word in the index and gone to the right page, a margin note leads you to the right line.

The margin also contains code chunk numbers in [[[]]] brackets (see the following section).


\subsection{Code Chunks}

The most important bits of information within each code chunk\index{code chunk} are the chunk name and the actual code, but there is more, and knowing what the additional elements of a code chunk mean will help you navigate the code more easily, for example when you find a function call to a function that you have forgotten (or that may be defined only later in the text). 

Figure~\ref{fig:code chunks} shows two example code chunks that demonstrate all the elements you will find in the chunks.

\begin{figure}[bh!]
  \centering
  % trim: left bottom right top
  \includegraphics[trim=3mm 0mm 2mm 0mm, width=17cm]{pics/code-chunks.pdf}
  \caption[Code chunks contain pointers that allow quick navigation to other chunks.]{Code chunks come with links to other parts of the source code and let you navigate through the sources: you can quickly find out where a function or variable was defined, and below the defining chunk you see all the places where it is used.}
  \label{fig:code chunks}
\end{figure}

\begin{itemize}

\item First of all, each code chunk\index{code chunk!chunk name} has a name. When a chunk is defined for the first time and you're on page 123 of the book, the chunk will begin with a line like 

$\langle$\emph{\normalfont\it chunk name} {\scriptsize 123}$\rangle \equiv$

which confirms that this chunk indeed starts on page 123. If more than one chunk starts on this page, a lower case letter is appended to the page number so that you can distinguish between them, e.\,g.\ 123a, 123b and 123c for three code chunks on page 123. If the chunk definition started earlier (and this is a continuation) then the original chunk number will appear next to the chunk name.

\item Regardless of whether the current chunk is an initial definition or a continuation, it always has an individual chunk number\index{code chunk!chunk number}. This number is displayed in the margin inside [[[]]] brackets, e.\,g. [122c] in the figure.

\item The top line of the chunk contains up to three further chunk numbers on the right-hand side. If you find a chunk number in round brackets (such as (62a) in the figure), then it is a reference to the first place where this chunk is used. The next two chunk numbers are prefixed or suffixed with a left or right facing triangle. If a number with a left triangle exists (in the example: $ \triangleleft$\,122b), this points to the previous continuation\index{code chunk!next/previous continuation}, and a number with a right triangle (in the figure: 124c\,$\triangleright$) leads you to the next continuation. Using these forward and backward pointers you can find all locations where this chunk is defined (and thus read the whole source code that the chunk is made of).

When one or more of these three numbers do not exist, that has the obvious meaning: A missing (\dots) reference means that the chunk is used nowhere. That should only happen for ``root chunks''\index{code chunk!root chunk}\index{root chunk}: those are the chunks which [[notangle]] \tindex{notangle} extracts to create the compiler/assembler source files. A missing forward or backward pointer simply indicates that you have reached the last or first part of the chunk definition, respectively.

\item \index{code chunk!used by}Under some chunks you find a line that starts with ``Used:'' and lists all (known) identifiers and the chunk numbers where they were defined. Both examples in Figure~\ref{fig:code chunks} contain such a line.

\item \index{code chunk!defined identifiers}Finally, a code chunk may define one or more identifiers. In that case, you will see a block starting with ``Defines:'' and a separate line for each defined identifier, giving its name and all the locations in the book where it is used. In the example figure only the second code chunk has such a block. The ``Used:'' and ``Defines:'' blocks let you track the usage of functions, variables and constants throughout the whole code which is often more helpful than searching for an identifier in the code files.

\item There is one case that we treat in a special way: The C language demands that functions are declared before their first use. Since we do not want to consider the ordering of function implementations it is often necessary to insert a function prototype\index{prototype (C function)}\index{C programming language!prototype}\index{C function: prototype vs. implementation}\marginnote{prototype vs.\\ implementation} which will appear early in the C file, whereas the implementation\index{implementation (C function)}\index{C programming language!implementation} occurs at a later position. So there will be prototype code of the form

\begin{Verbatim}
int function_name (arguments);     // prototype
\end{Verbatim}

and implementation code that looks like this:

\begin{Verbatim}
int function_name (arguments) {    // implementation
  ...
  return ret_val;
}
\end{Verbatim}

Technically (from a literate programming\index{literate programming!prototype vs. implementation} point of view), only one of those code blocks \emph{defines} the function, and the other one \emph{uses} it. In the book we will often, but not always, present both parts on the same page though they will appear in different places in the generated C file. We have decided to make the implementation chunk the \emph{defining} chunk (since that is what you will want to look up when you see usage of a function). We have also removed the ``Used:'' line for the prototype chunk since it will refer to the chunk which immediately follows.

\end{itemize}

Even if you have a printed copy of this book, it is helpful to use the PDF version as well, since all chunk numbers are links to those chunks, and most identifier names are clickable, too, leading to the place where a variable, constant or function is defined.


\subsection{Coding Standard}

\index{coding standard}%
The code uses two spaces for indentation, and the curly brackets [[{]] and [[}]] which declare the beginning and the end of a block are always written in this form:

\begin{Verbatim}
int sum_of_first_ten () {
  int j, sum;
  for (j = 1;  j < 11;  j++) {
    sum += j;
  }
  return sum;
}
\end{Verbatim}

We often use the [[//]]\marginhl{\texttt{//} vs.{} \texttt{/*\,\,*/}} one-line comments which originally were not part of the C standard, but are supported by modern C compilers. So instead of classical C comments\index{C programming language!comments} such as

\begin{Verbatim}
int tmp = array[i].mem;   /* the memory address */
\end{Verbatim}

\noindent
you will more often see this form:

\begin{Verbatim}
int tmp = array[i].mem;   // the memory address
\end{Verbatim}

In the book, the comparison operators\index{comparison operators} \verb#<#\verb#=# and \verb#>#\verb#=# are
displayed as [[<=]] and [[>=]]\marginhl{[[<=]], [[>=]]}, but this is the only 
kind of pretty-printing that we have applied to the source code chunks, except
for a little color highlighting of comments, brackets and the exclamation mark and slanted
printing of the [[#define]] and [[#include]] pre-processor commands:

%nouse
<<example for syntax highlighting>>=
#include "ulixlib.h"           // use the library
#define TRUE 1                 // define a symbolic constant
void example_function (int param) {
  int vector[10];
  for (i = 0;  i <= 10; /* inline comment */  i++) {
    if ( !param ) { vector[i] = vector[i] * 2; }
  }
}
@

In functions which have no return value (typed as [[void]]) we omit the [[return]] statement because the function automatically returns when it reaches the end of the function's body; the C standard allows this practice, and it saves a line in each such function.


\subsection{``Going where?''}

At the beginning of some sections you will find a short text in two-column layout using a different font, such as the following:

\vspace{5mm}\hrule\vspace{2mm}%
\begin{goingwhere}%
This is an example for a ``Going where?'' paragraph. Right now it has no useful contents, so let's just note that you will soon see the first lines of real code.
\end{goingwhere}
\hrule
\vspace{5mm}

Sometimes it is easy to get lost and wonder: why have we been dealing with this or that function? In such cases, the ``Going where'' paragraph gives you some orientation. How do things fit together? Where are we in the larger picture?



\section{Creating an Operating System From Scratch}

Writing an operating system is very different from developing an application. That is because, when you start out, there is literally nothing. For example, there are no libraries that would provide standard functions such as \verb#printf#. Also there are no rules dictating how the operating system is going to handle things---it is up to the developers to decide what those rules should be.

First of all, some elementary questions need to be answered: 

\begin{itemize}
\item What kind of hardware will the OS work on?

\item What programming language(s) should be used for development?

\item What kind of applications will the OS be able to host?
\end{itemize}

If you expect to create an OS using Java that will be compatible
with Windows\index{Windows operating system}, Linux and OS X and will also sport a high
performance 3D engine so that the latest console games run on
it, then this textbook will be pretty disappointing.


\subsection{Selection of Target Hardware}

The computing world is diverse, allowing for all sorts of
hardware architectures. CPUs can have very different
features---if you have attended a course on computer
architectures, you will have noted things like RISC and CISC
CPUs with very small and simple or huge and complicated
instruction sets. In this book we will focus on the 32-bit Intel
\index{Intel x86 architecture}architecture, for the simple reason that most people have
quick access to an Intel-compatible machine or can at least
run an Intel-based operating system in an emulator. With their
32-bit architecture, the CPUs can access 4~GByte of physical
memory which is enough for most purposes. During the last years
32-bit CPUs have become a bit outdated, as the latest processors
have a 64 bit wide address bus and provide internal registers
with the same size. \looseness=-1

Intel hardware has some legacy problems because even
the latest (64-bit) Intel chips are compatible with old systems from
last century's 80s. We will see this when we discuss the
management of memory.


\subsection{Language of Choice}

\enlargethispage{2mm}
Operating systems are very close to the actual hardware.
In fact you won't see any other class of ``programs'' which
get any closer to the hardware (except for a computer's firmware), 
because there's always the
OS as a natural barrier between hard- and software. We're
in the area of systems programming, and this is where
``old school'' languages still dominate. So with most
operating systems you'll see lots of C\index{C programming language}\marginnote{C language} code. For those who
have never heard of C (without a $++$ or \# postfix): C is a
procedural language that was created in 1969--1973 by
Dennis Ritchie\index{Ritchie, Dennis}\footnote{%
  Ritchie reviewed the early history of C in an
  article \cite{Ritchie:1993:DCL:154766.155580}.
}
and it's a predecessor to C$++$, Java and C\#. It does not
know objects.\footnote{%
  For those readers who are unfamiliar with C, we have included a
  short introduction to C which requires C++ or Java knowledge,
  see appendix \ref{chap:intro-to-c} on page \pageref{chap:intro-to-c}.
}
\Ulix{} was (mostly) written in C. 

\felix
The principle of simplicity demands that we use \index{C programming language!clear C}``clear C'', i.\,e., we
discipline ourselves to non-optimized and clear code that can also be
understood by people familiar with Java. We also restrict inclusion of
library header files\index{C programming language!header files} (we want to be self contained).  

\black
Even closer to the hardware is assembler\index{Assembler language}\marginnote{Assembly\\ language} code, and for that
reason all the early operating systems were programmed in
assembler. Assembler code is what a C compiler will generate
when you provide it with some C source code. Today it is no longer
necessary to write complete operating systems in 
assembler (some people still do this, e.\,g.\ the BareMetal\index{Assembler language!BareMetal operating system}\index{BareMetal operating system}
\cite{BareMetal:web} developers), 
but you'll still need some assembler code from time to time,
because some parts of the OS need to access CPU registers\index{register} or
execute special machine instructions which are not available
in the C language.\footnote{%
  Appendix \ref{chap:intro-to-asm} on page \pageref{chap:intro-to-asm}
  provides an introduction to the x86 Assembly language.
}

For the Intel processor platform, two ``dialects'' exist, the
Intel and the AT\&T one.\index{Assembler language!AT\&T syntax}\index{Assembler language!Intel syntax}\index{AT\&T syntax (Assembler)}\index{Intel syntax (Assembler)} The GNU C compiler supports both but
defaults to the AT\&T variant. We have decided to use the
Intel syntax, because it is closer to C's syntax: For example,
you can load the \register{EAX} register with the value 0 via the
command [[mov eax, 0]] (in Intel syntax). So the target of
the [[mov]] command comes first which resembles the C command
[[eax = 0]]. In AT\&T syntax, the operands
are reversed, with the target coming last and extra
syntactical elements being needed ([[mov $0, %eax]]).


\subsection{Applications}

An operating system X
will run applications\index{application} which have been developed for X (let's
call them ``X applications''), and it will be either impossible or
very hard to run Y applications for any Y which is not X.
Every OS creates its own software universe, and if you want to
run a program from a parallel universe, you'll need some sort
of emulation---which is not a topic of this book.

Most applications require libraries which are typically considered
part of the operating system. Even for something as simple as 
printing ``Hello world'', you need a library that contains the
code which is necessary to make the OS print something (in a
text console, a window or perhaps on a printer).

In principle it would be possible to port many of the existing
Unix\index{Unix!porting to Ulix} (text-mode) applications to \UlixI{}, however most
programs make excessive use of the available libraries, so those
would have to be ported first. This version of \UlixI{} comes
with a limited set of tools, including a very limited version
of the [[vi]] editor. So do not expect to replace your current
Linux installation with a \UlixI{} system.



\section{What's in the Book?}

Reading this book, you will see introductory descriptions of
several theoretical concepts, and at the same time you'll see
the complete source code necessary to implement these concepts.

What's in the book is in principle what's required for a typical
operating system---but note that for all theoretical problems
there are lots of possible solutions, and \UlixI{} provides
\emph{one} solution to most problems. In many chapters we will 
begin with a theory section which gives broader information about
the topic. We might present several different approaches but show
only the implementation of one of them: the one we picked for
\UlixI{}. This will typically be the most simple solution,
because we did not want to make the code too bloated.

Let us first look at some of the tasks an operating system needs
to perform. For every modern system, the process (or more precisely:
several processes) is a central idea. Many processes may coexist
on a machine, and the CPU shall execute them in parallel. We need
ways to spawn new processes and terminate processes which have
completed their tasks.

\looseness=-1
The OS kernel will need internal \verb#fork#, \verb#exec# and \verb#exit#
functions for process creation
and termination, but those will not be available to running programs
(which are not running inside the kernel)---this problem is typically
solved via system calls. So we need a system call interface and
system calls \verb#fork#, \verb#exec# and \verb#exit# which allow access to
the kernel functions.

Starting a new process often requires loading the program code from
a disk, and once the program is running, it will perform I/O operations:
typically with the disk, the keyboard and the video display. Keyboard
input arrives via keyboard interrupts, so our operating system must
deal with interrupts. These are also needed for talking to the disk,
and since we do not want to perform raw sector read/write operations
to access data, we need a logical filesystem (which will be the
Minix filesystem, version 2). Both the OS itself and processes will \verb#open#,
\verb#read# and \verb#write# files, and in order to let processes 
perform these actions, we need more system calls that---again---allow 
access to these functions.

Since each process has its separate memory, we need kernel routines
for memory management. \UlixI{} uses paging and creates address
spaces for all processes (which are basically page tables with some
additional administrative data). For each newly created process the
system must reserve some memory; at least it will have to create a
new address space. Later (at process termination) this memory must
be set free. We must define a memory layout that describes
what parts of (virtual) memory belong to the kernel and what parts
belong to processes.
A process may also ask for more memory while it is 
running, this requires another system call ([[brk]]) which can
be implemented by allocating a new page for the process.

Unix systems use a signaling system that allows both processes to
send signals to other processes as well as the kernel itself to
signal a process. Processes may register signal handlers in order 
to avoid the default actions for receiving a signal (typically:
ignore or abort). Again we need more system calls for registering
handlers (\verb#signal#) and sending signals (\verb#kill#). The scheduler
must check whether a process has pending signals when it activates
it; in that case it must call the signal handlers (or perform the
default action).

If we combine the ideas about processes which we have presented
so far and add some further process properties, we arrive at the 
mind map shown in Figure \ref{fig:mindmap:process}: it is rather
complex, and we have only looked at the system from the process
perspective.

\begin{figure}
\centering
\includegraphics[width=14.5cm]{pics/Process.pdf}
\caption{Mind map for process functionality.}
\label{fig:mindmap:process}
\end{figure}


Thus, we will cover the following topics:

\begin{itemize}
\item \textbf{Memory Management Theory} (Chapter \ref{chap:memory:theory}) gives an introduction to the possible ways in which the system's main memory can be shared between several processes. We start with some simple models and quickly turn to paging, today's standard method.

\item \textbf{Boot Process and Memory Management in \UlixI{}} (Chapter \ref{chap:ulix:boot}): After the theoretical introduction you're prepared to look at the first steps of the system initialization. We need to load the kernel, but where should we place it in RAM? The code in this chapter enables the paging mechanism and builds the foundation for process-related code which will allow to switch between several address spaces.

\item \textbf{Interrupts and Faults} (Chapter \ref{chap:ulix:interrupts}) trigger the execution of handler functions which we must provide---they should do something useful about the event that started them, for example read data from a device that signaled the completion of some activity.

\item \textbf{Processes and Threads} (Chapters \ref{chap:ulix:processes} and \ref{chap:ulix:threads}) are all about running programs which most people consider the primary task of an operating system. We present code for classical Unix processes (handled by the \verb#fork#, \verb#exec#, \verb#exit# functions) and an approximation of POSIX threads.

\item \textbf{Scheduling} (Chapter \ref{chap:ulix:scheduling}) provides \UlixI{} with its multitasking feature. You will learn about some approaches towards scheduling and then see the implementation of a round-robin scheduler. This is both about deciding when to switch to a different process (and which one) and about the switching itself: What do we have to do to temporarily halt one process so that another one can run?

\item \textbf{Handling Page Faults} (Chapter \ref{chap:pagefault}) is a continuation of both the chapters on memory management and fault handling; a page fault is a fault that we can often recover from without terminating the causing process. In this chapter we also present our routines for paging out and back in: When memory becomes scarce, we write parts of a process' memory to a disk file in order to free space---when we need it again, we bring it back.

\item \textbf{Talking to the Hardware} (Chapter \ref{chap:ulix:hardware}) deals with support for some standard devices, including the screen, the keyboard and the on-board clock's timer.

\item \textbf{Synchronization} (Chapter \ref{chap:ulix:sync}) is necessary because we allow multitasking. We show the implementation of kernel semaphores and mutexes which are standard primitives that help protect data against data"=corrupting simultaneous access.
We also explain how interrupt handlers and system call handlers (called by processes) which access shared data can be synchronized.

\item \textbf{Filesystems} (Chapter \ref{chap:ulix:fs}): Here we deal with the logical aspects of accessing files on media. We present the \UlixI{} Virtual Filesystem and our implementation of the Minix filesystem. Actually talking to the disk drive controllers is left to the next chapter.

\item \textbf{Accessing Hard Disk and Floppy Disk Drives} (Chapter \ref{chap:ulix:disk-i-o}) requires some understanding of the protocols that these controllers ``speak''. This chapter is very technical, but you do not have to deal with all the details in order to see how disk access works and data can be transferred between a disk and memory.

\item \textbf{Signals} (Chapter \ref{chap:ulix:signals}) are a classical Unix mechanism which allows a simple kind of messaging: processes can send signals to other processes which makes them either terminate or call a registered signal handler. One use case is killing a process.

\pagebreak
\item \textbf{Users and Groups} (Chapter \ref{chap:ulix:usersgroups}) let several users share one system but keep each user's data private. Every file belongs to one specific user (its owner), and each process is associated with one user (its creator), as well. We show how \UlixI{} implements the standard user/group mechanisms of Unix systems.

\item The \textbf{Small Standard Library} (Chapter \ref{chap:ulix:standard-functions}) provides often-used but less interesting functions such as [[printf]] and [[memcpy]]. This is not really what an operating system is concerned with, but without output and string management functions we could not do a lot.

\item \textbf{Debugging Help} (Chapter \ref{chap:ulix:debugging}) contains the code of the kernel shell and its internal commands. That shell is only available for debugging purposes.

\item \textbf{Build Process} (Chapter \ref{chap:ulix:build-process}): In this chapter we discuss how you can extract the source code from this book (assuming you have its Noweb source file [[ulix-book.nw]] and then build the system. Read it if you want to \emph{modify} the system. If you only want to \emph{run} \UlixI{}, there are easier ways to get started.

\item Finally, for those new to C and/or Assembler, there are introductions to C (Appendix \ref{chap:intro-to-c}) and to the Intel x86 Assembly Language (Appendix \ref{chap:intro-to-asm}).

\end{itemize}

We will give a more detailed description of some of these topics in
Chapter \ref{chap:ulix:layout}.

If you copy all the code from the book into appropriate files
(or download the version we provide on the website) you can
compile it into an operating system that will actually boot
on the [[qemu]] PC emulator.

We'll set the OS name and version now:
<<macro definitions>>=
#define UNAME "Ulix-i386 0.13"
#define BUILDDATE "SCRIPTBUILDDATE"
@ %def UNAME BUILDDATE

% Note: [[SCRIP TBUILD DATE]] will automatically be replaced with the build date.

%nouse
<<version information>>=
/*
v0.01  2011/06     first version: boots, enables interrupts, keyboard handler,
                   protected mode; most code taken from kernel tutorials
v0.02  2011/07/31  paging for the kernel (not yet for user space)
v0.03  2011/08/12  paging with Higher Half Kernel / GDT trick (preparation for
                   user space)
v0.04  2011/08/17  dynamic memory allocation: request frame, request new page
                   (with update of page table; creation of new page table if
                   last used one is full) 
v0.05  2012/10/02  serial hard disk and external storage server (for use with
                   qemu & co.)
v0.07  2013/04/05  Scheduling and fork / exec / exit / waitpid are working.
v0.08  2013/07/13  Minix Filesystem support (replaces "simplefs"). Can read,
                   write, create files. 
                   Kernel uses floppy (FDC controller) instead of serial disk
                   Terminal support (up to ten terminals with shells)
v0.09  2013/11/02  execv (with ELF loader) works; moved internal shell 
                   commands to ELF binaries in the bin/ directory
v0.10  2014/01/07  Mounting works, VFS functions (u_open, u_read etc.) work 
                   across several mounted volumes
                   Enter kernel shell: Shift+Esc, return to user mode: exit
v0.11  2014/04/23  Filesystem code is complete, buffer cache also used for
                   writing. Kernel level threads with pthread_* and pthread_
                   mutex_* functions.
v0.12  2014/08/19  Code is complete for the first public release.
v0.13  2015/09/02  Modified version (error fixes).
*/
@

\noindent
Welcome to \UlixI{} 0.13!




\section{Helpful Previous Knowledge}

This book is targeted towards both undergraduate and post-graduate students and instructors who consider using a Unix-like system in a course on the design and implementation of operating systems. At the minimum, readers should be familiar with the following topics:

\begin{itemize}

\item Software development with a C-like language, e.\,g.\ C++, C\# or Java
\item Data structures and algorithms
\item Basic understanding of \emph{some} assembler\index{Assembler language} language (the \Ulix{} sources contain a few lines of 32-bit Intel assembler code)

\end{itemize}

Experience with the following topics is not required but considered helpful:

\begin{itemize}

\item Standard Unix library functions such as \verb#open#, \verb#read#, \verb#write#, \verb#fork#, \verb#exec# (as they are sometimes taught in a system programming course)
\item Unix command line (shell), such as \verb#bash# or \verb#ksh#
\item \LaTeX{} document preparation system (required for most of the exercises in the book)
\item Software development with C
\item 32-bit Intel Assembler language
\item Build process in a Unix environment, using makefiles and command line tools for compiling, assembling and linking

\end{itemize}



\section{Online Resources}

The \Ulix{} website\index{Ulix!website} \url{http://www.ulixos.org/} has a download area with files which are needed for working on the exercises in this book (Figure~\ref{img:ulixos-website}).

\begin{figure}[ht!]
\centering
\includegraphics[width=10cm]{pics/ulixos-website.png}
\caption[The \texttt{ulixos.org} website has a download area and general information.]{Download resources and information about the project are available on the \url{http://www.ulixos.org} website.}
\label{img:ulixos-website}
\end{figure}


This is the
\vspace{3mm}%

\centerline{\textbf{First Edition \quad (09/2015)}}
\vspace{3mm}%

\noindent
of the book, so at the time of writing the website contained only the resources for this edition, but later editions may use different versions of the download files; so you should make sure that you access the right files.

The two main files you find in the download area are the following:

\begin{itemize}

\item Development system:\index{Ulix!development system} We provide a VirtualBox appliance which you can import in the VirtualBox virtualization software. It contains a Debian Linux\index{Linux} 6.0.1 installation with a simple desktop (Xfce) and all the development tools that you need for compiling the current \Ulix{} version (see Figure~\ref{img:ulix-devel}). The sources are included as well, and also a few feature-reduced versions of the \Ulix{} source code which you can extend when you work on the exercises. This virtual machine is the recommended development environment.

\item The Noweb source file \path!ulix-book.nw! from which you can generate this book and the \Ulix{} kernel. We recommend this download if all you want to do is regenerate the PDF file of the book. For compiling the \Ulix{} kernel you should use the development system described above, because the source code depends on the right compiler version being installed.

\end{itemize}

\begin{figure}[ht!]
\centering
\includegraphics[width=13.8cm]{pics/ulix-devel.png}
\caption[\mtcpolymlof{\vspace{2mm}The development environment is a virtual Debian Linux.}{}{}{The development environment is a virtual Debian Linux.}]{The website provides a virtual machine image (a VirtualBox appliance) that can be used for compiling \Ulix{} and working on the exercises.}
\label{img:ulix-devel}
\end{figure}


For a detailed description of how to get started, see Section~\ref{sec:bootstrap-ulix} which describes how you can set up a development environment. Note that you need no such installation if you simply want to read the book. However, if you want to work on the exercises which you can find in some chapters, you need the tools and sources.



\section{Further Reading}

There are several educational operating systems which have been used in courses or as the basis for textbooks with a similar purpose as this one. They are all united by the idea that students should take a look at real code in order to fully understand what tasks an operating system has to fulfill and how this can be done in practice. In addition, for some ``real'' operating systems documentation of design principles and implementation details is available that is also helpful in an educational setting. In Appendix \ref{appendix:more related work} we give several examples for both categories.

\label{minix-and-xinu}%
\felix
In our view, the two most positive examples of operating system exposition
for students are the well-known Minix operating system\index{Minix!operating system} and
the less well-known \vindex{Xinu operating system}:

\begin{itemize}
\item Minix\marginhl{Minix} was
originally written by Andrew Tanenbaum \cite{Tanenbaum:1987:OSD} to
serve as a minimal working example for teaching his operating systems
course at VU University Amsterdam (\emph{Vrije Universiteit Amsterdam}).  In its most advanced form
(Minix 3), the system is still well-structured, simple and very well
documented \cite{Tanenbaum:2006:OSD}. However, it has also evolved into
a commercially relevant system with all advantages and
disadvantages. Although the Minix book \cite{Tanenbaum:2006:OSD}
contains the entire source code of the operating system, it lives a
separate life being relegated to an appendix that essentially fills
the second half of the book.

\black
\Ulix{} uses version 2 of the Minix filesystem as its native filesystem because Linux\index{Linux} supports this filesystem very well. However, no code was borrowed from Minix except for some structure declarations.
\felix

\item The Xinu\marginhl{Xinu} system was written by Douglas Comer 
\cite{Comer:1984:XINU}
for the DEC LSI 11/2 microcomputer (a successor of the famous PDP 11
minicomputer for which UNIX was initially written). 
\black This system was later ported to the IBM PC's Intel 8088 processor 
\cite{Comer:1988:XINU:PC}, the Apple Macintosh's Motorola 68000 CPU 
\cite{Comer:1989:XINU:Mac} and, quite recently, to the Linksys E2100L Wireless 
Router \cite{Comer:2011:XINU-Linksys} which uses a MIPS processor.
There are even further ports of the Xinu code (e.\,g.\ to 32-bit Intel
machines), but those have not led to new editions of the Xinu book.
While not written in literate programming style, the documentation and presentation of code portions somewhat resemble literate programming. 
\end{itemize}

\black


\section{About the Authors}

\textbf{Felix C.\ Freiling} is a professor of computer science at Friedrich Alexander University Erlangen-Nürnberg and heads the Chair for IT Security Infrastructures of the Computer Science department (\url{http://www1.cs.fau.de/}). Before coming to Erlangen, he was a professor at RWTH Aachen and University of Mannheim. He started the \Ulix{} project during his time in Mannheim where he gave lectures on operating system principles.\\

\noindent
\textbf{Hans-Georg Eßer} was a PhD student at the same chair; he studied computer science and mathematics at RWTH Aachen. He is the editor-in-chief of EasyLinux magazine (\url{http://www.easylinux.de/}) and has been teaching operating systems at several universities of applied sciences since 2006. The completion of this book (and the \Ulix{} implementation) was the major part of his PhD thesis.






%-----------------------------------------------------------------------------



\addtocontents{toc}{\protect\parttocpagebreak}

\chapter{Layout of the Kernel Code}
\label{chap:ulix:layout}%

\index{Ulix!layout of the kernel code}%
You will soon see the first lines of code of the \UlixI{} operating system.
The presentation of code roughly follows the order in which it was developed and
in which you could also work if you wanted to write your own kernel.

When the system runs through its initialization steps, some tasks need to
be handled before others, for example we need to get the memory access right 
before everything else, and we need to establish methods for handling
interrupts and faults before we can start talking to hardware components.
Here's an overview:

\begin{description}
\item[Memory.] 
This is the first thing the OS will face: The
   boot loader\index{boot loader} will load the kernel into RAM where the kernel
   will start executing.
   But where precisely is that? And how do we have to compile
   the kernel so that it will work properly in the RAM areas
   we load it to? (Think of function calls and references to
   data addresses: We must know at compile time where the
   kernel's code and data will be located.)

   There are different modes of memory usage, and we need our
   OS to use \marginhl{virtual memory} Virtual Memory\index{virtual memory} so that we can 
   protect the kernel
   from the processes and the processes from each other.

   We need to check in which mode the CPU runs when the kernel
   is loaded, and then we have to create a transition to the
   mode we want to use: The latter one is called 
   \marginhl{Paging} Paging, and
   it provides all the protection mechanisms we need while
   using the memory in a flexible way.

   So, the first implementation chapter deals with loading the kernel and
   setting up the memory in such a way that the next initialization
   steps of the OS can work properly. Then we switch to
   paging which is a needed preparation for introducing
   processes.

\item[Interrupts and Faults.]
Before we can start using the hardware, we need to deal with
interrupts: several devices use interrupts to tell us that they
have completed some activity, and there are components like 
the clock chip which regularly generates an interrupt.

Closely related to interrupts\index{interrupt} are faults\index{fault}: they occur when the
operating system (or a process) tries to do something that's
impossible, e.\,g.\ access a memory address that does not exist
or for which access is forbidden. We need to treat these, too,
because if we don't, then any fault will just make the whole
system halt.

The main difference between interrupts and faults is that
faults occur as a direct consequence of some specific 
instruction that our code executes. In that sense they are
\marginhl{synchronous} synchronous. Interrupts on the other
hand occur without any connection to the currently 
executing instruction, since they are not triggered (immediately)
by our code but by some device. That is why they are called
\marginhl{asynchronous} asynchronous.

Handling an interrupt and handling a fault are very similar
tasks, so we deal with both in the same chapter. We present a
framework which lets us supply handlers as we need them, so
for example the concrete interrupt handler for the IDE disk
controller will be shown later, but it will use the code that's 
presented here.

\item[Basic Hardware Support.] 
Once we've established the general interrupt handling
mechanism, we can start setting up the hardware. We begin with
the clock chip (which generates timer interrupts) and the keyboard
(which generates an interrupt each time you press a key). We'll
look at further hardware components in later chapters, for example
the code for floppy and hard disks will follow after the filesystem
chapter.

\item[Processes.]
Here we introduce one of the most important
data structures of the operating system, the 
\marginhl{process\\ control block} process control block (PCB).
We also have to revisit the virtual memory code and introduce
a mechanism to switch between different page tables---every process
will use its own one, since every process has its own virtual
memory. 

The following chapter discusses the necessary changes for
supporting threads which share an address space if they belong
to the same process.

In the chapters that deal with processes, threads and
the scheduler you will also see how the system can make
a context switch\marginnote{context switch} which happens when 
one process is interrupted and another one continues executing.


\item[System Calls.]
The operating system does not only
guarantee that the memory areas of the kernel and all the
processes are protected against one another, it also disables
direct access to the hardware. So if a process wants to open and
read a file, it needs a mechanism for calling a kernel function
which does just that. The standard mechanism for calling 
OS functions is a system call. The system call\index{system call} interface
somewhat resembles the interrupt handling interface which we've
seen earlier. We only explain how the general
mechanism works---concrete system calls will be implemented where
we need them, for example in the filesystem chapter.

\pagebreak

\item[Filesystem.] 
The \UlixI{} filesystem code provides us with
a virtual filesystem\index{virtual filesystem}\index{VFS (virtual filesystem)}. With it, we can use several kinds of drives
(we'll show the code for floppy disks, hard disks and a virtual
device we've named the ``serial hard disk''), and we can
support several logical filesystem formats: \UlixI{} has a driver
for the \marginnote{Minix\\ filesystem} Minix filesystem which was 
introduced for the Minix operating
system. Linux\index{Linux} can use Minix media as well which makes it easier
to prepare the disk images we use with \UlixI{}. Code for other
logical filesystems (e.\,g.\ FAT or NTFS) could easily be added.

\end{description} 

\noindent
We will now present the overall layout of the \UlixI{} kernel code.
Basically every kernel has to do some essential setup (such as
initializing RAM and other components of the machine), then
activate interrupts and the process system, create a first (\verb#init#) 
process and transfer control to that process (which will start
further processes). \UlixI{} is no different,
but where it differs from other operating systems is that we're going
to store (almost) everything in one single C source file, [[ulix.c]].
If you take a look at other systems you will find a huge collection
of source ([[*.c]]) and header ([[*.h]]) files and several makefiles
which turn the source files into object files ([[*.o]])
independently before linking them all together into a single binary.
We'll also link the kernel binary because we have some assembler\index{Assembler language} code
in the file \path!start.asm! that is translated with [[nasm]], but all
the rest goes into [[ulix.c]]. The literate programming approach allows
us to combine everything without losing the overview: the pages you
look at right now structure the code well enough.

Since C requires functions to be defined before they are called and
user-defined types to be declared before they are used in function
prototype definitions, we need to make sure that all symbols are
known at the right time. 

\begin{itemize}
\item We start with two code chunks [[<<constants>>]]\marginnote{constants\\ and macros}
and [[<<macro definitions>>]] where we put all pre-compiler
([[#define]]) statements.

\item Then follow [[<<public elementary type definitions>>]]\marginnote{types}
(mostly stuff like [[typedef unsigned int uint32_t]]) and 
[[<<type definitions>>]] (for structures). The distinction is
necessary since structure definitions use elementary types.

\item 
Next come the [[<<function prototypes>>]]\marginnote{prototypes\\ and variables} 
\index{prototype (C function)}\index{C programming language!prototype}%
and the [[<<global variables>>]]: the latter
ones often receive their initial values at the point of declaration.

\item
Finally, the real code starts: with all kernel functions in the
chunk named [[<<function implementations>>]]\marginnote{implementation}, 
\index{implementation (C function)}\index{C programming language!implementation}%
and at the end of the file
you will find the [[<<kernel main>>]] function ([[main()]]).
\end{itemize}

\noindent
Most of these code chunks ``exist'' twice, for example [[<<constants>>]]
and\marginnote{public chunks} [[<<public constants>>]]. The code chunks with a \emph{public} prefix
will later be included in the user mode library's header file
([[ulixlib.h]]) or the implementation file ([[ulixlib.c]]), and this trick 
allows us to automatically keep data structures and constants synchronized 
between kernel and user land, and it saves us from having duplicate code
chunks for standard functions like [[memcpy]] which are used both in kernel
and user level land.

So this is the basic structure, with most of the kernel code collected in just
one C file, [[ulix.c]]:

\pagebreak

\tindex{ulix.c}
<<ulix.c>>=
<<copyright notice>> 
<<version information>>
<<constants>>  <<public constants>>
<<macro definitions>>  <<public macro definitions>>
<<public elementary type definitions>>
<<type definitions>>  <<public type definitions>>
<<function prototypes>>  <<public function prototypes>>
<<global variables>>
<<function implementations>>  <<public function implementations>>
<<kernel main>>
@



\section[The {\tt main()} Function]{The {\tt \textbf{main()}} Function}

The [[main()]] function of the \UlixI{} kernel brings the system
up and starts the first (user mode) process, an [[init]] program
which launches several copies of a [[login]] program that in turn
start simple shells. This happens on a number of virtual terminals 
(text consoles), allowing tests with several logged-in users.

% old code:
% int main (void *mboot_ptr, unsigned int initial_stack) {
% (we do not use this)
<<kernel main>>=
void main () {
  <<initialize kernel global variables>>
  <<setup serial port>>  // for debugging
  <<setup memory>>
  <<setup video>>
  <<setup keyboard>>
  <<initialize system>>
  <<initialize syscalls>>
  <<initialize filesystem>>  
  <<initialize swap>>
  initialize_module ();  // external code
  <<start [[init]] process>>
}
@ %def main

% removed:
%   debug_printf ("initial_stack = 0x%x\n", initial_stack);
% (was before <start shell>)
Before all other hardware we initialize the serial port since we use
it for debugging purposes; the function [[debug_printf]] sends information
to the first serial port, and when we run \UlixI{} in the [[qemu]] emulator,
we can grab that output and display it elsewhere---even before it is
possible to write to the (virtual) screen. Note that you will not find
code lines with [[debug_printf]] statements in the PDF version of this
book, but if you download the sources, you can see them directly in the
Noweb file (and also in the generated source code). In order to enable
this debugging, the [[DEBUG]] macro must be defined via
[[#define DEBUG]] (see Chapter~\ref{sec:ulix:printf:kernel}).

Setting up the memory is a complex task which we describe in detail in
Chapter~\ref{sec:ulix:vm}.
Next we can start accessing the memory buffer of the graphics card to
display messages on the screen, we will define the [[<<setup video>>]]
chunk in Chapter~\ref{chap:ulix:virtualconsoles}.

Since \UlixI{} can be (and has been) used for Bachelor's or Master's thesis projects,
we provide a mechanism to integrate the OS code with a module that is implemented by
the student; during kernel initialization we will call the
<<function prototypes>>=
extern void initialize_module ();
@ %def initialize_module
function which may perform further initialization tasks.

\index{Ulix!system initialization}%
<<initialize system>>=
<<install the interrupt descriptor table>>
<<install the fault handlers>>
<<install the interrupt handlers>>
<<install the timer>>
<<enable interrupts>>
@



For initializing the filesystem, we first detect the hardware and then
print the (currently static) mount table:

<<initialize filesystem>>=
<<setup serial hard disk>>
fdc_init ();  ata_init ();     // register floppy and hard disks
print_mount_table ();
@


When everything is prepared we can finally enter user mode: We enable the 
interrupts, load the \verb#init# program and start it as the first process.

<<start [[init]] process>>=
<<enable interrupts>>
#ifdef START_KERNEL_SHELL    // REMOVE_DEBUGGING_CODE
  kernel_shell ();           // REMOVE_DEBUGGING_CODE
#endif                       // REMOVE_DEBUGGING_CODE
printf ("Starting five shells on tty0..tty4. Press [Ctrl-L] for de/en keyboard.\n");
start_program_from_disk ("/init");   // load flat binary of init
// never reach this line!
@

With the first process being active, initialization of the system is finally complete.


\section{Type Definitions}

Before we introduce the first data structures, we define some elementary data types which make our code more readable. For example, the C language has no specific ``byte'' and ``boolean'' data types. Instead, an [[unsigned char]] is used whenever bytes or booleans are needed. We also define a ``word'' type.

<<public elementary type definitions>>=
typedef unsigned char            byte;
typedef unsigned char         boolean;
typedef unsigned short           word;
@ %def byte boolean word

Along with the [[boolean]] datatype we also provide constants for the two standard values 1 and 0 (note that C regards any non-zero integer value as true). [[NULL]] is a null pointer.

<<public constants>>=
#define true  1
#define false 0
#define NULL ((void*) 0)
@ %def true false NULL


\noindent
Sometimes we create data structures with differently-sized components, and in those cases we want to show clearly how ``big'' each element is. So we also define [[uint*_t]] types which are standard in many systems, e.\,g.\ in the Linux\index{Linux} kernel:

<<public elementary type definitions>>=
typedef unsigned char         uint8_t;
typedef unsigned short       uint16_t;
typedef unsigned int         uint32_t;
typedef unsigned long long   uint64_t;

typedef int                    size_t;
typedef unsigned int             uint;   // short names for "unsigned int",
typedef unsigned long           ulong;   // "unsigned long" and
typedef unsigned long long  ulonglong;   // "unsigned long long" (64 bit)
@ %def uint8_t uint16_t uint32_t uint64_t uint size_t ulong ulonglong

\noindent
Memory addresses in our code are always 32 bits wide since \UlixI{} is a 32-bit operating system. We intruduce an address type:

<<public elementary type definitions>>=
typedef unsigned int       memaddress;
@ %def memaddress


\section{Assembler Code}

As we will occasionally have to use assembler\index{Assembler language} statements and the 
standard command in the GNU C compiler [[gcc]] is [[__asm__]], we define
a shorthand:

<<macro definitions>>=
#define asm __asm__
@

\noindent
We have created an assembler\index{Assembler language!pre-processor} pre-processor which replaces code that has the form
of the left side with code that looks like the right side:
\vspace{1mm}

\begin{minipage}[t]{0.55\textwidth}
\begin{verbatim}
asm {
  starta: mov eax, 0x1001   // comment
  mov ebx, 'A'              // more comment
  int 0x80
}
\end{verbatim}
\end{minipage}%
\vline\quad
\begin{minipage}[t]{0.45\textwidth}
\begin{verbatim}
asm (".intel_syntax noprefix; \
  starta: mov eax, 0x1001; \
  mov ebx, 'A'; \
  int 0x80; \
  .att_syntax; ");
\end{verbatim}
\end{minipage}%
\vspace{3mm}

\noindent
This allows usage of the Intel assembler\index{Assembler language!Intel syntax}\index{Intel syntax (Assembler)} syntax (without changing the normal compilation
process which uses AT\&T syntax\index{Assembler language!AT\&T syntax}\index{AT\&T syntax (Assembler)}), it also enables us to add comments in the code, and
the new syntax is closer to C.

The pre-processor also understands [[asm volatile]]. What it cannot cope with is variable / register usage; thus, occasionally there will be appearances of the less readable standard assembler syntax.

Note that it does not change the number or position of code lines. The source code for the assembler parser is shown on page \pageref{code:assembler parser}~ff.


\subsection{Turning Interrupts On and Off}

We will often have to disable and re-enable interrupts. The assembler\index{Assembler language!cli and sti instructions@\texttt{cli} and \texttt{sti} instructions}\tindex{cli}\tindex{sti}
instructions are [[cli]] (clear interrupt flag; disables the interrupts)
and [[sti]] (set interrupt flag\index{interrupt flag}; enables them). Instead of writing
[[asm("cli")]] or \verb#asm("sti")# (which would force you to remember
which of the commands turns the interrupts on or off) we provide 
code chunks for them:

<<disable interrupts>>=
asm ("cli");    // clear interrupt flag
@

<<enable interrupts>>=
asm ("sti");    // set interrupt flag
@


\section{The User Mode Library}

\index{Ulix!user mode library}\index{user mode library}%
Besides the kernel we also need a user mode library which provides some standard features for user mode applications.

The library code consists of two files: [[ulixlib.c]]\tindex{ulixlib.c} contains
the implementations of the library functions, whereas
[[ulixlib.h]]\tindex{ulixlib.h} provides declarations which have to be included
both in [[ulixlib.c]] and any program that wants to use the
library functions. In this section we introduce the code chunks
that the library files are made of.

The header file shares some constants and type declarations as
well as some generic function prototypes with the kernel:

\pagebreak

%nouse
<<ulixlib.h>>=
// ulixlib.h
// To compile a Ulix program, include "ulixlib.h"
<<copyright notice>>
<<public constants>>  <<ulixlib constants>>
<<public macro definitions>>  <<ulixlib macro definitions>>
<<public elementary type definitions>>
<<public type definitions>>  <<ulixlib type definitions>>
<<public function prototypes>>  <<ulixlib function prototypes>>
@



\subsection{Functions of the Library}

Some functions are needed both in the kernel and in the user mode library. We put their implementations into the [[<<public function implementations>>]] chunk (which is included both by the kernel and the library C files) so that we need not present the code for [[memcpy]], [[strncpy]] and other standard functions twice.

%nouse
<<ulixlib.c>>=
// ulixlib.c
// To compile a Ulix program, include "ulixlib.h"
<<copyright notice>>
#include "ulixlib.h"
<<public function implementations>>
<<ulixlib function implementations>>
@

So, whenever you see a code chunk that starts with ``$\langle$\emph{public}'', you know that it contains declarations or code which will appear both in the kernel and in the user mode library.


\section{Next Steps}

In the following chapter we introduce the theory of memory management---that's a requirement for doing any further steps, since the next \UlixI{} code chunks show you how we load the kernel from the boot manager. But in order to do that, we need to first think about how we want to use the physical memory. Thus, Chapter~\ref{chap:memory:theory} gives you all the needed theory, and then the following Chapter~\ref{chap:ulix:boot} explains the boot process and the \UlixI{} approach towards memory usage. 





%-----------------------------------------------------------------------------

\chapter{Managing Memory}
\label{chap:memory:theory}%

\index{memory management}%
Processing power (that is, the computing cycles of the CPU) and memory are the two most important resources\marginnote{resources} for any machine. In the next chapter we will describe how to boot the \UlixI{} operating system, and that procedure will include copying the kernel into the computer's main memory. We need to know where to put it and how to continue using memory.

Doing that properly requires some understanding of the general concepts of memory management and also of the concrete mechanisms provided by the target CPU which, in our case, is the Intel i386. In this chapter we start with an overview of the memory management theory, and the following chapter will present the implementation details of the management solution which we have chosen.

Memory management is all about the question: ``How can we make the best use of the available physical memory?'' When a computer only needs to execute one single program, there is not much to do. But the invention of multi-tasking led to the task of providing several processes with sufficient memory to store their code and data. The extra requirement of memory protection (processes shall not access the memory areas of other processes or of the operating system) further complicates the task.

There are also many similarities between memory management and filesystem management (which we discuss in detail in Chapter~\ref{chap:ulix:fs}): In both cases, a fixed-size resource (the physical memory or the collection of sectors on a disk) needs to be shared. 

Note that from a process' point of view, memory is a direct resource and is needed for running the process: If the process' program code is not available in memory (at least partially), it cannot be executed, because the CPU can only execute instructions that are located in RAM. On the other hand, disk space is not something that a process will (directly) need: while access to certain files may be necessary for running a program, it is not needed permanently. But if we look at disk space from a file's point of view, we could say that a file (in order to exist and allow access to it) needs disk space in a similar way as a process needs memory to run. From that point of view, we can compare a process which has no memory with a disk file that was moved to tertiary storage (e.\,g., a magnetic tape that is part of a tape collection).

These are some of the concepts that appear in both memory management and filesystems:

\begin{description}
\item[Partitioning of resources:] On a system that will handle several processes in parallel, memory must somehow be partitioned so that each process can use a fraction of the RAM. Individual cells of memory are exclusive: They can hold precisely one byte of information, and it has to belong to a specific process (or the operating system itself) at any given time. It may not be necessary that a process has memory throughout his whole lifetime (for we will see that concepts such as swapping and paging allow data to be stored on the disk for a while), but at least in those moments when a process is actually excecuted by the CPU, it will have to be given some memory. It may be useful to limit the maximum RAM that a process can access at any given time.\looseness=1

Similarly, if a system allows several files (and possibly directories) to be created, accessed and modified on the disk, disk space has to be partitioned in a way that the disk can hold all these files and present simple means to look up files on the disk and access them. The smallest unit of storage would in theory also be a byte, and such a byte (now meaning the fixed location on disk) can only belong to one file (or to the filesystem metadata) at any given time. As in the memory situation, it may be useful to define a maximum filesize so that no file uses too much of this resource, though most filesystems that implement such limits do this on a per-user basis and not on per-file basis---limiting disk usage per user (or per user group) is called a \emph{quota system}\index{quota system}.

\item[Access control:]\index{memory management!access control}\index{access control} Access to memory locations should always be exclusive to one process (or the operating system), otherwise a process could read or even modify the process memory of a different process which is not advisable, because it would be a source of instability or security problems.

Access to files is also often handled in a way that makes it exclusive to a file owner, typically the file creator (or perhaps some other users, depending of the access concepts a specific filesystem may have). And from the view of processes it may be necessary to restrict file access to only one process (even in a situation when several processes belong to the same user who is also the owner of the file), so that no errors can result from parallel access to a file.

\item[Free space management:]\index{memory management!free space management}\index{free space management} Memory and disk usage must be handled dynamically, because processes newly appear and are removed from the system all the time, their needs for memory may change during the process runtime, and also files can be created and deleted as well as grown while the system is active.

In many memory management schemes there will be a list of free memory locations. We will see that is not useful to grant memory access byte-wise, memory will often be partitioned into equal-sized smallest chunks of memory that can be assigned to a process or removed from it. If we call these smalles chunks (say, of size 1 KByte) memory frames, then there will be need of a ``free frame list'' that knows which frames are currently unused.

In the same way disks aren't typically accessed byte-, but block-wise, a block being a fixed size segment of the disk space. Note also that read and write operations on the raw disk device always transfer a whole block of data and not a single byte (which is why they are called \emph{block devices} as opposed to \emph{character devices}. We will need a ``free block list'' in order to know which blocks are still available for file storage and which are not.

Methods for administering such free frame lists and free block lists will be similar.

\end{description}


\section{Contiguous Allocation}
\label{sect:contiguous-allocation}%

\index{memory management!contiguous allocation}\index{contiguous allocation}%
In this section we present the most simple methods to distribute memory among processes and disk space among files. Contiguity means that a process gets to use a contiguous (connected) area of memory, there are no ``holes'' in it which would be memory areas assigned to a different process or not assigned at all. If memory did have such holes, a process would have to keep track of which memory regions it can use and which not.


\subsection{Fixed Equal Size Partitioning}

\index{memory management!fixed equal size partitioning}\index{fixed equal size partitioning}%
Consider a computer that has 1 GByte of RAM. If we divide this memory into 1-MByte-sized partitions, then we get 1024 such partitions, some of which will have to be reserved to the operating system itself (see Figure~\ref{img:partitioning-fixed}). Assuming that 1000 ``unused'' partitions will remain, such a system would allow for up to 1000 processes to be started and held in memory in parallel. Each of the processes will then have its own 1 MByte memory partition, meaning it can use up to this 1 MByte for storing its own program code, stack and data.

\begin{figure}[b!]
%\centering
\hspace{-4mm}
\includegraphics[width=1.25\textwidth]{pics/partitioning-fixed.pdf}
\caption[Partitioning: Fixed equal size.]{Fixed equal size partitioning is the simplest but also the least flexible approach to partitioning memory or disk space.}
\label{img:partitioning-fixed}
\end{figure}

Obviously this method is not very flexible and it limits the possible usage of the system in two ways:
\begin{itemize}
\item No more than about 1000 processes can be run in parallel. If there was need for, say, running 2000 or more processes at the same time, then the whole system would have to be reconfigured (with smaller, but more memory partitions) and completely rebooted.
\item No more than 1 MByte of RAM can be given to a single process. If a program required more than that, say 2~MByte or more memory, again the system would have to be reconfigured.
\item It would be completely impossible to change the system parameters in either direction, i.\,e., allow for more than 1000 processes \emph{and} some of them using more than 1 MByte RAM.
\end{itemize}

Now, in the same way consider a harddisk of size 1 GByte and a similar partitioning scheme that would allow 1024 (minus a few) files of up to 1 MByte size to be written to this disk. The same problems as in the memory example would occur: There would be a filesize limit as well as a limit on the number of files, and changing the filesystem structure in order to either allow more or larger files would require the disk to be newly formatted, and a change would only increase one of these numbers while reducing the other.

This simple approach is called ``fixed equal size partitioning'' in both the memory and the harddisk case, and besides the limitations already discussed it leads to a problem called \emph{internal fragmentation}\marginnote{internal\\ fragmentation}: While the RAM is fully split into partitions, i.\,e., there remains no unpartitioned and possibly unusable memory (that would be external fragmentation), a lot of memory will go unused, e.\,g.\ when a process runs that needs only a few kilobytes of RAM but still gets the whole 1 MByte. There is no way for other processes to claim some of this unused memory because the fixed partitioning forbids this (see Section~\ref{sec:memory:fragmentation}).

It is an example of contiguous allocation methods: Contiguity means that all the parts of a process' memory (or of a file on disk) are stored in consecutive frames/blocks, and also in order. So no jumps to other memory locations or disk blocks are necessary when reading the whole file (or the process' whole memory) from the first to the last byte. The opposite of this in non-contiguous allocation, and we will get to that approach in Section~\ref{sect:non-contiguous-allocation}. \looseness=1

Note that we use the term ``disk partition'' in a non-standard way; we do not mean the logical partitions into which a disk is separated on today's standard computers in order to create several logical volumes (in Windows\index{Windows operating system} language: \emph{drives}) each of which is formatted with its own filesystem. For simplicity we assume that a harddisk contains exactly one filesystem and that this filesystem uses all of the disk, as it is the case on floppy disks and (some) USB sticks. See section \ref{subsection:fdisk-partitions} for a few words about the classical understanding of ``disk partition''.


\subsection{Fixed Variable Size Partitioning}

\index{memory management!fixed variable size partitioning}\index{fixed variable size partitioning}%
The partitioning scheme that gives all partitions equal size causes the two limitations in file size and file number. A little more flexibility is introduced when we dispense with the equality condition: That leads us to a new method of creating fixed partitions, but of varying sizes (see Figure~\ref{img:partitioning-flexible}).


\begin{figure}[ht!]
%\centering
\hspace{-4mm}
\includegraphics[width=1.25\textwidth]{pics/partitioning-flexible.pdf}
\caption[Partitioning: Fixed variable size.]{Fixed variable size partitioning gets rid of the file size and file number limitations, but still the partitioning parameters cannot change once the system uses the partitions.}
\label{img:partitioning-flexible}
\end{figure}


It is just a small alteration, but it already improves the situation a lot: In the memory case, if a process is associated with a memory partition and it wants to extend its memory usage beyond the current partition's limits, it can be relocated to a different (larger) partition, and on the other hand many more processes can use the system if there is a good mix of processes with small and large memory demands. Note that this partitioning scheme is still fixed: At system boot-time, the memory partitions are created and cannot be modified until the next booting (and a modification is likely to require a recompilation of the operating system kernel).

In the same way a filesystem with fixed partitions will profit from this modification by allowing both more and (some) larger files. The strictness of the partitioning applies here as well: Once the disk has been formatted, the partition (i.\,e.: maximum file) sizes can only be changed by reformatting the whole disk.




\subsection{Dynamic Partitioning}

\index{memory management!dynamic partitioning}\index{dynamic partitioning}%
A lot more freedom in memory or disk space allocation is possible if the partitioning becomes fully dynamic: This means that no partitioning occurs at system initialization or while formatting the disk, but instead partitions are created as need for them occurs.

This has the effect that the operating system must carry out a lot more administrative work. For example, keeping an overview of free areas of memory becomes more complicated, because whatever data structures are used for the memory or disk allocation, they are now dynamic.


\subsubsection{Free Frame Lists}

The simplest approach is to keep a list of free locations. This list will be called a \emph{free frame list}\index{free frame list} in memory management or a \emph{free block list} in filesystems. Typically there is a smallest possible fragment that can be allocated, called a frame or block, and free space managements only deals with these frames/blocks. The smaller the frames or blocks are, the more of them exist and have to be handled by the free frame list.

One approach is to have a linked list that contains descriptions of free areas, e.\,g. a start address and a length for each one. In the list each entry points to the next entry when working with pointers. In order to find a free area of a given size an algorithm will walk through this list and stop when it finds an area of sufficient size. For this purpose it may be necessary to scan the whole list if (in the worst case) the only fitting area is at the end of this list. When a number of previously free frames is allocated to a process (or blocks to a file), the list has to be modified, 

\begin{itemize}
\item either by removing the entry if the whole lot of contiguous blocks are allocated,
\item or by modifying the entry if only a few of the blocks are allocated, and they are located at the beginning or end of the area described by this entry,
\item or by splitting the entry in two parts, if (for whatever reason) a section taken from the middle is allocated, leaving free areas in front of and behind them.
\end{itemize}

If the used space is later released, it must be added to the list again, possibly creating a list entry that has to be merged with entries describing directly neighboring areas.

Another possibility is to work with bitmaps\index{bitmap}\index{memory management!bitmap}\marginnote{bitmap}: For each frame/block a bit in this bitmap defines whether it is free (0) or in use (1). Here no complex list administration (with the mentioned splitting and mergers of list entries) is required, however allocation and release of blocks lead to modification of several bits in the bitmap, and looking up free space of a given size means finding a number of consecutive 0-bits in the bitmap.

Note that it does not matter at all whether we think of memory frames or disk blocks, the concepts are identical. Differences will however appear when thinking of storage of these lists or bitmaps: In the memory case it is obvious that the list must also lie in memory for quick access. In the filesystem case it might make sense to store the list in memory (and not on disk as well) in order to speed up the lookup of free areas---but depending on the size of the free block list, it may be too large to keep all of it in memory.


\subsubsection{Allocation}

When working with dynamic allocation of free areas, there will typically be a choice among several free areas which are of sufficient size, and the procedure for choosing one of them will have consequences both on performance and on \emph{external fragmentation}\marginnote{external\\ fragmentation} (an increasing number of small unallocated areas): If the decision algorithm is very complex, allocation will always take a lot of time; if it is simple, there will be many small unpartitioned (not allocated) areas which are too small to be useful anymore, so this external fragmentation will lead to memory or the disk filling up more quickly than necessary.

On the following pages we will present five simple approaches to allocation called first-fit, next-fit, best-fit, worst-fit and quick-fit; and after that a more advanced concept called the \emph{Buddy System} will be introduced.

\begin{description}
\item[First-fit] \index{memory management!first-fit allocation}\index{first-fit allocation}This strategy picks the first free area of sufficient size. It has the advantage of being fast, because once an acceptable area has been found, the system looks no further. On the negative side, first-fit leads to a lot of fragmentation and continuously reduces big areas, so that processes which start later and need a big area cannot run.
\item[Next-fit] \index{memory management!next-fit allocation}\index{next-fit allocation}This is a variant of first-fit. The difference is that after every allocation the system keeps in mind the position of this allocated area. The search algorithm then continues immediately behind this area. That way all of memory is being used, whereas first-fit might use only areas in the low-address range if demands can be fulfilled there.
\item[Best-fit] \index{memory management!best-fit allocation}\index{best-fit allocation}The idea behind best-fit is to allocate space in the smallest possible area where the process fits. Assuming that what is left after the allocation is likely to become unusable (because it is too small), this approach tries to minimize the waste of space.
\item[Worst-fit] \index{memory management!worst-fit allocation}\index{worst-fit allocation}Exactly the opposite of best-fit, worst-fit searches for the biggest free area and allocates space within it. From the perspective of the remaining space, this maximizes the size of the new free area that is left after allocation, hoping that it will still be large enough to allow for further allocations.
\item[Quick-fit] \index{memory management!quick-fit allocation}\index{quick-fit allocation}is a combination of a first-fit approach with fixed partitioning. A part of the available memory is partitioned into areas of some varying sizes which are often requested. (What is often requested must be known from experiences with memory allocations.) So there will be lists of free partitions of some standard sizes, say, 1~KByte, 2~KByte, \dots, 16~KByte. If a memory request of one of those sizes occurs, the system will first try to satisfy it with one of the partitions in the corresponding list. Only if that fails, memory will be allocated from the unpartitioned space using first-fit.
\end{description}


\subsubsection{Buddy System}

\index{memory management!Buddy system}\index{Buddy system}%
The \emph{Buddy System} \cite{Knowlton:1965:FSA:365628.365655} assumes that we start with a free memory area whose size in bytes is a power of 2. The system reacts to memory requests of arbitrary sizes by repeatedly dividing a free chunk of memory in two halves until a chunk becomes available which is just large enough to satisfy the request. An example illustrates this system better than the description: Let's assume that 1 MByte of memory (1024 KByte) is available at the start. This memory chunk is not partitioned. If a request for 90 KByte arrives, the Buddy System takes the following steps:

\begin{itemize}
\item Since the 1024 KByte chunk is too large, it is split into two 512 KByte chunks.
\item 512 KByte are still too large, so the first of these chunks is split into two 256 KByte chunks.
\item Again, 256 KByte are too large, so another split takes place, turning the first of the 256 KByte chunks into two chunks of size 128 KByte.
\item The first of the 128 KByte chunks is chosen since it can satisfy the request. It is marked as used.
\end{itemize}

\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=8.5mm]{16}
%\bitheader[b]{0-15}\\
\bitbox{16}{\textbf{1024 KB}} \\
\bitbox{8}{\textbf{512 KB}}
\bitbox{8}{512 KB} \\
\bitbox{4}{\textbf{256 KB}}
\bitbox{4}{256 KB}
\bitbox{8}{512 KB} \\
\bitbox{2}{\textbf{\green 128 KB}}
\bitbox{2}{128 KB}
\bitbox{4}{256 KB}
\bitbox{8}{512 KB}
\end{bytefield}
\caption[Partitioning: Buddy System.]{The Buddy System repeatedly splits available space in halves. The chunks with bold face descriptors are chosen for splitting; the green and bold chunk satisfies the request of 90 KByte.}
\label{fig:buddy system}
\end{centering}
\end{figure}

Figure~\ref{fig:buddy system} shows how the Buddy System partitions the memory step by step when trying to satisfy this request. Afterwards, there are three free chunks left, their sizes are 128~KByte, 256~KByte and 512~KByte. If another request for 90~KByte arrives, the free 128~KByte chunk is chosen; in case of a 40~KByte request, the 128~KByte chunk would be split again.
The way in which memory is partitioned can also be represented by a tree; Figure~\ref{img:buddy system tree} shows the tree which corresponds to the situation described above.



\begin{figure}[ht!]
\centering
\includegraphics[width=11cm]{pics/buddy-system-tree.pdf}
\caption[Partitioning: Buddy System (tree representation).]{The tree representation of memory that was partitioned by the Buddy System shows available memory chunks in the tree's leaves.}
\label{img:buddy system tree}
\end{figure}

When a used chunk of memory is returned and its equal-sized direct neighbor (in the tree) is a free leaf, these two leaves are joined to form a new leaf of twice the size; this process continues, possibly all the way up to the root of the tree. The tree view makes it easier to see which chunks can be joined and which cannot. Figure~\ref{fig:buddy system impossible join} shows an example in which joining is impossible: the second and third 128 KByte blocks are not direct neighbors, they would have to be joined with their left and right neighbors first.


\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=8.5mm]{16}
%\bitheader[b]{0-15}\\
\bitbox{2}{128 KB}
\bitbox{2}{\textbf{128 KB}}
\bitbox{2}{\textbf{128 KB}}
\bitbox{2}{128 KB}
\bitbox{8}{512 KB}\\
\bitbox{2}{128 KB}
\bitbox{4}{\textbf{256 KB}}
\bitbox{2}{128 KB}
\bitbox{8}{512 KB}
\end{bytefield}
\caption[Partitioning: Buddy System (impossible join).]{This is an impossible join operation; a tree representation would show that the two 256 KByte blocks marked bold are not direct neighbors.}
\label{fig:buddy system impossible join}
\end{centering}
\end{figure}


\subsection{A Few Words on Disk Partitions}
\label{subsection:fdisk-partitions}%

As mentioned above, we have not been talking about hard disk partitions in the sense of creating several logical volumes on a disk for use by various operating systems (e.\,g.\ a Windows\index{Windows operating system} and a Linux partition) or for structuring the disk so that different data can be stored on different partitions (e.\,g.\ ``drives'' \path!C:! and \path!D:! for Windows or partitions \path!/!, \path!/home! and \path!/usr! for Linux)---now we do, because this kind of partitioning is another example for contiguous allocation with flexible size. Most disks have a partition table as created by Windows, Linux, DOS and other operating systems when initializing a hard disk. (The BSD operating systems use a different method to partition disks, calling the partitions \emph{slices} and the partition table \emph{disklabel}.)

A classical partition table puts no limits on the sizes of individual partitions, but allows only up to four (\emph{primary}) partitions for whose administrative data it reserves space in the first blocks of the disk. There, you basically find the start address and the length of each partition. If more than four partitions are needed, one of the four must be set up as an \emph{extended partition} that holds an additional partition table and the \emph{logical partitions} that reside inside the extended one.

If we ignore logical partitions, we see that this is a simple implementation of dynamical contiguous allocation with flexible size; partitions can be created and deleted, each partition has to be contiguous, and in principle the partitioning also suffers from external fragmentation: If you start with a 40 GByte disk that is partitioned into four 10 GByte partitions and you resize each of them to 9 GByte, you end up with four unused 1 GByte areas that cannot be used. If there was no ``four partitions'' limitation, the four free areas could be made into four separate 1 GByte partitions, but never into one 4 GByte one, since these four areas are not contiguous.

In order to change the size of a formatted partition (i.\,e., one with a valid filesystem on it), always two steps are necessary, with their order depending on whether the partition is to be extended or shrunk: The logical filesystem must be resized and the partition itself must be resized.

\begin{itemize}
\item When extending a partition, the operation on the partition (and partition table) comes first. Only when this is completed, can the filesystem size be increased as well so that it grows into the newly available space.
\item When shrinking a partition, the filesystem has to be modified first, because for example files residing in the parts of the partition that is to be removed must be relocated to a different area on the partition first. Only then can the partition itself be resized (making the removed parts unaccessible to the filesystem).
\end{itemize}

Note that modifying a filesystem size requires more than (possibly moving files from an area that is to be removed and) changing the information about the partition size in the partition's metadata, for example on a Unix filesystem the free block bitmap has to be grown or shrunk as well in order to correspond to the changed number of blocks.


\subsection{Segmentation}
\label{sec:memory:segmentation}%

\index{memory management!segmentation}\index{segmentation}%
Segmentation is a memory management technique that requires support by the processor. In general, an address consists of a segment number and an offset (an address that is relative to the physical start of that segment). Segments may (but need not) have a size---if they have, the CPU can check whether access to an address exceeds the boundary of that segment.

The CPU must know the start addresses (often called \emph{base addresses}\index{base address}\index{segmentation!base address}\marginnote{base address}) and sizes of the segments. That can be achieved by filling a segment table or by loading special CPU registers. Table~\ref{table:segments-example} shows an example with three segments on a 64~MByte machine. Figure~\ref{img:segmentation-adder-only} shows the CPU-internal implementation of address calculation for a machine which is not aware of segment limits.

\begin{table}[h!]
\centering
\begin{tabular}{|c|l|l|l|}
\hline
No. & start address   & size                   & absolute range \\
\hline
1   & \hex{00000000}  & \hex{100000} (1 MByte) & \hexrange{00000000}{000FFFFF} \\
2   & \hex{00800000}  & \hex{400000} (4 MByte) & \hexrange{00800000}{00BFFFFF} \\
3   & \hex{03F00000}  & \hex{100000} (1 MByte) & \hexrange{03F00000}{03FFFFFF} \\
\hline
\end{tabular}
\caption[\hgepolylot{Example of a segment table with three segments.}]{Example of a segment table with three segments.}
\label{table:segments-example}
\end{table}


\begin{figure}[b!]
\centering
\includegraphics[width=0.8\textwidth]{pics/segmentation-adder-only.pdf}
\caption[Segmentation: Calculation of the physical address.]{Calculating the physical address from a segment number and a logical address is simple: The CPU just adds the segment base address and the logical address.}
\label{img:segmentation-adder-only}
\end{figure}


In the first and the third segment, relative addresses in the \hexrange{00000}{FFFFF} range are valid (since those segments are 1 MByte large), and in the second segment, relative addresses from the \hexrange{000000}{3FFFFF} range can be used (4 MByte).

A complete address is a (segment, address) tuple, for example, (2, \hex{ABCD}) would refer to the relative address \hex{ABCD} in segment 2, and its physical address can be calculated by adding \hex{ABCD} to the segment's start address: \hex{ABCD} + \hex{800000} = \hex{80ABCD}.

If limits are not checked, then there is the special case of overflow (when the sum of relative address and base address exceed the maximum addressable value). Consider for example the case of a CPU with a 32-bit address bus (which allows addresses ranging from \hex{0} to \hex{FFFFFFFF}. If the base address is set to \hex{E0000000} and the relative address \hex{40000000} is used, the processor will calculate the sum \hex{120000000}---which is not a 32-bit value. Overflow occurs, and the $33^{\textrm{rd}}$ bit is dropped, the resulting absolute 32-bit address is \hex{20000000}. You will see an application of this behavior in the next chapter.

Figure~\ref{img:segmentation-adder-limitcheck} shows the additional integration of a limit check.

\begin{figure}[ht!]
\centering
\includegraphics[width=1.0\textwidth]{pics/segmentation-adder-limitcheck.pdf}
\caption[Segmentation: With segment limits.]{An additional limit value guarantees that segment borders are never overstepped.}
\label{img:segmentation-adder-limitcheck}
\end{figure}

We will discuss two concrete segmentation mechanisms in the next chapter: The Intel 8086 processor used a segmentation technique that is still available in today's Intel-compatible processors for compatibility reasons (starting with the 80286, it has been called \emph{Real Mode}\index{real mode}\index{Intel x86 architecture!real mode}; see Section \ref{sec:intel:segmentation:realmode}), and the Intel 80286 and 80386 processors introduced two (similar) improved segmentation models that were and are used in \emph{Protected Mode}\index{protected mode}\index{Intel x86 architecture!protected mode} (see Section \ref{sec:intel:segmentation:protectedmode}).

\pagebreak

\subsection{Fragmentation}
\label{sec:memory:fragmentation}%

\index{memory management!fragmentation}\index{fragmentation}%
When memory is allocated dynamically, that can lead to a waste effect called \emph{fragmentation} that we already mentioned. It comes in two varieties:

\begin{description}
\item[Internal Fragmentation] \index{internal fragmentation}\index{fragmentation!internal}means that a memory area was allocated that is larger than the actually needed area. For example, in the Buddy System example, the request for 90 KByte was served with a 128 KByte chunk of memory. If we assume that exactly 90 KByte are needed, then an additional 38 KByte were allocated which will not be used by the requester, and they also cannot be used for anything else since they are marked as used (from the allocator's point of view).
\item[External Fragmentation] \index{external fragmentation}\index{fragmentation!external}is the effect that can be best seen in the general dynamic allocation systems (e.\,g., Best Fit or Quick Fit): After a longer sequence of allocating memory chunks and returning them there will be small memory areas which are marked as free, but are too small to be useful. In that case it is possible that the total free memory size is quite large, but even a modest memory request will fail because there is no sufficiently large contiguous chunk of memory.
\end{description}

To summarize the two types, internal fragmentation refers to unused memory that is part of allocated chunks, whereas external fragmentation represents free, non-allocated memory that is too small to satisfy a typical request (see Figure~\ref{img:fragmentation-types}).

\begin{figure}[ht!]
\centering
\includegraphics[width=.98\textwidth]{pics/fragmentation-types.pdf}
\caption{Internal vs.\ external fragmentation.}
\label{img:fragmentation-types}
\end{figure}

External fragmentation can be cured via a process that is called \emph{compaction}\marginnote{compaction}\index{compaction}\index{fragmentation!compaction} (also: \emph{defrag}-\emph{mentation}\index{defragmentation}\index{fragmentation!defragmentation}) where the memory management system detects the fragments and reorders the allocated memory chunks so that those fragments disappear; after compaction all (or most) allocated chunks will be located right behind one another, and all free areas will have moved to the end of the physical memory (Figure~\ref{img:compaction}). But this approach is costly (because it requires intensive memory copy operations) and it is only applicable if the processes which use the memory can cope with relocation of their memory.

\begin{figure}[ht!]
\centering
\includegraphics[width=.98\textwidth]{pics/compaction.pdf}
\caption[Compaction of externally fragmented memory.]{Compaction cures external fragmentation but is costly and needs to be repeated whenever the fragmentation level is high again.}
\label{img:compaction}
\end{figure}



\section{Non-Contiguous Allocation}
\label{sect:non-contiguous-allocation}%

\index{memory management!non-contiguous allocation}\index{non-contiguous allocation}%
So far we have seen several examples for contiguously assigning memory or disk space to processes or files. That allows for a very simple handling of accesses, because only an absolute start address and the length of a (memory or disk) partition must be known.

However, since this leads to strong limitations in usability, all modern operating systems use a more flexible approach both for process memory and files, assigning memory frames and harddisk blocks non-contiguously.

Non-contiguous allocation makes things more complicated, and for process memory it is worse than for files:

\begin{itemize}
\item If a file consists of several, non-contiguous blocks which are spread all over the disk, there has to be a list of blocks that tells the operating system where to find the data. When trying to read a specific byte from the file, the address within the file has to be translated into a disk block and a relative address inside that block. It also means that reading a file from beginning to end can no longer be achieved by reading several disk blocks in their natural order, but the operating system has to jump from one location to another all the time, so several disk head movements are involved which slows the access.

\item With memory things become even more complicated: Here also some kind of table is needed that will be used for address translation, but memory access is different from file access. A program performs a lot of memory access operations: every (absolute) jump to another instruction in the program code, every direct data access (where the content of some memory address is loaded into a CPU register) and similarly each indirect memory access (e.\,g. {\tt mov [edx], eax}) works with an absolute address.
\end{itemize}

A process could be told the absolute address ranges of the memory locations it was given access to, imagine it has a list like this:

\begin{enumerate}
\item region 1: \hex{10000}--\hex{10FFF} (4 KByte)
\item region 2: \hex{14000}--\hex{15FFF} (8 KByte)
\item region 3: \hex{20000}--\hex{2FFFF} (64 KByte)
\end{enumerate}

Assume further that the program code is 6 KByte long and the rest of the memory will be used for data (we ignore the stack in this simple example). Then the program code will have to be split between the first and second region, and the data between the second and third one. (For this example we also ignore that it might be a better approach to store all of the program code in the second region and use the first and third one for data, especially since the program might not know the precise number and sizes of partitions before it actually gets them.)

If there is a jump instruction in the program code that leads from the front part of the code to the rear part, it will cross region borders. Also when the programs needs to access its data it has to be aware whether the currently needed data reside in the second or in the third region.

All these problems can be solved with a method called \emph{address relocation}\marginnote{address\\ relocation}\index{address relocation}\index{memory management!address relocation}. When using this system, at compile time a list of address references will be generated. It lists all references to data or instruction addresses that are used within the program code. At load time the system must know the maximum memory demand of the program, assign memory regions and then use the relocation list to adjust the memory references to the concrete region locations.

While this means some overhead during compile and load time, it works quite well, but only for static addresses. If the program dynamically ``acquires'' memory using some function such as {\verb#malloc()#}, then this function will also have to be informed about the memory regions and return proper addresses.

Another problem with this approach occurs when the operating system allows a process to be swapped\marginnote{swapping}\index{swapping|seealso {paging}}%
\index{swapping}\index{memory management!swapping} out to disk (i.\,e., all of its memory is written to the disk) and swapped in again later: When swapping it back in, the process may be given different regions than before, and then all address references have to be relocated again, this time not only considering the addresses that were stored in the relocation table, but also the dynamically assigned addresses.

The relocation approach makes it hard to protect one process' memory against accesses by another process, because the address calculation in the relocation step only guarantees that static address references are fixed at program start; the program would however be free to access any part of the memory unless the operating system somehow checked each memory access against the region list for this process. The simple start and length registers from the contiguous case would no longer be sufficient, because there are possibly a lot of regions if a process uses much memory.

Note that for files a similar scheme can be adopted, and it causes much fewer problems: typical operations on a file are seek, read and write operations, and they will require translation of linear file positions (thinking of a file's bytes as numbered from 0 to $n-1$ for a file size of $n$) to absolute disk addresses inside the disk partitions. This translation occurs with every single access to the file. It could be avoided by also using some kind of address relocation as in the memory case, but the gained performance would not be worth the extra effort, because address translation is fast in comparison to disk access.


\felix
\subsection{Virtual Memory}

\index{memory management!virtual memory}\index{virtual memory}%
A \emph{\vindex{virtual memory}} is an abstraction of physical
memory. Roughly speaking, a virtual memory is an array of memory
cells. Usually the size of the virtual memory corresponds to the
maximum addressable space allowed by the hardware.  A computer may
handle multiple such address spaces (and therefore virtual memories)
at the same time.  They are used to encapsulate effects of
programs on memory. Briefly spoken, every program has its own virtual
memory and no program can (easily) access the virtual memory of
another program.

Physical memory is \emph{physical}\index{physical memory}\marginnote{physical\\ vs.\ virtual}, 
i.\,e., it consists of hardware
circuits that must be produced, bought and installed on the mainboard
of the computer.  Virtual memory can be created and destroyed on
demand. This is its main distinguishing feature from physical memory.
Virtual memory is \emph{virtual}, i.\,e., it is a construct which exists
only in software. A computer can have much more virtual memory than
physical memory. In such cases, a mechanism ``multiplexes'' the
available physical memory resources to possibly multiple virtual
memories.

In this section we will have a look at how virtual memory can be
implemented. We will look at the idea of address translation in
Section~\ref{sec:address:translation} and sketch the requirements for
virtual memory from a user's point of view in
Section~\ref{sec:virtual:memory:requirements}. We will go through
the three historic stages of virtual memory development. In essence,
these stages reflect the increasing hardware support for virtual
memory in computer architecture. 
\black 
You have already seen the first technique (segmentation, in 
Section~\ref{sec:memory:segmentation}) which provides modified
addresses by adding a (segment-dependent) base address to logical addresses.
\felix
Early approaches basically organize physical memory in a slightly more 
convenient way, but the transparency of this mechanism is naturally limited. 
Here, we focus on virtual memory implemented with
the help of an external \vindex{memory management unit} (MMU\index{memory management unit}). This
approach is the most common one and is also the one chosen
in the implementation of \Ulix{} which is described in
Section~\ref{sec:paging:ulix}.


\subsection{Address Translation}
\label{sec:address:translation}

\index{memory management!address translation}\index{address translation}%
\index{virtual memory!address translation}%
The term \emph{\vindex{address space}}\marginnote{address space} refers to a space of
\index{memory management!address space}\index{virtual memory!address space}\index{address space}%
addressable units in a computer. Every computer based on the
Von-Neumann architecture\index{von-Neumann architecture} (named after John von Neumann\index{von Neumann, John}) has at least one (physical) address space.
Its size depends on the size of the address bus. 
If the computer has 32
bits on the address bus, the hardware can address $2^{32}$ distinct
units of memory. If one such unit is a byte, the architecture supports
an address space of 4~GByte.

Having 32 bits on the address bus, addresses are 32-bit values between
\hexaddr{0000.0000} and \hexaddr{FFFF.FFFF}.  In physical memory, not all
addresses may be backed by real memory cicuits on the mainboard. 
(Access to such an address usually causes a specific type of
interrupt on the CPU or returns an undefined value when it is accessed.)
If we view the physical address space of a computer it therefore
may have ``holes'' (see left side of Figure~\ref{fig:address:decoder}).

\begin{figure}
  \centering
  \includegraphics[width=0.75\textwidth]{pics/address-decoder-logic.pdf}
  \caption[Address translation via an address decoder logic.]{Logical view of physical address space (left) and address
    translation via address decoder logic (right).}
  \label{fig:address:decoder}
\end{figure}

\pagebreak
But how does the machine ``know'' where memory circuits are and where
not? The hardware internally stores a mapping of parts of the address
space to memory circuits in the form of an 
\emph{\vindex{address decoder logic}}\marginnote{address deco-\\ der logic}. 
This logic is a simple boolean circuit that
translates an address on the address bus into one-out-of-$n$
bits. This bit is used to select the particular memory circuit on the
mainboard via its \emph{\vindex{chip select}} pin. Only a circuit
with an enabled chip select pin will load or store data which travels
over the data bus. For example, if the address \hexaddr{0000.0000} is put
on the address bus, the logic enables (only) the memory chip that is
responsible for serving that address (see right side of
Figure~\ref{fig:address:decoder}).

Not only memory chips can be activated through such a logic. Also
external devices can be mapped into the physical address space.
Through this mechanism, they can provide their programming registers
just like normal memory cells which can be read and written by the CPU
using normal load and store commands. This is the basis for
\emph{\vindex{memory-mapped I/O}}\marginnote{memory\\ mapped I/O}
\index{memory management!memory-mapped I/O}%
 (which we do not discuss in this book,
except for the video adapter's screen buffer).

The effect of such an address decoder logic is that the mapping of
memory chips to physical addresses is literally \emph{hardwired} into
the system. This mapping cannot easily be changed. Therefore,
programming physical memory directly makes it necessary to know the
precise whereabouts of the structure of physical memory. This is only
advisable where the physical address space is rather small and
well-structured. In the old days with less memory, operating systems
like MS-DOS\index{MS-DOS operating system} could afford to work directly on physical memory:
Their programming manuals contained detailed accounts of where RAM and
ROM were placed in the physical address space. With today's 32 or 64
Bit desktop systems this is not advisable anymore. It is far better to
use a homogeneous \emph{virtual} address space which is independent of
the precise placing of memory chips in the physical address space.
This can be achieved through an \emph{\vindex{address translation}}
step performed before the address decoder logic kicks in.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{pics/address-translation.pdf}
  \caption{Address translation for virtual memory.}
  \label{fig:address:translation}
\end{figure}

Address translation needs some form of hardware support. The idea is
depicted in Figure~\ref{fig:address:translation}: The \emph{virtual address}\index{virtual address}
put on the address bus is taken and translated by the hardware using
some translation table to a physical address which is fed into the
decoder logic to select the right memory chip. This translation
requires additional hardware/software effort. But from general experience
this pays off quickly given the simplicity and homogeneity of the virtual 
address space. Program execution can now be performed entirely in the
virtual space. An additional advantage is that the address translation
is flexible: It can be redefined in \emph{software}.




\subsection{Virtual Memory Requirements}
\label{sec:virtual:memory:requirements}

A \emph{\vindex{virtual memory}} is a homogeneous sequence of memory
cells together with their content. It can be regarded as
a ``well-behaved'' address space with its content.  The homogeneity is
what makes the address space nice: All memory cells are considered to
return well-defined values. So in contrast to physical memory there
are no ``undefined'' regions of storage in a virtual memory.



\subsubsection{Types of Data}


A virtual memory completely defines the memory context of a running
application. This means that it has to provide all necessary data for
executing the program. Three types of data are commonly distinguished:
%
\begin{enumerate}

\item Program code\pindex{program code}\pindex{code region} (also
  called \emph{\vindex{text}})\marginnote{text}. This refers to all instructions to be
  executed by the CPU.

\item Data.\pindex{data region} This refers to the contents of all
  variables used by the program.

\item Stack.\pindex{stack region}\marginnote{stack} This refers to data used to manage
  subroutine calls.

\end{enumerate}
%
Usually these different types of data are collected and stored in
different regions of the virtual memory.

The data region is further separated into two areas. The first area is
for \emph{\vindex{static data}}\marginnote{static data}. Static data are variables and data
structures which are known at compile time of a program and exist
throughout the execution of the program. Examples of static data are
global variables. The second area is for \emph{\vindex{dynamic data}}
which is usually called the \emph{\vindex{heap}}\marginnote{heap}. The heap holds
variables which are dynamically allocated at runtime by the program
(e.\,g., using [[malloc]] in C or [[new]] in C++ or Java). Data 
on the heap usually depends on program parameters which are only known
at runtime.

For completeness we note that a certain form of dynamic data is also
stored on the stack. Compilers often generate code that stores local
variables of subroutines on the stack. This is especially noteworthy
for recursive functions. Also, parameters are often passed to
subroutines via the stack.

\subsubsection{Address Space Organization}
\label{sec:address:space:organization}

\index{address space!organization}%
From a user's point of view we would like to organize virtual memory
in a clear and tidy way. In practice, text, stack and data areas are
located in virtual memory in a fixed order (see
Figure~\ref{fig:address:space:organization}). Starting at address 0 we
find the text area with all program code followed by static
data. These areas are both fixed in size throughout the lifetime of
the program. The remaining part of virtual memory is divided up
between the more dynamic parts: heap and stack. The heap is usually
placed right behind static data at the ``lower'' end of the free
space. The stack is located on the opposite side. Note that while the
heap grows in an intuitive way towards rising addresses, the stack
grows rather unintuitively into the direction of falling addresses.
In this way, the free space
between heap and stack is utilized in the most effective way since any
memory cell can either be used by the stack or by the heap.  Imagine
the alternative where the stack would have been placed ``half way'' up
the virtual memory just to allow it to grow in the direction of rising
addresses. In such a case, the free memory cells could only be used by
either stack \emph{or} heap.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{pics/organization-of-process-address-space.pdf}
  \caption{Organization of the virtual address space.}
  \label{fig:address:space:organization}
\end{figure}

As we see later in Chapter~\ref{chap:ulix:threads}, it may be necessary to
provide multiple stacks in virtual memory (for the same program).
In such a case we try to utilize the virtual memory as efficiently
as possible by dividing up the remaining space into equal parts for
each stack. This maximizes the distance between each stack. 

\begin{figure}
  \centering
  \includegraphics[width=0.95\textwidth]{pics/organization-of-process-address-space-multi-stack.pdf}
  \caption{Organization of the virtual address space with multiple stacks.}
  \label{fig:address:space:organization:multiple:stacks}
\end{figure}

\pagebreak

Looking at Figure~\ref{fig:address:space:organization} and especially
Figure~\ref{fig:address:space:organization:multiple:stacks}
immediately shows a problem which arises with this memory layout:
Dynamic data areas can grow to such an extent that they collide with
others. In normal circumstances (i.\,e., one heap and one stack) this is
not a problem because the free space between them is very large.  As
an example, consider the classic 4~GByte of virtual memory, a 20~MByte
program (text and data) and initially empty stack and heap. The gap
which opens up between them has a size of 4076~MByte. This is quite
some memory to allocate in heap and stack. Of course, the probability
that heap and stack collide multiplies with the number of stacks.  If
a collision is not avoided it usually causes strange and hard to track
down runtime errors. As we will see later, it is possible to
effectively protect from such collisions with hardware support.

\subsubsection{Amount of Useable Virtual Memory}
\label{sec:useable:virtual:memory}

\looseness=-1
Without any additional help, the amount of effectively useable virtual
memory cannot be larger than the amount of physical memory installed
in the computer. Fortunately, most programs do not really use a lot of
the available virtual memory so that you don't always have to equip
your system with a full (e.\,g., 4~GByte) main memory. However, using
some tricks it is possible to ``simulate'' more physical memory using
secondary storage. The details of this mechanism will become clear
later when we discuss page-based virtual memory. The main idea
however is to add special information to the translation table and use
main memory as a \emph{cache}\marginnote{cache} for secondary storage. If a part of
virtual memory is not in the cache, program execution is interrupted,
the missing data is brought into the cache, and the program resumes
operation thereafter. Note that if something is brought into main
memory in this process, other information may have to be written out
of the cache, i.\,e., from main memory to secondary storage. This
performance overhead is the price you have to pay. The advantage of
this scheme is that secondary storage hardware is much cheaper than
main memory chips. In well"=designed systems it is possible to
simulate a substantial amount of main memory using secondary storage
without much performance overhead.


\black
\subsubsection{Protection of Code, Data and Stack}
\label{sec:protection:of:code:data:stack}

\index{memory management!access control}\index{memory management!protection}\index{protection of code, data and stack}%
\looseness=-1
We often want to make sure that certain memory areas are only used in the specific way they were intended to. For example, the program code of a process should not be modified, but only executed (which requires only read access). On the other hand, data areas must be changeable, but we don't want a process to treat data as code and start executing it. Some malware works by storing binary code in the stack of a process and then jumping to that code; if the system does not accept a jump to a stack address, this type of attack is impossible. We would also like to differentiate between what we will call \emph{user mode}\marginnote{user mode} (a process executing its own code) and \emph{kernel mode}\marginnote{kernel mode} (the process executing a service function inside the kernel) and grant access to specific addresses only when the system is in kernel mode.

Thus, it makes sense to have access attributes which allow reading, writing and executing and which may also depend on the current (user/kernel) mode. When we set up the memory for a new process we should be able to tell the system which memory areas can be accessed in which ways.


\felix
\subsubsection{Summary of Requirements}

To summarize, here are the main requirements we have for virtual
memory from a user's perspective:
% 
\begin{itemize}

\item Virtual memory should provide a homogeneous address space.

\item The size of virtual memory should be independent of the size of
  physical memory in the system.

\item Virtual memory should be able to protect different types of
  data from certain forms of access (e.\,g., text from being written).

\item Collisions of heap and stack should be detected and avoided
  whenever possible.

\end{itemize}
%
If the system provides multiple virtual memories (one for each
program), then we have the additional requirements:
%
\begin{itemize}

\item Virtual memories should be protected from one another, i.\,e., a
  program running in one address space should not be able to access
  the other address space and vice versa.

\item The physical resources of the system should be distributed in a
  fair manner between the existing virtual memories.

\item Physical memory should be used efficiently. Especially any type
  of fragmentation should be avoided.

\end{itemize}

\begin{figure}[b!]
  \centering
  \includegraphics[width=0.95\textwidth]{pics/translation-table.pdf}
  \caption{Schematic view of a refined translation table for virtual memory.}
  \label{fig:translation:table}
\end{figure}
% source for disk logo:
% http://commons.wikimedia.org/wiki/File:Oxygen480-devices-drive-harddisk.svg
% license: LGPL version 3
% Oxygen 4.8.0 icon from "Devices" group


\looseness=1
As a glimpse on to the implementation of the above requirements we
return to the idea of a translation table which was previously
discussed in Section~\ref{sec:address:translation}, this time with
some more details. Figure~\ref{fig:translation:table} depicts the idea
of a translation table with the additional information necessary to
implement all above requirements. The table not only holds information
about the physical address which belongs to the virtual address. It
also contains flags that indicate access restrictions (like read,
write, execute) as well as pointers to secondary storage should this
memory location be stored there. Note that the figure only gives a
schematic view which is very simplistic, even impossible to realize.
After all, the translation table must somehow fit into (physical) main
memory to be useable. If we need one (physical) memory cell (at least)
to store the translation information for every (virtual) memory cell,
we could never simulate more virtual memory than we have physical
memory available. The main challenge therefore lies in implementing
this concept in a way such that the usage of memory as well as the
translation time is minimized.


\black
\subsection{Page-based Virtual Memory}
\label{sec:page:based:virtual:memory}

\index{memory management!page-based virtual memory}\index{page-based virtual memory}%
All modern operating systems use a \emph{virtual} memory management mechanism called \emph{paging}\marginnote{paging}\index{paging}. The idea behind paging is to give each process a virtual memory space that is addressed contiguously and linearly (starting with an address 0 and ending with an address $size-1$) and that is partitioned into a set of \emph{memory pages}\index{page}. All pages have the same size, say, 1 KByte, and they are mapped to \emph{page frames}\index{frame} which are equally sized chunks of the real memory. With the help of a page table each access to a virtual address is translated to a real address by first calculating to which page the address belongs, then looking up the corresponding page frame via the page table and finally locating the relative position within that page frame (see Figure~\ref{fig:pages:and:page:frames})---the technical details of this approach are what we discuss in the rest of this chapter.

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.9\textwidth]{pics/pages-and-page-frames.pdf}
  \caption{Pages and page frames.}
  \label{fig:pages:and:page:frames}
\end{figure}

This approach makes compiling an application very easy: All references to addresses, be they jump instructions or data accesses, can be stored with absolute addresses inside the program, and no relocation takes place when loading the program. Instead each memory address will be translated using the page table. 

When, for whatever reasons, locations of page frames have to be changed, it only takes a correction of the page table to make sure that the program continues to be runnable. This scheme also allows for individual pages to be removed from memory altogether and stored on the hard disk for later retrieval---this is called paging as well, and it is not to be confused with swapping a process' memory (meaning: writing all of it to the disk). A process that has some of its pages paged to disk can still be run, whereas a process that was swapped to disk must first be swapped back in before it can resume action. However, the disk space reserved for paging is often called swap space for historical reasons. E.\,g. the Linux\index{Linux} operating system calls paging partitions or files swap partitions and swap files, but it does not implement swapping; it pages.


\felix

Although page frames and pages have the same size, they are totally
different concepts. A page is a logical unit of virtual memory. Any
virtual address resides in some page. A frame is a concrete area of
physical memory waiting to hold some page. A large part of physical 
memory will consist of frames, i.\,e., will be devoted to storing
pages. But not \emph{all} physical memory is part of some frame.


\subsubsection{Hardware Support}

In contrast to segment-based virtual memory, page-based virtual memory
needs no hardware support on the CPU, i.\,e., no special registers. This
means that this type of virtual memory can (at least in principle) be
implemented with any CPU on the market. In a sense, the hardware
support is ``outsourced'' to a dedicated device called the
\emph{\vindex{memory management unit}} (MMU)\pindex{memory management unit}\marginnote{MMU}.
The MMU can be thought of as a hardware address translator that sits
on the address bus and divides it into two parts. One part between the
CPU and the MMU is considered the ``virtual address'' part of the
address bus, the other (between MMU and main memory) is the ``physical
address'' part. When the CPU issues a virtual address onto the
address bus, the MMU transparently translates it into a physical
address on the other side, i.\,e., it changes the value of the
bits as the address passes through the MMU from one to the
other side.

To tell the truth, the MMU doesn't change \emph{all} the address bus
bits, but only the higher order bits. The $k$ lower order bits remain
unchanged. The value $d$ represented by the $k$ lower order bits is
called the \emph{\vindex{offset}}\index{page!offset}\marginnote{offset} of the address (see
Figure~\ref{fig:virtual:address}). The idea of this separation is the
following: The higher order bits of the virtual address implicitly
refer to the \emph{page}\marginnote{page number}\index{page number}\index{page!page number} that the virtual address is located in. The
$k$ lower order bits then are interpreted as the \emph{offset} of the
address within the page, i.\,e., the distance from the beginning of the
page to the address.


\begin{figure}[h!]
\begin{centering}
\begin{bytefield}[bitwidth=4.2mm]{32}
%\bitheader[b]{0-31}\\
\bitbox{20}{page number}
\bitbox{12}{offset}
\end{bytefield}
\caption{Structure of virtual address.}
\label{fig:virtual:address}
\end{centering}
\end{figure}


The interpretation of the address in page number and offset has
several consequences. The main one is that the size of a page must be
a power of 2. If the $k$ lower order bits represent the offset within
a page, the number of addresses in a page is exactly $2^k$. For a
value of $k=10$, a page would contain exactly $2^{10}=1024$ Bytes.
The value of $k=10$ is a typical value in practice where there are 32
bits on the address bus. This case is depicted in
Figure~\ref{fig:virtual:address:k10}. It shows that the $k$ lower
order bits (those with index 0 to 9) define the offset $d$ and the
remaining $32-10=22$ bits (with indexes 10 to 31) define the page
number $p$.

\begin{figure}[h!]
\begin{centering}
\vspace{2mm}
\begin{bytefield}[bitwidth=4.2mm]{32}
%\bitheader[b]{0-31}\\
\bitheader[b]{0,9,10,31}\\
\bitbox{22}{page number (22 bits), $p$}
\bitbox{10}{offset ($k = 10$ bits), $d$}
\end{bytefield}
\caption[Virtual addresses with a 10-bit offset.]{An address consists of a page number and an offset. This example uses $k=10$.}
\label{fig:virtual:address:k10}
\end{centering}
\end{figure}


\subsubsection{Page Descriptors and Address Translation}
\label{sec:page:descriptors}

The central data structure to manage pages in virtual memory is the
\index{virtual memory!page descriptor}
\emph{\vindex{page descriptor}}\marginnote{page descriptor}. There is exactly one page descriptor
per page in virtual memory. All page descriptors are held within the
operating system in a big internal table called the 
\emph{\vindex{page table}}\marginnote{page table}\index{virtual memory!page table}. 
The page descriptor contains all information necessary to
locate the contents of the (virtual) page in physical memory,
therefore knowledge of the starting address of the page table is the
key to performing address translation. So to enable address
translation, the \vindex{page table register} [[PTR]]\tindex{PTR} of the MMU is
pointed to that starting address (see
Figure~\ref{fig:address:translation:using:page:descriptors}). Assuming
that there is just one big table, the MMU can now directly locate the
page descriptor of page $p$ by doing a small address calculation.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{pics/address-translation-using-page-descriptors.pdf}
  \caption{Address translation using page descriptors.}
  \label{fig:address:translation:using:page:descriptors}
\end{figure}


\pagebreak

Given the size of a page descriptor to be $x$ bytes, then the page
descriptor of page $p$ has the address:
%
$$[[PTR]] + p \cdot x$$


As mentioned above, a page descriptor is a data structure that holds
all necessary information to manage the associated virtual page.  Here
is an overview over the types of information that can be stored in a
page descriptor of page $p$:
%
\begin{itemize}

\item Since the page descriptor is used to perform address
  translation, it must contain a pointer to the \emph{physical} page
  frame of page $p$. The MMU adds the offset of the virtual address to
  this pointer to yield the actual physical address of the virtual
  address in question.

\item Since page frames act as a \emph{\vindex{cache}} for the
  contents of pages, certain management bits must be present to handle
  cache contents. Recall that main memory is regarded as a cache for
  pages stored on secondary storage (see
  Section~\ref{sec:useable:virtual:memory}). The first such bit is the
  \emph{presence bit}\marginnote{presence bit} 
  (P bit)\pindex{presence bit (P bit), page descriptor}. 
  The P bit indicates whether or not the page contents are
  present in main memory.

\item The next management bit is the \emph{reference bit}\marginnote{reference bit}
  (R bit)\pindex{reference bit (R bit), page descriptor}. Roughly speaking, it indicates
  whether or not the page descriptor was referenced within some period
  of time. The R bit is set by the MMU with every access to the
  page descriptor in main memory. Technically speaking, the reference
  bit is not actually an essential management bit of the cache, but
  rather a bit which is used to optimize the cache performance. This
  will be discussed later in Section~\ref{sec:page:replacement}.

\item A vital cache management bit is the \emph{dirty bit}\marginnote{dirty bit}
  (D bit)\index{dirty bit (D bit), page descriptor}, sometimes called
  \emph{\vindex{written bit}}. It is set by the MMU whenever the
  contents of page $p$ are written. The D bit is important since it
  solves the \emph{\vindex{cache coherence problem}}\marginnote{cache coherence}: Contents of the
  cache (i.\,e., main memory) and secondary storage can diverge if main
  memory is written and secondary storage not (due to performance
  reasons). The D bit indicates exactly when this divergence exists.
  Pages which have diverged in main memory eventually have to be made
  coherent with secondary storage again.

\item The page descriptor also contains 
  \emph{\vindex{protection bits}}\marginnote{protection bits}
  used to manage the type of access allowed to this page. 

\item The page descriptor usually also contains several multi"=purpose
  bits which can be used by the operating system for different means.

\end{itemize}

Ignoring protection and multi"=purpose bits, this is what a page
descriptor could look like in code:

%nouse
<<tentative declaration of page descriptor>>=
typedef struct page_desc_struct {
  void *frame_addr;                // address of page frame for this page
  unsigned int present    : 1;     // presence bit
  unsigned int referenced : 1;     // reference bit
  unsigned int written    : 1;     // dirty bit
} page_desc;
@

To summarize, we now recall how a successful page translation finally
happens (see Figure~\ref{fig:successful-page-translation}): 
%
\begin{enumerate}

\item The CPU accesses a virtual address $v$ on the address bus. The
  virtual address consists of a page number $p$ and an offset $d$ in
  the page.

\item The MMU uses the page number $p$ and the base address of the
  page table (stored in [[PTR]]) to locate the page descriptor of the
  page.

\item Using the page frame number $k$ stored in the page descriptor,
  the MMU adds the offset $d$ to form the final physical address in
  main memory.

\end{enumerate}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{pics/successful-page-translation.pdf}
  \caption{Successful page translation.}\vspace{-3mm}
  \label{fig:successful-page-translation}
\end{figure}

What can potentially go wrong during page translation? The simplest
error condition is that the virtual memory location doesn't (yet)
exist in physical memory. This means that the page table doesn't know
where it should point to. This information is encoded in a special
\emph{\vindex{null page descriptor}}\marginnote{null page\\ descriptor}. 
If the MMU tries to translate an
address and finds such a null page descriptor in the page table it
signals an interrupt to the CPU which must be handled immediately.

\enlargethispage{3mm}
The next error condition concerns the protection bits. The MMU checks
whether the current access context is allowed by the protection bits.
For example, if the CPU wants to write something to a virtual address
and the protection bits don't allow write access, then again the MMU
raises an interrupt with the CPU.

The final error condition which we discuss here refers to the fact
that main memory is just a cache for secondary storage: a
\emph{\vindex{cache miss}}\marginnote{cache miss} may happen. What is a cache miss in this
context? It means that the page accessed by the current instruction
exists but it currently isn't in main memory (the cache). This is
indicated by the presence bit (P bit)\index{presence bit (P bit), page descriptor} in the
page descriptor. If the P bit is not set, an interrupt is raised
by the CPU. In effect the interrupt handler must try and load
the page contents back in to main memory so that the application
that wished to access the page contents can continue to operate.
More details on how this works will follow later.



\subsubsection{Page Descriptor Trees}
\label{sec:page:descriptor:trees}

\begin{figure}[b!]
  %\centering
  \hspace{-0.23\textwidth}\hspace{2mm}%
  \includegraphics[width=1.235\textwidth]{pics/multi-level-page-table.pdf}
  \caption[Multi-level page table example, page size = 1 byte.]{Example of a multi-level page table that maps individual virtual addresses to physical addresses (page size: 1 byte).}
  \label{fig:multi:level:page:table}
\end{figure}

In contrast to the naive address translation described at the end of
Section~\ref{sec:virtual:memory:requirements} where we had one entry
in the translation table per virtual address, the idea of pages reduces the
size of the page table dramatically. The larger the page size, the
smaller the page table because translation information and protection
bits etc.~are stored per page. However, page tables still have
considerable size. The problem is partly a result of the memory layout
sketched in Section~\ref{sec:address:space:organization} because code,
data and heap reside on one end of virtual memory and the stack on the
other end. This means the page table must \emph{always} cover
\emph{all} pages in virtual memory. As an example, imagine you need eight
bytes for each page descriptor (which is not much), a 12-bit offset for
pages (giving a page size of 4~KByte, rather large) and a 32-bit
address bus. In total you have $2^{20}$ entries in the page table,
each uses eight bytes, yielding a page table size of 8~MByte. Small computer
systems with only 16 or 64~MByte of physical memory could only hold
one or two page tables (at most) since additionally
the \emph{contents} of pages also must be stored in main memory.

Given the fact that most programs have a large void space in virtual
memory between heap and stack, there is much potential to save
storage space here. Recall the example we discussed in
Section~\ref{sec:address:space:organization} where a program
of 20~MByte had a gap of almost 4~GByte in virtual memory.
If a page had the size of 1~KByte, then this program would need
``only'' 2000 entries (out of $2^{20}$), meaning that more than
99.5\,\% of the page table is not used.

The common solution employed in operating systems is to have
\emph{\vindex{hierarchic page tables}} or 
\emph{\vindex{page descriptor trees}}\marginnote{page descrip-\\ tor trees}. 
A single page table is regarded as a special
case of a hierarchic page table. Each entry in the page table is
either a page descriptor or a pointer to another page table.

The idea is to start with a small page table (i.\,e., a page table with
a small number of entries). Each such entry is responsible for
covering a relatively large part of the virtual address space. Each
entry can be refined by another page table in a similar way. For
example in Figure~\ref{fig:multi:level:page:table}, virtual memory has
16 addresses (numbered \bin{0000} to \bin{1111}). The first level page 
table has four entries. Each entry
is responsible for handling a quarter of the entire virtual address
space, i.\,e., four addresses.  An entry at the first level then points to
a second level page table with again four entries but which deals with
the details of address translation. In this example you can already
see that a full (single level) page table would have needed 16 page
descriptors. In the hierarchic version we need only three small tables
with four entries each, i.\,e., twelve page descriptors altogether.

\black
A real-world example from the Intel i386 architecture shows the effect even
more dramatically: The Intel processor uses 4-KByte-sized pages, thus a
virtual address is split into a 20-bit page number and a 12-page offset.
Using a hierarchical page table, it is possible to split the 20 page number 
bits in two halves.

Following Intel terminology, the first ten bits are used as index into
the \emph{page directory}\marginnote{page directory}\index{page directory}, and the second ten 
bits reference a \emph{page table}\marginnote{page table}.

The first ten bits in this example can be called upper page number, the last ten bits lower page number (Figure~\ref{fig:address-paging2}). The effect on the page table size is a reduction to roughly the square root, i.\,e., from $2^{20}$ to $2^{10}$ entries. (If the size of one entry were one byte, the reduced table would have exactly square root size.)

\begin{figure}[h!]
\begin{centering}
\begin{bytefield}[bitwidth=4.2mm]{32}
\bitheader[b]{0,11,12,21,22,31}\\
\bitbox{10}{page directory entry}
\bitbox{10}{page table entry}
\bitbox{12}{offset}
\end{bytefield}
\caption[Paging on the Intel i386 architecture.]{On the Intel i386 architecture, paging uses a (per-process) page directory whose entries point to page tables. This constitutes a hierarchical page table with 20 bits for the page number and twelve bits for the offset.}
\label{fig:address-paging2}
\end{centering}
\end{figure}

Notice however that while going from a million entries to 1000, this introduces 1000 secondary page tables. If a process actually used this much RAM, all the secondary page tables would be filled, and no space would be saved. (Actually, in that case you get an increased amount of space used for tables, because the primary table counts extra.) But normal processes will not have such enormous memory demands, and this saves a lot of space because secondary page tables can be created on demand---as long as a process uses only a few kilo- or megabytes of RAM, only the first few secondary page tables need exist.


\felix

\subsubsection{Page Descriptors and Page Table Descriptors}

In general, a hierarchic page table is a tree of
descriptors. Descriptors can be of two forms: 
%
\begin{itemize}

\item \emph{Page descriptors}\pindex{page descriptor}\marginnote{page descriptor} (PD)\pindex{PD
    (page descriptor)} are the ``leaves'' of the tree. They are page
  descriptors in their original sense, including information about the
  location of the page frame and protection bits.

\item \emph{Page table descriptors}\marginnote{page table\\ descriptor}\pindex{page table descriptor}
  (PTD)\pindex{PTD (page table descriptor)} are the ``inner nodes'' of
  the tree. They basically are pointers to descriptors (either page
  descriptors or page table descriptors).

\end{itemize}
%
The resulting tree-like structure is visualized in
Figure~\ref{fig:tree:structure:of:descriptors}.

\begin{figure}[b!]
  \centering
  \includegraphics[width=1.0\textwidth]{pics/tree-structure-of-descriptors.pdf}
  \caption{Tree structure of descriptors.}
  \label{fig:tree:structure:of:descriptors}
\end{figure}

Since we know what is part of a page descriptor already (see
Section~\ref{sec:page:descriptors}), what is part of a page table
descriptor? Generally we can find these entries:
%
\begin{itemize}
\item A flag indicating the \emph{type} of the descriptor, i.\,e., 
  is it a page descriptor or a page table descriptor. In fact, also
  every page descriptor needs this field.

\item The address of the page table which this page table descriptor
  points to.

\item In case it is not clear from the hardware architecture, a page
  table descriptor may also store the \emph{size} of the page table.
  This is analogous to the size of a segment in segment-based virtual
  memory.

\item A \emph{presence bit}
  (P bit)\index{presence bit (P bit), page descriptor}
  which indicates whether the page table pointed to by the
  descriptor is in main memory or not. This indicates that also page
  tables can themselves be paged out into secondary storage. We will get back
  to the problems this may cause later in
  Section~\ref{sec:paging:ulix}.

\item Multi purpose bits, just like in a page descriptor.

\end{itemize}



\subsubsection{Structure of a Virtual Address}
\label{sec:structure:of:virtual:address}

\index{virtual address!structure}%
In a hierarchic page table, the virtual address is used in a special
way to traverse the tree of descriptors. If there are $L$ levels in
the page descriptor tree, the bits of the page address $p$ within a
virtual address are subivided into $L$ parts $p_1,p_2,\ldots,p_L$ such
that 
%
$$p=p_1 \oplus p_2 \oplus \ldots \oplus p_L$$
%
\black
(where $\oplus$ denotes the join operation of strings). Mathematically, this
corresponds to
%
$$p=p_1 \times 2^{e_1}+p_2 \times 2^{e_2}+\ldots+p_L \times 2^{e_L}$$
%
for some decreasing sequence of exponents $\{ e_1, e_2, \ldots, e_L \}$
with $e_L = 0$.
\felix
The address translation starts with the leftmost (highest order)
bits. Briefly spoken, the first bits (in $p_1$) are an index into the first
level page table, the next bits (in $p_2$) an index into the second level
page table and so on. Therefore the number of bits per level
determines the size of the page table at that level. 

As an example, consider the division of $p$ into parts in
Figure~\ref{fig:virtual:address:structure}. The first seven bits
(for $p_1$) allow a first level table size of $2^7=128$ entries. In a 
32 bit system, each entry covers an area of 32 MByte. The second level's
seven bits for $p_2$ handle again 128 entries, each of them now covering 256
KByte. Finally, the third level's seven bits (for $p_3$) are an index into a page
table with 128 entries, each entry finally covering a full page of
2~KByte (eleven bits remain for the offset). As in this example, it is
common to have two or three distinct levels in the page descriptor
tree of a virtual address space.


\begin{figure}[h!]
\begin{centering}
\begin{bytefield}[bitwidth=4.2mm]{32}
%\bitheader[b]{0-31}\\
\bitheader[b]{0,10,11,17,18,24,25,31}\\
\bitbox{7}{$p_1$ (7 bits)}
\bitbox{7}{$p_2$ (7 bits)}
\bitbox{7}{$p_3$ (7 bits)}
\bitbox{11}{offset $d$ (11 bits)}
\end{bytefield}
\caption[Example structure of a multi-level virtual address.]{Example structure of a multi-level virtual address; $p = p_1 \oplus p_2 \oplus p_3 = p_1 \times 2^{14} + p_2 \times 2^7 + p_3$.}
\label{fig:virtual:address:structure}
\end{centering}
\end{figure}


\begin{figure}[p!]
  %\centering
  %\hspace{-1mm}%  % right space placement
  \hspace{-0.235\textwidth}\hspace{2mm}%  % left page placement
  \includegraphics[width=1.235\textwidth]{pics/page-table-2layers.pdf}
  \caption{Address translation using a two-level page descriptor tree.}
  \label{fig:two:level:address:translation}
\end{figure}

\begin{figure}[p!]
  %\centering
  \hspace{-0.235\textwidth}\hspace{2mm}%
  \includegraphics[width=1.235\textwidth]{pics/page-table-3layers.pdf}
  \caption{Address translation using a three-level page descriptor tree.}
  \label{fig:three:level:address:translation}
\end{figure}


\subsubsection{Multi-Level Address Translation}

\index{paging!multi-level address translation}%
\index{multi-level address translation}%
\index{address translation!multi-level address translation}%
We now discuss several examples of how address translation works using
hierarchic page tables. The first example is depicted in
Figure~\ref{fig:two:level:address:translation}. It shows a two-level
descriptor tree. How does the MMU perform address translation here?
It starts with the ``root'' page table, pointed to by the MMU register
[[PTR]]. This is the first level page table. The MMU takes the first
part $p_1$ of the virtual address as an index into this table where it
finds a page table descriptor. This points to the relevant second
level page table. Within this page table, the second part $p_2$ of the
virtual address is used as an index.  Since we are at the highest
level of the tree, the descriptor at index $p_2$ in the second level
page table is a real page descriptor allowing to perform the address
translation into a physical address.

The example above can easily be extended to three-level page
descriptor trees. As an example consider
Figure~\ref{fig:three:level:address:translation}. In contrast to the
first example, the level two page table does not point to the page
frame but to a level three page table. The virtual address has a third
part $p_3$ which is used as an index into this table where we find the
page descriptor finally pointing to the page frame. 


We can save a little storage space in the descriptor
if its type is clear from the context. For example, the Intel i386 CPU
assumes a two-level descriptor tree. Any descriptor found at level~1
is automatically a page table descriptor. All other descriptors
(i.\,e., those at level~2) must be page descriptors. 


\subsubsection{Discussion}

The advantage of hierarchic page tables is their potential to save
significantly on main memory. Unused parts of virtual address
spaces can be ``removed'' from the page table using 
\emph{null page descriptors}\index{null page descriptor}. A null descriptor 
is a special descriptor
indicating that the virtual memory at this location is void or unused.
Usually it is encoded by a special flag or value in a field of the
descriptor (either page descriptor or page table descriptor).
By placing a null descriptor into the descriptor tree,
all pages below this descriptor are effectively removed from
virtual memory. The lower the level of the null descriptor, the
larger the part of virtual memory which is mapped out.

To see how effectively null descriptors can be used, we reconsider the
example we introduced in Section~\ref{sec:address:space:organization}
and revisited in Section~\ref{sec:page:descriptor:trees}: the classic
organization of virtual memory with a 20~MByte program, an empty heap
and an empty stack. Recall that a single page table would need roughly
8~MByte of main memory. Using hierarchic page tables and null
descriptors we can reduce the amount of necessary storage to 5~KByte,
as is shown in Figure~\ref{fig:using:null:descriptors}. Here the example
is simplified to the situation where the program has no code and
data pages to show the effect more clearly. Remember that
on each level of the descriptor tree we had 128 entries per table,
each entry requiring eight bytes. This means each table has a size of 
1~KByte.  By placing null descriptors in all places which point to empty
virtual memory, we end up with page tables only for those parts of the
system which really exist. Since the assumed hardware of this example
places page descriptors only on level~3, we need to extend the descriptor
tree up to level~3 for the two page descriptors necessary
to point to heap and stack. When you count the number of page tables,
you end with 5. Hence we need only 5~KByte instead of 8~MByte.

\begin{figure}[t!]
  %\centering
  % \hspace{-2mm}%  % right page placement
  \hspace{-0.235\textwidth}\hspace{2mm}%  % left page placement
  \includegraphics[width=1.26\textwidth]{pics/use-of-null-descriptors.pdf}
  \caption{Saving main memory using null descriptors in hierarchic page tables.}
  \label{fig:using:null:descriptors}
\end{figure}

The disadvantage of a multi-level page tables is that address translation
takes slightly longer. This is because the MMU has to traverse the
tree (i.\,e., follow the pointers) when doing the address translation.
A multi-level page table needs one main memory lookup per level,
which takes longer than a single memory lookup if there were only
a single page table. The memory savings however usually outweigh the
performance drawback. Furthermore, performance can still be in the
range of a single memory lookup (or less) by using caching, as
we explain in the following section.


\black
\subsubsection[Translation Look-aside Buffer and Locality Principle]{Translation Look-aside Buffers and the Locality Principle}

Each memory access requires address translation which needs yet (at least) one other memory access for reading the page table, so it makes sense to use some kind of caching mechanism for the page to frame translation because most programs will not randomly access memory but instead access addresses which are close to one another. Think of loops reading all the elements of an array: they will be stored consecutively. So after one access to a memory frame it is likely that further accesses to the same frame will occur soon after the first one. This is called the \emph{locality principle}\index{locality principle}\marginnote{locality\\ principle}. Lookups of the same frame would mean translating the page number to a page frame number again and again---in order to speed up this process many memory management units contain a \emph{translation look-aside buffer}\index{translation look-aside buffer} (TLB)\marginnote{TLB}\index{TLB}. That is a special type of memory called \emph{associative memory}\index{associative memory} which can store page/ page frame pairs and allows lookup in constant time: In order to find the page frame for a given page (assuming it is stored in the buffer) there is no need to loop over the entries in the buffer, but the buffer will return the frame number immediately if it contains the page number. If it does not, the result is an error, and the normal lookup process will start. But finding a frame via the TLB is orders of magnitude faster than going through the regular tables, and this holds even more if split page tables are used.

The size of the TLB is typically very small, because those kinds of chips are limited in their size but the locality principle will guarantee that for ``well-behaving programs'' (i.\,e., those that respect this principle) it will be sufficient to dramatically speed up the address translation.

Since the TLB is part of the memory management unit, it will be used automatically by the CPU; no specific programming is necessary to activate or use it.

Note that the (page $\mapsto$ page frame) mapping exists for every single process in the system: Since each process has its own virtual memory space, it makes no sense to combine their page tables in some kind of system-wide table. This has consequences for the TLB as well: If it, as described so far, only stores page and frame numbers, then every context switch to another process will \emph{invalidate}\marginnote{invalidation\\ of TLB}\index{TLB!invalidation}\index{invalidation of the TLB} all its entries. So if the scheduler switches processes very often, this will limit the use of the TLB. Alternatively the TLB could be constructed in a way that maps (process ID, page number) pairs to frames: That would keep all entries valid across context switches, but with different processes always accessing different page frames it would only work well in a setup with either very few processes or with a sufficiently increased TLB size.


\subsubsection{Digression: Indirection in Filesystems}
\label{sect:memory:fs:indirection}

\enlargethispage{5pt}
Somewhat similar to the way in which a page table holds information about the page frames currently used by a process, filesystems keep records of disk areas used by a file. A thing that is shared by both methods is the use of equal-sized partitions of the medium---in the case of hard disks they are called blocks or clusters and typically have the size of a few kilobytes, e.\,g., 1, 2, 4 or 8 KByte.

For each file the operating system has to keep a list of blocks that the file's data occupy. With very large files this list also becomes very large, because a file of size 1 MByte uses 1024 blocks, if the block size is 1 KByte.

\begin{figure}[p!]
%\centering
%\hspace{-2mm}%
\hspace{-0.22\textwidth}%
\includegraphics[width=1.235\textwidth]{pics/indirection.pdf}
\caption[\hgepolylof{Multiple indirection in Unix filesystems.}]{Multiple indirection in Unix filesystems: A Minix inode stores seven direct block numbers and three block numbers for single, double and triple indirection blocks. Triple indirection is not implemented in \UlixI{}.}
\label{img:disk-indirection}
\end{figure}

Storing the block list in the overall data structure that the operating systems keeps for administering the filesystem is not very efficient, because in order to allow for huge files, each such entry would have to reserve space for a possibly very long list---even for those files that only use a few blocks. Thus many filesystems store the block list in special data blocks. This approach is called \emph{single indirection}\marginnote{indirection}: From wherever the information about a certain file is stored, entries do not point directly to a data block, but to an indirection block that contains further pointers to several other data blocks. These entries can be block numbers, since by multiplying the block number with the block size the absolute disk address can be calculated. If it takes two bytes to store a block number and a data block has a size of 4~KByte, then 2048 block addresses can be stored in one indirection block. When the first indirection block is fully used, a second one can be introduced in order to allow for even bigger files.

Typically the administration data will not only contain pointers to indirection blocks but also a few direct pointers (to data blocks) so that in the case of small files it is possible to find all data blocks without going through indirection blocks. Only when the number of data blocks exceeds the number of directly stored block addresses, a first indirection block will be used.

With single indirection the maximum size of files grows a lot; however it is still limited: If there are 20 pointers to indirection blocks and such a block stores 2048 block numbers (as above), then this allows for 40 K data blocks or file sizes of up to 40 K $\times$ 4 KByte = 160 MByte. By adding more and more indirect pointers in order to allow for yet bigger files, the administrative data for a single file grows equally; so a second level of indirection is introduced to keep the file entries small. With \emph{double indirection} there are pointers that point to indirection blocks which link to further indirection blocks. Those then finally point to address blocks. What we said about the number of block addresses remains valid in the case of double indirection, but now one double indirection pointer allows to address 2048 $\times$ 2048 = 2048$^2$ (or roughly four million) data blocks.

If this is still not good enough, \emph{triple indirection} or even higher levels of indirection can be introduced: With each additional indirection step the maximum file size grows by the same factor (2048 in the example). But notice that it makes no point to use, say, ten or eleven layers of indirection just to be prepared for any possible future demands on file sizes: Indirection leads to extra accesses; in order to read a specific block from the disk whose block number is only available through a long indirection, several blocks have to be read from the disk. If the block is on a triple indirection path, it actually takes at least five read operations to retrieve the data: The first one is for looking up the address of the first level indirection block in the file's administrative data. The second to fourth are for reading the indirection blocks, and the fifth one is the data block itself.

Whatever level of indirection is used, there are typically also indirection entries of all lower levels: In the same way that it makes sense to keep a few direct block number entries to speed up access to very small files, it is useful to have one (or a few) single indirections for those medium size files that do not require double indirection, and so on.

Figure \ref{img:disk-indirection} shows an example for multiple indirection in a Unix type filesystem. What is called \emph{inode}\marginnote{inode} in the image is a special administrative entry for a file that holds most of this file's attributes including direct and indirect block numbers as well as things such as owner, owning group, access permissions, but not a filename. We will come to this later when we discuss examples of real filesystems in Chapter~\ref{chap:ulix:fs}.


\subsubsection{Further Reading}

A comparison of three paging architectures (x86, PowerPC and MIPS)
by Bruce Jacob and Trevor Mudge is available online \cite{Jacob:1998:VMI:619030.621004}.


\felix
\subsection{Page-based Virtual Memory in \Ulix{}}
\label{sec:paging:ulix}

\index{memory management!implementation in Ulix}%
\index{virtual memory!implementation in Ulix}%
Virtual memory in \Ulix{} is designed along the following principles:
%
\begin{itemize}

\item Every process will have its own virtual address space, i.\,e., an
  own page table (tree). Address spaces of processes are protected from
  one another, i.\,e., it is not possible to access address space $a$
  from a process that uses address space $b$ and vice versa.

\item Pages are stored in a set of page frames. Pages can be locked
  in physical memory. Locked pages cannot be paged out. 

\item Page replacement is done on a global basis, i.\,e., page
  replacement algorithms treat all frames in the same way irrespective
  of what pages reside in the frames (unless, of course, they are
  locked).

\item The kernel has its own virtual address space\index{address space!Ulix}. The virtual address
  space of every process is accessible from the virtual address space of
  the kernel.

\end{itemize}

\black

\noindent
In the following chapter you will see the data structures that \Ulix{} uses to implement paging on the Intel i386 architecture, but we will only set up an initial page table that we need for completing the boot process. It will get more interesting in Chapter~\ref{sec:processes:address spaces} when we introduce address spaces for processes.




%-----------------------------------------------------------------------------

\black

\addtocontents{toc}{\protect\parttocpagebreak}

\chapter{Boot Process and Memory Management in \UlixI{}}
\label{chap:ulix:boot}%

\index{boot process}%
Our goal is to have an operating system which will be able to boot from
some media. Obviously we cannot just compile a standard binary executable
file for some platform (e.\,g.\ the one we use for development), but instead
will need a file format that a boot loader can load and execute on a real
machine (or inside some PC emulator or virtualization software).

Writing a boot loader is not a hard task as long as we create the boot disk
in such a way that the kernel binary is stored contiguously on the disk and
we know its first sector number on the disk: the BIOS provides functions
for reading sectors from disk. The older Linux\index{Linux} boot loader LILO\index{LILO} \cite{lilo-2000}
worked this
way: after rebuilding the Linux kernel and writing it to the boot disk,
the boot loader had to be reinstalled because the sectors containing the
kernel were hard-coded into the boot loader. LILO's successor 
\marginnote{GRUB\\ boot loader}\index{GRUB boot loader}
GRUB \cite{grub-legacy} uses a
more complex approach: it contains drivers for several filesystems and can
find its configuration data and the kernel without knowing the sector
numbers; it just looks up the relevant data in the disk's directories.

We have decided against implementing our own boot loader because this tool
is not part of the kernel. As capable tools such as GRUB already
exist, it makes no sense to reinvent the wheel.


\section{GRUB Loads the \UlixI{} Kernel}

We will use a FAT-formatted GRUB boot floppy disk ([[ulix-fd0.img]]) onto 
which we copy the 
\UlixI{} kernel binary [[ulix.bin]], and we configure the boot loader by 
placing the following file \path!MENU.LST! in the \path!BOOT/GRUB! subdirectory
of the same disk:

\pagebreak

%nouse
<<MENU.LST>>=
timeout 5

title   ULIX-i386  (c) 2008-2014 Felix Freiling & Hans-Georg Esser
        root (fd0)
        kernel /ulix.bin
@

When we power on the emulated (or real) PC, the BIOS\index{BIOS} will search for bootable
media, and it will find an acceptable boot sector on the floppy disk. It
loads the GRUB boot loader into memory and executes it. GRUB understands
several filesystems, including Minix and FAT, and it will recognize the
FAT disk and locate the above configuration file. Its only entry tells it
to load the kernel binary.

But to what memory location does GRUB copy the kernel, and where will it
start executing it? The kernel binary will be an 
\marginnote{ELF}\index{ELF (executable and linking format)}
ELF file (Executable and 
Linking Format, see Section \ref{sec:elf-loader}) that contains a description
of what data to copy from the ELF file to which memory locations.

GRUB supports kernel images which have a \emph{Multiboot header}\index{multiboot header}\marginnote{Multiboot\\ header}.
The Multiboot specification \cite{multiboot:2009} states:

\begin{quotation}
\noindent
``An OS image must contain an additional header called Multiboot header, besides 
the headers of the format used by the OS image. The Multiboot header must be
contained completely within the first 8192 bytes of the OS image and must be 
longword (32-bit) aligned. In general, it should come as early as possible and 
may be embedded in the beginning of the text segment after the real executable 
header.''
\end{quotation}

\noindent
In order to put a proper Multiboot header into our kernel binary, we will
need to write some assembler\index{Assembler language} code. The [[nasm]] assembler\index{Assembler language!nasm assembler@\texttt{nasm} assembler}\index{nasm assembler} offers commands
such as [[db]] (data byte), [[dw]] (data word) and [[dd]] (data double word)
for writing eight bits, 16 bits or 32 bits of data into the file
(see Appendix~\ref{appendix:assembler:special-commands}), and the 
[[equ]] statement lets us define
symbolic constants, similar to C's [[#define]] pre"=processor statement.
The full header is only twelve bytes long, its contents are shown in Table
\ref{table:multiboot header}.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Bytes} & \textbf{Content} & \textbf{Fixed Values} \\
\hline
00--03 & magic string & \hex{1badb002} \\
04--07 & flags & \\
08--11 & checksum & \\
%12--15 & header address & \\
%16--19 & load address & [[code]] \\
%20--23 & load-end address & [[bss]] \\
%24--27 & bss-end address & [[end]] \\
%28--31 & entry address & [[start]] \\ 
\hline
\end{tabular}
\caption[\hgepolylot{Contents of the Multiboot header}]{Contents of the Multiboot header.}
\label{table:multiboot header}
\end{center}
\end{table}

What are the proper values for the \emph{flags} and \emph{checksum} fields?
According to the Multiboot specification, we need to set the bits 0 and 1
of the \emph{flags} entry:

\begin{description}
\item[0:] this is the ``page alignment'' flag, it guarantees that the 
kernel will be loaded to a physical address which is a multiple of 4\,096,
the default page size on the Intel architecture.
\item[1:] the ``memory information'' flag provides the loaded operating
system with data about the available memory. This data will be accessible
via the ``Multiboot information structure'', and the boot manager must
place the address of this structure in the \register{EBX} register.
\UlixI{} does not currently use these data.
% \item 16: setting this bit declares that the addresses stored in bytes 12--27
% are valid, the boot loader should use those values (and not alternative
% values found in the ELF headers of the kernel binary).
\end{description}


\noindent
The following code shows a slightly modified version of the Multiboot
header definition which we took from Bran's Kernel Development Tutorial 
\cite{brans-tutorial:200x}.

%BEGIN ASM CHUNK
<<start.asm>>=
[section .setup]
[bits 32]
align 4
mboot:
    MB_HEADER_MAGIC   equ 0x1BADB002
    ; Header flags: page align (bit 0), memory info (bit 1)
    MB_HEADER_FLAGS   equ 11b   ; Bits: 1, 0
    MB_CHECKSUM       equ -(MB_HEADER_MAGIC + MB_HEADER_FLAGS)

    ; GRUB Multiboot header, boot signature
    dd MB_HEADER_MAGIC   ; 00..03: magic string
    dd MB_HEADER_FLAGS   ; 04..07: flags
    dd MB_CHECKSUM       ; 08..11: checksum
@ %def mboot
%END ASM CHUNK
(For an explanation of the assembler commands \verb#equ# (which is similar to
C's \verb!#define!) and \verb#dd# (which writes data right into the assembled
object file) see Section~\ref{appendix:assembler:special-commands} of the
appendix on x86 assembly language.)

When we look at the compiled kernel, we will find the Multiboot header.
Note that 32-bit numbers are stored in \emph{little-endian}\marginnote{little-endian}: 
for example, the magic string \hex{1badb002} shows up as [[02 b0 ad 1b]].


\begin{Verbatim}
$ hexdump -C ulix.bin 
[...]
00001000  02 b0 ad 1b 03 00 00 00  fb 4f 52 e4 17 00 12 00  |.........OR.....|
[...]
\end{Verbatim}


\section{The \UlixI{} Memory Layout}

\index{memory management!Ulix memory layout}%
\index{virtual memory!Ulix memory layout}%
\index{Ulix!memory layout}%
While it's too early to discuss the memory management implementation in detail, 
we need to decide now what the general memory layout is going to be: when we
load the kernel it will end up somewhere in memory, so we must say where that 
is going to be.

\UlixI{} will implement virtual memory (with paging), and every process
on the system will have its own address space which is basically a mapping
of virtual addresses to physical memory.

We\marginnote{User / Kernel\\ Space} split the available 4~GByte of virtual 
memory which are available on a 32-bit machine into 3~GByte for user space 
(addresses \hexrange{00000000}{BFFFFFFF}) and 1~GByte for kernel space
(addresses \hexrange{C0000000}{FFFFFFFF}). Every process will see the
same upper 1~GByte of kernel space 
(see Figure~\ref{fig:ulix memory layout simple}).


\begin{figure}[h!]
\begin{centering}
\begin{tabular}{|c|c|}
\hline
\hex{FFFFFFFF} & \\
\vdots & Kernel space \\
\hex{C0000000} & \\
\hline
\hex{BFFFFFFF} & \\
\vdots & User space \\
\hex{00000000} & \\
\hline
\end{tabular}
\caption[Simplified view of the \UlixI{} memory layout.]{This is a simplified view of the \UlixI{} memory layout.}
\label{fig:ulix memory layout simple}
\end{centering}
\end{figure}

This memory layout is similar to the one used by 32-bit-Linux\index{Linux} which also
puts the kernel in the upper quarter of the virtual memory.

With this in mind we will compile the \UlixI{} kernel such that it uses
addresses above \hex{c0000000}.


\section{From Real Mode to Protected Mode}

When the computer powers up, it runs in \emph{Real Mode}\index{real mode}\marginnote{Real Mode}, a legacy mode of
operation which is compatible to earlier Intel CPU generations---all the way
back to the Intel 8086 processor from 1978.

When using a simple boot loader the operating system has to do the switch
from Real Mode to \emph{Protected Mode}\marginnote{Protected Mode}\index{protected mode} manually, however GRUB activates Protected
Mode for us, so all we have to do in the early initialization is to set up
segmentation properly.


\subsection{Segmentation in Real Mode}
\label{sec:intel:segmentation:realmode}

\index{segmentation!real mode}%
In Real Mode, the CPU uses 16 bit wide registers to address the memory,
and via a built-in method called segmentation a 20 bit wide address space
can be used. That is achieved via an odd technique: several segment registers 
can be used to point to a different memory range. Segments are always 
$2^{16}$ bytes = 64 KByte large.

Let's see an example for this: Assume we have a machine with 512 KByte of RAM,
it has 
\marginnote{Physical Address}
\emph{physical addresses} \hex{00000} to \hex{7FFFF}.
In principle, the 16-bit registers of the 8086 CPU could only access the first
64 KByte (with addresses \hex{0000} to \hex{FFFF}) of that memory---the first 
segment. In order to access the second segment (addresses \hex{10000} to
\hex{1FFFF}), we use a 
\marginnote{Segment\\ Register}\index{segment register}
segment register, e.\,g.\ [[DS]] (data segment).
The segment registers are also 16 bits wide, but we intend to store a
20-bit wide address inside them. Since 20 bits cannot fit inside a 16-bit
register, we discard the four lowest bits, assuming they are always 0.

Here are the binary representations of \hex{10000} and \hex{1FFFF}:\\[-8pt]

\begin{centering}
\hex{10000} = \bin{10000000000000000} \\
\hex{1FFFF} = \bin{11111111111111111} \\[7pt]
\end{centering}

\noindent
The 20-bit wide represention of \hex{10000} is
\bin{00010000000000000000},
and when we remove the lowest four zero bits, we get
\bin{0001000000000000} = \hex{10000} [[>> 4]] = \hex{1000}.

We can now access addresses \hex{10000} to \hex{1FFFF} by setting [[DS]]
to \hex{1000} and actually addressing \hex{0} to \hex{FFFF}, because the
CPU will automatically left-shift [[DS]] by four bits and add the resulting
value to the addresses we supply.

Segmented addresses are always written in the form [[seg:addr]] and
called 
\marginnote{Logical Address}\index{logical address}\index{segmentation!logical address}
\emph{logical addresses}, for the
example above, \hex{10000} = [[1000:0000]] and \hex{1FFFF} = [[1000:FFFF]].

We could partition the 512 KByte = $8 \times 64$ KByte RAM of our example
machine into eight segments with addresses [[0000:x]], [[1000:x]], \dots,
[[7000:x]]. The maximum amount of memory that the 8086 CPU can use is
1 MByte, and for a machine with that much RAM we would add the segments
with addresses [[8000:x]], [[9000:x]], \dots, [[F000:x]].

However, it is not required that a segment starts at a multiple of 
64 KByte; instead a segment register may hold any 16-bit value (which will
be left-shifted into a 20-bit address with four trailing zeroes), thus
the start address of a segment is some multiple of $2^4=16$.

Now, for our operating system we do not want to use Real Mode, since it offers
no memory protection and 1 MByte of memory is not much. The alternative is
Protected Mode, and it also uses segmentation, but in a more complex way.
The 80386 processor's segmentation mode is similar to segmentation on the
80286 CPU with the difference that the 80386 supports a 32-bit address space
instead of a 24-bit address space, as well as paging.


\subsection{Privilege Levels in Protected Mode}

\index{privilege level}\index{protected mode!privilege level}%
When we run the PC in Protected Mode there are four different
``privilege levels'' 0--3 in which the CPU can operate. Protected Mode
segments allow us to declare the rights needed to access a segment,
for example, if we are currently running in privilege level 3 and
try to read a memory address in a segment which only allows access
from level 0, our attempt will fail.

Later, when we talk about paging, we will give a more detailed
description of the privilege levels; for now it is sufficient to note
that \UlixI{} will use two of these levels: level 0 for the kernel
and level 3 for user mode applications (processes). We will use the
following phrases as synonyms: 
\begin{itemize}
\item ``The system runs in privilege 
\marginnote{Level 0 (Kernel)}
level 0'',
\item ``the system is in kernel mode'', and
\item ``the system runs in ring 0''.
\end{itemize}
Similarly for level 3, we treat 
\begin{itemize}
\item ``the system runs in privilege 
\marginnote{Level 3 (User)}
level 3'',
\item ``the system is in user mode'', and
\item ``the system runs in ring 3''
\end{itemize}
as equivalent statements.


\subsection{Segmentation in Protected Mode}
\label{sec:intel:segmentation:protectedmode}

\index{segmentation!protected mode}%
The more modern implementation of segmentation does not store addresses in
the segment registers, instead it works with a \emph{segment table}\index{segment table}\marginnote{Segment Table} and lets
the segment registers point to entries in that table. A table entry does
not only specify where a segment starts but also what length it has. If the
length is not set to the maximal value (\hex{FFFFFFFF}), it is possible to
generate a forbidden access (to an address outside the segment) which the
CPU will block, generating a fault.

When we start the OS initialization we must provide such a segment table,
since it is not possible to use Protected Mode without one: Volume 3 of the 
Intel (R) 64 and IA-32 Architectures Software Developer's Manual 
\cite[p. 3-1]{intel-part3} states:

\begin{quote}
``When operating in protected mode, some form of segmentation must be used. There is no mode bit to disable segmentation.''
\end{quote}

\noindent
Sample assembler code for setting up segmentation can be found
in the same document on p.~419 (p.~9-23).

After GRUB turns over control to our kernel, a segment table
is in use (after all, we're already running in Protected Mode), however
we will discard that table and provide our own one.

\label{description:gdt:start}%
The data structure
we have to create is called the 
\marginnote{GDT}\index{global descriptor table|see {GDT}}\index{Intel x86 architecture!global descriptor table}
``global descriptor table'' (GDT\index{GDT (global descriptor table)}) and
consists of several \emph{segment descriptors}\index{segment descriptor}\index{Intel x86 architecture!segment descriptor}.

Each 
\marginnote{Segment\\ Descriptor}
segment descriptor is eight bytes long, and besides other values it
contains a 32-bit \emph{base} address and a 20-bit \emph{limit} which is
left-shifted by 12 bits to form a 32-bit limit. During the shift, 1-bits
are inserted on the right, thus for example \hex{FFFFF} (20 1-bits) becomes
\hex{FFFFFFFF} (32 1-bits) during the shift.

Both values are spread in
a weird pattern across the descriptor:

\begin{itemize}
\item base (bits 0..23): in bytes 2, 3, 4 of the descriptor
\item base (bits 24..31): in byte 7 of the descriptor
\item limit (bits 0..15): in bytes 0, 1 of the descriptor
\item limit (bits 16..19): lower four bits of byte 6 of the descriptor
\end{itemize}


\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{8}{Base: 31--24}
\bitbox{1}{Gr}
\bitbox{1}{Sz}
\bitbox{2}{[[0 0]]}
\bitbox{4}{Limit: 19--16} \,\, {\tiny 7..6} \\
\bitbox{1}{P}
\bitbox{2}{DPL}
\bitbox{1}{[[1]]}
\bitbox{3}{Type}
\bitbox{1}{A}
\bitbox{8}{Base: 23--16} \,\, {\tiny 5..4} \\
\wordbox{1}{Base: 15--0} \,\, {\tiny 3..2} \\
\wordbox{1}{Limit: 15--0} \,\, {\tiny 1..0}   \\[-15pt]
\end{bytefield}
\caption[Intel i386 segment descriptor with base and limit.]{In a segment descriptor the base and limit values are spread across the eight bytes in a weird pattern.}
\label{fig:segment descriptors}
\end{centering}
\end{figure}


A descriptor contains more than just the address range (see
Figure~\ref{fig:segment descriptors}): The upper four 
bits of byte 6 contain two flags (granularity and size) and two 0 bits;

\begin{itemize}
\item we must set the granularity bit to 1: this causes the left-shift
for the limit value; if the bit was 0, we could declare the limit in
bytes instead of multiples of 4 KByte.
\item the size bit must also be set to 1, declaring this descriptor to
be a 32-bit protected mode descriptor; otherwise it would be a 16-bit
descriptor which is something we don't need (it exists for backwards
compatibility with the 80286).
\end{itemize}
Thus, the upper four bits of byte 6 are always \bin{1100}.

We have now described everything except byte 5 of the descriptor which
defines its type. Its bits have the following functions:

\begin{description}
\item[7:] present bit, must be set to 1
\item [6/5:] descriptor privilege level (DPL)\index{DPL (descriptor privilege level)}\index{descriptor privilege level} \marginnote{DPL}, must be set to 00 for ring 0 
  (kernel mode) or 11 (=3) for ring 3 (user mode)
\item [4:] reserved, must contain 1
\item [3:] executable bit, we will set this to 1 in our code segment descriptor
  and to 0 in our data segment descriptor
\item [2:] direction bit / conforming bit: 
  \begin{itemize}
  \item for the data segment, 0 means that
  the segment grows upwards; 
  \item for the code segment, 0 means that the code
  in this segment can only be executed if the CPU operates in the ring that
  is declared in bits 6/5 (privilege level).
  \end{itemize}
\item [1:] readable bit / writable bit: we always set these to 1; for a code
  segment it means that we can also read from this segment, and for a data
  segment it means we can also write to it.
\item [0:] accessed bit: we set this to 0; the CPU flips it to 1 when this
  segment is accessed.
\end{description}

\noindent
The corresponding C datatype for a GDT entry is the following:

<<type definitions>>=
struct gdt_entry {
  unsigned int limit_low   : 16;
  unsigned int base_low    : 16;
  unsigned int base_middle :  8;
  unsigned int access      :  8;
  unsigned int limit_high  :  4;
  unsigned int flags       :  4;
  unsigned int base_high   :  8;
};
@ %def gdt_entry

When we tell the processor to use our table we cannot directly point
it to the beginning of the GDT (e.\,g.\ via [[gdt[0]]]), instead we
need an extra data structure which just contains the size and the
start address of the table:

<<type definitions>>=
struct gdt_ptr {
    unsigned int limit       : 16;
    unsigned int base        : 32;
} __attribute__((packed));
@ %def gdt_ptr

\noindent
With [[__attribute__((packed))]] we force the compiler to store the
data precisely in this way, otherwise optimizations could change the
order.

\label{gdt and gp declaration}
<<global variables>>=
struct gdt_entry gdt[6];
struct gdt_ptr gp;
@ %def gdt gp

\noindent
Note that [[gdt]] allows us to store six segment descriptors; this is
the number of descriptors we will use in \UlixI{}---in general, many
more descriptors (up to 8192) can be used.
\label{description:gdt:end}%


Since we want to create segment descriptors for kernel mode (ring 0) and
we need one code and one data selector, the type bytes will be

\begin{itemize}
\item \bin{10011010} for the code segment \\
  (present; ring 0; fixed-1; executable; exact privilege level; allow reading;
  not accessed)
\item \bin{10010010} for the data segment \\
  (present; ring 0; fixed-1; not executable; grow upwards; allow writing; not accessed).
\end{itemize}


\newcommand{\colorbitbox}[3]{%
  \rlap{\bitbox{#2}{\color{#1}\rule{\width}{\height}}}%
  \bitbox{#2}{#3}}
\definecolor{lightcyan}{rgb}{0.84,1,1}
\definecolor{lightgreen}{rgb}{0.64,1,0.71}
\definecolor{lightred}{rgb}{1,0.7,0.71}


\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{8}{Base: 31--24}
\bitbox{1}{[[1]]}
\bitbox{1}{[[1]]}
\bitbox{2}{[[0 0]]}
\bitbox{4}{Limit: 19--16} \,\, {\footnotesize 7..6} \\
\bitbox{1}{[[1]]}
\bitbox{2}{[[0 0]]}
\bitbox{1}{[[1]]}
\colorbitbox{lightgreen}{3}{[[1 0 1]]}
\bitbox{1}{[[0]]}
\bitbox{8}{Base: 23--16} \,\, {\footnotesize 5..4} \\
\wordbox{1}{Base: 15--0} \,\, {\footnotesize 3..2} \\
\wordbox{1}{Limit: 15--0} \,\, {\footnotesize 1..0} \\
\end{bytefield}

\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{8}{Base: 31--24}
\bitbox{1}{[[1]]}
\bitbox{1}{[[1]]}
\bitbox{2}{[[0 0]]}
\bitbox{4}{Limit: 19--16} \,\, {\footnotesize 7..6} \\
\bitbox{1}{[[1]]}
\bitbox{2}{[[0 0]]}
\bitbox{1}{[[1]]}
\colorbitbox{lightgreen}{3}{[[0 0 1]]}
\bitbox{1}{[[0]]}
\bitbox{8}{Base: 23--16} \,\, {\footnotesize 5..4} \\
\wordbox{1}{Base: 15--0} \,\, {\footnotesize 3..2} \\
\wordbox{1}{Limit: 15--0} \,\, {\footnotesize 1..0}  \\[-15pt]
\end{bytefield}

\caption[Segment descriptors for code and data segments in the GDT.]{Our descriptors for the code segment (top) and the data segment (bottom)
only differ in the Type fields.}
\end{centering}
\end{figure}



\subsection{Preparations for Paging}

Without delving into the details of paging, we need to prepare our kernel
for its usage right now: Later, when we turn on virtual memory, we want
the kernel to use virtual addresses \hexrange{c0000000}{ffffffff} and user
mode programs to use virtual addresses \hexrange{00000000}{bfffffff}.
This means that we have to compile and link the kernel in such a way that
all absolute addresses (of functions and data) lie in the range above
\hex{c0000000}. But that's a large number, and we do not expect to have physical
memory with such high addresses. By setting the base address in our descriptors
to \hex{40000000}, we can load the kernel to low addresses. 

Imagine for example that the kernel calls a function which has the
entry address \hex{c000 1234}. With the way we will set up the segments
the base address \hex{40000000} will be added, resulting in

\begin{displaymath}
\begin{array}[b]{lr}
  & \text{\hex{c0001234}}\\
 +& \text{\hex{40000000}}\\
\hline
 =& \text{\hex{100001234}}
\end{array}
\end{displaymath}

\noindent
which is no longer a 32 bit address; the leading 1 will be lost in
this addition, resulting in the address \hex{00001234}---where we'll
physically put the code of this function.

\label{higher half trick}
This is called the 
\marginnote{Higher Half\\ Trick}\index{higher half trick}
``higher half trick''
\cite{higher-half-with-gdt,robinson-memory1}
(even though we're reserving the upper quarter and not the upper
half of the virtual memory for the kernel).


%BEGIN ASM CHUNK
<<start.asm>>=
[section .setup] 
 
trickgdt: dw gdt_end - gdt_data - 1        ; GDT size
          dd gdt_data                      ; linear address of GDT
 
gdt_data: dd 0, 0    ; selector 0x00: empty entry

          ; code selector 0x08:
          ; base 0x40000000, limit 0xFFFFF, type 10011010, flags 1100
          db 0x0F, 0xFF, 0, 0, 0, 10011010b, 11001111b, 0x40	
	
          ; data selector 0x10: 
          ; base 0x40000000, limit 0xFFFFF, type 10010010, flags 1100
          db 0x0F, 0xFF, 0, 0, 0, 10010010b, 11001111b, 0x40	
gdt_end:
@ %def trickgdt
%END ASM CHUNK


Now, in order to actually do the memory initialization, we need to load
the global descriptor table and activate it. Again, we use code from
Bran's Kernel Development Tutorial \cite{brans-tutorial:200x}:


% Docu at http://www.monstersoft.com/tutorial1/VESA_intro.html#4
%
% 6.4 Function 02h - Set Super VGA video mode
%
% This function initializes a video mode. The BX register contains the 
% mode to set. The format of VESA mode numbers is described in chapter 2. 
% If the mode cannot be set, the BIOS should leave the video environment 
% unchanged and return a failure error code.
%
%        Input:  AH = 4Fh        Super VGA support
%                AL = 02h        Set Super VGA video mode
%                BX = Video mode
%                     D0-D14 = Video mode
%                     D15 = Clear memory flag
%                           0 = Clear video memory
%                           1 = Don't clear video memory
%
%        Output: AX = Status
%                (All other registers are preserved)



\pagebreak

\tindex{lgdt}\index{GDT (global descriptor table)!lgdt@\texttt{lgdt}}\index{Assembler language!load the GDT}%
%BEGIN ASM CHUNK
<<start.asm>>=
global start
[section .setup]
start:    ; BEGIN higher half trick 
          lgdt [trickgdt]
          mov ax, 0x10
          mov ds, ax
          mov es, ax
          mov fs, ax
          mov gs, ax
          mov ss, ax
          jmp 0x08:higherhalf   ; far jump to the higher half kernel

[section .text] 
higherhalf:    ; END higher half trick 
          mov esp, _sys_stack   ; set new stack
          push esp              ; save ESP
          push ebx              ; address of mboot structure (from GRUB)

          extern main           ; C function main() in ulix.c
          call main
          jmp $                 ; infinite loop
@ %def higherhalf start
%END ASM CHUNK

This code does the following things:

\begin{itemize}
\item It loads our descriptor table via the 
\marginnote{[[lgdt]]}\tindex{lgdt}\index{GDT (global descriptor table)!lgdt@\texttt{lgdt}}
[[lgdt]] instruction,
\item it sets the segmentation registers \register{DS}, \register{ES}, \register{FS},
\register{GS} and \register{SS} to \hex{10} (thus making them point to
our data segment descriptor which has index \hex{10}),
\item since it cannot directly write a value to the \register{CS} register,
it makes a far jump. The instruction [[jmp 0x08:higherhalf]] jumps
to the address [[higherhalf]] in the segment specified by the
segment descriptor with index \hex{08}---and this automatically
sets \register{CS} properly.
\item Then it defines the stack we will use during system 
initialization (by loading \register{ESP}) and finally calls the [[main()]]
function from our C file [[ulix.c]].
\end{itemize}

Note that most parts of the code ``live'' in the [[.setup]] section of
the code, whereas the last lines (starting with the [[higherhalf]] label)
live in the [[.text]] section.


We will also need an additional stack, and we reserve its place
in the same assembler file. The [[resb]] instruction does just that:
it reserves a certain number of bytes, in our case $32 \times 1024$
for 32 KByte of stack memory. Since a stack grows from higher to
lower addresses (downwards), the label [[_sys_stack]] follows after
the reserved bytes:

\pagebreak

%BEGIN ASM CHUNK
<<start.asm>>=
global stack_first_address
global stack_last_address

[section .bss]
stack_first_address:
    resb 32*1024         ; reserve 32 KByte for the stack
stack_last_address:
_sys_stack:
@ %def stack_first_address stack_last_address _sys_stack
%END ASM CHUNK

We use separate sections because we will tell the linker [[ld]] to 
use different
addresses for those sections. This can be achieved with the following
linker configuration file\index{linker configuration file} [[ulix.ld]]. 
(This linker file is a modified version of the one provided 
in Bran's Kernel Development Tutorial \cite{brans-tutorial:200x}; we 
changed the output format
to [[elf32-i386]] and the start address to 0 and introduced an
offset of \hex{c0000000} for the main parts of the kernel.)


\nextchunklabel{code:loader configuration}

<<ulix.ld>>=
OUTPUT_FORMAT("elf32-i386")
ENTRY(start)
phys = 0x00100000;
virt = 0xC0000000;
SECTIONS {
  . = phys;
  
  .setup : AT(phys)       { *(.setup) }

  . += virt;

  .text : AT(code - virt) { code = .;
                            *(.text)
                            *(.rodata*)
                            . = ALIGN(4096); }

  .data : AT(data - virt) { data = .;
                            *(.data)
                            . = ALIGN(4096); }

  .bss  : AT(bss - virt)  { bss = .;
                            *(COMMON*)
                            *(.bss*)
                            . = ALIGN(4096); }
  end = .; }
@ %def phys virt

\noindent
The file mainly accomplishes two things:

\pagebreak

\begin{itemize}
\item it tells the linker [[ld]] to use addresses in the address range
starting with \hex{100000} (= 1 MByte mark) for everything that we have
declared as part of the [[.setup]] section, and it will also cause the
boot manager to load the whole kernel to \hex{100000}.

The [[.setup]] region contains the code that runs before paging is 
enabled. It prepares the segment table and switches it on.

\item the line [[. += virt;]] lets the linker use modified addresses
for all the other sections: wherever an absolute address occurs in a
CPU instruction, it will get \hex{C0000000} added to its original value.
(Technically, it adds \hex{C0000000} to the current output location 
counter ``[[.]]'': if the last linked instruction ended on position
\hex{105555}, linking would continue with address \hex{c0105556}.)

If this line was not followed by

\begin{Verbatim}
.text : AT(code - virt) { code = .;
\end{Verbatim}

\noindent
it would have the effect to generate code and data which would be
loaded at addresses beyond \hex{C0000000}, but the [[AT]] statement
says that it shall be placed in a different location:
[[code]] is set to [[.]] which is the current location, and [[AT]]
calculates [[code - virt]] which is just the next address behind
the [[.setup]] section. The consequence is that the [[text]] section
will be loaded within the second MByte of physical RAM, and---without
enabling paging---it will not be executable in that place because
all addresses in the code will have an additional offset of 
\hexaddr{C0000000}. This must later be corrected before jumping into
that section. Our segment table does just that.

\item [[.text]] is the code section, it will contain everything that gets
executed (except for the parts in [[.setup]]).

\item [[.data]] and [[.bss]] contain program data structures which can be read and
written, but not executed. The difference between the two is that variables
in [[data]] have an explicit non-zero initialization in the code, whereas
the ones in [[bss]] do not---the linker initially sets them up with zeroes.
\end{itemize}

\noindent
This means: for code in the [[.setup]] section, physical addresses are
identical with the addresses used in that part of the binary. That does
not hold for the rest of the kernel, where all addresses are increased
by \hex{C0000000}---which would normally render that part of the code
useless, but our segmentation trick with a base address of \hex{40000000}
makes it just right.

The [[.ALIGN]] statements force the linker to align each section to the 
start of a page (or page frame) of size 4096.
You can find more information about the linker in the [[ld]] manual 
\cite{using-ld:2004}.

When we inspect the linked kernel binary \path!ulix.bin! with the
[[objdump]] tool, we see what happens:

\begin{Verbatim}
$ objdump -h ulix.bin 
ulix.bin:     file format elf32-i386
Sections:
\end{Verbatim}

\pagebreak

\begin{Verbatim}
Idx Name          Size      VMA       LMA       File off  Algn
  0 .setup        00000049  00100000  00100000  00001000  2**0
                  CONTENTS, ALLOC, LOAD, READONLY, DATA
  1 .text         00012fa0  c0100060  00100060  00001060  2**5
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .data         00002000  c0113000  00113000  00014000  2**5
                  CONTENTS, ALLOC, LOAD, DATA
  3 .bss          00189000  c0115000  00115000  00016000  2**12
                  ALLOC
[...]
\end{Verbatim}

The columns [[VMA]] and [[LMA]] display the first virtual memory
address and the load memory address of each section. The first one
shows what memory location the code was prepared for, and the second
one shows the absolute load address, i.\,e., where the boot loader
will store the section in RAM.

As we've already described, our code starts executing in the 
[[.setup]] section, where it sets up the GDT and enables it; then
it continues execution in the [[.text]] section. 


\section{Virtual Memory for the Kernel}
\label{sec:ulix:vm}%


Setting up the memory consists of creating an initial page table for
the kernel: This is a two-step procedure, we start with an 
\emph{identity mapping}\index{identity mapping}\index{virtual memory!identity mapping}\marginnote{identity\\ mapping}: that is a page table which maps virtual
addresses 1:1 to physical addresses. The identity mapping lets us
smoothly enable paging; when the CPU fetches the instruction which 
follows immediately after the enabling instruction, that memory
access uses the memory management unit (MMU) and the translation
information in the page table, whereas all earlier instructions
accessed the memory (almost) directly.

<<setup memory>>=
<<setup identity mapping for kernel>>
<<enable paging for the kernel>>
<<install flat gdt>>
@ We will discuss the details in this section.



Since we implement \Ulix{}-i386 for Intel chips, we need to have a 
look at the Intel architecture which uses a two-layer design
(see Figure \ref{fig:intel paging}).

% trim: left, bottom, right and top
\begin{figure}[ht]
%\centering
\hspace{-1mm}%
\includegraphics[width=1.02\textwidth]{pics/page-table-intel.pdf}
\caption[Two-layered page table tree for the Intel x86 architecture.]{The Intel x86 Architecture uses a two-layered page table; the first layer is called ``page directory'', the second one ``page table''.}
\label{fig:intel paging}
\end{figure}

When paging is active, the CPU register 
\marginnote{CR3 (control\\ register 3)}\index{virtual memory!CR3 register}\index{Intel x86 architecture!CR3 register}\index{CR3 register}\index{register!CR3}
\register{CR3} (control 
register 3) points to
a page directory which is a collection of 1024 page directory entries.
Each of those entries is four bytes large, so the whole page directory
has a size of 4 KByte (one page).

Each page directory entry points to a page table (its address is given
via bits 31..12).

Page tables have the same size as page directories (4 KByte), and they
also hold 1024 entries, the page table entries. Such an entry points
to a frame (again using bits 31..12).

We will look at these data structures in detail in the following sections.
While---as an OS designer---you are free to implement many things in any
way you can conceive, the Intel processor expects page directories and
page tables to have a well-defined form that cannot be changed.



\subsection{Page Descriptors and Page Table Descriptors in \Ulix{}}

We now define the structures [[page_desc]] and [[page_table_desc]] for page 
(table) descriptors. They use the layout that is required
by the Intel CPU. Recall that it expects that the page table tree has exactly two
levels. Descriptors at level 2 are either null descriptors or page
descriptors. Descriptors at level 1 are either null descriptors
or page table descriptors.

Intel uses a different vocabulary: In the Intel terminology,

\begin{itemize}
\item a page descriptor is a \emph{page table entry}\marginnote{page table entry}\index{page table entry} (\emph{PTE}; within a page table), and
\item a page table descriptor is a \emph{page directory entry}\index{page directory entry}\marginnote{page directory\\ entry} (\emph{PDE}; in a page directory).
\end{itemize}

Each entry (for both page tables and page directories) is four bytes
long; a page table or page directory contains 1024 such entries,
filling exactly one page (of size 4 KByte).

A virtual address is always split in three parts: the page table
number (bits 31--22), the page number (21--12) and the offset (11--0),
see Figure \ref{fig:virtual address}.
\vspace{3mm}

\begin{figure}[ht]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=4mm]{32}
\bitheader[b]{0-31}\\
\bitbox{10}{page table}
\bitbox{10}{page}
\bitbox{12}{offset}
\end{bytefield}
\caption[Virtual address for Intel x86: directory, table and offset.]{Virtual addresses consist of three parts: a 10 bit index into
the page directory, 10 further bits as entry into a page table and
12 bits as offset.}
\label{fig:virtual address}
\end{centering}
\end{figure}
%\begin{Verbatim}
%/---------------+------------+-----------\
%| 31 ....... 22 | 21 .... 12 | 11 .... 0 |
%|   page table  |    page    |   offset  |
%\---------------+------------+-----------/
%\end{Verbatim}

Page table number and page number are Intel's specific terms for the general concept of
split page table numbers where each portion corresponds to some level
of page tables.


\pagebreak 

The system must associate a page directory with each process, the
start address of the page directory must be stored in the
process descriptor base register\index{process descriptor base register (PDBR)}\index{register!PDBR}\index{PDBR register} 
\marginnote{PDBR (in CR3)}
(\register{PDBR}), the upper 20 bits of control register 3 
(\register{CR3}).

20 bits are sufficient to store an address because pages are 
page-size-aligned, i.\,e., they all start at addresses with zeroes
in the lower 12 bits. (A page has size 4 KByte = $2^{12}$ bytes,
which is why the offset length is 12.)


\subsubsection{Page Table Entries}

The upper 20 bits of a page descriptor contain the upper bits of a
frame address (in RAM); the remaining bits of that address are zeroes
for the same alignment reason as already described above: In RAM,
no frame starts at an ``odd'' address which is not a multiple of the
page size. Thus the frame address can easily be extracted from the
page descriptor by setting the lower 12 bits to zero, if we treat
the whole page descriptor\index{page descriptor!32-bit integer interpretation} as a 32-bit integer (which can be achieved
with a cast operation in C, see also Exercise~\ref{ex:page table as int} on 
page~\pageref{ex:page table as int}):

<<get frame address from page descriptor's integer representation>>=
frame_address = page_descriptor & 0xFFFFF000;  
// F (hex) = 1111 (bin);  0 (hex) = 0000 (bin)
@

\index{Intel x86 architecture!page descriptor}%
The remaining bits in the page descriptor are either unused and can be
used by the operating system for its own purposes (bits 9--11) or 
store attributes of this page descriptor (see Figure~\ref{fig:intel page descriptor}):

\begin{itemize}
  \item Bits 8 and 7 must always be 0.
  \item Bit 6 holds the \emph{Dirty} (D) flag.
  \item Bit 5 holds the \emph{Accessed} (A) flag. It is automatically set by the MMU
    when this page is accessed.
  \item Bit 4 is called \emph{Page Cache Disabled} (PCD) -- if set, data from
    this page must not be cached.
  \item Bit 3 is called \emph{Page Write Transparent} (PWT), we will ignore
    this one and always set it to 0.
  \item Bit 2 holds the \emph{User Accessible} (U) flag.
  \item Bit 1 holds the \emph{Writeable} (W) flag.
  \item Bit 0 holds the \emph{Present} (P) flag.
\end{itemize}


\begin{figure}[ht]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=4.3mm,bitheight=13mm]{32}
\bitheader[b]{0-8,9,11,12,31}\\
\bitbox{20}{page base address}
\bitbox{3}{unused}
\bitbox{2}{0} % 8, 7
\bitbox{1}{D} % 6, dirty
\bitbox{1}{A} % 5, accessed
\bitbox{1}{P\\[-1mm] C\\[-1mm] D}
\bitbox{1}{P\\[-1mm] W\\[-1mm] T}
\bitbox{1}{U}
\bitbox{1}{W}
\bitbox{1}{P}
\end{bytefield}
\caption[Page descriptors hold 20 address bits and twelve configuration bits.]{A page descriptor stores the upper 20 bits of the frame address and administrative data.}
\label{fig:intel page descriptor}
\end{centering}
\end{figure}

\pagebreak
We can now describe the page descriptor in C:\index{page descriptor!structure declaration}

<<type definitions>>=
typedef struct {
  unsigned int present         :  1;  //  0
  unsigned int writeable       :  1;  //  1
  unsigned int user_accessible :  1;  //  2
  unsigned int pwt             :  1;  //  3
  unsigned int pcd             :  1;  //  4
  unsigned int accessed        :  1;  //  5
  unsigned int dirty           :  1;  //  6
  unsigned int zeroes          :  2;  //  8.. 7
  unsigned int unused_bits     :  3;  // 11.. 9
  unsigned int frame_addr      : 20;  // 31..12
} page_desc;
@ %def page_desc

We repeat the code for calculating the physical
address from this page descriptor, but now in a proper function
that we can use later:

<<function implementations>>=
memaddress page_desc_2_frame_address (page_desc pd) {
  // pointer magic/cast: a page descriptor is not really an unsigned
  // int, but we want to treat it as one
  memaddress address = *(memaddress*)(&pd);
  return address & 0xFFFFF000;   // set lowest 12 bits to zero
}
@ %def page_desc_2_frame_address

\noindent
(This uses the casting trick we mentioned above: First we take the
address of the page descriptor [[pd]] with the [[&]] operator,
then we cast this pointer to a page descriptor to a pointer to
a 32-bit integer with [[(memaddress*)]], and last we access the
value with the [[*]] operator. Note that it is not possible to
directly cast the page descriptor to an integer with a command
like \verb#address = (memaddress)pd;#---that is forbidden in the
C language.)

The following function fills a page descriptor with values;
its address must be provided (the space must be reserved by
the caller). We provide the descriptor's address as the first
argument via a pointer; the other arguments are the present,
writeable, user accessible and dirty bits\index{dirty bit (D bit), page descriptor} and---most
important---the physical frame address:

<<function implementations>>=
page_desc *fill_page_desc (page_desc *pd, unsigned int present,
                           unsigned int writeable, unsigned int user_accessible,
                           unsigned int dirty, memaddress frame_addr) {

  memset (pd, 0, sizeof (page_desc));      // first fill the four bytes with zeros
  
  pd->present         = present;           // then enter the argument values in  
  pd->writeable       = writeable;         // the proper struct members
  pd->user_accessible = user_accessible;
  pd->dirty           = dirty;
  pd->frame_addr      = frame_addr >> 12;  // right shift, discard lower 12 bits
  return pd;
};
@ %def fill_page_desc

We have used the right shift operator [[>>]] in this function which
takes the 32 bits from the \verb#memaddress# variable [[frame_addr]], 
right shifts them and fills the hole on the left side with zeroes.
The function assumes that we always call it with a proper, page-size-aligned
frame address [[frame_addr]] since its lower twelve bits will be discarded
(they should have been zero to start with).

We provide two macros for quickly calling [[fill_page_desc]] with
standard values, both for kernel memory and user mode memory:

<<macro definitions>>=
#define KMAP(pd,frame) fill_page_desc (pd, true, true, false, false, frame)
#define UMAP(pd,frame) fill_page_desc (pd, true, true, true,  false, frame)
@ %def KMAP UMAP

\noindent
Both macros set the present and writeable bits to 1, they set the dirty
bit to 0, and they supply the frame address; the difference is that
[[KMAP]] sets the user accessible bit to 0 (making the page inaccessible
to user mode code), whereas [[UMAP]] sets it to 1.

A page table contains 1024 page descriptors:

<<type definitions>>=
typedef struct {
   page_desc pds[1024];
} page_table;
@ %def page_table

\noindent
We make this a {\tt struct} so that we can easily create a
pointer to such a page table.



\subsubsection{Page Directory Entries}

\noindent
A page table descriptor or page directory entry\index{page directory entry}\index{Intel x86 architecture!page directory entry} looks similar to a page table 
entry: it has the same size and shares many common fields with the other one.

The upper 20 bits contain---again---the upper bits of a
frame address (in RAM), the same alignment argument allows us to 
leave out the lowest 12 bits of the address.

The remaining bits in the page descriptor are either unused and can be
used by the operating system for its own purposes (bits 9--11) or 
store attributes of this page descriptor:

\begin{itemize}
  \item Bits 8 and 7 must always be 0. (Actually if bit 7 is set, this
    declares that the page described by this entry is a 4 MByte, not 4 KByte,
    page. We will not discuss 4 MByte pages.)
  \item Bit 6 is undocumented, we will always set it to 0.
\end{itemize}

\noindent
The remaining fields are identical to those of a page table entry:

\begin{itemize}
  \item Bit 5 holds the \emph{Accessed} (A) flag.
  \item Bit 4 is called \emph{Page Cache Disabled} (PCD) -- if set, data from
    all pages belonging to this page table must not be cached.
  \item Bit 3 is called \emph{Page Write Transparent} (PWT), we will ignore
    this one and always set it to 0.
  \item Bits 2, 1 and 0 hold the \emph{User Accessible} (U), \emph{Writeable} (W) and
        \emph{Present} (P) flags.
\end{itemize}

\noindent
The PCD, U, W and P flags enforce these properties for all pages that belong to this page table. Figure~\ref{fig:intel page table descriptor} shows the layout of the descriptor which is almost identical to that of the page descriptor, except for the missing Dirty flag.

\begin{figure}[ht]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\vspace{2mm}
\begin{bytefield}[bitwidth=4.3mm,bitheight=13mm]{32}
\bitheader[b]{0-8,9,11,12,31}\\
\bitbox{20}{page table base address}
\bitbox{3}{unused}
\bitbox{3}{0} % 8, 7, 6
\bitbox{1}{A} % 5, accessed
\bitbox{1}{P\\[-1mm] C\\[-1mm] D}
\bitbox{1}{P\\[-1mm] W\\[-1mm] T}
\bitbox{1}{U}
\bitbox{1}{W}
\bitbox{1}{P}
\end{bytefield}
\caption[Page table descriptors hold 20 address bits and twelve configuration bits.]{A page table descriptor stores the upper 20 bits of the physical address of the page table it points to and administrative data.}
\label{fig:intel page table descriptor}
\end{centering}
\end{figure}



The C structure which describes page table descriptors only differs from the page descriptor structure [[page_desc]] by replacing the [[dirty]] field with an [[undocumented]] field:\index{page table descriptor!structure declaration}

<<type definitions>>=
typedef struct {
  unsigned int present         :  1;  //  0
  unsigned int writeable       :  1;  //  1
  unsigned int user_accessible :  1;  //  2
  unsigned int pwt             :  1;  //  3
  unsigned int pcd             :  1;  //  4
  unsigned int accessed        :  1;  //  5
  unsigned int undocumented    :  1;  //  6
  unsigned int zeroes          :  2;  //  8.. 7
  unsigned int unused_bits     :  3;  // 11.. 9
  unsigned int frame_addr      : 20;  // 31..12
} page_table_desc;
@ %def page_table_desc

For extracting the frame address from a page table descriptor
we rewrite the function [[page_desc_2_frame_address]] by simply using the new
[[page_table_desc]] structure instead of [[page_desc]]:

\pagebreak

<<function implementations>>=
memaddress page_table_desc_2_frame_address (page_table_desc ptd) {
  memaddress address = *(memaddress*)(&ptd);
  return address & 0xFFFFF000;
}
@ %def page_table_desc_2_frame_address

\noindent
and we also duplicate [[fill_page_desc()]] as [[fill_page_table_desc()]].
Note that the function has one argument less since the [[dirty]] attribute
does not exist in page table descriptors:

<<function implementations>>=
page_table_desc *fill_page_table_desc (page_table_desc *ptd, unsigned int present,
                           unsigned int writeable, unsigned int user_accessible,
                           memaddress frame_addr) {

  memset (ptd, 0, sizeof (page_table_desc));  // fill the four bytes with zeros
  
  ptd->present         = present;             // then enter the argument values
  ptd->writeable       = writeable;
  ptd->user_accessible = user_accessible;
  ptd->frame_addr      = frame_addr >> 12;    // right shift, 12 bits
  return ptd;
};
@ %def fill_page_table_desc

Just as we did for the page tables, we provide macros [[KMAPD]] and [[UMAPD]]
which let us call [[fill_page_table_desc]] with standard values:

<<macro definitions>>=
#define UMAPD(ptd, frame) fill_page_table_desc (ptd, true, true, true,  frame)
#define KMAPD(ptd, frame) fill_page_table_desc (ptd, true, true, false, frame)
@ %def UMAPD KMAPD
In most cases we will use the [[UMAP]], [[KMAP]], [[UMAPD]] and [[KMAPD]] macros
for modifying descriptors.

A page directory contains 1024 page table descriptors:

<<type definitions>>=
typedef struct {
   page_table_desc ptds[1024];
} page_directory;
@ %def page_directory



\pagebreak

\subsection{Identity Mapping the Kernel Memory}

\index{identity mapping}%
\index{virtual memory!identity mapping}%
We will now use a trick that allows a smooth transition from
non-paging mode to paging mode: \emph{identity mapping} creates
a page directory for the kernel that maps the first virtual
addresses to identical hardware addresses. When we later switch
on paging, nothing changes for the kernel, because the MMU
will be set up to use a page table that translates virtual
addresses to the same addresses we've used before. This will
also demonstrate why we've set up the segment tables with
\hex{40000000} offsets earlier.


\subsubsection{First Attempt at a Kernel Layout}

\noindent
We now present a first and intuitive approach to placing the
kernel in memory---both real memory and virtual memory; we will
soon see that this approach is not the best possible choice and
use a different layout.

Here are some general considerations that will lead us in the
following steps:

\begin{itemize}
\item When the machine starts it must load the kernel into RAM. At
that time paging is not yet enabled, so when the computer begins
executing our kernel it uses physical memory addresses.
\item Since we cannot know how much physical memory will be installed
in a machine, it makes sense to place the kernel in some area with
low memory addresses, such as the first megabyte of RAM.
\item At some point in time during initialization of the operating
system we will enable paging. However, code execution must logically
continue at the next instruction and must not become confused by
the fact that addresses are now translated by the MMU.
\end{itemize}

The easiest thing to do is compiling and linking the kernel with
addresses starting at 0x0. If we assume that the kernel (and its
stack) fit in 1 MByte of memory, we can reserve this physical
memory area (\hexaddr{0000.0000}--\hexaddr{000F.FFFF}). The instruction that is 
going to enable paging will be sitting somewhere in this area, so
we have to make sure that after paging is turned on, the instruction
pointer will point to the instruction that follows immediately.

We need to identify
the virtual addresses \hexaddr{0000.0000} to \hexaddr{000F.FFFF} with
the same physical addresses. This amounts to 256 page table
entries; they all fit in one page table ([[kernel_pt]]), and the page 
directory ([[kernel_pd]]) will have exactly one non-null entry pointing 
to that one page table.

This way, when the kernel has enabled paging, the first megabyte
of virtual addresses will be in use (and reserved for the kernel),
whereas the rest will have null pointers in the page directory and
the page tables. So when we later talk about processes and threads,
we can create processes which use virtual memory addresses starting
at (virtual) address \hex{00100000} (just after the first MByte),
and those processes will have the first $2^{20}$ addresses unmapped.
That way, when the process makes a syscall, we can modify the
page tables so that the kernel's address space is added---then all
addresses (\hexrange{00000000}{000FFFFF}: kernel; 
\hex{00100000} and above: process) will be available so that
data can be copied between process and kernel memory (see Figure
\ref{fig:identity-mapping-1}).

\begin{figure}[ht!]
\centering
\includegraphics[width=9cm]{pics/identity-mapping-1.pdf}
\caption[Identity mapping, 1st attempt: 1st MByte virtual memory = 1st MByte RAM.]{Identity mapping, first attempt: We identify the first MByte of virtual memory with the first MByte of physical RAM.}
\label{fig:identity-mapping-1}
\end{figure}


Let's start by declaring the necessary global variables:\index{kernel page directory}

<<global variables>>=
page_directory kernel_pd  __attribute__ ((aligned (4096)));
page_table     kernel_pt  __attribute__ ((aligned (4096)));

// prefer to work with pointers
page_directory *current_pd = &kernel_pd;
page_table     *current_pt = &kernel_pt;
@ %def kernel_pd kernel_pt current_pd current_pt
We need to declare these with \verb#__attribute__ ((aligned (4096)))#
so that the C compiler aligns them properly in pages.

<<setup identity mapping for kernel 1st attempt>>=
for (int i = 0;  i < 1024;  i++) {
  fill_page_table_desc (&current_pd->ptds[i], false, false, false, 0);
};

// make page table kernel_pt first entry of page directory kernel_pd
KMAPD ( &(kernel_pd.ptds[0]), (memaddress)(&kernel_pt) );
for (int i = 0;  i < 1024;  i++) {               // map 1024 pages (4 MB)
  <<identity map page i in [[kernel_pt]]>>
};
@

In order to identity"=map page [[i]] in [[kernel_pt]] we need to fill
the $i^{\,\text{\scriptsize th}}$ entry. Page frame $i$ starts
at physical address $i\, \times$ \verb#PAGE_SIZE#:

<<identity map page i in [[kernel_pt]]>>=
KMAP ( &(current_pt->pds[i]), i*4096 );
@

Finally, we have to enable paging in the CPU. That can be achieved
by making some changes to the control registers \register{CR0} and 
\register{CR3} as follows:

\begin{itemize}
  \item Control register 3 (\register{CR3}) must contain the address of the page
    directory ([[kernel_pd]]),
  \item in control register 0 
    \marginnote{CR0 (Control\\ Register 0)}
    (\register{CR0}) we must set the PG (paging) bit
    which is bit 31. Setting this single bit is done by calculating
    [[cr0 = cr0 | (1@<<31)]]. 
\end{itemize}

<<global variables>>=
char *kernel_pd_address;      // address of kernel page directory
@ %def kernel_pd_address

<<enable paging for the kernel 1st attempt>>=
kernel_pd_address = (char*)(&kernel_pd);
asm volatile ("mov %0, %%cr3" : : "r"(kernel_pd_address));     // write_ CR3
uint cr0; asm volatile ("mov %%cr0, %0" : "=r"(cr0) : );       // read_  CR0
cr0 |= (1<<31);                // Enable paging_ by setting PG bit 31 of CR0
asm volatile ("mov %0, %%cr0" : : "r"(cr0) );                  // write_ CR0
@

We call this code block [[<<enable paging for the kernel 1st attempt>>]] 
because we're not done yet; with the higher half trick, [[&kernel_pd]] will
not be a physical address and won't fit the base values in our segment
descriptors.



\subsubsection{Second Attempt at a Kernel Layout}

\noindent
For several reasons (which we will not dig into), legacy properties
of Intel machines suggest to keep the first megabyte of RAM unused.
So we will physically store the kernel in the second MByte.
However, once paging is turned on, the kernel's addresses shall be
found in the last of the four gigabytes (starting at \hex{c0000000}),
as we've shown at this chapter's beginning
(see Figure \ref{fig:ulix memory layout simple} on page 
\pageref{fig:ulix memory layout simple}). We want processes to use
the first three gigabytes and the kernel to reside in the last
of the four available gigabytes of virtual memory. 
Figure~\ref{fig:identity-mapping-2} shows the necessary mapping of
virtual addresses to physical addresses.

\begin{figure}[p!]
\centering
\includegraphics[width=10cm]{pics/identity-mapping-2.pdf}
\caption[Second mapping attempt: Kernel starts at 3 GB + 1 MB (virtual).]{Second mapping attempt: Kernel starts at 3 GB + 1 MB (virtual) or 1 MB (physical).}
\label{fig:identity-mapping-2}
\end{figure}

\begin{figure}[p!]
\centering
\includegraphics[width=10cm]{pics/identity-mapping-3.pdf}
\caption[\hgepolylof{Final mapping: Kernel starts at 3 GB + 1 MB \emph{and} 1 MB (virtual).}]{Final mapping: Kernel starts at 3 GB + 1 MB \emph{and} 1 MB (virtual) or 1 MB (physical).}
\label{fig:identity-mapping-3}
\end{figure}

This is not an identity mapping, so when we start the system we run
into a problem: We could link the kernel twice und also physically load it 
twice, into the physical ranges [\,1~MB, 2~MB\,[ and [\,3~GB + 1~MB, 3~GB + 2~MB\,[---but 
that would require our physical memory to be big enough.

The solution is to work with a double mapping, as can be seen
in Figure~\ref{fig:identity-mapping-3} (during initialization).

So we do the following:

\begin{enumerate}
\item Load the kernel to physical addresses [\,1~MB, 2~MB\,[ (\hexrange{100000}{1FFFFF}).
\item Do the Higher Half Trick\index{higher half trick} (see page \pageref{higher half trick}):
  Enable the trick GDT with base address \hex{40000000} and jump to
  the higher half.
\item Setup an identity mapping from [\,1~MB, 2~MB\,[ (virtual) to [\,1~MB, 2~MB\,[ (physical).
  Actually, we'll map the whole first 4 megabytes, since one page table describes
  4~MByte of virtual memory.
\item Additionally set up a mapping from [\,3~GB + 1~MB, 3~GB + 2~MB\,[ 
  (\hexrange{C0100000}{C01F FFFF}; virtual) to [\,1~MB, 2~MB\,[ (physical) -- the 
  corresponding page table has the same contents as the first
  one, it just gets pointed to from a different page directory entry.
  Again, we'll map a whole 4~MByte block, [\,3~GB, 3~GB + 4~MB\,[ to [\,0, 4~MB\,[.
\item Activate paging.
\item Install a new ``flat'' GDT with base address \hex{0}.
\item Get rid of the initial mapping for [\,0, 4~MB\,[ (virtual).
\end{enumerate}

After that the kernel sees virtual addresses starting at 3~GByte (\hex{C0000000}) only,
and things work perfectly with the linker configuration we've discussed
on page \pageref{code:loader configuration}.

Now we have to modify the setup of the identity mapping:

<<setup identity mapping for kernel>>=
// file page directory with null entries
for (int i = 0;  i < 1024;  i++) {
  fill_page_table_desc (&(current_pd->ptds[i]), false, false, false, 0);
};

// make page table kernel_pt      the first entry of page directory kernel_pd
// maps: 0x00000000..0x003FFFFF -> 0x00000000..0x003FFFFF  (4 MB)
KMAPD ( &(current_pd->ptds[  0]), (memaddress)(current_pt)-0xC0000000 );

// make page table kernel_pt also the 768th entry of page directory kernel_pd
// maps: 0xC0000000..0xC03FFFFF -> 0x00000000..0x003FFFFF  (4 MB)
KMAPD ( &(current_pd->ptds[768]), (memaddress)(current_pt)-0xC0000000 );

// map 1023 pages (4 MB minus 1 page)
for (int i = 0;  i < 1023;  i++) {
  <<identity map page i in [[kernel_pt]]>>
};

kputs ("Kernel page directory set up.\n");
@

\enlargethispage{5mm}
Note that we're leaving one entry free (mapping only 1023 pages)---we'll
later need this one to create the next page table.

\pagebreak

Then we can load the process descriptor base register\index{process descriptor base register (PDBR)}\index{PDBR register}\index{register!PDBR} (\register{PDBR},
part of \register{CR3}\index{CR3 register}\index{register!CR3}) and modify \register{CR0}\index{CR0 register}\index{register!CR0} so that the CPU
switches to paging mode\index{paging!enable via CR0 register}\index{Intel x86 architecture!enable paging, CR0 register}---the following code is almost the same as the
one in [[<<enable paging for the kernel 1st attempt>>]], but it calculates
the physical address of the page directory by subtracting
\hex{C0000000}:

<<enable paging for the kernel>>=
kernel_pd_address = (char*)(current_pd) - 0xC0000000;
asm volatile ("mov %0, %%cr3" : : "r"(kernel_pd_address) ); // write_ CR3
uint cr0; asm volatile ("mov %%cr0, %0" : "=r"(cr0) : );    // read_  CR0
cr0 |= (1<<31);             // Enable paging_ by setting PG bit 31 of CR0
asm volatile ("mov %0, %%cr0" : : "r"(cr0) );               // write_ CR0
@

After paging is enabled we first update the GDT (and make it flat),
then we can get rid of the identity mapping which
works with low addresses.


\subsection{Installing the ``Flat'' GDT}

One of the last steps is installing the ``flat'' GDT: it looks
like our trick GDT, but uses a base address of \hex{0} instead of
\hex{40000000}. We're already executing C code, so we'll provide
a C function for loading the GDT\footnote{The functions in this
section are---again---based on code from Bran's Kernel Development Tutorial
\cite{brans-tutorial:200x}.}:

%nouse
<<function prototypes>>=
void fill_gdt_entry (int num, ulong base, ulong limit, byte access, byte gran);
extern void gdt_flush ();
@

<<function implementations>>=
void fill_gdt_entry (int num, ulong base, ulong limit, byte access, byte gran) {
  // base address; split in three parts
  gdt[num].base_low    = (base & 0xFFFF);         // 16 bits
  gdt[num].base_middle = (base >> 16) & 0xFF;     //  8 bits
  gdt[num].base_high   = (base >> 24) & 0xFF;     //  8 bits

  // limit address; split in two parts
  gdt[num].limit_low   = (limit & 0xFFFF);        // 16 bits
  gdt[num].limit_high  = (limit >> 16) & 0x0F;    //  4 bits

  // granularity and access flags
  gdt[num].flags       = gran & 0xF;
  gdt[num].access      = access;
}
@ %def fill_gdt_entry

The following code shows how the first three GDT entries are
created, however, we will later introduce three further entries
which we need for user mode processes---you can ignore that
for now, but that is the reason why we reserve space for six
GDT entries (instead of three) and we include the code chunk
[[<<install GDTs for User Mode>>]] and function calls to
[[gdt_flush]] and [[tss_flush]], the latter of which will be
explained when we discuss processes.
\index{data segment (kernel mode)}%
\index{code segment (kernel mode)}%
\index{segmentation!data segment (kernel mode)}%
\index{segmentation!code segment (kernel mode)}%
\index{GDT (global descriptor table)!code segment (kernel mode) entry}%
\index{GDT (global descriptor table)!data segment (kernel mode) entry}%
\index{kernel mode!GDT entries}%

\nextchunklabel{install-flat-gdt}
\label{fill kernel segment descriptors}
<<install flat gdt>>=
// We'll have six GDT entries; only three are defined now
gp.limit = (sizeof (struct gdt_entry) * 6) - 1;  // must be -1
gp.base = (int) &gdt;

fill_gdt_entry (0, 0, 0, 0, 0);    // null descriptor

// code segment: base = 0, limit = 0xFFFFF
fill_gdt_entry (1, 0, 0xFFFFF, 0b10011010, 0b1100);

// data segment: base = 0, limit = 0xFFFFF
fill_gdt_entry (2, 0, 0xFFFFF, 0b10010010, 0b1100);

<<install GDTs for User Mode>>  // explained later
gdt_flush ();   // Notify the CPU of changes
tss_flush ();   // explained later
@ (We've declared [[gp]] and [[gdt]] on page \pageref{gdt and gp declaration}
after defining the C data structures for the GDT.)
The function [[gdt_flush]] resides in the assembler\index{Assembler language} file; it uses
the [[lgdt]]\marginnote{[[lgdt]]}\tindex{lgdt}\index{GDT (global descriptor table)!lgdt@\texttt{lgdt}}\index{Assembler language!load the GDT} instruction to load the new segment descriptors, sets
all segment registers except \register{CS} to \hex{10} and then
makes a far jump for setting \register{CS} as well (to \hex{08}). 

%BEGIN ASM CHUNK
<<start.asm>>=
[section .text]
           extern gp           ; defined in the C file
           global gdt_flush
gdt_flush: lgdt [gp]
           mov ax, 0x10
           mov ds, ax
           mov es, ax
           mov fs, ax
           mov gs, ax
           mov ss, ax
           jmp 0x08:flush2
flush2:    ret
@ %def gdt_flush
%END ASM CHUNK
If you compare this code with the code for the higher half trick
(see page \pageref{higher half trick}), you will see that it basically
does the same and just uses a different address in the [[lgdt]]
\tindex{lgdt}\index{GDT (global descriptor table)!lgdt@\texttt{lgdt}}\index{Assembler language!load the GDT}%
instruction.

Effectively, the flat GDT sort of disables segmentation: the segmentation
unit maps logical addresses to identical linear addresses (which are then
translated into physical addresses by the paging unit).


\subsection{Accessing the Video RAM}

\index{video RAM}\index{framebuffer (VGA)}%
We need to access the video adapter's text mode framebuffer
which is mapped into the physical address space starting at
\hexaddr{B8000} (and takes up 4 KByte of memory). So we provide
a mapping for this memory as well:

<<global variables>>=
page_table video_pt __attribute__ ((aligned (4096)));  // must be aligned!
@ %def video_pt

We create a new page table (initialized with null entries) and from
there we only create a mapping of 4 KByte (starting at \hexaddr{B8000}).

<<initialize system>>=
for (int i = 0;  i < 1024;  i++) { 
  // null entries:
  fill_page_desc ( &(video_pt.pds[i]), false,false,false,false,0 );
};
  
KMAP ( &(video_pt.pds[0xB8]), 0xB8*4096 );   // one page of video RAM

// enter new table in page directory
KMAPD ( &(current_pd->ptds[0]), (memaddress) (&video_pt) - 0xC0000000 );

gdt_flush ();
@


\section{Physical Memory: Page Frames in \Ulix{}}
\label{sec:page:frames}

\index{frame!list of free frames}\index{frame table}%
\index{page frame|see {frame}}%
The physical memory consists of page frames, some of which are already
in use. When we dynamically assign frames to pages (i.\,e., change some
page table), we need to know which frames are free and which are in use.
For that purpose we use a bitmap (that we will call the 
\emph{frame table}\marginnote{frame table})
which holds the current usage state
of every frame. Since we have just set up the initial memory usage, we
know exactly what our memory looks like at this point in time, so now is
a good time to create and initialize that bitmap.

We assume that our system has 64 MByte of physical RAM.
\felix
The size of
the frame table depends on the size of the available physical memory
which we define to contain [[MEM_SIZE]] many addresses. Dividing
this by the [[PAGE_SIZE]] gives us the number of page frames.  This of
course assumes that [[MEM_SIZE]] is larger than [[PAGE_SIZE]] and
both values are powers of two.\index{maximum physical address}
\black

<<public constants>>=
#define MEM_SIZE 1024*1024*64       // 64 MByte
@ %def MEM_SIZE

\pagebreak

<<constants>>=
#define MAX_ADDRESS MEM_SIZE-1       // last valid physical address
#define PAGE_SIZE 4096               // Intel: 4K pages
#define NUMBER_OF_FRAMES (MEM_SIZE/PAGE_SIZE)
@ %def MAX_ADDRESS PAGE_SIZE NUMBER_OF_FRAMES

\felix

The usage of main memory is directly reflected in the amount of
frames which are not free. We will try to keep track of the
number of free frames throughout the lifetime of the system
in a global variable [[free_frames]].

<<global variables>>=
unsigned int free_frames = NUMBER_OF_FRAMES;
@ %def free_frames

\black

So [[NUMBER_OF_FRAMES]] is the number of bits we need to store in
the frame table. Since a byte holds eight bits, we need a structure
that is [[NUMBER_OF_FRAMES/8]] bytes large:

<<global variables>>=
char place_for_ftable[NUMBER_OF_FRAMES/8];
unsigned int *ftable = (unsigned int*)(&place_for_ftable);
@ %def place_for_ftable ftable

<<initialize system>>=
memset (ftable, 0, NUMBER_OF_FRAMES/8);  // all frames are free
@

Now we need to tell the frame table that some of our frames are
already in use: We have two mappings for the first 4 MByte of physical
RAM (even though we don't use the first MByte at all). So we
declare the first 4 MByte as used. 4 MByte contain 1024 pages,
thus the first 1024 frames must be marked used.
1024/8 = 128; we set the first 128 bytes to \hex{ff}
= \bin{11111111}. We also 
subtract the frames in these 4 MByte from [[free_frames]]:


<<initialize system>>=
memset (ftable, 0xff, 128);
free_frames -= 1024;
@


\subsection{Bitwise Manipulation}

We want to be able to set and clear single entries in our 
frame table, so we have to access single bits: read them, write
them and test them.

We can think of a frame number as consisting of

\begin{itemize}
\item an upper part that is an index into the frame table (which
  is built from 32-bit [[unsigned int]]s). Every such [[unsigned int]] stores
  32 bits.
\item and a lower part that is an offset whose value can lie
  between 0 and 31, giving a precise position within one such indexed [[unsigned int]].
\end{itemize}

So we get \emph{frameno} = 32 $\times$ \emph{index} + \emph{offset}, like this:

\[ \textsl{frameno} = \dots i_4\, i_3\, i_2\, i_1\, i_0\, o_4\, o_3\, o_2\, o_1\, o_0 \]

When we divide a frame number by 32, we find the [[unsigned int]] which stores
the bit we're searching for. The modulo function gives us the offset:\footnote{
The macros [[INDEX_FROM_BIT]] and [[OFFSET_FROM_BIT]] and the functions
[[set_frame]], [[clear_frame]], and [[test_frame]] have been taken from 
\url{http://www.jamesmolloy.co.uk/tutorial_html/6.-Paging.html}, they were
slightly modified and adapted to \UlixI{}.}

<<macro definitions>>=
#define INDEX_FROM_BIT(b) (b/32)   // 32 bits in an unsigned int
#define OFFSET_FROM_BIT(b) (b%32)
@ %def INDEX_FROM_BIT OFFSET_FROM_BIT

The following two functions allow us to set or clear individual
bits in the frame table:

<<function implementations>>=
static void set_frame (memaddress frame_addr) {
  unsigned int frame = frame_addr / PAGE_SIZE;
  unsigned int index = INDEX_FROM_BIT (frame);
  unsigned int offset = OFFSET_FROM_BIT (frame);
  ftable[index] |= (1 @<< offset);
}

static void clear_frame (memaddress frame_addr) {
  unsigned int frame = frame_addr / PAGE_SIZE;
  unsigned int index = INDEX_FROM_BIT (frame);
  unsigned int offset = OFFSET_FROM_BIT (frame);
  ftable[index] &= ~(1 @<< offset);
}
@ %def set_frame clear_frame

Note how individual bits are set or cleared:

\begin{itemize}
\item \verb#|=# and \verb#&=# work in a similar way as \verb#+=# for addition,
  however they perform ``bitwise or'' and ``bitwise and'', respectively. So
  \verb#x|=y# is short for \verb#x=x|y# and \verb#x&=y# is short for \verb#x=x&y#.
\item In the [[set_frame]] function, [[1 @<< offset]] uses left shift to create
  a value whose offset's bit is set (and all others are not), e.\,g.\
  [[1 @<< 3]] is \verb#00000000000000000000000000001000# (in binary notation).
\item Next the corresponding [[unsigned int]] is ``bitwise-or''ed with this value.
  That means: all bits which were already 1, remain 1; and the [[offset]]'s bit
  is being set (whatever its value was before).
\item In a similar way the [[clear_frame]] function can clear a bit. It
  also starts with a shift operation, but the result goes through bitwise negation
  (\verb#~#) which flips all bits. For example,
  [[~(1 @<< 3)]] is \bin{11111111111111111111111111110111}. So there is exactly
  one 0 bit in there with all other bits being 1.
\item Then the corresponding [[unsigned int]] is `bitwise-and''ed with this value. That means:
  all bits which were already 0, remain 0; and the [[offset]]'s bit
  is being cleared (whatever its value was before).
\end{itemize}

\noindent
What remains is a function that can test a bit. It returns [[true]] (1) or [[false]] (0):

<<function implementations>>=
static boolean test_frame (unsigned int frame) {
  // returns true if frame is in use (false if frame is free)
  unsigned int index = INDEX_FROM_BIT (frame);
  unsigned int offset = OFFSET_FROM_BIT (frame);
  return ((ftable[index] & (1 @<< offset)) @>> offset);
}
@ %def test_frame

A result of 0 means that a frame is available, whereas 1 means that the frame
is already in use---which corresponds to the way we have already initialized
a part of the frame table.

The function uses left and right shifts in order to always return either 0 or 1.
If you never do any comparisons with 1, but only call the function in \verb#if#
statements such as

%nouse
<<example call of test\_frame>>=
if ( test_frame (frameno) ) {
  // result non-0 (true); frame is not available
} else {
  // result 0 (false);    frame is available
}
@

\noindent
then you can skip the right shift at the end of the line and make the calculation
a bit faster.


\subsection{Direct Access to the Physical RAM}

So far we haven't encountered any conceptual problems, but consider this:
The information stored in the page directories, page tables and in the frame 
table refers to physical memory. But the kernel has activated paging, and even
though it runs with the most privileges any code on the machine can get, it
cannot directly access physical memory. Yet it has to modify or create new
page tables and it has to update the frame table. So the kernel needs to have
an understanding of what is going on in the physical memory, without accessing
it.

If physical memory is very small in comparison to the virtual address space,
it is possible to permanently map all of the RAM into some area of the kernel's 
\index{virtual memory!accessing physical memory}%
virtual address space. For our code we assume that the machine has only 64 MByte
of RAM---compared to the 4~GByte address space that is not much. We can spare
64~MByte of the virtual kernel memory and sponsor a mapping to this physical RAM.
We will put this in the area \hexaddr{D0000000} \dots \hexaddr{D3FFFFFF}, so that any physical
address $x$ can be accessed via the virtual address $x$ + \hexaddr{D0000000}.
 However, there's a cost: the corresponding
page table entries will require some room: 64 MByte = 16384 pages, so we will need
16384 page table entries each of which uses 4 bytes. Thus, it requires 16 pages
(64 KByte) to store the extra page tables.
Where can we put these tables? To simplify things we'll declare yet more static
variables which hold our 16 tables:

<<global variables>>=
page_table kernel_pt_ram[16] __attribute__ ((aligned (4096)));
@ %def kernel_pt_ram

\noindent
and we initialize them with references to all of our RAM.

<<initialize system>>=
for (uint fid = 0;  fid < NUMBER_OF_FRAMES;  fid++) {
  <<map page starting at [[0xD0000000 + PAGE_SIZE*fid]] to frame [[fid]]>>
}
@ The code for this mapping is not too complicated, either:

<<map page starting at [[0xD0000000 + PAGE_SIZE*fid]] to frame [[fid]]>>=
KMAP ( &(kernel_pt_ram[fid/1024].pds[fid%1024]), fid*PAGE_SIZE );
@

(Note that instead of
\verb#&(kernel_pt_ram[fid/1024].pds[fid%1024])#
we could have used \linebreak
\verb#&(kernel_pt_ram[0].pds[fid])#
which would access out of bound indices of \verb#kernel_pt_ram# \linebreak \verb#[0].pds#,
but since these arrays are arranged one after the other without
other data in between, it would work as well.)

To finalize this, we have to enter the 16 new page tables in 16
page directory entries. Note that we need the physical addresses
of the page tables, not the virtual ones. While 
[[&(kernel_pt_ram[i])]] delivers the virtual address just fine,
it does not help to write it into the page directory. Subtracting
\hexaddr{C0000000} does the job: we know that we loaded the
kernel at \hex{100000} with addresses starting at \hex{C0100000},
so we just need to subtract that artificial offset, and we're good.

<<initialize system>>=
for (int i = 0;  i < 16;  i++) {
  // get physical address of kernel_pt_ram[i]
  memaddress physaddr = (memaddress)(&(kernel_pt_ram[i])) - 0xc0000000;
  KMAPD ( &(current_pd->ptds[832+i]), physaddr );
};
kputs ("RAM: 64 MByte, mapped to 0xD0000000-0xD3FFFFFF\n");
@

Since we will often have to access a physical address, we'll define
a macro [[PHYSICAL]] that will translate an address from the first
64 MByte to the \hexaddr{D000.0000} \dots \hexaddr{D3FF.FFFF} range:

<<macro definitions>>=
#define PHYSICAL(x) ((x)+0xd0000000)
@ %def PHYSICAL

Now that we can access all of the physical addresses (including
video memory) we can get rid of the video mapping for \hex{b8000}\dots\hex{b9000},
we'll actually remove the first entry of the page directory which so far
mapped part of the first (virtual) 4~MByte.

<<initialize system>>=
VIDEORAM = 0xD00B8000;
// remove first page table (including the old video mapping)
fill_page_table_desc (&current_pd->ptds[0], 0, 0, 0, 0);
gdt_flush ();
@

We define a macro which casts [[VIDEORAM]] into a [[word]] pointer which
will later be helpful for accessing individual characters on the screen
(they are encoded as words, not bytes):
<<macro definitions>>=
#define textmemptr ((word*)VIDEORAM)
@ %def textmemptr


\subsubsection{MMU Emulation}

\index{MMU|see {memory management unit}}%
\index{memory management unit!emulation in Ulix}%
Sometimes we want to find out what frame is used by a page. We
present a function

%nouse
<<function prototypes>>=
unsigned int pageno_to_frameno (unsigned int pageno);
@ for this purpose which basically works like the MMU when it
translates addresses: It
uses the fact that for a page number [[pageno]] we first look
at entry [[pageno/1024]] of the page directory, locate the
referenced page table and then look at entry [[pageno%1024]]
of that page table. When the page is not mapped to a frame,
the function returns $-1$:

\label{function pageno to frameno}
<<function implementations>>=
unsigned int pageno_to_frameno (unsigned int pageno) {
  unsigned int pdindex = pageno/1024;
  unsigned int ptindex = pageno%1024;
  if ( ! current_pd->ptds[pdindex].present ) {
    return -1;       // we don't have that page table
  } else {
    // get the page table
    page_table *pt = (page_table*)
                     ( PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12) );
    if ( pt->pds[ptindex].present ) {
      return pt->pds[ptindex].frame_addr;
    } else {
      return -1;     // we don't have that page
    };
  };    
};
@ %def pageno_to_frameno
Note that [[frame_addr]] holds (the upper 20 bits of) a physical
address. Luckily we have a mapping of the physical address space
to \hex{d000.0000} and above that we can access via the [[PHYSICAL]]
macro---otherwise we would have no way of accessing the page table.


\subsection{PEEK and POKE Functions}

\noindent
If you remember home computers like the Commodore C64\index{Commodore C64 home computer} or the Schneider/Amstrad
CPC\index{Amstrad CPC home computer}\index{Schneider CPC home computer}, their built-in Basic\index{Basic programming language} interpreters
often had a way to directly access memory contents. The classical
command names were [[PEEK]] (for reading) and [[POKE]] (for writing).
Here they are again: They convert an address into a pointer to a
\verb#byte# and then read or write. (Credits to
Dan Henry who supplied the first two lines of this code on 
\url{http://www.keil.com/forum/8275/}.)

<<macro definitions>>=
// Peek and Poke for virtual addresses
#define PEEK(addr)           (*(byte *)(addr))
#define POKE(addr, b)        (*(byte *)(addr) = (b))
// Peek and Poke for physical addresses 0..64 MB
#define PEEKPH(addr)         (*(byte *)(PHYSICAL(addr)))
#define POKEPH(addr, b)      (*(byte *)(PHYSICAL(addr)) = (b))

// Macros for accessing unsigned ints (instead of bytes)
#define PEEK_UINT(addr)      (*(uint *)(addr))
#define POKE_UINT(addr, b)   (*(uint *)(addr) = (b))
#define PEEKPH_UINT(addr)    (*(uint *)(PHYSICAL(addr)))
#define POKEPH_UINT(addr, b) (*(uint *)(PHYSICAL(addr)) = (b))
@ %def PEEK POKE PEEKPH POKEPH PEEKPH_UINT POKEPH_UINT PEEK_UINT POKE_UINT

\noindent
[[PEEK]] and [[POKE]] read and write bytes using virtual addresses,
[[PEEKPH]] and [[POKEPH]] do the same with physical addresses
(using our \hex{D0000000} trick with the [[PHYSICAL]] macro),
and finally [[PEEK_UINT]], [[POKE_UINT]], [[PEEKPH_UINT]] and 
[[POKEPH_UINT]] do the same as the first four functions but work 
with unsigned 32-bit integers instead of bytes.

With the little-endian ordering of larger integers, the following code

\pagebreak

%nouse
<<peek and poke example>>=
unsigned int testvar;
unsigned int address = (unsigned int)&testvar;
POKE (address,   0x12);
POKE (address+1, 0x34);
POKE (address+2, 0x56);
POKE (address+3, 0x78);
printf ("32-bit value: 0x%x\n", PEEK_UINT (address));
@ prints 

\begin{Verbatim}
32-bit value: 0x78563412
\end{Verbatim}

\noindent
(and not [[0x12345678]]).


\subsection{Allocating and Releasing Frames}

\index{frame!allocation}%
\index{memory management!frame allocation}%
So far we have not used any dynamically generated data structures
in the kernel, so there was no need for some kind of allocation function
for the kernel.

When we start creating processes, we will need to reserve (virtual)
memory for those processes, and there may also be areas in the kernel
which need memory.

So we will start simple: with a function that requests a new frame
of physical memory. It has the following definition:

<<function implementations>>=
int request_new_frame () {
  <<find a free frame und reserve it>>
};
@ %def request_new_frame

This alone will not be all too useful---only in combination with
entering it in some paging table that memory will be accessible
(unless code uses the mapping of the physical RAM to \hexaddr{D000.0000}
and above).

Finding a free frame is simple: We look at the frame table and
return the first available frame:

<<find a free frame und reserve it>>=
unsigned int frameid;
boolean found;
//inside_req_frame++;                                         // REMOVE_DEBUGGING_CODE
start_find_frame:
//if (inside_req_frame > 1)                                   // REMOVE_DEBUGGING_CODE
//  printf ("WARNING: request_new_frame() recursion (%d)!\n", // REMOVE_DEBUGGING_CODE
//  inside_req_frame);                                        // REMOVE_DEBUGGING_CODE
found = false;
for (frameid = 0;  frameid < NUMBER_OF_FRAMES;  frameid++) {
  if ( !test_frame (frameid) ) {
    found=true;
    break;   // frame found
  };
}
@

\noindent
Then we use [[set_frame]] to mark the frame used and return the frame ID:
<<find a free frame und reserve it>>=
if (found) {
  // memset ((void*)PHYSICAL(frameid << 12), 0, PAGE_SIZE); // REMOVE_DEBUGGING_CODE
  set_frame (frameid*4096);
  free_frames--;
  // inside_req_frame--;                                    // REMOVE_DEBUGGING_CODE
  // printf ("NEW FRAME: 0x%0x\n", frameid);                // REMOVE_DEBUGGING_CODE
  return frameid;
} else {
  <<page replacement: free one frame>>    // will be explained later
  goto start_find_frame;
  // return -1;    // never fail
}
@ Note that the function clears a frame if no free one is available---we will explain the code chunk [[<<page replacement: free one frame>>]] in Chapter \ref{sec:page replacement implementation}.

We'll add code for releasing a frame: basically we just call
[[clear_frame]], but we also need to modify [[free_frames]]:

<<function implementations>>=
void release_frame (int frame) {
  if ( test_frame (frame) ) {
    // only do work if frame is marked as used
    clear_frame (frame @<< 12);
    free_frames++;
  };
};
@ %def release_frame
We may call [[release_frame]] for unused frames which
will have no effect.


\section{Managing Pages in \UlixI{}}

Since we have now established a mechanism for reserving frames, we can proceed with page requests. You have already seen all the required data structures when we initialized paging in Chapter~\ref{sec:ulix:vm} (pp.~\pageref{sec:ulix:vm} ff.). 


\subsection{Allocating Pages}

\index{page!allocation}%
\index{virtual memory!page allocation}%
\index{memory management!page allocation}%
Now we need to implement functions for dynamically requesting new pages and releasing them after they are no longer needed. Both are only possible via requesting and releasing frames, and we need to update existing page directories and page tables as well as occasionally create new page tables.

%nouse
<<function prototypes>>=
void *request_new_page  ();
void *request_new_pages (int number_of_pages);
@

\noindent
Getting one page is just a special case of getting several ones:
<<function implementations>>=
void *request_new_page () { return request_new_pages (1); }
@ %def request_new_page
The real work must be done here:
<<function implementations>>=
void *request_new_pages (int number_of_pages) {
  <<find contiguous virtual memory range>>
  <<enter frames in page table>>
};
@ %def request_new_pages
That function is more useful, but there's a lot to do in the two code
chunks:

\begin{itemize}
\item In [[<<find contiguous virtual memory range>>]] we need to find
a contiguous block of virtual memory\marginnote{contiguous\\ virtual memory}\index{contiguous allocation}
addresses which are unused
so far. That's important if, say, we want to reserve memory for
a large array of data which will be spread across several pages:
We need the virtual address range to have no ``holes'' so that
accessing array entries by index and pointer arithmetic work 
properly. With 1 GByte of virtual (kernel) memory available we expect
that this will always be possible. In order to find unmapped
pages we use the function [[mmu_p()]], an improved version of
[[pageno_to_frameno]].

\item For the next step [[<<enter frames in page table>>]] we must
reserve a frame for each page we want to map and enter its address
in the page table.
\end{itemize}

<<find contiguous virtual memory range>>=
unsigned int first_page = 0xc0000;  // first page
unsigned int count = 0;             // number of contiguous pages
while (count < number_of_pages && first_page+count <= 0xfffff) {
  if ( mmu_p (current_as, first_page + count) == -1 ) {
    count++;
  } else {
    // the block we just looked at is too small
    first_page += (count+1);        // restart search
    count = 0;
  }
}
if (count != number_of_pages)
  return NULL;   // could not find a sufficiently large area
@ (The function [[mmu_p]] does the same as [[pageno_to_frameno]],
see page \pageref{function pageno to frameno}, but it works with
address spaces which we have not yet defined---we'll introduce
them when we implement the process system. [[current_as]] refers
to the current address space, which you can ignore right now.)

There is one condition under which simply entering the
data in the page table will fail: if we fill the last
entry of the page table, it will afterwards be full,
and the next attempt to create a new page will find no
place to store it. Then it will be too late to create a
new page table (because that new page table must also
have a virtual address).

So we check now whether we're attempting to fill the
last entry.

<<enter frames in page table>>=
for (int pageno = first_page;  pageno < first_page+count;  pageno++) {
  int newframeid = request_new_frame ();  // get a fresh frame for this page
  if (newframeid == -1) {                 // exit_ if no frame was found
    // this can only happen if the swap file is full
    return NULL; 
  }
  unsigned int pdindex = pageno/1024;
  unsigned int ptindex = pageno%1024;
  page_table *pt;
  if (ptindex == 0 && !current_pd->ptds[pdindex].present) {
    // new page table!
    <<create new page table>>
    newframeid = request_new_frame ();    // get yet another frame
    if (newframeid == -1) {
      return NULL;                        // exit_ if no frame was found
      // again, this can only happen if the swap file is full
      // note: we're not removing the new page    // REMOVE_DEBUGGING_CODE
      // table since we assume                    // REMOVE_DEBUGGING_CODE
      // it will be used soon anyway              // REMOVE_DEBUGGING_CODE
    }
  };
@ Now we need to access the page directory and the right page
table again:

<<enter frames in page table>>=
  if ( !current_pd->ptds[pdindex].present ) {
    // we don't have that page table -- this should not happen!
    kputs ("FAIL! No page table entry\n");
    return NULL;
  } else {
    // get the page table
    pt = (page_table*)( PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12) );
    // enter the frame address
    KMAP ( &(pt->pds[ptindex]), newframeid * PAGE_SIZE );
    // invalidate cache entry
    asm volatile ("invlpg %0" : : "m"(*(char*)(pageno<<12)) );
  };
@ (The last line executes the 
\marginnote{[[invlpg]]}
[[invlpg]] instruction which invalidates
the cache entry for the modified page if one exists.)

\enlargethispage{5mm}
Finally, we clear the new page and return a pointer to the new page:

<<enter frames in page table>>=
  memset ((void*) (pageno*4096), 0, 4096);
}
return ((void*) (first_page*4096));
@

If a page table does not yet exist, it has to be created
\index{page table!creation}%
and referenced from the page directory.
On-the-fly creation of a new page table works like this: We have a
frame at [[newframeid]] which we can use, its physical address is 
[[newframeid << 12]]. It is not mapped (so it has no virtual address);
we'll deal with this fact later. We can use our [[PHYSICAL]] function
to ``talk'' to it directly: The address is [[PHYSICAL(newframeid<<12)]].
So we create the page table and fill it with zeroes:

<<create new page table>>=
//page_table *                    // REMOVE_DEBUGGING_CODE
pt = (page_table*) PHYSICAL(newframeid<<12);
memset (pt, 0, PAGE_SIZE);
@

We need to tell the page directory that this page table
is responsible for the next chunk of memory. When we calculated
[[pdindex]] and [[ptindex]] above, we found that [[ptindex]] is 0,
and [[pdindex]] points to the page directory entry that is
currently empty. So it is just [[pdindex]] which we have to use:

<<create new page table>>=
// KMAPD ( &(current_pd->ptds[pdindex]), newframeid << 12 );
@ The line above is commented out; it used to work before we 
introduced processes (and address spaces). The following code
is a variation of the above line which updates all page
directories (each process has its own one). This will become clear
when you reach the process chapter.

\label{code:create new page table, update all address spaces}%
<<create new page table>>=
for (addr_space_id asid=0; asid<1024; asid++) {
  if (address_spaces[asid].status == AS_USED) {  // is this address space in use?
    page_directory *tmp_pd = address_spaces[asid].pd;
    KMAPD ( &(tmp_pd->ptds[pdindex]), newframeid << 12 );
  }
}
@

Note: these new page tables only exist physically. Their frames are
marked as used, but no virtual addresses point to them.
Is that a problem? We can always get their physical addresses
through the page directory. So we should be fine.


\subsection{Releasing Pages}

Now we are able to request new pages, but occasionally we will
also want to release them. That is much simpler: In order to
release a page, we simply have to

<<function implementations>>=
void release_page (unsigned int pageno) {
  <<remove page to frame mapping from page table>>
  <<release corresponding frame>>
};
@ %def release_page

First we have to get rid of the page mapping, i.\,e., we need to
find the entry in the correct page table and replace it with a
null entry. The lookup code is similar to the code for creating
the new entry (in [[<<enter frames in page table>>]]). However,
we first test whether a page mapping exists, because if not,
we can return immediately:

<<remove page to frame mapping from page table>>=
// int frameno = pageno_to_frameno (pageno);
int frameno = mmu_p (current_as, pageno);  // we will need this later
if ( frameno == -1 )  { return; }          // exit_ if no such page
@ (As you can see, this code originally used [[pageno_to_frameno]]. However, with the introduction of address spaces, this does not work any longer since [[pageno_to_frameno]] is only aware of the first address space (that belongs to the kernel). As already mentioned, we will provide an [[mmu_p]] function which is very similar to [[pageno_to_frameno]], but takes an extra argument which lets us specify the address space. The variable [[current_as]] always stores the ID of the currently active address space.)

Next we look up the right entry and set it to zero:

<<remove page to frame mapping from page table>>=
unsigned int pdindex = pageno/1024;
unsigned int ptindex = pageno%1024;
page_table *pt;
pt = (page_table*)( PHYSICAL(current_pd->ptds[pdindex].frame_addr << 12) );

// write null page descriptor
fill_page_desc ( &(pt->pds[ptindex]), false, false, false, false, 0 );

// invalidate cache entry
asm volatile ("invlpg %0" : : "m"(*(char*)(pageno<<12)) );
@ We need to invalidate the cache entry for this page so that any further access to addresses inside the page lead to page faults.

Lastly, we free the frame---we have the [[release_frame]] function
for that:

<<release corresponding frame>>=
release_frame (frameno);  // note: this increases free_frames
@ That's all there is to it.

Sometimes we will want to release a whole consecutive range of
pages, so we'll add an extra function for this purpose:

<<function implementations>>=
void release_page_range (unsigned int start_pageno, unsigned int end_pageno) {
  for (int i = start_pageno;  i < end_pageno+1;  i++)  release_page (i);    
};
@ %def release_page_range



\section{Next Steps}

The system is now initialized and uses paging to manage the physical memory. However, whenever something goes wrong, the system will halt or reboot, and it cannot access any hardware, except the video card: Since the video memory can be accessed like normal RAM, we can display status or error messages, but that is all. Especially the code allows no interaction, because we cannot read the keyboard's status.

In the upcoming chapter we describe the mechanism that is required to handle faults (something went wrong) and interrupts (some device wants to inform the system about an event). With interrupts we can also have timers, and that brings us one step closer to working with processes which need working timers so that we can switch back and forth between several programs that run simultaneously.


\section{Exercises}

This is the first set of exercises. You will need the development environment that you can download from the \UlixI{} website (\url{http://www.ulixos.org/}). Install the virtual machine in VirtualBox and login as \verb#ulix# (with password \verb#ulix#).

\begin{enumerate}

\item On the \UlixI{} development system, locate the directory\marginnote{Tutorial 1}
\path!/home/ulix/tutorial/01/!. This directory contains parts of the 
code that we've presented so far; we've added the \verb#printf# function
which lets the C program write to the screen.

Read the source code files \verb#ulix.c# and \verb#start.asm#. Compile 
the sources with \verb#make# and run the kernel with \verb#make run#. 
You should see the following output:\vspace{3mm}

\enlargethispage{5mm}
\includegraphics[width=13cm,height=5.2cm]{pics/ulix-ex01.png}

\item Obviously, the kernel executes the C function \verb#main#. How does
the system jump from the early assembler\index{Assembler language} code (beginning with the
\verb#start# label) into the C function?

\item The file \verb#ulix.dump# contains a listing of the generated
assembler code. Here you can find all labels from the assembler
file \verb#start.asm# and also the function names from \verb#ulix.c#.
Search the file for the labels \verb#start#, \verb#higherhalf# and \verb#main#
and check for which memory addresses the corresponding code has been
generated. (You find the memory addresses on the very left in
hexadecimal format without leading ``0x''.)

Do you recognize the GDT trick in the assembler code? It is 
initiated via a ``long jump'' (\verb#jmp#) with a logical address
\verb#segment:address# as jump target.

Do also search for the labels  
\verb#stack_first_address# and \verb#stack_last_address# 
and compare the shown addresses with those from the VM's output
(in the last line)---they should match.

\item The kernel uses the \verb#printf()# function (you can find its
code in the separate \verb#printf.c# file) for text output, but
its main task to is to format the output as requested by the format strings
(such as [[%s]] for strings or [[%d]] for integers)
and send it to the terminal character-wise via the \verb#kputch# function
whose implementation resides in \verb#ulix.c#.

How does \verb#kputch# write characters to the screen? This will also be
explained later when we discuss the corresponding code section of the
full \UlixI{} sources. It may help to search the web or this book for ``0xb8000''
and ``video''. Consider how pointers can be used for accessing memory:
The commands

\begin{Verbatim}
char *mem;  mem = (char*) 0x1234; *mem = 'a';
\end{Verbatim}

can write the byte `a' (ASCII value: \hex{61}) to the memory address
\hex{1234}.

\item Why does the following line from \verb#kputch()#

\begin{Verbatim}
screen = (char*) 0xc0000000 + 0xb8000 + posy*160 + posx*2;
\end{Verbatim}

use multiplicators 160 and 2, and why does it add \hex{c0000000}?

\item Use the command [[objdump -h ulix.bin]] to check which memory areas
are used by the three sections \verb#.setup#, \verb#.text# and \verb#.bss#. 
(You can ignore the additional sections \verb#.comment#, \verb#.stab# and 
\verb#.stabstr#.) Compare the values with the information that the boot
loader GRUB outputs in the ``Multiboot-elf, \dots'' line when it loads the kernel.


\item The\marginnote{Tutorial 2} folder \path!tutorial/02/! in the \path!ulix/! directory
contains an improved version of the \UlixI{} kernel which implements
paging.

Read the source code files \path!ulix.c! and \path!start.asm! and localize
the code chunks which you have seen in this chapter. (There is also
additional code that we have not discussed yet.)

\item Compile/assemble and link the code with \verb#make# and start the
system with \verb#make run#.

\item In \path!ulix.c! the \verb#kputch()# function has seen some slight changes,
there is now the following code block:

\begin{Verbatim}
if (paging_ready)	
  screen = (char*) 0xb8000 + posy*160 + posx*2;	
else	
  screen = (char*) 0xc0000000 + 0xb8000 + posy*160 + posx*2;
\end{Verbatim}

It evaluates the \verb#paging_ready# variable which is initially set to
\verb#false# and changed to \verb#true# after paging has been
initialized. In that case, adding \hex{c0000000} is no longer 
necessary for calculating the address (cf.~exercise 5). Why does
that work?

\pagebreak

\item (Literate Programming) Convert the files \path!ulix.c! and
\path!start.asm! (from \verb!tutorial/02/!) into a literate program
\path!tutorial02.nw!. You can restrict the documentation that you add to
some keywords and roughly follow the ordering of descriptions in this chapter.

\item Test that you can reconvert the literate program into the original
code files (or at least sufficiently similar versions which also compile
and generate a working kernel). Also create a \LaTeX{} file and from that
a PDF version.


% Übungsblatt 4
\item In the folder\marginnote{Tutorial 3} \path!tutorial/03/! you find yet another version of the \UlixI{} kernel which contains an improved version of the paging code. It is a literate program (\path!ulix.nw!). \verb#cd# into the folder and use \verb#make# to extract the source code files \verb#ulix.c# und \verb#start.asm# from \path!ulix.nw!. They will automatically be compiled or assembled. Then launch the kernel with \verb#make run#. The system performs some tests of memory management and then halts.

Also take a look at the PDF file \path!ulix.pdf! (this file is written in German language, so it is likely that you want to skip this step) that you can recreate with \verb#make pdf# if you apply changes to \path!ulix.nw!. In the document you can find a description of the code for frame and page management; it is also a sample solution for exercise 10. Compare how the code is broken down into code chunks in your own solution and in the sample solution.

\item \label{ex:page table as int}We have defined the page table descriptors ([[page_table_desc]]) and the page descriptors ([[page_desc]]) as structures. Since they are both exactly 32 bits large, there is an alternative interpretation as \verb#unsigned int#. The goal of this exercise is to modify the literate program so that it works with these simple integer types instead of the structures.

First, create a copy of the folder (so that you can keep the original files). If you \verb#cd# into the \path!tutorial! folder, you can do that with the
\begin{Verbatim} 
cp -r 03 03-copy
\end{Verbatim}
command and make all your changes in \path!03-copy/!.

\begin{enumerate}
  \item Start with changing the type declarations for \verb#page_table_desc# und \verb#page_desc# to
\begin{Verbatim} 
typedef unsigned int page_table_desc;	
typedef unsigned int page_desc;
\end{Verbatim} 
  \item The types \verb#page_directory# and \verb#page_table# are not needed any longer; instead you can declare individual directories or tables like this:
\begin{Verbatim} 
page_table_desc pd[1024] __attribute__ ((aligned (4096)));	
page_desc       pt[1024] __attribute__ ((aligned (4096))); 
\end{Verbatim} 
That way, you can access entry \verb#n# of \verb#pt# via \verb#pt[n]# instead of \verb#pt.pds[n]#. The expression \verb#pt# (without an index) serves as a pointer (of type \verb#unsigned int*#) to the start of the table. If you need to hand over a single descriptor to functions like \verb#fill_page_desc()# or \verb#fill_page_table_desc()#, you can pass them a pointer to \verb#pt[n]#, i.\,e., \verb#&pt[n]#.

  \item After the changes all functions which work with these types are broken, you need to modify them. For example, in order to fill a page descriptor in \verb#fill_page_desc()#, you can take an address [[frame_addr]] and set its lowest twelve bits to 0:
\begin{Verbatim} 
tmpvalue = frame_addr & 0b11111111111111111111000000000000;
\end{Verbatim} 
or
\begin{Verbatim} 
tmpvalue = frame_addr & 0xFFFFF000;
\end{Verbatim} 
(The hexadecimal number combines four bits to one hex digit.) Then you add the flags in the lower twelve bits. You could define flag constants which are based on the bit positions, e.\,g.,
\begin{Verbatim} 
#define FLAG_PRESENT  1@<<0   //  Bit 0: present	
#define FLAG_ACCESSED 1@<<5   //  Bit 5: accessed
\end{Verbatim} 
etc. Then use a bitwise ``or'' operation ([[|]]), e.\,g.
\begin{Verbatim} 
tmpvalue = tmpvalue | FLAG_ACCESSED;
\end{Verbatim} 
to set a specific bit. When everything is done, you can write the value with [[*desc = tmpvalue;]]. (You must also modify the function prototype and pass a pointer to [[unsigned int]] when you call the function.)
  \item In order to extract the address from a descriptor, you simply set the lowest twelve bits to 0 (like above). On the other hand, you can extract single flags by performing a bitwise ``and'' operation ([[&]]) with the appropriate [[FLAG_*]] constant and test whether the result is 0 or not:\begin{Verbatim} 
if ((descriptor & FLAG_ACCESSED) == 0) { /* flag is not set */ }
\end{Verbatim} 
\end{enumerate}

\item Verify that the old and new program versions work identically. In both versions you can use the [[hexdump()]] function which displays a memory region as hex dump. Use the starting and ending addresses of the page table or page directory as arguments, e.\,g.
\begin{Verbatim} 
hexdump ( (unsigned int)current_pd, (unsigned int)current_pd + 4096 );
\end{Verbatim} 
(which will output the whole page-sized table). The output is written to the file [[output.txt]] (in the current directory of the development VM), you can later compare them:
\begin{Verbatim} 
cd 03/;       make;  make run > output.txt	
cd 03-copy/;  make;  make run > output.txt	
cd .. ;  diff ~/03*/output.txt
\end{Verbatim} 
If [[diff]] creates no output, the two files are identical.
(The [[hexdump()]] calls must occur after the test changes to the tables.)
\item Check with [[make pdf]] that your literate program can still be converted to a PDF file---if that does not work, identify and remove the errors.

\end{enumerate}


%-----------------------------------------------------------------------------




\chapter[Interrupts and Faults]{Interrupts and Faults}
\label{chap:ulix:interrupts}%

All modern CPUs and even many of the older ones such as the Zilog Z80\index{Zilog Z80 processor}\index{Z80 processor} 8-bit
processor can be interrupted\index{interrupt}: the CPU has an input line which can be
triggered by an external device connected to this line. When such an
interrupt occurs, the current activity is suspended, and the CPU continues
operation at a specified address: it executes an interrupt handler\index{interrupt handler}.

In principle a device could be directly connected to the CPU, but modern
machines contain many devices which want to interrupt the processor,
e.\,g.\ the disk controllers, the keyboard controller, the serial ports,
or the on-board clock. Thus an extra device, called the 
\emph{interrupt controller}\marginnote{interrupt\\ controller},
intermediates between the other devices and the CPU. One of the advantages
of such an interrupt controller is that it is programmable: it is possible
to enable or disable specific interrupts whereas the CPU itself can only
completely enable or disable all interrupts, using the [[sti]]\marginnote{[[sti]], [[cli]]}\tindex{sti}\tindex{cli}
(set interrupt flag\index{interrupt flag}) and [[cli]] (clear interrupt flag) instructions.
(These machine instructions exist on Intel-x86-compatible CPUs; other chips 
have similar instructions.) Being programmable also means that interrupt
numbers can be remapped (we will see later why this is helpful). Interrupt
controllers with these features are called 
\emph{programmable interrupt controllers}\marginnote{PICs}
(PICs), and we'll use that abbreviation throughout the rest of this chapter.

After the implementation of interrupts we will also take a look at
fault handling %and system calls 
since the involved mechanisms are very
similar to those which we need for handling interrupts. As we mentioned
in the introduction, the main difference between interrupts and faults 
is that
faults occur as a direct consequence of some specific 
instruction that our code executes. In that sense they are
\marginnote{synchronous} \emph{synchronous}. Interrupts on the other
hand occur without any connection to the currently 
executing instruction, since they are not triggered (immediately)
by our code but by some device. That is why they are called
\marginnote{asynchronous} \emph{asynchronous}.


\section{Examples for Interrupt Usage}

Interrupt handling is a core functionality which is used in lots of places:
without interrupts we would not be able to build a useful operating
system.

Let's look at some example features of \UlixI{} which depend heavily on
interrupts:

\begin{description}

\item[Multi-tasking] \UlixI{} can execute several processes in parallel
and switch between them using a simple round-robin scheduling mechanism.
That is only possible because the clock chip on the motherboard
regularly generates timer interrupts, and \UlixI{} installs a timer
interrupt handler\index{timer interrupt handler}\marginnote{timer handler} which---when activated---calls the scheduler to check
whether it is time to switch to a different process. If there were no
interrupts, we could only implement \emph{non-preemptive scheduling} which 
relies on the processes to give up the CPU voluntarily.

\item[Keyboard input] Whenever you press or release a key on a PC, either
event generates an interrupt. \UlixI{} picks up these interrupts and
the keyboard interrupt handler\marginnote{keyboard\\ handler} reads a key 
press or key release code from
the controller.

\index{keyboard interrupt handler}%
A keyboard driver does not need interrupts, but the alternative is to
constantly \marginnote{polling}poll (query) the keyboard controller in order 
to find out whether
a new event has occurred. That's possible but wastes a lot of CPU time.
Polling does not work well in a multi-tasking environment. (However for a
single-tasking operating system it may be good enough.)

\item[Media] Reading and writing hard disks and floppy disks also depends
on interrupts: In the \UlixI{} implementation of filesystems (and disk
access) a process which wants to read or write makes a system call which
sends a request to the drive controller. Then \UlixI{} puts the calling
process to sleep. Once the request has been served, the drive controller
generates an interrupt, and the interrupt handler for the hard disk
controller or the floppy disk controller\marginnote{ATA/FDC\\ handlers} 
(these are two separate handlers)
deals with the data and wakes up the sleeping process.
\index{floppy disk interrupt handler}%
\index{hard disk interrupt handler}%

Again, this could be done without interrupts. But the process would have
to remain active and continuously poll the controller to find out whether
the data transfer has been completed.

\item[Serial ports] Finally, the serial ports are similar to the keyboard,
since all of them are \emph{character devices}: they transfer single
bytes (instead of blocks of bytes). 

\end{description}


\section{Interrupt Handling on the Intel Architecture}

\intelindex{interrupt}%
The classical IBM PC used the \marginnote{Intel 8259 PIC}\index{Intel 8259 PIC}
Intel 8259 Programmable Interrupt Controller\index{programmable interrupt controller}, compatible descendents 
of which are still used in modern computers. The 8259 has eight
input lines (through which up to eight separate devices may connect)
and one output line which forwards received interrupt signals to
the CPU. It is possible to use more than one 8259 PIC since
these controllers can be \marginnote{Cascading PICs}\index{cascading PIC} cascaded
which means that a second controller's output pin is connected
with one of the first controller's input pins (typically the one
for device 2, see Figure~\ref{fig:cascading pics}). With that
cascade, devices connected to the first controller keep their
normal numbers (0, 1, 3--7 with 2 reserved for the second controller),
and devices connected to the second controller use device numbers
between 8 and 15, allowing for a total of 15 ($=16-1$) separate
device numbers. The first or primary controller is called
\marginnote{Master PIC}\emph{Master PIC}\index{master PIC}, the second
one is the \emph{Slave PIC}\marginnote{Slave PIC}\index{slave PIC} (as it is not directly connected to
the CPU but relies on the master PIC to have its interrupts 
signals forwarded). The numbers 0--15 are called
\marginnote{IRQ} \emph{Interrupt Request Numbers}\index{interrupt request number} (IRQs\index{IRQ}).

\begin{figure}[ht]
\centering
\includegraphics[width=14cm]{pics/8259-drawing2.pdf}
\caption{Two PICs are cascaded, which allows for 15 distinct interrupts.}
\label{fig:cascading pics}
\end{figure}

As you can see from the figure, there is a fixed mapping of
some devices to specific IRQs. We will use the following IRQs
in the \UlixI{} implementation:

\begin{itemize}
\item \textbf{0: Timer Chip.} On a PC's mainboard you can find a (programmable)
timer chip which regularly generates interrupts. We will use timer
interrupts to call the scheduler (besides other tasks).
\item \textbf{1: Keyboard.} This is the interrupt generated by PS/2 keyboards.
A USB keyboard would be handled differently, but we do not support USB devices.
\item \textbf{2: Slave PIC.} As already mentioned, IRQ 2 is reserved for 
connecting the secondary (slave) PIC.
\item \textbf{3: Serial Port 2.} The second serial port will be used for our
implementation of what we've called the \emph{serial hard disk}---you can find
it in Chapter~\ref{sec:serial hard disk}.
\item \textbf{4: Serial Port 1.} We only use the first serial port for output
(when running \UlixI{} in a PC emulator), thus we will not install an interrupt
handler for this IRQ.
\item \textbf{6: Floppy.} This is the IRQ for the floppy controller\index{floppy controller}. It can
handle up to two floppy drives. 
\item \textbf{14: Primary IDE Controller.}\index{IDE controller} And finally, 14 is the IRQ of the
primary IDE controller. Many PC mainboards contain two controllers, with each
of them allowing two drives to connect. The secondary IDE controller
would generate the interrupt number 15, but we're going to support only one
controller.
\end{itemize}

\noindent
We can define names for the IRQ numbers right now:

<<constants>>=
#define IRQ_TIMER      0
#define IRQ_KBD        1
#define IRQ_SLAVE      2     // Here the slave PIC connects to master
#define IRQ_COM2       3
#define IRQ_COM1       4
#define IRQ_FDC        6
#define IRQ_IDE       14     // primary IDE controller; secondary has IRQ 15
@ %def IRQ_SLAVE IRQ_COM1 IRQ_COM2 IRQ_TIMER IRQ_KBD IRQ_FDC IRQ_IDE


\subsection{Using Ports for I/O Requests}

\begin{goingwhere}%
We want to initialize the PICs, which means directly talking to these
controllers. Like with most other devices we can use the machine instructions
[[in]] and [[out]] to find out the PIC's current status and tell it what
to do.

Here we provide the code which lets us access the controllers.
\end{goingwhere}

\noindent
Access to many hardware components (including the PICs) is possible via \marginnote{I/O Ports}\emph{I/O ports}. Using [[in]] and [[out]] machine instructions it is possible to transfer bytes, words or doublewords between a CPU register and a memory location or register on some device (such as a hard disk controller).

The Intel 80386 Programmer's Reference Manual \cite[pp. 146--147]{intel80386} explains:
\begin{quotation}
\noindent
``The I/O instructions [[IN]] and [[OUT]]\marginnote{[[in]], [[out]]}\tindex{in}\tindex{out} are provided to move data between I/O ports\index{I/O port}\index{port} and the \register{EAX} (32-bit I/O), the \register{AX} (16-bit I/O) or \register{AL} (8-bit I/O) general registers. [[IN]] and [[OUT]] instructions address I/O ports either directly, with the address of one of up to 256 port addresses coded in the instruction, or indirectly via the \register{DX} register to one of up to 64K port addresses.

[[IN]] (Input from Port) transfers a byte, word or doubleword from an input port to \register{AL}, \register{AX} or \register{EAX}. If a program specifies \register{AL} with the [[IN]] instruction, the processor transfers 8 bits from the selected port to \register{AL}. If a program specifies \register{AX} with the [[IN]] instruction, the processor transfers 16 bits from the port to \register{AX}. If a program specifies \register{EAX} with the [[IN]] instruction, the processor transfers 32 bits from the port to \register{EAX}.

[[OUT]] (Output to Port) transfers a byte, word or doubleword to an output port from \register{AL}, \register{AX} or \register{EAX}. The program can specify the number of the port using the same methods as the [[IN]] instruction.''
\end{quotation}

For accessing 8-bit, 16-bit and 32-bit ports, the Intel assembler\index{Assembler language!ports}\index{port!Assembler language}\intelindex{accessing ports} language provides
separate commands [[inb]] / [[outb]] (byte), [[inw]] / [[outw]] (word) and
[[inl]] / [[outl]] (long: doubleword) which make it explicit what kind of
transfer is wanted. We'll use them in the functions
%nouse
<<function prototypes>>=
byte inportb (word port);
word inportw (word port);
void outportb (word port, byte data);
void outportw (word port, word data);
@ There are several possible C implementations with inline assembler\index{Assembler language!inline assembler}\index{C programming language!inline assembler} code,
the following code is most readable:

<<function implementations>>=
byte inportb (word port) {
  byte retval;  asm volatile ("inb %%dx, %%al" : "=a"(retval) : "d"(port));
  return retval;
}

word inportw (word port) {
  word retval;  asm volatile ("inw %%dx, %%ax" : "=a" (retval) : "d" (port));
  return retval;
}

void outportb (word port, byte data) {
  asm volatile ("outb %%al, %%dx" : : "d" (port), "a" (data));
}

void outportw (word port, word data) {
  asm volatile ("outw %%ax, %%dx" : : "d" (port), "a" (data));
}
@ %def inportb inportw outportb outportw

\begin{figure}[b!]
\centering
\includegraphics[width=9cm]{pics/eax-ax-al.pdf}
\caption[Accessing parts of \register{EAX} as \register{AX}, \register{AH} and \register{AL}.]{The lower half of \register{EAX} is \register{AX} which in turn is split into \register{AH} (high) and \register{AL} (low).}
\label{fig:eax-ax-al}
\end{figure}

We could provide [[inportl]] and [[outportl]] (for 32-bit values) in a
similar fashion, using [[inl]], [[outl]] and the 32-bit register 
\register{EAX} (instead of the 16-bit and 8-bit versions \register{AX}
and \register{AL}), but we do not need them. (Remember that 
\register{EAX}, \register{AX} and \register{AL} are (parts of) the
same register, see Figure~\ref{fig:eax-ax-al}. On a 64-bit machine,
\register{RAX} is the 64-bit extended version of \register{EAX}.)



\subsection{Initializing the PIC}

\index{programmable interrupt controller!initialize}%
\begin{goingwhere}%
Now that we have functions for talking to devices we can set up the
two PICs. We will configure one as master and the other as slave,
and we also remap the interrupt numbers from 0--15 to 32--47
because the first 32 numbers are reserved for faults (see Section
\ref{sec:faults}).
\end{goingwhere}

\noindent
The PICs can be accessed via the following four ports:
\index{port!programmable interrupt controller (PIC)}%
<<constants>>=
// I/O Addresses of the two programmable interrupt controllers
#define IO_PIC_MASTER_CMD   0x20  // Master (IRQs 0-7), command register
#define IO_PIC_MASTER_DATA  0x21  // Master, control register

#define IO_PIC_SLAVE_CMD    0xA0  // Slave (IRQs 8-15), command register
#define IO_PIC_SLAVE_DATA   0xA1  // Slave, control register
@ %def IO_PIC_MASTER_CMD IO_PIC_MASTER_DATA IO_PIC_SLAVE_CMD IO_PIC_SLAVE_DATA
They need to be initialized by sending them four ``Initialization
Command Words'' (ICW) called ICW1, ICW2, ICW3 and ICW4 in a specific order,
using specific ports. Each of the PICs has a command register and a data
register. During normal operation we can write to the data register 
(using the ports [[IO_PIC_MASTER_DATA]] and [[IO_PIC_SLAVE_DATA]] for PIC1 
or PIC2, respectively) to set the \emph{interrupt mask}\index{interrupt mask}\marginnote{interrupt\\ mask}:
That's a byte where each
bit tells the controller whether it shall respond to a specific interrupt
(1 means: mask, i.\,e., ignore the interrupt; 0 means: forward it to the CPU). We will
start with an interrupt mask of \hex{FF} for each controller (all bits are 1), 
thus all hardware interrupts will be ignored.


The following code was taken from
Bran's Kernel Development Tutorial \cite{brans-tutorial:200x} 
(e.\,g. from the source file [[irq.c]]) and modified.

For programming the controller, we can send configuration data to the
data port, but we have to initialize the programming by writing to the
command port. The complete sequence is as follows:

\begin{itemize}
\item First we send ICW1 to both PICs. ICW1 is a byte whose bits have the
  following meaning \cite[p. 11]{pic-8259a}:
  \begin{description}
    \item[0] $D_0$: ICW4 needed? We set this to 1 since we want to program the controller.
    \item[1] $D_1$: Single (1) / Cascade (0) mode: We set this to 0 since there's a slave. 
    \item[2] $D_2$: Call Address Interval (ignored), the default value is 0.
    \item[3] $D_3$: Level (1) / Edge (0) Triggered Mode: we set this to 0.
    \item[4] $D_4$: Initialization Bit: We set it to 1 because we want to initialize the controller.
    \item[5,6,7] $D_5$, $D_6$, $D_7$: not used on x86 hardware, set to 0.
  \end{description}
  This results in the byte \verb#00010001# (\hex{11}). The value is the same for both PICs.
  As mentioned before, ICW1 must be sent to the PICs' command registers.
\end{itemize}

<<remap the interrupts to 32..47>>=
outportb (IO_PIC_MASTER_CMD,  0x11);  // ICW1: initialize; begin programming
outportb (IO_PIC_SLAVE_CMD,   0x11);  // ICW1: dito, for PIC2
@

\begin{itemize}
\item In the next step we send ICW2 to the PICs' data registers. The lowest three
  bits specify the offset for remapping\marginnote{remap the\\ interrupts} the interrupts. Since the first 32
  interrupts must be reserved for processor exception handlers (e.\,g.\ 
  ``Division by Zero'' and ``Page Fault'' handlers), we map the interrupts 0--15
  to the range 32--47 (\hexrange{20}{2f}). 
  
  Each PIC would normally generate
  interrupts in the range 0--7, thus the offset is not the same for both PICs:
  For PIC1 it is \hex{20} (32; mapping 0--7 to 32-39), and for PIC2 it is \hex{28}
  (40; mapping 0--7 to 40--47).
\end{itemize}

<<remap the interrupts to 32..47>>=
outportb (IO_PIC_MASTER_DATA, 0x20);  // ICW2 for PIC1: offset 0x20 
                                      // (remaps 0x00..0x07 -> 0x20..0x27)
outportb (IO_PIC_SLAVE_DATA,  0x28);  // ICW2 for PIC2: offset 0x28 
                                      // (remaps 0x08..0x0f -> 0x28..0x2f)
@

\begin{itemize}  
\item The next command word is ICW3. Its functionality depends on whether we send
  it to the master (PIC1) or the slave (PIC2): The PICs already know that they are
  master and slave (because we sent that information as part of ICW1)
  \cite[p. 12]{pic-8259a}.
  
  The master expects a command word byte in which each set bit specifies a slave
  connected to it. We have only one slave and want to make it signal new interrupts
  on interrupt line 2 of the master. Thus, only the third bit (from the right)
  must be set: \bin{00000100} = \hex{04}.
  
  The slave needs a slave ID. We give it the ID 2 = \hex{02}.
\end{itemize}

<<remap the interrupts to 32..47>>=
outportb (IO_PIC_MASTER_DATA, 0x04);  // ICW3 for PIC1: there's a slave on IRQ 2 
                                      // (0b00000100 = 0x04)
outportb (IO_PIC_SLAVE_DATA,  0x02);  // ICW3 for PIC2: your slave ID is 2
@

\begin{itemize}
\item To end the sequence, we send ICW4 which is just \hex{01} for x86 
  processors \cite[p. 12]{pic-8259a}.
\end{itemize}

<<remap the interrupts to 32..47>>=
outportb (IO_PIC_MASTER_DATA, 0x01);  // ICW4 for PIC1 and PIC2: 8086 mode
outportb (IO_PIC_SLAVE_DATA,  0x01);
@

With the remapping in place we can now create entries for the
interrupt handler table---we need some new data structures for them.
\pagebreak

\subsection{Interrupt Descriptor Table}

\index{IDT (interrupt descriptor table)}\index{interrupt descriptor table|see {IDT}}%
\intelindex{interrupt descriptor table}%
\begin{goingwhere}%
The PICs are initialized and will do the right thing when an
interrupt occurs, but we haven't told the CPU yet what to do when
it receives one. This calls for a new data structure, the
\emph{Interrupt Descriptor Table}, which we must define 
according to the Intel standards and fill with proper values.
\end{goingwhere}

\noindent
While the first Intel-8086/8088-based personal computers used a fixed 
address in RAM to store the 
interrupt handler addresses, modern machines let us place the table
anywhere in memory. After preparing the table we must use the
machine instruction \marginnote{[[lidt]]}\tindex{lidt}\index{IDT (interrupt descriptor table)!lidt@\texttt{lidt}} [[lidt]] (load interrupt
descriptor table register) to tell the CPU where to search.

The procedure we need to follow is similar to the one for activating
segmentation via a GDT (see pages 
\pageref{description:gdt:start}--\pageref{description:gdt:end}):

\begin{enumerate}
\item We first store interrupt descriptors (each of which is eight bytes
 large) in a table consisting of [[struct idt_entry]] entries,
\item then we create some kind of pointer structure [[struct idt_ptr]]
 which contains the length and the start address of the table,
\item and finally we execute [[lidt]] (compare this to [[lgdt]] for
 the GDT).
\end{enumerate}


\begin{figure}[b!]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{16}{Address: 31--16} \,\, {\tiny 7..6}  \\
\bitbox{1}{P}
\bitbox{2}{DPL}
\bitbox{1}{[[0]]}
\bitbox{4}{Type}  
\bitbox{3}{[[0  0  0]]}
\bitbox{5}{(unused)}  \,\, {\tiny 5..4} \\
\bitbox{16}{GDT Selector} \,\, {\tiny 3..2} \\
\bitbox{16}{Address: 15--0} \,\, {\tiny 1..0}  \\[-15pt]
\end{bytefield}
\caption[Structure of an interrupt descriptor.]{An Interrupt Descriptor contains the address of an interrupt handler and some configuration information.}
\label{fig:interrupt descriptors}
\end{centering}
\end{figure}


\noindent
Figure \ref{fig:interrupt descriptors} shows the layout of an IDT entry. The
\emph{Flags} halfbyte (second line, left in the figure) consists of

\begin{itemize}
\item the present flag (bit 3) which must always be set to 1,
\item two bits (2 and 1) for the Descriptor Privilege Level (DPL)\index{DPL (descriptor privilege level)}\index{descriptor privilege level}. We will
  always set this to \bin{11} = 3 since we want all interrupts to be available
  all the time (when we're in kernel or user mode) and
\item a so-called ``storage segment'' flag (bit 0; which must be set to 0 for
  an ``interrupt gate'', see next entry).
\end{itemize}

\noindent
The \emph{Type} halfbyte declares what kind of descriptor this is: we
will always set it to \bin{1110}, making this descriptor an
\begin{itemize}
  \item \emph{80386 32-bit interrupt gate}\marginnote{interrupt gate}\index{interrupt gate} descriptor (which is what we want). 
\end{itemize}

\pagebreak
Besides this type, there are alternatives:
\begin{itemize}
  \item \bin{0101} for an \emph{80386 32-bit task gate}, 
  \item \bin{0110} for an \emph{80286 16-bit interrupt gate},
  \item \bin{0111} for an \emph{80286 16-bit trap gate} and
  \item \bin{1111} for an \emph{80386 32-bit trap gate}\marginnote{trap gate}\index{trap gate}, 
\end{itemize}


\noindent
but we will not go into the
details about these. Instead of interrupt gates we could also use trap gates,
the difference between those being that ``for interrupt gates, interrupts 
are automatically disabled upon entry and reenabled upon [[IRET]] which restores 
the saved \register{EFLAGS}'' \cite{osdev:interrupt-descriptor}.
We will use a trap gate for the system call handler (see Chapter~\ref{chap:ulix:syscall}).

An interrupt descriptor table entry is described by the following datatype definitions:
\index{IDT (interrupt descriptor table)!structure declaration}%

<<type definitions>>=
struct idt_entry {
    unsigned int addr_low  : 16;   // lower 16 bits of address
    unsigned int gdtsel    : 16;   // use which GDT entry?
    unsigned int zeroes    :  8;   // must be set to 0
    unsigned int type      :  4;   // type of descriptor
    unsigned int flags     :  4;
    unsigned int addr_high : 16;   // higher 16 bits of address
} __attribute__((packed));
@ %def idt_entry


\noindent
The \emph{selector} must be the number of a code segment descriptor (in the GDT);
we will always set this to \hex{08} since our kernel (ring 0) code segment
uses that number (see code chunk [[<<install flat gdt>>]] on page \pageref{install-flat-gdt}).

The IDT pointer has the same structure as the GDT pointer: it informs about
the length and the location of the IDT:

<<type definitions>>=
struct idt_ptr {
    unsigned int limit   : 16;
    unsigned int base    : 32;
} __attribute__((packed));
@ %def idt_ptr

In theory, an interrupt number can be any byte, i.\,e., a value between
0 and 255. We will use a full IDT with 256 entries even though most
of the entries will be null descriptors---if somehow an interrupt
is generated which has a null descriptor, the CPU will generate an
``unhandled interrupt'' exception. We will talk about exceptions
right after we've finished the interrupt handling code.

\pagebreak

<<global variables>>=
struct idt_entry idt[256] = { { 0 } };
struct idt_ptr idtp;
@ %def idt idtp
The variables [[idt]] and [[idtp]] will now be used in a way that
is similar to how we used [[gdt]] (a [[struct gdt_entry[]]] array)
and [[gp]] (a [[struct gdt_ptr]] structure) when we wrote the GDT code.

We start with a function 

%nouse
<<function prototypes>>=
void fill_idt_entry (byte num, unsigned long address, 
    word gdtsel, byte flags, byte type);
@ which writes an entry of the IDT:

<<function implementations>>=
void fill_idt_entry (byte num, unsigned long address, 
    word gdtsel, byte flags, byte type) {
  if (num >= 0 && num < 256) {
    idt[num].addr_low  = address & 0xFFFF; // address is the handler address
    idt[num].addr_high = (address >> 16) & 0xFFFF;
    idt[num].gdtsel    = gdtsel;           // GDT sel.: user mode or kernel mode?
    idt[num].zeroes    = 0;
    idt[num].flags     = flags;
    idt[num].type      = type;
  }
}
@ %def fill_idt_entry

\noindent
Parts of all of our interrupt handlers will be assembler\index{Assembler language!interrupt handler} code (which
we store in [[start.asm]]); we'll explain soon why that has to be.
For the moment, let's declare 16 external function symbols [[irq0]],
[[irq1]], \dots, [[irq15]] whose addresses we're about to enter
into the IDT with [[fill_idt_entry]]:

%nouse
<<function prototypes>>=
extern void irq0(), irq1(), irq2(),  irq3(),  irq4(),  irq5(),  irq6(),  irq7();
extern void irq8(), irq9(), irq10(), irq11(), irq12(), irq13(), irq14(), irq15();
@ We will store the function addresses in an array which simplifies accessing them:

\pagebreak

<<global variables>>=
void (*irqs[16])() = { 
  irq0, irq1, irq2,  irq3,  irq4,  irq5,  irq6,  irq7,      // store them in
  irq8, irq9, irq10, irq11, irq12, irq13, irq14, irq15      // an array
};
@ %def irqs
The following code chunk enters their address in the IDT:\index{IDT (interrupt descriptor table)!entering interrupt handlers}

\label{chunk:install-irqs}%
<<install the interrupt handlers>>=
<<remap the interrupts to 32..47>>
set_irqmask (0xFFFF);           // initialize IRQ mask
enable_interrupt (IRQ_SLAVE);   // IRQ slave

for (int i = 0;  i < 16;  i++) {
  fill_idt_entry (32 + i, 
                  (unsigned int)irqs[i],  
                  0x08, 
                  0b1110,     // flags: 1 (present), 11 (DPL 3), 0
                  0b1110);    // type:  1110 (32 bit interrupt gate)
}
@ This code chunk sets the \emph{IRQ mask}\marginnote{IRQ mask}\index{IRQ mask} to \hex{FFFF} = \bin{1111111111111111} 
via 
%nouse
<<function prototypes>>=
static void set_irqmask (word mask);
@ which disables all interrupts, and then it
enables the interrupt for the slave PIC with
%nouse
<<function prototypes>>=
static void enable_interrupt (int number);
@ ---both functions have not been mentioned so far. The IRQ mask
is a 16-bit value in which each bit says whether some interrupt
is enabled (value 0) or not (value 1). We must talk to both PICs
to set the mask, the master PIC gets the lower eight bits
(for the interrupts 0--7), the slave PIC gets the upper eight bits
(for the interrupts 8--15):

<<function implementations>>=
static void set_irqmask (word mask) {
  outportb (IO_PIC_MASTER_DATA, (char)(mask % 256) );
  outportb (IO_PIC_SLAVE_DATA,  (char)(mask >> 8)  );
}
@ %def set_irqmask
We can also read the mask from the two PICs with a similar function
we call
%nouse
<<function prototypes>>=
word get_irqmask ();
@ in which we read the two data registers instead of writing them:

<<function implementations>>=
word get_irqmask () {
  return inportb (IO_PIC_MASTER_DATA) 
      + (inportb (IO_PIC_SLAVE_DATA) << 8);
}
@ %def get_irqmask

In the following chapters we will often enable a specific interrupt
for some device after we've prepared its usage, e.\,g.\ for the
floppy controller. For that purpose, we will always use [[enable_interrupt()]] 
like we did above. It simply reads the current IRQ mask, clears a bit,
and writes the new value back:\index{interrupt!enable a specific interrupt}\index{enable an interrupt}

<<function implementations>>=
static void enable_interrupt (int number) {
  set_irqmask ( 
    get_irqmask ()        // the current value
    & ~(1 << number)      // 16 one-bits, but bit "number" cleared
  );
}
@ %def enable_interrupt



\subsection{Writing the Interrupt Handler}

\index{interrupt handler!implementation}%
\begin{goingwhere}%
Everything is prepared for interrupt handlers --- now we need to define
them, i.\,e., implement the [[irq0()]], \dots\ [[irq15()]] functions.
This step requires some assembler code and some C code.
\end{goingwhere}

\noindent
We have installed handlers for all 16 interrupts, but what do they
do? We will define part of their code in the assembler file, but we start
with a description of what we expect to happen in general.

When an interrupt occurs, the CPU suspends the currently running code,
saves some information on the stack, and then jumps to the address
that it finds in the IDT. (It also uses a different stack and switches
to kernel mode if it was in user mode when the interrupt occurred.)
Then the interrupt handler runs, and once it has finished its job,
it returns with the [[iret]] instruction. \marginnote{[[iret]]} [[iret]]
is different from the regular [[ret]] instruction which normal
functions use for returning to the calling function: it is the
special ``return from interrupt'' instruction which restores the
original state (user or kernel mode, stack, \register{EFLAGS} register) 
so that the regular code can continue as if the interrupt had never 
happened.

Switching to the interrupt handler can mean a change of the privilege
level that the CPU executes in: So far we've only let \UlixI{} work
in ring 0 (kernel mode), but later when we introduce processes it can
happen that an interrupt occurs while the CPU runs in ring 3 (user mode).
If that is the case, the privilege level changes (from 3 to 0).
When such a transition occurs, the information (return address etc.) 
is not written to the process' user mode stack, but on the process'
kernel stack which is located elsewhere and normally used during
the execution of system calls---we'll describe that in more detail
later. For now, the relevant piece of information is that different
information gets stored on the ``target stack'': In case of a
privilege change the CPU first writes the contents of the
\register{SS} and \register{ESP} registers on the (new) stack---this
does not happen if the CPU was already operating in ring 0.
Next, \register{EFLAGS}, \register{CS} and \register{EIP} are written
to the stack: that is all we need for returning to the interrupted
code. Figure \ref{fig:interrupt stack changes}\index{interrupt handler!stack layout when entering}\index{stack!layout when entering interrupt handler} shows the different
stack contents when the interrupt handler starts executing 
\cite[p. 159]{intel80386}.

\begin{figure}[ht]
\centering
\includegraphics[width=12cm]{pics/irq-stack.pdf}
\caption[Stack layout when entering an interrupt handler.]{When entering the interrupt handler, the stack contains information
for returning from the handler. Left: without privilege level change; right: 
with change from level 3 to 0, extra data marked red.}
\label{fig:interrupt stack changes}
\end{figure}

We cannot directly use a C function as an interrupt handler because
once it would finish its work, it would do a regular [[RET]] which
does not do what we want. (Of course we could use inline assembler
code inside the C function to make it work anyway, but it makes
more sense to directly implement parts of the handlers in assembler.)


\subsubsection{The Context Data Structure}

We want to be able to define handler functions in C which get called
from the assembler code. Those functions will all have the following
prototype:
\begin{Verbatim}
void handler_function (context_t *r);
\end{Verbatim}
where [[context_t]] is\marginnote{context}\index{context} a central data structure that can hold all the 
registers we use on the Intel machine. It will also be used in fault
handlers, system call handlers and several other functions which need
information about the current state.

We define the [[context_t]] structure so that it matches the way in 
which we set up the stack in the assembler part of the handler:

<<public type definitions>>=
typedef struct {
  unsigned int gs, fs, es, ds;
  unsigned int edi, esi, ebp, esp, ebx, edx, ecx, eax;
  unsigned int int_no, err_code;
  unsigned int eip, cs, eflags, useresp, ss;
} context_t;
@ %def context_t


\subsubsection{Assembler Part of the Handler}

In order to have a handler function see useful values in the structure
that [[r]] points to, we need to push the register contents in the
reverse order onto the stack:

%BEGIN ASM CHUNK
%nouse
<<push registers onto the stack>>=
pusha
push ds
push es
push fs
push gs
push esp  ; pointer to the context_t
@ % 
%END ASM CHUNK
The first instruction [[pusha]] (push all general registers) pushes 
a lot of registers onto the stack: \register{EAX}, \register{ECX}, 
\register{EDX}, \register{EBX}, the old value of \register{ESP} (before 
the [[pusha]] execution began), \register{EBP}, \register{ESI}, 
and \register{EDI}---in that order. We add the segment registers 
\register{DS}, \register{ES}, \register{FS} and \register{GS},
and you can see that we've successfully handled the first two lines
of the [[context_t]] type definition.
When the interrupt occurred,
the registers \register{EFLAGS}\index{ELFAGS register}\index{register!EFLAGS}, \register{CS} and \register{EIP}
(and possibly also \register{SS} and the user mode's \register{ESP})
were also pushed on the stack which gives us the values in the
fourth line of the [[context_t]] definition. 

What's missing are the values on the third line: We want to tell the
handler \emph{which interrupt} occurred so that we can use the same
interrupt handler for several interrupts---for example, if we supported
both IDE controllers (with interrupts 14 and 15) we could use that
trick to run the same IDE handler when either of those interrupts
occurred; thus, between the automatically happening push operations
and the ones we perform in [[<<push registers onto the stack>>]] we
also push the interrupt number and another value [[err_code]] which
can hold an error code. Interrupts don't have an error code, but we
will recycle the same code later when we deal with faults, and some
of those do provide an error code.

The final [[push esp]] statement in [[<<push registers onto the stack>>]]
is necessary because we cannot just place the structure contents on
the stack: the handler function expects a pointer ([[context_t *r]]),
and [[ESP]] contains just that pointer: the start address of the 
structure. Figure~\ref{fig:stack handler entry} shows the layout of
the stack after the assembler part has finished the preparations.

\begin{figure}[ht]
\centering
\includegraphics[width=8.5cm]{pics/stack-handler-entry.pdf}
\caption[\hgepolylof{Stack after interrupt handler initialization by the assembler part.}]{Stack after interrupt handler initialization by the assembler part.}
\label{fig:stack handler entry}
\end{figure}

Later, when the handler's task is completed, we will need to
pop the registers from the stack---in the reverse order:

<<pop registers from the stack>>=
pop esp
pop gs
pop fs
pop es
pop ds
popa
@

Now here's an example of how we could implement the interrupt handler
for IRQ 15:

%BEGIN ASM CHUNK
<<irq15 example>>=
push byte 0           ; error code
push byte 15          ; interrupt number
<<push registers onto the stack>>
call irq_handler      ; call C function
<<pop registers from the stack>>
add esp, 8            ; for errcode, irq no.
iret
@ %
%END ASM CHUNK
This contains all we need:

\begin{enumerate}
%\item First, [[cli]] disables interrupts; we do not want the interrupt handler
%  itself to be interrupted.
\item The two [[push]] commands add the error code and the interrupt number
  (which is 15 in this example).
\item With [[<<push registers onto the stack>>]] we complete the [[context_t]]
  data structure and also push a pointer to it.
\item Now the stack is prepared properly to call the C function [[irq_handler]].
\item After returning, we first have to undo the push operations with 
  [[<<pop registers from the stack>>]].
\item Then we modify the stack address: we add 8, thus undoing the two
  [[push]] operations for the error code and the interrupt number.
\item Finally we return from the handler with [[iret]].
\end{enumerate}

\noindent
We need almost the same code 16 times (for IRQs 0 to 15)---the only difference
between the 16 versions is the interrupt number that we push in the second
instruction. We simplify our code by having our individual handlers just
push the two values (0 and the interrupt number) and then jump to an address
which provides the common commands. The 0 value is a placeholder for an error
code which cannot occur in interrupt handlers, but (as mentioned before) we will also implement
fault handlers which shall use the same stack layout, and some of them will 
write a fault-specific error code into that location.

%BEGIN ASM CHUNK
<<start.asm>>=
global irq0, irq1, irq2,  irq3,  irq4,  irq5,  irq6,  irq7
global irq8, irq9, irq10, irq11, irq12, irq13, irq14, irq15

%macro irq_macro 1 
       push byte 0          ; error code (none)
       push byte %1         ; interrupt number
       jmp irq_common_stub  ; rest is identical for all handlers
%endmacro

irq0:  irq_macro 32
irq1:  irq_macro 33
irq2:  irq_macro 34
irq3:  irq_macro 35
irq4:  irq_macro 36
irq5:  irq_macro 37
irq6:  irq_macro 38
irq7:  irq_macro 39
irq8:  irq_macro 40
irq9:  irq_macro 41
irq10: irq_macro 42
irq11: irq_macro 43
irq12: irq_macro 44
irq13: irq_macro 45
irq14: irq_macro 46
irq15: irq_macro 47

extern irq_handler          ; defined in the C source file

irq_common_stub:            ; this is the identical part
       <<push registers onto the stack>>
       call irq_handler     ; call C function
       <<pop registers from the stack>>
       add esp, 8
       iret
@ %def irq0 irq1 irq2 irq3 irq4 irq5 irq6 irq7 irq8 irq9 irq10 irq11 irq12 irq13 irq14 irq15 irq_common_stub
%END ASM CHUNK

Our interrupt handling code is a slightly improved version of the code
which Bran's Kernel Tutorial \cite{brans-tutorial:200x} uses; the original
code contains some extra instructions that we don't need for the \UlixI{}
kernel.


\subsubsection{C Part of the Handler}

Finally, we show what happens when the assembler code calls the 
external handler function [[irq_handler()]] that we implement
in the C file.

The first thing our handler needs to do is acknowledge the
interrupt. For that purpose it sends the command
<<constants>>=
#define END_OF_INTERRUPT  0x20
@ %def END_OF_INTERRUPT
to all PICs which are involved: In case of an interrupt
number between 0 and 7 that is only the primary PIC; in case
the number is 8 or higher, both controllers need to be
informed. Omitting this step would stop the controller
from raising further interrupts which would basically disable
interrupts completely.

Next we check whether a specific handler for the current 
interrupt has been installed in the
<<global variables>>=
void *interrupt_handlers[16] = { 0 };
@ %def interrupt_handlers
array of interrupt handlers.

<<function implementations>>=
void irq_handler (context_t *r) {
  int number = r->int_no - 32;                      // interrupt number
  void (*handler)(context_t *r);                    // type of handler functions

  if (number >= 8) { 
    outportb (IO_PIC_SLAVE_CMD, END_OF_INTERRUPT);  // notify slave  PIC
  }
  outportb (IO_PIC_MASTER_CMD, END_OF_INTERRUPT);   // notify master PIC (always)

  handler = interrupt_handlers[number];
  if (handler != NULL) {
    handler (r);
  }
}
@ %def irq_handler

As a last step we provide a function

<<function prototypes>>=
void install_interrupt_handler (int irq, void (*handler)(context_t *r));
@ which lets us enter (pointers to) handler functions in this array; it
is pretty simple:

<<function implementations>>=
void install_interrupt_handler (int irq, void (*handler)(context_t *r)) {
  if (irq >= 0 && irq < 16)
    interrupt_handlers[irq] = handler;
}
@ %def install_interrupt_handler

Early in the [[<<initialize system>>]] step of the kernel's [[main()]]
function we need to load the Interrupt Descriptor Table Register\index{interrupt descriptor table register}\index{IDTR register}\index{register!IDTR}\tindex{lidt}\index{IDT (interrupt descriptor table)!lidt@\texttt{lidt}}
(\register{IDTR}\marginnote{IDTR}) so that the CPU can find the table:
 
<<install the interrupt descriptor table>>=
idtp.limit = (sizeof (struct idt_entry) * 256) - 1;   // must do -1
idtp.base  = (int) &idt;
idt_load ();
@ It uses the assembler function\index{Assembler language!load the IDT}
%nouse
<<function prototypes>>=
extern void idt_load ();
@ which is related to [[gdt_flush]], just writing the address of
[[idtp]] to the \register{IDTR} register via the [[lidt]]\marginnote{[[lidt]]} instruction
instead of writing the address of [[gp]] to \register{GDTR} via [[lgdt]]:
%BEGIN ASM CHUNK
<<start.asm>>=
extern idtp               ; defined in the C file
global idt_load
idt_load:    lidt [idtp]
             ret
@ %def idt_load
%END ASM CHUNK
In the following chapters we will often use this function in commands
similar to
\begin{Verbatim}
install_interrupt_handler (IRQ_SOMEDEV, somedev_handler);
\end{Verbatim}

For comparison, once more [[gdt_flush]] and [[idt_load]]:

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
\begin{Verbatim}
extern gp   ; defined in the C file
global gdt_flush

gdt_flush: lgdt [gp]
           mov ax, 0x10
           mov ds, ax
           mov es, ax
           mov fs, ax
           mov gs, ax
           mov ss, ax
           jmp 0x08:flush2
flush2:    ret
\end{Verbatim}
\columnbreak
\begin{Verbatim}
extern idtp   ; defined in the C file
global idt_load

idt_load: lidt [idtp]
          ret
\end{Verbatim}
\end{multicols}

\noindent
(The [[gdt_flush]] function does more than [[idt_load]] since it also
updates all segment registers.)


\section{Faults}

\label{sec:faults}%
As we've mentioned in the introduction to this chapter, handling a 
fault\index{fault} is very similar to handling an interrupt. Since you've just seen
the interrupt code, you will recognize many concepts at once while we
present the fault handling\index{fault handler} code.

Like we defined the interrupt handlers [[irq0()]] to [[irq15()]] in the assembler
file \path!start.asm!, we do the same with 32 fault handler functions
[[fault0()]] to [[fault31()]].

<<function prototypes>>=
extern void 
  fault0(),  fault1(),  fault2(),  fault3(),  fault4(),  fault5(),  fault6(),  
  fault7(),  fault8(),  fault9(),  fault10(), fault11(), fault12(), fault13(), 
  fault14(), fault15(), fault16(), fault17(), fault18(), fault19(), fault20(), 
  fault21(), fault22(), fault23(), fault24(), fault25(), fault26(), fault27(),
  fault28(), fault29(), fault30(), fault31();
@ and we enter these in the IDT\index{IDT (interrupt descriptor table)!entering fault handlers} just like we did with the [[irq*()]]
functions. 

<<global variables>>=
void (*faults[32])() = {
  fault0,  fault1,  fault2,  fault3,  fault4,  fault5,  fault6,  fault7,
  fault8,  fault9,  fault10, fault11, fault12, fault13, fault14, fault15,
  fault16, fault17, fault18, fault19, fault20, fault21, fault22, fault23,
  fault24, fault25, fault26, fault27, fault28, fault29, fault30, fault31
};
@ %def faults

We install those handlers in the same way that we registered the interrupt
handlers earlier (see page~\pageref{chunk:install-irqs}):

\label{chunk:install-faults}%
<<install the fault handlers>>=
for (int i = 0; i < 32; i++) {
  fill_idt_entry (i,
                  (unsigned int)faults[i],
                  0x08,
                  0b1110,   // flags: 1 (present), 11 (DPL 3), 0
                  0b1110);  // type: 1110 (32 bit interrupt gate)
}
@ 
In the assembler file we use the same trick for the [[fault*()]] functions 
that you've just seen for [[irq*()]]:

%nouse
<<start.asm>>=
global fault0,  fault1,  fault2,  fault3,  fault4,  fault5,  fault6,  fault7
global fault8,  fault9,  fault10, fault11, fault12, fault13, fault14, fault15
global fault16, fault17, fault18, fault19, fault20, fault21, fault22, fault23
global fault24, fault25, fault26, fault27, fault28, fault29, fault30, fault31
@

\noindent
The handlers all look similar: We push one or two bytes
on the stack and then jump to [[fault_common_stub]]. The choice of one or two
arguments depends on the kind of interrupt that occurred: for some faults
the CPU pushes a one-byte error code\marginnote{error code}\index{error code}\index{fault!error code} on the stack, and for some others it 
does not. In order to have the same stack setup (regardless of the fault) 
we push an extra null byte in those cases where no error code is pushed.

The code always looks like one of the following two cases:
\begin{Verbatim}
fault5:  push byte 0  ; error code          fault8:  ; no error code
         push byte 5                                 push byte 8
         jmp fault_common_stub                       jmp fault_common_stub
\end{Verbatim}
Since we do not want to type this repeatedly, we use [[nasm]]'s macro feature
which lets us write simple macros for both cases. [[fault_macro_0]] handles the
cases where we need to push an extra null byte (as in [[fault5]] above), and
[[fault_macro_no0]] handles the other cases (as in [[fault8]] above):

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
%BEGIN ASM CHUNK
<<start.asm>>=
%macro fault_macro_0 1 
       push byte 0  ; error code
       push byte %1
       jmp fault_common_stub
%endmacro




%macro fault_macro_no0 1 
       ;  don't push error code
       push byte %1
       jmp fault_common_stub
%endmacro
@ %def fault_macro_0 fault_macro_no0
%END ASM CHUNK
\end{multicols}


With these macros the rest is straight-forward:

%BEGIN ASM CHUNK
<<start.asm>>=
fault0:  fault_macro_0     0   ;  Divide by Zero
fault1:  fault_macro_0     1   ;  Debug
fault2:  fault_macro_0     2   ;  Non Maskable Interrupt
fault3:  fault_macro_0     3   ;  INT 3
fault4:  fault_macro_0     4   ;  INTO
fault5:  fault_macro_0     5   ;  Out of Bounds
fault6:  fault_macro_0     6   ;  Invalid Opcode
fault7:  fault_macro_0     7   ;  Coprocessor not available
fault8:  fault_macro_no0   8   ;  Double Fault
fault9:  fault_macro_0     9   ;  Coprocessor Segment Overrun
fault10: fault_macro_no0  10   ;  Bad TSS
fault11: fault_macro_no0  11   ;  Segment Not Present
fault12: fault_macro_no0  12   ;  Stack Fault
fault13: fault_macro_no0  13   ;  General Protection Fault
fault14: fault_macro_no0  14   ;  Page Fault
fault15: fault_macro_0    15   ;  (reserved)
fault16: fault_macro_0    16   ;  Floating Point
fault17: fault_macro_0    17   ;  Alignment Check
fault18: fault_macro_0    18   ;  Machine Check
fault19: fault_macro_0    19   ;  (reserved)
fault20: fault_macro_0    20   ;  (reserved)
fault21: fault_macro_0    21   ;  (reserved)
fault22: fault_macro_0    22   ;  (reserved)
fault23: fault_macro_0    23   ;  (reserved)
fault24: fault_macro_0    24   ;  (reserved)
fault25: fault_macro_0    25   ;  (reserved)
fault26: fault_macro_0    26   ;  (reserved)
fault27: fault_macro_0    27   ;  (reserved)
fault28: fault_macro_0    28   ;  (reserved)
fault29: fault_macro_0    29   ;  (reserved)
fault30: fault_macro_0    30   ;  (reserved)
fault31: fault_macro_0    31   ;  (reserved)
@ %def fault0 fault1 fault2 fault3 fault4 fault5 fault6 fault7 fault8 fault9 fault10 fault11 fault12 fault13 fault14 fault15 fault16 fault17 fault18 fault19 fault20 fault21 fault22 fault23 fault24 fault25 fault26 fault27 fault28 fault29 fault30 fault31
%END ASM CHUNK
\index{divide by zero fault}%
\index{non-maskable interrupt fault}%
\index{out of bounds fault}%
\index{invalid opcode fault}%
\index{coprocessor not available fault}%
\index{double fault}%
\index{bad TSS fault}%
\index{segment not present fault}%
\index{stack fault}%
\index{general protection fault}%
\index{page fault}%
\index{floating point fault}%
%
[[fault_common_stub]] is---almost---a rewrite of [[irq_common_stub]], the only
difference is that we call a different C function [[fault_handler()]] in the middle.
\enlargethispage{5mm}

<<start.asm>>=
extern fault_handler
@ The stub saves the processor state,
calls the handler function and restores the stack frame:

%BEGIN ASM CHUNK
<<start.asm>>=
fault_common_stub:
    <<push registers onto the stack>>
    call fault_handler    ; call C function
    <<pop registers from the stack>>
    add esp, 8            ; for errcode, irq no.
    iret
@ %def fault_common_stub
%END ASM CHUNK

Initially our fault handlers will just output a message stating the cause of
the fault and then halt the system; later we will provide fault handlers
for some types of faults which try to solve the problem and let the operation
go on. Here are the error messages: 

<<global variables>>=
char *exception_messages[] = {
    "Division By Zero",        "Debug",                          //  0,  1
    "Non Maskable Interrupt",  "Breakpoint",                     //  2,  3
    "Into Detected Overflow",  "Out of Bounds",                  //  4,  5
    "Invalid Opcode",          "No Coprocessor",                 //  6,  7
    "Double Fault",            "Coprocessor Segment Overrun",    //  8,  9
    "Bad TSS",                 "Segment Not Present",            // 10, 11
    "Stack Fault",             "General Protection Fault",       // 12, 13
    "Page Fault",              "Unknown Interrupt",              // 14, 15
    "Coprocessor Fault",       "Alignment Check",                // 16, 17
    "Machine Check",                                             // 18
    "Reserved", "Reserved", "Reserved", "Reserved", "Reserved",
    "Reserved", "Reserved", "Reserved", "Reserved", "Reserved",
    "Reserved", "Reserved", "Reserved"                           // 19..31
};
@ %def exception_messages
We get the correct message by accessing the proper entry of the
array, e.\,g., for a page fault (with fault number 14) it is stored
in [[exception_messages[14]]].

Our C \marginnote{Fault Handler} fault handler\index{fault handler!implementation} 

%nouse
<<function prototypes>>=
void fault_handler (context_t *r);
@ displays some information about the problem and
checks whether the fault occurred while a process was running (by 
testing whether [[r->eip < 0xc0000000]]). If not, the system
switches to the kernel mode shell (and is broken).

The page fault handler is a special case: we expect to deal with 
page faults silently (see Chapter~\ref{chap:pagefault}),
so we check for this case before doing anything else.

<<function implementations>>=
void fault_handler (context_t *r) {
  if (r->int_no == 14) {                             // fault 14 is a page fault
    page_fault_handler (r); return;
  }
  
  memaddress fault_address = (memaddress)(r->eip);
  
  if (r->int_no < 32) {
    <<fault handler: display status information>>
    
    if ( fault_address < 0xc0000000 ) {              // user mode 
      <<fault handler: terminate process>>
    }
    
    <<disable scheduler>>                            // error inside the kernel
    <<enable interrupts>>
    printf ("\n");   
    asm ("jmp kernel_shell");
  }
}
@ %def fault_handler

For displaying the status information we look at the register
contents which are provided by [[r]]. Especially interesting
are the task number, the address space number, the address of
the faulting instruction, the \register{EFLAGS}\index{EFLAGS register}\index{register!EFLAGS} register and
the error code which the CPU has provided upon entry into the
fault handler.

<<fault handler: display status information>>=
printf ("'%s' Exception at 0x%08x (task=%d, as=%d).\n", 
  exception_messages[r->int_no], r->eip, current_task, current_as);        
printf ("eflags: 0x%08x  errcode: 0x%08x\n", r->eflags, r->err_code);
printf ("eax: %08x  ebx: %08x  ecx: %08x  edx: %08x \n",
  r->eax, r->ebx, r->ecx, r->edx);
printf ("eip: %08x  esp: %08x  int: %8d  err: %8d \n", 
  r->eip, r->esp, r->int_no, r->err_code);
printf ("ebp: %08x  cs: 0x%02x ds: 0x%02x es: 0x%02x fs: 0x%02x ss: 0x%02x \n",
  r->ebp, r->cs, r->ds, r->es, r->fs, r->ss);
printf ("User mode stack: 0x%08x-0x%08x\n", TOP_OF_USER_MODE_STACK 
  - address_spaces[current_as].stacksize, TOP_OF_USER_MODE_STACK);
@

If a process was running, the fault handler terminates it:

\index{fault handler!terminate process}\index{process!termination by fault handler}%
<<fault handler: terminate process>>=
thread_table[current_task].state = TSTATE_ZOMBIE;
remove_from_ready_queue (current_task);
r->ebx = -1;  // exit_ code for this process
syscall_exit (r);
@ %
Since we have not talked about processes yet, you need not worry
about the reference to the thread table
via \verb#thread_table[current_task]# or [[remove_from_ready_queue()]].
We will explain this function and the thread table data
structure later, and we will also show what the [[syscall_exit()]]
function does. You can choose to ignore the complete 
[[<<fault handler: terminate process>>]] block in the code for now.

A page fault need not be a problem: it often occurs because the
code attempted to access an invalid address (which is bad), but
yet more often the address will be valid, but the page won't be
in the physical RAM. That situation can be helped.
In Chapter~\ref{chap:pagefault} we will implement the \emph{page fault
handler}\marginnote{page fault\\ handler}. It requires a working hard 
disk since we will \emph{page out} pages to the disk and later 
\emph{page them in} again.



\section{Exercises}

\begin{enumerate}
%start with no. 16
\setcounter{enumi}{15}

\item \textbf{Keyboard driver: Polling}

In\marginnote{Tutorial 4} the folder \path!tutorial/04/! you find a version of the \UlixI{} kernel which contains the new interrupt and fault handling code. It is a literate program (\path!ulix.nw!). You will now develop a simple keyboard driver, extending the provided code, and you should try to retain the literate programming style, i.\,e., integrate code and documentation in the file.

[[cd]] into the folder and open the file \path!ulix.nw!. At the end you will find a section ``keyboard driver'' where you can place your new code; at least most of it. The rest of the file corresponds to the literate program from the last exercise, but some new mechanisms have been added.
 
As a first step you can test querying the keyboard controller\index{keyboard controller} via polling\index{polling}\index{keyboard interrupt handler!alternative: polling}:

\begin{enumerate}
\item The keyboard controller can be accessed via two ports\index{port!keyboard controller} (\hex{60} and \hex{64}) which you can read from via [[inportb()]]. Append the port numbers to the [[<<constants>>]] code chunk:

\begin{Verbatim}
#define KBD_DATA_PORT   0x60
#define KBD_STATUS_PORT 0x64
\end{Verbatim}

The data port delivers information about pressed and released keys, and the status port lets you check whether a key was pressed (or released) at all.
\vspace{1mm}%

\item Try to continuously read the data port in a loop and print the results (as numbers). You can query with the following code:

\begin{Verbatim}
byte scancode;
scancode = inportb (KBD_DATA_PORT);
\end{Verbatim}

(We have prepared an empty code chunk [[<<kernel main: user-defined tests>>]] at the end of the Noweb file which will be called after initialization.) Print the scan codes with [[printf()]]. This will quickly fill the screen (even if you add no newlines to your [[printf]] call), so you should clear the screen when you reach the bottom line:

\begin{Verbatim}
if (posy == 25) clrscr ();
\end{Verbatim}

You will notice that this approach writes a continuous (and quick) stream of data onto the screen. While the system is running, press a few keys; that will modify the output.\marginnote{keyboard\\ scan code} (You may have to keep the keys pressed to recognize the changes.) The values are \emph{keyboard scan codes}\index{scan code}, each of them represents an action of pressing or releasing a key. You will see the same value again and again until a new press/release event occurs.
\vspace{1mm}%

\item Improve the code by also checking the status register (via the status port). That works in the same way that you've accessed the data port, but uses the port number [[KBD_STATUS_PORT]]. If the lowest bit of the return value is set (which you can check with \verb#if ((status & 1) == 1)#), then there is a fresh scan code, and only then should you query the data port. The modified code will only generate an output when you press or release a key.
\vspace{1mm}%

\item The scan codes for pressing and releasing a key only differ in the eighth bit (it it set for release events), so for example scan codes for the ``A'' key are 30 and 158 ($= 30 + 128$), for its left neighbor key ``S'' they are 31 and 159 ($= 31 + 128$). Create a mapping table which stores the upper case letters which correspond to a few scan codes. You need not look up an ASCII table but can simply enter characters, such as [['A']] or [['B']], in the table. Initialize the table with zero values:

\begin{Verbatim}
char scancode_table[128] = { 0 };
\end{Verbatim}

Then you can start with adding entries for the scan codes you already know, e.\,g.\ 30 and 31 for the ``A'' and ``S'' keys. (We ignore release codes in this table.)

\begin{Verbatim}
scancode_table[30] = 'A';
scancode_table[31] = 'S';
\end{Verbatim}

Identify the return key's scan code. The corresponding character is [['\n']].

Modify your existing code so that it does not only print the scan code but also the character (if it is known, i.\,e., the corresponding table entry is not 0). Test your program. (The [[printf]] format code for characters is [[%c]].
When you print release scan codes you get negative numbers---you can get rid of them by casting the scan code to the [[int]] type.)
\end{enumerate}
\vspace{-2mm}
This leaves you with a simple, polling keyboard driver.
\vspace{3mm}

\item \textbf{Keyboard driver: Interrupts}

In this exercise you switch to an interrupt-based keyboard driver.
\vspace{-2mm}

\begin{enumerate}
\item Add the following lines to an appropriate place in the system initialization, e.\,g.\ in the [[<<kernel main: initialize system>>]] chunk:

\begin{Verbatim}
install_interrupt_handler (IRQ_KBD, keyboard_handler);
enable_interrupt (IRQ_KBD);
asm ("sti");                  // enable interrupts
\end{Verbatim}

[[IRQ_KBD]] is already [[#define]]d as 1: It is the interrupt number used by the keyboard controller. Now you have to implement the keyboard handler. It has the signature

\begin{Verbatim}
void keyboard_handler (struct regs *r);
\end{Verbatim}

([[struct regs]] is the same as [[context_t]] in the rest of the book.) It will automatically be called whenever you press or release a key.
\vspace{1mm}%

\item Make sure that your handler gets called by letting it print a single character (e.\,g.\ [['*']]) and leaving the handler with [[return;]].

\pagebreak

\item In the next step you evaluate and print the values that you can read from the keyboard controller. It is not necessary to query the controller's data port (as you did in the above exercise), because the handler is only called when a new event has occurred. After the output (like above, using the scan code table) you can leave the handler with [[return;]]. Note that again, due to the simplified [[printf]] implementation, you will need to insert [[clrscr()]] calls when you reach the screen's bottom.

The advantage of using interrupts is that the main program (in [[main]]) need not concern itself with the keyboard.
\vspace{1mm}%

\item Next, implement a function 

\begin{Verbatim}
void kreadline (char *s, int len);
\end{Verbatim}

that you call from [[main()]], e.\,g.\ with

\begin{Verbatim}
char input[41];   // 40 characters plus \0 terminator
kreadline ((char*)input, 40);
\end{Verbatim}

The goal is that \verb#kreadline()# fills the provided string (a [[char]] pointer) with the characters you enter (as far as they are known in the scan code table) until you either complete the input by pressing [Enter] or until the maximum number of characters (\verb#len#) is reached. Only then shall the function return. The main program can then print the read string and start over, using an infinite loop.

The important aspect of this exercise is that the \verb#kreadline# needs to cooperate with the interrupt handler. You will need two new global variables for an input buffer and for the next character position in the buffer:

\begin{Verbatim}
char buffer[256];      // buffer for input
short int pos = 0;     // current position in the buffer
\end{Verbatim}

The interrupt handler should work as follows:
\vspace{-1mm}%

\begin{itemize}
\item If the scan code is larger than 127 (release event), the handler returns immediately (it simply ignores release events).
\item When an unknown scan code shows up, the handler also returns at once.
\item Otherwise it will print the character and also write it into the buffer.
\item Then it increases \verb#pos# and returns.
\end{itemize}
\vspace{-1mm}%

\verb#kreadline()# performs an infinite loop and checks whether [[(pos>0 && buffer[pos-1] =='\n')]] is true---if so, then the function copies the entered string (from position 0 to [[pos-2]]) to [[s]], sets [[pos=0]] and returns. Note that the string must be [['\0']]-terminated so that [[printf()]] can later use it. You can simply replace the [['\n']] chacracter with [['\0']] if the input is terminated by pressing [Enter]; if you reach the maximum allowed number of characters, you write [['\0']] into the last byte of the string.

For copying the string you can use [[strncpy()]]. That function works like the corresponding Linux function (see \verb#man strncpy#), i.\,e., it expects target, source and maximum length of the target string as arguments.

Your scan code table will need an entry for the [Enter] key in order to make this work.
\end{enumerate}


\item \textbf{Backspace Support}

Modify your code for the keyboard handler and the \verb#kreadline# function so that it treats the backspace key appropriately: With that key you shall be able to delete the last character that was entered. It shall both be removed from the screen and from the string which \verb#kreadline# returns.
\vspace{2mm}

\item \textbf{Faults}

The current version of the mini kernel contains fault handlers. Verify that they work correctly by generating some typical faults:
\vspace{-1mm}

\begin{itemize}
\item Division by zero: Have your main program perform a division by zero, for example via [[int z = 1 / 0;]]---you can ignore any compiler warnings that this code will cause. 

\item Try to access non-available memory, e.\,g., with
\begin{Verbatim}
char *address = (char*)0xE0000000; char tmp = *address;
\end{Verbatim}

\item Set the segment register \register{DS} to an invalid segment number, e.\,g.:
\begin{Verbatim}
asm ("mov $32, %ax;  mov %ax, %ds");
\end{Verbatim}

\item You can explicitly cause each fault (for fault numbers between 0 and 31) by using the assembler instruction [[int $number]]. For example, in order to generate an ``Out of Bounds Fault'' (number 5), you can use the line \verb#asm ("int $5");#.
\end{itemize}
\vspace{-2mm}

\enlargethispage{5mm}
The reward should be a Division by Zero Fault, a Page Fault and a General Protection Fault (and an Out of Bounds Fault in the last step).

\end{enumerate}





%------------------------------------------------------------------------------------




\black
\addtocontents{toc}{\protect\parttocpagebreak}

\chapter{Implementation of Processes}
\label{chap:ulix:processes}%
\index{process!implementation}%
\index{Ulix!process implementation}

We have now written most of the code that we need to introduce the
most important concept: the process. In this chapter we take a first
look at the data structures and kernel functions which will let us
create and schedule processes. 

\begin{itemize}
\item In Chapter \ref{sec:processes:address spaces} we present
the desired memory layout of a \UlixI{} process and describe our
implementation of address spaces.

\item Chapter \ref{sec:processes:TCBs} introduces the central data
structure for processes and threads, the process control block (which
we will refer to as a thread control block, TCB),
as well as queues for handling ready and blocked threads.

\item Chapter \ref{sec:processes:start the first} shows what we need
to do in order to start the very first process; all further processes
will be created via the [[fork]] mechanism.

\item Since forking will require the existence of a system call
interface, it is time to introduce it: we present our
implementation in Chapter \ref{sec:processes:syscall}.

\item With system calls available we can explain the implementation of the fork 
mechanism (and the \verb#fork# system call) in Chapter \ref{sec:processes:fork}.

\item While it is an important step to bring new processes into existence,
we also need to handle their termination. In Chapter~\ref{sec:processes:exit}
we show how to \verb#exit# from a process.
\end{itemize}

The remaining sections of this chapter are less interesting but still required: We provide a method for requesting process information in Chapter~\ref{sec:processes:information} (which will let us write a \verb#ps# program), describe the ELF binary format and an ELF program loader in Chapter~\ref{sec:elf-loader} (so that a process can start a different application via \verb#exec#) and finally discuss an idle process that will be activated when there is no other process that could do something useful (Chapter~\ref{sec:processes:idle}).

\pagebreak

Everything you will see in this chapter deals with single-threaded processes. In Chapter~\ref{chap:ulix:threads} we will extend our execution model so that it also supports multiple threads inside one process. You might want to remember this whenever you wonder why we keep talking about \emph{thread} control blocks (instead of \emph{process} control blocks) throughout this chapter.

There's also a need to discuss how the system can switch between concurrent processes and threads: once we have more than one active task, a scheduler must take care of this. We delay this until Chapter \ref{chap:ulix:scheduling}.


\section{Address Spaces for Processes}
\label{sec:processes:address spaces}%

\index{address space!implementation}
We will store information about memory usage in a data structure
that we call \emph{address space descriptor}\index{address space descriptor}\marginnote{address space\\ descriptor}. 
The idea is that every process uses its
own address space while several threads (of the same process) share
a common address space.

\felix

Address space descriptors are stored in one large
\emph{\vindex{address space table}}. This table must be finite,
i.\,e., there must exist a maximum number of address spaces for
the system. This must correspond to the maximum number
of threads [[MAX_THREADS]] \black that we'll soon define: 
While threads may share an address space, it is impossible for
one thread to use more than one address space. Thus
[[MAX_ADDR_SPACES]] has to be $\le$ [[MAX_THREADS]]---we give
both constants the same value: 
\index{maximum number of address spaces}

<<constants>>=
#define MAX_ADDR_SPACES 1024
@ %def MAX_ADDR_SPACES

\felix
As we will see later, every thread may have its own virtual address
space and needs to own a reference to an address space descriptor.
Even the kernel will have to do that.  Since there can be so many
address spaces, we need a shorthand to identify virtual address
spaces. We introduce the type [[addr_space_id]] to do this.  It is
declared as [[unsigned int]]. Basically, an [[addr_space_id]] can
be thought of as an index into the address space table. So rather
than storing a complete address space descriptor per thread, we
will rather store an address space identifier.

<<public elementary type definitions>>=
typedef unsigned int addr_space_id;
@ %def addr_space_id

\black
We already note that the thread control block (which will be the
central data structure for processes and threads) needs an [[addr_space_id]]
element. That data structure is called [[TCB]], and we will define it later
in this chapter, but you will often see the code chunk 
[[<<more TCB entries>>]] that lets us append entries to this structure
whenever the need occurs:

\felix
<<more TCB entries>>=
addr_space_id addr_space;
@

\black

\pagebreak


\subsection{Memory Layout of a Process}
\label{sec:processes:memory layout}%
\index{process!memory layout}%

Every process needs three (virtual) memory areas. 

\begin{itemize}
\item \textbf{Code and Data:}\index{code region}\index{data region} We will later compile user mode binaries
which expect to be loaded to the virtual addresses \hex{0} and above.
This area is used for the code (the machine instructions in the binary)
as well as variables defined statically in the program. The 
\marginnote{Heap} \emph{heap}\index{heap} will exist just behind this memory area,
processes can later dynamically expand this memory area using the
[[sbrk]] function.
\end{itemize}

<<constants>>=
#define BINARY_LOAD_ADDRESS 0x0
@ %def BINARY_LOAD_ADDRESS

\begin{itemize}
\item \textbf{User Mode Stack:}\index{user mode stack}\index{stack!user mode} Every process needs its own stack: That is 
where the CPU will store return addresses and arguments whenever the process
makes a function call. We'll use the virtual addresses below
\hex{b0000000} which will leave a lot of space between the code and data
and the stack: We want the stack to grow automatically, so we'll start
with just one single page of memory for the stack and increase it as
needed: When you think of recursive functions where the end of the
recursion depends on some calculation inside the program, it is clear
that we cannot have a maximum size for the stack. Expanding the stack is
a task for the page fault handler which we've already mentioned. You will
see its implementation on page \pageref{chap:pagefault} ff.
\end{itemize}

<<constants>>=
#define TOP_OF_USER_MODE_STACK 0xb0000000
@ %def TOP_OF_USER_MODE_STACK

\begin{itemize}
\item \textbf{Kernel Stack:}\index{kernel mode stack}\index{stack!kernel mode} For several reasons we need a second stack 
when a process switches to kernel mode (using a system call, see Section
\ref{chap:ulix:syscall}). While it would be possible to share one kernel
stack between all the processes, that would also limit us: With a 
single kernel stack we would run into problems when two or more
processes need to enter kernel mode at the same time.

There's also a security aspect: The kernel stack may contain kernel data
that the process should not have access to.

We'll put the kernel stack just under the kernel space of memory,
at addresses below \hex{c0000000}.
\end{itemize}

<<constants>>=
#define TOP_OF_KERNEL_MODE_STACK 0xc0000000
@ %def TOP_OF_KERNEL_MODE_STACK

\noindent
Thus, the memory layout of a process is as shown in 
Figure~\ref{fig:process memory layout}. The double line below
\hex{c0000000} marks the barrier between process-specific
and generic memory ranges: everything above \hex{c0000000} is
globally visible and identical in every address space, whereas
the lower addresses differ for each process, and they do not
exist at all before the first process has been created.

Address ranges marked `K' in the last column need kernel 
privileges to be accessed. Heap areas will only become
available after they are manually requested. The `(U)'
annotation of the combined stack/heap area refers to the 
fact that it is not allocated when a process starts but
rather can grow both from the top and from the bottom,
depending on the process' actions.

\begin{figure}[h!]
\begin{centering}\begin{tabular}{|r@{\hspace{1mm}}c@{\hspace{1mm}}l|l|c|}
\hline
\multicolumn{3}{|l|}{\textsf{\textbf{Address Range}}} & \textsf{\textbf{Usage}} & \textsf{\textbf{Access}} \\
\hline
\hline
\hex{D4000000} & -- & \hex{FFFFFFFF} & \emph{unused} & --\\
\hline
\hex{D0000000} & -- & \hex{D3FFFFFF} & 64 MByte Physical RAM (mapped) & K\\
\hline
\hex{C0000000} & -- & \hex{CFFFFFFF} & Kernel Code and Data & K\\
\hline
\hline
\hex{BFFFF000} & -- & \hex{BFFFFFFF} & Kernel Stack (4 KByte = one page) & K\\
\hline
\hex{B0000000} & -- & \hex{BFFFEFFF} & \emph{unused} & --\\
\hline
\dots          & -- & \hex{AFFFFFFF} & User Mode Stack & U\\
\hline
&&&&\\
               &    &                & User Mode Stack (grows automatically) & \\
&&&& (U) \\
               &    &                & Heap (can be grown with [[sbrk]]) & \\
&&&&\\
\hline
\hex{00000000} & -- & \dots & Process Code and Data & U\\
\hline
\end{tabular}
\caption[Memory layout of a process.]{This is the memory layout of a process.}
\label{fig:process memory layout}
\end{centering}
\end{figure}

We will later provide a modified version of this memory model, when we
introduce several threads (of the same process), but for now this
description is sufficient to understand the process implementation.


\subsection{Creating a New Address Space}

Essentially, an address space is just a fresh page directory\index{page directory!address space}. Its
kernel memory part (addresses \hex{c0000000} and higher) will be
identical to the kernel's page directory which we've already
set up earlier.

It is helpful to reconsider how the CPU (or the MMU\index{memory management unit}) accesses
the paging information: A register holds the address of the page
directory which has 1024 entries, each of which is either null or
points to a page table.

The upper $1024-768 = 256$ entries are responsible for the kernel
memory (\hexrange{C0000000}{FFFFFFFF}), and the lower 768 entries are available
for process memory (\hexrange{00000000}{BFFFFFFF}) with the upper
part of each process' private memory (\hexrange{BFFFF000}{BFFFFFFF})
being the kernel stack which is only available in kernel mode.

We want to allow for three different situations, as far as access
to process memory and kernel memory is concerned:

\pagebreak

\begin{description}
\item[pure kernel mode:] The kernel is actively dealing with specific kernel tasks, such as memory management or interrupt service. The kernel's view on memory in this state is as it was after we enabled paging: It sees its own memory (\hexrange{C0000000}{CFFFFFFF}) and the physical memory which is mapped to addresses starting at \hexaddr{D0000000}, but no process memory.
We will not use this mode once the first process was created.

\item[process in user mode:]\index{user mode} A process is active and running in user mode. It only sees its own memory (\hexrange{00000000}{AFFF.FFFF}: code, data, heap and user mode stack). The paging information will map the kernel stack and the kernel's memory as well, but since it will be marked non-user-mode-accessible, that will be the same as not having it at all when running in user mode. In this mode any attempt to access kernel memory (either its data or its code) will generate a page fault---even if the address is valid.

\item[process in kernel mode:]\index{kernel mode} A process has entered kernel mode via a system call or an interrupt has occurred. In this situation the page tables must give access to both the current process' memory and the kernel memory. All 4 GByte of virtual memory are visible. The paging information can be the same as for the process in user mode: the current level of execution (kernel mode instead of user mode) grants the access to all of the virtual memory. (For handling an interrupt it is not necessary to see the current process' user mode memory, so we could switch to \emph{pure kernel mode} in order to prevent interrupt handlers from looking at process memory. But since we intend to trust our interrupt handlers, we will not do that.)
\end{description}

\noindent
We reserve memory for an address space list\index{address space table}. This list does not hold
the page directory or the page tables it points to, but just the 
address of the page directory and some status information:

%nouse
<<type definitions>>=
typedef struct {
  void         *pd;                // pointer to the page directory
  int          pid;                // process ID (if used by a process; -1 if not)
  short        status;             // are we using this address space?
  memaddress   memstart, memend;   // first/last address below 0xc000.0000
  unsigned int stacksize;          // size of user mode stack
  memaddress   kstack_pt;          // stack page table (for kernel stack)
  unsigned int refcount;           // how many threads use this address space?
  <<more [[address_space]] entries>>
} address_space;
@ %def address_space
[[pd]] holds the (virtual) address of the page directory.
[[memstart]] and [[memend]] contain the first and last user mode
address (for code, data and heap), and [[stacksize]] tells the size
of the user mode stack. We also want to keep the address of the
kernel mode stack's page table handy, thus we will store it in [[kstack_pt]].
[[refcount]] lets us count how often the address space is used---for
non-threaded processes this value will always be 1.

We define three possible values for the [[status]] field of an address
space:

<<constants>>=
#define AS_FREE   0
#define AS_USED   1
#define AS_DELETE 2
@ %def AS_FREE AS_USED AS_DELETE
The meaning of [[AS_FREE]] and [[AS_USED]] is obvious, but why we need
a third state [[AS_DELETE]] will only become clear when you reach the
section that deals with process termination. Briefly, we cannot 
immediately destroy the address space of a process which has actively
requested its termination, so that has to happen a bit later, and in
the meantime the address space will be marked as ``to be deleted''.

The \emph{address space table}\marginnote{address space\\ table} is an 
array of address space descriptors, and we will need a function that lets us search for a free entry in the table:

<<global variables>>=
address_space address_spaces[MAX_ADDR_SPACES] = { { 0 } };
@ %def address_spaces

%nouse
<<function prototypes>>=
int get_free_address_space ();
@ It returns an integer value that serves as an index into the table.

<<function implementations>>=
int get_free_address_space () {
  addr_space_id id = 0;
  while ((address_spaces[id].status != AS_FREE) && (id < MAX_ADDR_SPACES)) id++;
  if (id == MAX_ADDR_SPACES) id = -1;
  return id;
}
@ %def get_free_address_space

We use the first entry of the array [[address_spaces]] for the kernel
and let it point to the kernel page directory.
We add the code for initializing this entry just after enabling paging:

\enlargethispage{5mm}
<<enable paging for the kernel>>=
address_spaces[0].status   = AS_USED;
address_spaces[0].pd       = &kernel_pd;
address_spaces[0].pid      = -1;         // not a process
@ Setting \verb#pid# to $-1$ marks this entry as an address space which
belongs to no process.

\pagebreak

Here is what we need to do in order to create a fresh address space:
We first retrieve a new address space ID and mark its entry in 
the table as used. Then
we reserve memory for a new page directory and copy the system's one
into it. Finally we set up some user space memory and add it to
the page directory:

\index{address space!creation}%
%nouse
<<function prototypes>>=
int create_new_address_space (int initial_ram, int initial_stack);
@ %
The argument [[initial_ram]] defines the amount of process-private 
memory that should be allocated at once, similarly [[initial_stack]]
is the initial size of the user mode stack which will always be
just 4 KByte (though it can grow later).
We expect the [[initial_ram]] and [[initial_stack]] values to be
multiples of the page size (4 KByte)---if not, we will make them so, 
using this macro:

<<macro definitions>>=
#define MAKE_MULTIPLE_OF_PAGESIZE(x)  x = ((x+PAGE_SIZE-1)/PAGE_SIZE)*PAGE_SIZE
@ %def MAKE_MULTIPLE_OF_PAGESIZE
%
If the function call is successful, [[create_new_address_space]]
returns the ID of the newly created address space, otherwise $-1$:

<<function implementations>>=
int create_new_address_space (int initial_ram, int initial_stack) {
  MAKE_MULTIPLE_OF_PAGESIZE (initial_ram);
  MAKE_MULTIPLE_OF_PAGESIZE (initial_stack);
  // reserve address space table entry
  addr_space_id id;
  if ( (id = get_free_address_space ()) == -1 )  return -1;    // fail
  address_spaces[id].status    = AS_USED;
  address_spaces[id].memstart  = BINARY_LOAD_ADDRESS;
  address_spaces[id].memend    = BINARY_LOAD_ADDRESS + initial_ram;
  address_spaces[id].stacksize = initial_stack;
  address_spaces[id].refcount  = 1;  // default: used by one process
  <<reserve memory for new page directory>>   // sets new_pd
  address_spaces[id].pd = new_pd;
  <<copy master page directory to new directory>>

  int frameno, pageno;  // used in the following two code chunks
  if (initial_ram > 0)   {  <<create initial user mode memory>>  }
  if (initial_stack > 0) {  <<create initial user mode stack>>     }
  return id;
};
@ %def create_new_address_space

As usual we use [[request_new_page]] to get a fresh page of virtual
memory which will store the new page directory: that function will also 
update the page directories of all already existing address spaces if 
it has to create a new page table (for addresses in the kernel memory).

<<reserve memory for new page directory>>=
page_directory *new_pd = request_new_page ();
if (new_pd == NULL) {  // Error
  printf ("\nERROR: no free page, aborting create_new_address_space\n");
  return -1;
};
memset (new_pd, 0, sizeof (page_directory));
@

For copying the kernel page directory to the new directory, we
simply use an assignment; this copies all references to page tables
which exist in the original (kernel) page directory.

<<copy master page directory to new directory>>=
*new_pd = kernel_pd;
memset ((char*)new_pd, 0, 4);    // clear first entry (kernel pd contains
                                 // old reference to some page table)
@

Note that once we have more than one address space, we must make sure that all changes to the kernel part (the addresses starting at \hex{C0000000}) will be made in each copy. The page tables of that area are all shared, but when we create a new page table, we have to write the new mapping into \emph{every} page directory---you have already seen the code on page \pageref{code:create new page table, update all address spaces}.

We modify the new page directory so that it contains information about
the user mode memory, stack and kernel stack. For that purpose we will
use a function 

%nouse
<<function prototypes>>=
int as_map_page_to_frame (int as, unsigned int pageno, unsigned int frameno);
@ %
which can create mappings of
page numbers to frame numbers in a specific address space. We will
define it just afterwards; it finds out what page table entry to modify 
and, if needed, also creates a new page table and updates the page
directory to point to it.

<<create initial user mode memory>>=
pageno = 0;
while (initial_ram > 0) {
  if ((frameno = request_new_frame ()) < 0) {
    printf ("\nERROR: no free frame, aborting create_new_address_space\n");
    return -1;
  };
  as_map_page_to_frame (id, pageno, frameno);
  pageno++;
  initial_ram -= PAGE_SIZE;
};
@

Reserving memory for the user mode stack looks almost the same, we
just let the stack\index{stack!address space} grow downwards whereas above the memory addresses
moved upwards: so we need to modify the page number with [[pageno--]]
instead of [[pageno++]]:

<<create initial user mode stack>>=
pageno = TOP_OF_USER_MODE_STACK / PAGE_SIZE;
while (initial_stack > 0) {
  if ((frameno = request_new_frame ()) < 0) {
    printf ("\nERROR: no free frame, aborting create_new_address_space\n");
    return -1;
  };
  pageno--;
  as_map_page_to_frame (id, pageno, frameno);
  initial_stack -= PAGE_SIZE;
}
@

We will now describe how to enter the page-to-frame mapping in the
new address space's page tables. 
Getting new physical memory is not a problem since we already have
defined the function [[request_new_frame()]] which reserves a new frame.

The function [[as_map_page_to_frame]] creates such a mapping in a given address space. It will basically be a rewrite of parts of [[<<enter frames in page table>>]].

<<function implementations>>=
int as_map_page_to_frame (int as, unsigned int pageno, unsigned int frameno) {
  // for address space as, map page #pageno to frame #frameno
  page_table *pt;
  page_directory *pd;

  pd = address_spaces[as].pd;           // use the right address space
  unsigned int pdindex = pageno/1024;   // calculuate pd entry
  unsigned int ptindex = pageno%1024;   // ... and pt entry

  if ( ! pd->ptds[pdindex].present ) {
    // page table is not present
    <<create new page table for this address space>>  // sets pt
  } else {
    // get the page table
    pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
  };
  if (pdindex < 704)   // address below 0xb0000000 -> user access
    UMAP ( &(pt->pds[ptindex]), frameno << 12 );
  else
    KMAP ( &(pt->pds[ptindex]), frameno << 12 );
  return 0;
};
@ %def as_map_page_to_frame
\label{discussion:umap vs kmap, 0-703}%
In the last lines of this function we differentiate between user mode
and kernel mode memory and use the appropriate macro ([[UMAP]] or
[[KMAP]]) to create an entry which allows or forbids access for
processes in user mode: The address range \hexrange{00000000}{afffffff}
grants the process access in user mode, whereas
\hexrange{b0000000}{ffffffff} shall only be accessible in kernel mode.

Remember that every page directory entry lets us address one page
table which holds the addresses of up to 1\,024 pages, or
$1\,024 \times 4\,096 = 4\,194\,304$ bytes (4~MByte) of memory. 
\[
\frac{\textrm{\hex{b0000000}}}{1\,024 \times 4\,096} = 704
\]
so we must use [[UMAP]] if [[pdindex]] $ < 704$.

Now we need to explain how to create a new page table: We start with
fetching a free frame and point to it from the page directory.

<<create new page table for this address space>>=
int new_frame_id = request_new_frame ();
memaddress address = PHYSICAL (new_frame_id << 12);
pt = (page_table *) address;
memset (pt, 0, sizeof (page_table));
UMAPD ( &(pd->ptds[pdindex]), new_frame_id << 12);
@


\subsection{Destroying an Address Space}
\label{sec:address-space-destroy}%

\index{address space!destruction}
When we \verb#exit# from a process, we must also destroy its address
space and release all pages used by it. For that purpose we write
a function [[destroy_address_space()]]:

%nouse
<<function prototypes>>=
void destroy_address_space (addr_space_id id);
@

\noindent
Its main task is to undo all the memory allocations that were performed when we created the address space so that no memory leaks occur: A sequence like 

\begin{Verbatim}
  id = create_new_address_space (...);
  destroy_address_space (id);
\end{Verbatim}

\noindent
should return the global memory status to the same situation that it had before the creation:

<<function implementations>>=
void destroy_address_space (addr_space_id id) {
  // called only from syscall_exit(), with interrupts off
  if (--address_spaces[id].refcount > 0) return;
  addr_space_id as = current_as;          // remember current address space
  current_as = id;                        // set current_as: we call release_page()

  <<destroy AS: release user mode pages>> // all pages used by the process
  <<destroy AS: release user mode stack>>  // all its user mode stack pages
  <<destroy AS: release page tables>>      // the page tables (0..703)
  
  current_as = as;                        // restore current_as
  address_spaces[id].status = AS_DELETE;  // change AS status
  
  // remove kernel stack (cannot do this here, this stack is in use right now)
  add_to_kstack_delete_list (id);
}
@ %def destroy_address_space

The comment in the above chunk's first line refers to protection of the thread table data. We will later discuss synchronization issues (in Chapter~\ref{chap:synchronization}), and the address space table is one of the critical data structures that must be treated carefully. So, one would expect to see code for protecting it in this function, but this protection occurs elsewhere. In short, we will only modify the address space table when we hold a lock for the thread table, and that lock is already held when the kernel enters this function. (The same holds for the [[create_new_address_space]] function.)

Releasing the user mode memory is done in two simple steps:

<<destroy AS: release user mode pages>>=
for ( int i = address_spaces[id].memstart / PAGE_SIZE;
      i < address_spaces[id].memend / PAGE_SIZE;
      i++ ) {
  release_page (i);
};
@

<<destroy AS: release user mode stack>>=
for ( int i = TOP_OF_USER_MODE_STACK / PAGE_SIZE - 1;
      i > (TOP_OF_USER_MODE_STACK-address_spaces[id].stacksize) / PAGE_SIZE - 1;
      i-- ) {
  release_page (i);
};
@

After releasing all the individual pages, we can also get rid of the page tables which
refer to user mode memory:

<<destroy AS: release page tables>>=
page_directory *tmp_pd = address_spaces[id].pd;
for (int i = 0;  i < 704;  i++) {
  if (tmp_pd->ptds[i].present)
    release_frame (tmp_pd->ptds[i].frame_addr);
}
@ In the last code chunk the loop goes from 0 to 703 since that is the
last page directory entry which points to a page table that is used
in user mode (cf.{} the discussion of [[UMAP]] vs.{} [[KMAP]] usage in 
the implementation of [[as_map_page_to_frame]] on 
page \pageref{discussion:umap vs kmap, 0-703}).

We will remove the kernel stack later when we're not using it any
more---doing this right now would crash the system because that
memory is still in use.
For that purpose we use a global variable which contains either 
0 or the ID of an address space whose kernel stack needs removal.
That is why we called the function

%nouse
<<function prototypes>>=
void add_to_kstack_delete_list (addr_space_id id);
@ in the above code. We allow up to 1024 entries in the kernel
stack delete list:

<<constants>>=
#define KSTACK_DELETE_LIST_SIZE 1024
@ %def KSTACK_DELETE_LIST_SIZE

\index{stack!kernel stack delete list}%
\index{kernel mode stack!delete list}%

The \emph{kernel stack delete list}\marginnote{kernel stack\\ delete list} 
is just an array of address space IDs that we 
initialize with null values.
<<global variables>>=
addr_space_id kstack_delete_list[KSTACK_DELETE_LIST_SIZE] = { 0 };
@ 

Entering an address space ID in the delete list is simple:

<<function implementations>>=
void add_to_kstack_delete_list (addr_space_id id) {
  <<begin critical section in kernel>>
  int i;
  for (i = 0;  i < KSTACK_DELETE_LIST_SIZE;  i++) {
    // try to enter it here
    if (kstack_delete_list[i] == 0) {
      // found a free entry
      kstack_delete_list[i] = id;  break;
    }
  }
  <<end critical section in kernel>>
  if (i == KSTACK_DELETE_LIST_SIZE) 
    printf ("ERROR ADDING ADDRESS SPACE TO KSTACK DELETE LIST!\n");
}
@ %def add_to_kstack_delete_list

We have not shown the code for the scheduler yet, it is responsible
for switching between the processes and is called regularly by the
timer interrupt handler. Whenever the system activates the scheduler
it will execute the following code chunk [[<<scheduler: free old kernel stacks>>]]
which frees those old kernel stacks that we've put into the list:

\pagebreak
<<scheduler: free old kernel stacks>>=
// check all entries in the to-be-freed list
<<begin critical section in kernel>>
for (int entry = 0;  entry < KSTACK_DELETE_LIST_SIZE;  entry++) {
  if (kstack_delete_list[entry] != 0 && kstack_delete_list[entry] != current_as) {
    // remove it
    addr_space_id id = kstack_delete_list[entry]; 
    page_directory *tmp_pd = address_spaces[id].pd;
    page_table     *tmp_pt = (page_table *) address_spaces[id].kstack_pt;
    // this is the page table which maps the last 4 MB below 0xC0000000
    for (int i = 0;  i < KERNEL_STACK_PAGES;  i++) {
      int frameno = tmp_pt->pds[1023-i].frame_addr;
      release_frame (frameno);
    }
    <<remove extra thread kernel stacks>>  // see Chapter 7
    kstack_delete_list[entry] = 0;   // remove entry from kstack delete list
    release_page (((memaddress)tmp_pt) >> 12);  // free memory for page table
    release_page (((memaddress)tmp_pd) >> 12);  // ... and page directory
    address_spaces[id].status = AS_FREE;        // mark address space as free
  }
}
<<end critical section in kernel>>
@

We haven't defined the constant [[KERNEL_STACK_PAGES]] yet: it tells the
system how many pages it shall reserve for the kernel stack.

<<constants>>=
// kernel stack (per process): 1 page = 4 KByte
#define KERNEL_STACK_PAGES 4
#define KERNEL_STACK_SIZE PAGE_SIZE * KERNEL_STACK_PAGES
@ %def KERNEL_STACK_PAGES KERNEL_STACK_SIZE
We may sometimes also need to know the size of the kernel stack ([[KERNEL_STACK_SIZE]]).


\subsection{Switching between Address Spaces}

\index{address space!switch between}\index{context switch}%
In order to switch between two address spaces it is sufficient
to load the new address space's page directory address into
the \register{CR3} register.

Note that using the function [[activate_address_space]] (which we show 
in this section) should be avoided because it has
the side effect of switching the kernel stack. Even while it is
implemented as [[inline]] function, it is still not safe to call
it: parameter passing creates local variables (on the kernel
stack) which are lost after the context switch. We will only use
it when we start the very first process.

In earlier versions of the code, [[<<scheduler: context switch>>]] used to
make a function call to [[activate_address_space()]] and it 
caused many problems (the operating system crashed). After moving
the \register{CR3} loading code directly into the context switch, the
problems disappeared.


%nouse
<<function prototypes>>=
inline void activate_address_space (addr_space_id id)  __attribute__((always_inline));
@

<<global variables>>=
addr_space_id current_as = 0;  // global variable: current address space
@ %def current_as

<<function implementations>>=
inline void activate_address_space (addr_space_id id) {
  // NOTE: Do not call this from the scheduler_ - where needed, replicate the code
  memaddress virt = (memaddress)address_spaces[id].pd;  // get PD address
  memaddress phys = mmu (0, virt);              // and find its physical address
  asm volatile ("mov %0, %%cr3" : : "r"(phys)); // write CR3 register
  current_as = id;                              // set current address space
  current_pd = address_spaces[id].pd;           // set current page directory
};
@ %def activate_address_space
Here we use another function
called [[mmu]] which emulates the behavior of the memory management unit (MMU) 
and calculates the physical address belonging to a virtual address with respect
to an address space. We will implement it soon.

\enlargethispage{5mm}
We provide a helper function
%nouse
<<function prototypes>>=
void list_address_spaces ();
@ which shows the list of used address spaces; it is only needed for
debugging.

<<function implementations>>=
void list_address_space (addr_space_id id) {
  int mem  = (memaddress) address_spaces[id].pd;
  int phys = mmu (id, (memaddress) address_spaces[id].pd);  // emulate MMU
  int memstart = address_spaces[id].memstart;
  int memend = address_spaces[id].memend;
  int stack = address_spaces[id].stacksize;
  printf ("ID: %d, MEM: %08x, PHYS: %08x  - USER: %08x, USTACK: %08x\n", 
    id, mem, phys, memend-memstart, stack); 
}
@ %def list_address_space
\pagebreak

<<function implementations>>=
void list_address_spaces () {
  addr_space_id id;
  for (id = 0;  id < MAX_ADDR_SPACES;  id++) {
    if (address_spaces[id].status != AS_FREE) {
      list_address_space (id);
    }
  }
}
@ %def list_address_spaces

[[list_address_space]] also uses the [[mmu]] function---it is time to
provide its implementation. We start with a function [[mmu_p]] which,
given an address space ID and a page number, finds out whether the
page is mapped in that address space and returns the frame number of
the mapped frame.
\index{memory management unit!emulation in Ulix}%

%nouse
<<function prototypes>>=
unsigned int mmu_p (addr_space_id id, unsigned int pageno); // pageno -> frameno
memaddress mmu (addr_space_id id, memaddress vaddress); // virtual -> phys. addr.
@

\noindent
[[mmu_p]] looks up the page directory and then the right page table
which holds the mapping for the virtual address. Note that this
function can only work if the page table is in memory---if it
was paged out, it will return $-1$ (or actually: [[INT32_MAX]], since
it is of type [[unsigned int]]).

<<function implementations>>=
unsigned int mmu_p (addr_space_id id, unsigned int pageno) {
  unsigned int pdindex = pageno/1024;
  unsigned int ptindex = pageno%1024;
  page_directory *pd = address_spaces[id].pd;
  if ( ! pd->ptds[pdindex].present ) {
    return -1;
  } else {
    page_table *pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
    if ( pt->pds[ptindex].present ) {
      return pt->pds[ptindex].frame_addr;
    } else {
      return -1;
    };
  }
};
@ %def mmu_p
and with [[mmu_p]] we can easily implement [[mmu]] because we just
have to split a virtual address into page number and offset, then
call [[mmu_p]] to find the frame number and reassemble that and 
the offset to form a physical address:

\pagebreak

<<function implementations>>=
memaddress mmu (addr_space_id id, memaddress vaddress) {
  unsigned int tmp = mmu_p (id, (vaddress >> 12));
  if (tmp == -1)
    return -1;  // fail
  else
    return (tmp << 12) + (vaddress % PAGE_SIZE);
}
@ %def mmu

Note that both functions return $-1$ if the page or virtual address
does not exist, but only when calling [[mmu_p]] we can be sure
that a return value of $-1$ indicates a non"=existing page---after
all, \emph{some} virtual address might be mapped to physical
address \hex{FFFFFFFF} (which is the same as $-1$).


\subsection{Enlarging an Address Space}
\label{sec:address-space:enlarge}%
\index{address space!enlargement}%

We want to allow processes to increase their standard memory usage (which
is 64 KByte). Unix systems provide an implementation of [[malloc]] as
part of their standard library.

\index{brk system call@\texttt{brk} system call}%
\index{system call!brk@\texttt{brk}}%
The [[brk]] system call (and corresponding library function) is still
available on modern Unix systems, but its use is advised against.
[[brk]] adds one or more pages to the calling process' data ``segment''. 
The function [[sbrk]] does the same but is more user-friendly: It takes
an increment as argument, so if the process needs 16 KByte of extra memory,
it can call [[sbrk(16*1024)]]. [[sbrk]] returns the lowest address of
the new memory: After executing [[void *mem = sbrk(incr)]], the
address range $[ \texttt{mem}\, ; \texttt{mem}+\texttt{incr}-1 ]$ is available to the process.

How can we do this in \UlixI{}? Remember that each process uses an
[[address_space]] which has elements named [[memstart]] and [[memend]]
(the last of which is the first address that is \emph{not} available)
and a pointer to the address space's page directory ([[pd]]). Thus,
[[sbrk]] just needs to 

\begin{itemize}
\item acquire the needed number of frames,
\item modify the page directory so that the new frames are mapped just
after the last old pages and
\item update the [[memend]] element.
\end{itemize}

It then returns the first (virtual) address of the first new page.

We start with the kernel-internal function [[u_sbrk]]; we expect that its
argument is always a multiple of [[PAGE_SIZE]]:

%nouse
<<function prototypes>>=
void *u_sbrk (int incr);
@

\pagebreak

<<function implementations>>=
void *u_sbrk (int incr) {
  int pages = incr / PAGE_SIZE;
  address_space *aspace = &address_spaces[current_as];
  memaddress oldbrk = aspace->memend;
    
  for (int i = 0;  i < pages;  i++) {
    int frame = request_new_frame ();
    if (frame == -1) { return (void*)(-1); } // error!
    as_map_page_to_frame (current_as, aspace->memend/PAGE_SIZE, frame);
    aspace->memend += PAGE_SIZE;
  }
  return (void*) oldbrk;  
}
@ %def u_sbrk

\label{please-come-from-syscall-chapter}%
Next we need to provide a system call for the [[u_sbrk]] function so
that a process can call this function. So far, you have not seen how 
\UlixI{} implements system calls (we will show this in 
Chapter~\ref{chap:ulix:syscall}), so you might want to skip the 
following description and turn back to it when you reach the
system call chapter. We've also put a reminder into that section.

As a brief summary, system calls are functions whose start addresses we enter in a syscall table. A process can make a system call by loading a syscall number (which serves as an index into that table) into the \register{EAX} register, storing arguments for the syscall in further registers (\register{EBX}, \register{ECX}, \dots) and then executing the [[int 0x80]] assembler\index{Assembler language!int 0x80 instruction@\texttt{int 0x80} instruction}\tindex{int 0x80} instruction. Filling a syscall table entry is handled by the function [[install_syscall_handler]].

The system call number [[__NR_brk]] is defined as 45. There is no [[sbrk]] system call since normally the [[sbrk]] function is implemented by calling a similar [[brk]] function. But we only implement [[u_sbrk]] and reuse the [[brk]] system call number.

%nouse
<<syscall prototypes>>=
void syscall_sbrk (context_t *r);
@

%nouse
<<code for [[syscall_sbrk]]>>=
void syscall_sbrk (context_t *r) {
  // ebx: increment
  r->eax = (memaddress)u_sbrk (r->ebx);
  return;
}
@

<<initialize syscalls>>=
install_syscall_handler (__NR_brk, syscall_sbrk);
@

This is the first of many appearances of a code pattern: Most system call handlers set [[r->eax]] in order to provide a return value and then leave the function with [[r->eax]]. To simplify our code we will provide a macro [[eax_return]]\index{eax\_return macro@\texttt{eax\_return} macro}\index{system call!passing the return value via EAX} which combines these two activities and also performs the type cast to an unsigned integer:

<<macro definitions>>=
#define eax_return(retval) { r->eax = (unsigned int)((retval)); return; }
@ %def eax_return

With this macro we can rewrite [[syscall_sbrk]] like this:

<<syscall functions>>=
void syscall_sbrk (context_t *r) {
  // ebx: increment
  eax_return ( u_sbrk (r->ebx) );
}
@ %def syscall_sbrk

We also provide a user mode library function [[sbrk]] so that you can simply call [[sbrk]] in an application program (instead of manually inserting the necessary code for the system call). Again, this will become clear once you reach the description of our system call interface---which is only a few pages away. We only display the necessary code without further explanation:

%nodef
<<ulixlib function prototypes>>=
void *sbrk (int incr);
@

<<ulixlib function implementations>>=
void *sbrk (int incr) { return (void*)syscall2 (__NR_brk, incr); }
@ %def sbrk


\section{Thread Control Blocks and Thread Queues}
\label{sec:processes:TCBs}%

\felix

The \emph{\vindex{thread control block}}\index{TCB|see {thread control block}}
(TCB)\marginnote{TCB} is the 
central place in the kernel where information
about a thread is held. In the times when people used to speak about
processes instead of threads, the TCB was called the 
PCB\marginnote{PCB}\pindex{PCB (process control block)} which stands for 
\emph{\vindex{process control block}}. 

One main purpose of the TCB is to store the \emph{processor state} of
a thread (sometimes also called \emph{context}\index{context}) during the times when
it is not assigned to a physical processor. 
Note that the processor state is not the same as the thread state. As 
you will see soon, the state of a thread can be
[[running]], [[blocked]] etc. The processor state is all information
that is necessary to pretend that the processor has never executed any
other thread as the one to which the TCB belongs.

\pagebreak 

The TCB contains (among other data) the following information:
%
\begin{itemize}
\item A unique identifier of the thread. This is the so-called
  \emph{\vindex{thread identifier}} (TID)
  \marginnote{Thread ID}\pindex{TID (thread identifier)}. In previous 
  times, the TID was often called
  PID\marginnote{Process ID}\pindex{PID (process identifier)} for 
  \emph{\vindex{process identifier}}.
  We also keep a PID entry in the TCB, it will be needed when we
  introduce threads as part of a process.

\item Storage space to save the processor context, i.\,e., the
  registers, the stack pointer(s), etc.

\item Depending on the thread state, the TCB contains an indication
  on what event the thread is waiting for if it is in state [[blocked]].

\item Information about the memory that this thread is using---we have
  already defined address spaces, and we will store an address space
  ID in the TCB.

\item Any other information which may be useful to keep the system
  running efficiently. For example, statistical information could be
  stored here on how often the thread has been running in the past.
  This could help the scheduler make efficient scheduling decisions.
\end{itemize}

Note that the information about the address space must be handled
differently in PCBs and in TCBs. In a system where multiple threads
can run within one address space, there is an $n:1$ mapping between
threads and address spaces. In a classical Unix system with processes
(one address space with exactly one thread), the mapping is $1:1$ and
each thread can store the full address space information in the PCB
itself. With an $n:1$ mapping, an extra data structure is necessary
to avoid having redundant information in the TCBs.

So here is the declaration of the TCB structure. We have entries for
the thread ID [[tid]], \black the process ID [[pid]], a parent 
process ID [[ppid]] (so we can build a process tree), \felix the 
processor context (of type [[context_t]]) consisting of the
general purpose registers and the special purpose registers and a 
reference to the address space in which the thread runs \black (which 
we already added to the data structure when we discussed address 
spaces). We also reserve place for three memory addresses which hold
the instruction pointer, stack pointer and base pointer contents). 
\felix More entries will follow later.

\black

<<public type definitions>>=
typedef struct {
  thread_id  pid;         // process id
  thread_id  tid;         // thread id
  thread_id  ppid;        // parent process
  int        state;       // state of the process
  context_t  regs;        // context
  memaddress esp0;        // kernel stack pointer
  memaddress eip;         // program counter
  memaddress ebp;         // base pointer
  <<more TCB entries>>
} TCB;
@ %def TCB

\pagebreak
\felix

The TCBs of all threads are collected in a large table within the
kernel. This table is called the \emph{\vindex{thread table}}\marginnote{Thread Table}.  Again,
in ancient times when the table was a collection of PCBs instead of
TCBs, it was called \emph{\vindex{process table}}\marginnote{Process Table}.

The thread table is simply an array of [[TCB]]s. The size of the
table must be finite, so there exists a \vindex{maximum number of threads}
which can coexist at any point in time. 

<<constants>>=
#define MAX_THREADS 1024
@ %def MAX_THREADS

<<global variables>>=
TCB thread_table[MAX_THREADS];
@ %def thread_table

We define the maximum number of threads here. It should somehow
correspond to the maximum number of address spaces [[MAX_ADDR_SPACES]]
defined earlier in Section~\ref{sec:processes:address spaces}. For
example, it doesn't make sense to allow more address spaces than
threads (since every thread can have at most one address space).
\black
We have set both values to 1024 which would let \UlixI{} run 1023
processes, each of which has its individual address space. The
number 0 is reserved---both in the address space table (where it
refers to the kernel address space) and in the thread table
(because we use that entry for a different purpose related to
the scheduler).

\felix


\subsection{Thread State}
\label{sec:thread:state}

\black
For each thread, the TCB contains a [[state]] field. We will define the possible
values which this field can hold later (p.~\pageref{definition of thread states}),
but here we already give an overview of the what can theoretically happen to a 
thread.
\felix


\subsubsection{Simple State Model for Threads}
\label{sec:simple:state:model}

Threads have a lifecycle. They are born, live and finally die. During
their life they undergo many changes. For example, they sometimes are
executed by a physical processor and sometimes not. This is what is
called the \emph{\vindex{thread state}}\marginnote{Thread State} or simply
\emph{\vindex{state}}. The number and type of states together with the
transitions which a thread can experience during its lifetime is
called a \emph{state model}\marginnote{State Model}.

The simplest state model which can be found in almost every textbook
on operating systems consists of three states: [[running]],
[[ready]] and [[blocked]]. Here's what these states mean:
%
\begin{itemize}

\item A thread in state [[running]] is actually executing on a
  physical processor. If there is more than one processor in the
  system, more than one thread can be in this state.

\item A thread in state [[ready]]\index{ready (thread state)} is not currently assigned to a
  physical processor, but it \emph{could} be assigned. In other words,
  the thread is ready to run in case a physical processor
  becomes free. Many threads can be in this state at the same time;
  they are kept within a list called the 
  \emph{\vindex{ready queue}}\marginnote{Ready Queue}.

\item A thread in state [[blocked]]\index{blocked (thread state)} is waiting for a certain
  event. Only after this event has happened, it can become [[running]]
  or [[ready]] again. There can be many different events for which a
  thread can wait. For example, a thread could be waiting for a page
  fault to be serviced, i.\,e., waiting for an I/O operating to
  terminate. Another example is that a thread is waiting for a
  synchronization operation to be executed by another thread (see
  Chapter~\ref{chap:synchronization}). 

  Usually an indication of the event for which the thread is waiting
  is part of the [[blocked]] state. This can be interpreted as many
  different [[blocked]] states. For simplicity, most textbooks
  therefore reduce these states to just one. Many threads can be
  in a blocked state at the same time. They are kept internally within
  one (or more) \emph{blocked queues}\pindex{blocked queue}\marginnote{Blocked Queue}.

\end{itemize}
%
We will use this state model in \Ulix{}.


\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{pics/simple-thread-state-model.pdf}
  \caption{States and state transitions in the simple state model for threads.}
  \label{fig:simple:state:model}
\end{figure}


The possible transitions between thread states are depicted in
Figure~\ref{fig:simple:state:model}. We enumerate and explain them
here now:
%
\begin{itemize}

\item [[add]]: a new thread is dynamically created and enters the set
  of threads in the state [[ready]].

\item [[assign]]: a new thread from state [[ready]] is assigned to 
  the processor and becomes [[running]].

\item [[block]]: a running thread invokes a blocking system operation
  (e.\,g., I/O), runs into a page fault or must wait for some other
  event to continue operation. Now a new thread can become
  [[running]]. (Note the difference between the thread state [[blocked]]
  and the state transition [[block]].)

\item [[deblock]]: the event for which a [[blocked]] thread is waiting
  has happened. Consequently, the [[blocked]] thread is transferred to
  the state [[ready]]. (Sometimes this transition is also called
  [[ready]], but since this can be confused with the thread state
  [[ready]] we prefer to call it \verb#deblock#.)

\item [[resign]]: the thread which is currently [[running]] has
  finished executing parts of its program and leaves the physical
  processor. It transits from state [[running]] back into state
  [[ready]]. Now a new thread can become [[running]].

\item [[retire]]: a currently [[running]] thread has finished
  executing its program code and terminates its lifetime.

\end{itemize}
%
Not all possible transitions from one state to the other exist in the
state model because a reduced state model decreases the complexity of
the implementation. For example it is rather uncommon to transit from
[[blocked]] directly to [[running]]. Similarly, a newly created thread
must be [[ready]] first before it may become [[running]].

The transitions of a thread from one state to the other are initiated
by the operating system and happen ``instantaneously''. Since a state
change needs many machine instructions, real
instantaneousness\pindex{instantaneousness (difficult word)} cannot be
achieved, so the operating system simulates atomic transitions using
synchronization operations in the kernel (see
Chapter~\ref{chap:synchronization}). In essence, the atomic\index{atomic}
transitions are implemented in such ``atomic'' kernel functions which
carry the same name as the state transitions (e.\,g., [[assign]],
[[resign]], etc.). The place in the kernel where all these functions
are collected is called the \emph{\vindex{dispatcher}}.

Here are the forward declarations of the dispatcher functions. 
They will be implemented on the following pages. Note that the
dispatcher operation [[block]] takes an indication to the event on
which the thread is blocking. This indication is encoded in the
particular blocked queue to which the thread should be added. The data
type of [[blocked_queue]] will be explained below.

<<public elementary type definitions>>=
typedef unsigned int thread_id;
@ %def thread_id

<<type definitions>>=
<<declaration of blocked queue>>
@

%nouse
<<function prototypes>>=
void add     (thread_id t);
void block   (blocked_queue *q, int new_state); 
void deblock (thread_id t, blocked_queue *q);
void retire  (thread_id t);
@

\black
(Instead of a \verb#resign# function we will later provide a code chunk [[<<resign>>]]. Assigning happens only inside the scheduler, so we do not implement a specific function for this activity.)

\felix

\subsubsection{Thread States with Swapping}

In case of shortage of memory it may make sense to completely ``swap
out'' a process with all its threads and virtual memory to external
storage. In this case it is necessary to define an additional thread 
state [[swapped]]\index{swapped out (thread state)}, \black which
also leads to a more complex set of state transitions since both a ready
or blocked thread might be swapped out; depending on the implementation
even an active process may ask for being swapped out. The system must
remember the last state and restore it when it swaps the process
back in (see Figure~\ref{fig:state:diagram:swapping}). \UlixI{} does not
implement swapping since it uses the more advanced paging model.
\felix

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{pics/state-diagram-swapping.pdf}
  \caption[Thread states and transitions for a system with swapping.]{Thread states and state transitions for a system that swaps processes out and back in.}
\label{fig:state:diagram:swapping}
\end{figure}


\subsubsection{Thread Queues}
\label{sec:thread:queues}

The operating system has to perform bookkeeping of the state of
threads. This can be done in several ways. One approach would be to
store an entry [[state]] of an enumeration type in the TCB that can
have the values [[blocked]], [[ready]] or [[running]].  This is viable
but not actually necessary. In modern operating systems the thread
state is stored implicitly through the collection of linked
lists\pindex{linked list}. These lists contain threads and function as
queues. The \emph{\vindex{ready queue}}\marginnote{Ready Queue} for 
example is a list of threads which all are in state [[ready]].

As global data structures we therefore need a couple of global
variables:
%
\begin{itemize}

\item For every CPU in the system we need a reference to the thread
  that is currently assigned to the processor. For monoprocessor
  systems (like those that \UlixI{} supports) it is sufficient to 
  provide a global variable [[current_task]] of type [[thread_id]]. 
  For multiprocessor systems we would have to provide such a variable 
  for every CPU in the system.

\item A \emph{\vindex{ready queue}} enumerating all threads that are
  in state [[ready]].

\item For every separate class of events which can cause a thread to
  go into state [[blocked]], we need a \emph{\vindex{blocked queue}}
  enumerating all threads that wait for such an event.

\item In case we have a system with swapping, another list is
  necessary holding all swapped out threads. This is called the
  \emph{\vindex{swapped out queue}}.

\end{itemize}


\black
\subsubsection{Thread States in the \UlixI{} Implementation}

\UlixI{} does not support swapping but writes out individual pages to disk, so we will not need a \emph{swapped}\index{swapped out (thread state)} state. However, we will use several separate states to indicate a specific \emph{blocked}\index{blocked (thread state)} state. (As we described above, we \emph{could} use queue membership to indicate the specific blocked state, but using several states lets us access the state more quickly.)
The following code chunk lists all the possible states that a process (or thread) can be in:

\label{definition of thread states}
%nouse
<<public constants>>=
// Thread states
#define TSTATE_READY     1   // process is ready
#define TSTATE_FORK      3   // fork() has not completed
#define TSTATE_EXIT      4   // process has called exit()
#define TSTATE_WAITFOR   5   // process has called waitpid()
#define TSTATE_ZOMBIE    6   // wait for parent to retrieve exit value
#define TSTATE_WAITKEY   7   // wait for key press event
#define TSTATE_WAITFLP   8   // wait for floppy
#define TSTATE_LOCKED    9   // wait for lock
#define TSTATE_STOPPED  10   // stopped by SIGSTOP signal
#define TSTATE_WAITHD   11   // wait for hard disk
@ %def TSTATE_READY TSTATE_FORK TSTATE_EXIT TSTATE_WAITFOR TSTATE_ZOMBIE TSTATE_WAITKEY TSTATE_WAITFLP TSTATE_LOCKED TSTATE_STOPPED TSTATE_WAITHD

We also define a list of state names which can be used when displaying
the process list:
<<global variables>>=
char *state_names[12] = {
  "---",   "READY", "---",   "FORK", "EXIT", "WAIT4", "ZOMBY", "W_KEY",   // 0.. 7
  "W_FLP", "W_LCK", "STOPD", "W_IDE"                                      // 8..11
};
@ %def state_names

Figure~\ref{fig:state:diagram:ulix} shows the state transitions in \UlixI{}. The various [[TSTATE_*]] states are shown as a single state in order to simplify the picture.

\begin{figure}
  %\centering
  \hspace{-2mm}%
  \includegraphics[width=1.235\textwidth]{pics/state-diagram-ulixprocess.pdf}
  \caption{Process states and state transitions as implemented by \UlixI{}.}
\label{fig:state:diagram:ulix}
\end{figure}


\felix
\subsection{Implementing Lists of Threads}
\label{sec:implementing:lists:of:threads}

Queues are standard data structures offered by almost all modern
programming languages. As an example, Java provides the generic class
[[ArrayList<E>]] in which objects of any type [[E]] can be stored and
manipulated with standard operations like [[add()]], [[size()]] and
[[get()]]. Unfortunately, ``plain'' C does not offer this convenience
so we have to implement queues by ourselves.

As explained in Section~\ref{sec:thread:queues}, we have to maintain a
couple of thread queues within the kernel. In \Ulix{} we maintain
only two: the \vindex{ready queue} and the \vindex{blocked queue}.
In fact, the blocked queue is not a single queue but there can
be multiple blocked queues, one for every event upon which a thread
can wait. 

When implementing such queues, we could think about using the standard
implementation of a (double) linked list found in any introductory
textbook on programming. However these implementations usually are
examples of programming with dynamic memory allocation, e.\,g., in C
using the [[malloc]] library call to allocate fresh memory on the
heap. This would be a problem in \Ulix{} since we neither have a
heap nor a library to call into.

So how can we program linked lists without allocating memory?  The
first option is to do it like Knuth\pindex{Knuth, Donald E.} did it in
\TeX{}\pcindex{TeX}{\TeX{}} \cite{Knuth:1986:TTP} and provide both a
large memory area plus functions for memory allocation and
deallocation by ourselves.  Since this would be overkill, we choose
the second option, which is also the option taken in many operating
systems: We use the thread table to implement lists. The idea is to
declare two additional entries in the \vindex{thread control block}:
one entry called [[next]] and one called [[prev]]. Both point to other
entries in the thread table. So consider a thread control block [[TCB t]]. 
The entry [[t.next]] points to the ``next'' thread in the queue
that [[t]] belongs to. Similarly, [[t.prev]] points to the ``previous''
thread in [[t]]'s queue. 

We define the range of these two pointers to be [[thread_id]]. 

<<more TCB entries>>=
thread_id next;       // id of the ``next'' thread
thread_id prev;       // id of the ``previous'' thread
@ %
An example of the semantics of the [[prev]] and [[next]] entries in
the thread table is shown in
Figure~\ref{fig:ready:queue:implementation}. It shows that the thread
identifier 0 is used as an ``end marker'' for the lists. It also shows
that the [[prev]] entry of the first entry in the queue points to the
last element in the queue. In this way, it is easily possible to
navigate through the queues in any way which is convenient. 

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{pics/ready-queue-implementation.pdf}
  \caption[Implementation of ready queue and blocked queues.]{Implementation 
    of ready queue and blocked queues. The
    beginning of the ready queue is implicitly defined by entry 0 in
    the thread table. The beginning of a blocked queue is a pair of
    thread identifiers pointing into the thread table from ``outside''.}
  \label{fig:ready:queue:implementation}
\end{figure}

Figure~\ref{fig:ready:queue:implementation} also shows a small
implementation trick. The \vindex{thread identifier} of the
thread itself is always equal to the index of the thread in the
\vindex{thread table}. Given a TID\pindex{TID (thread identifier)} of
[[t]], then [[thread_table[t]]] is the thread control block of that
thread. This also means that the entry [[tid]] in the \vindex{thread
  control block} is more or less superfluous.

Now since we are using the value 0 to mark the end of a list, the
entry 0 in the thread table has become more or less useless to store
thread information. We use it instead as the ``anchor'' of the
\vindex{ready queue}. So to access the first element in the ready queue,
we just need to look into: 
%
\begin{center}
  [[thread_table[0].next]]
\end{center}
%
The last entry in the ready queue can similarly be accessed using the
following expression:
%
\begin{center}
  [[thread_table[0].prev]]
\end{center}
%
The ready queue in the figure contains threads 1, 4 and 7 (in this
order).

Recalling the simple state model of threads in
Section~\ref{sec:simple:state:model}, every thread is in exactly one
state at any time. This means that a thread is either running, ready
or blocked. It also means that a thread can be in at most one queue
at a time. In case the thread is blocked instead of ready, we can
re-use the [[prev]] and [[next]] entries in the thread table
to implement the blocked list. We only need to have an anchor
for this blocked list. This anchor will be a structure similar to 
entry 0 in the thread table, \black but without all the extra fields. \felix

<<declaration of blocked queue>>=
typedef struct {
  thread_id next;       // id of the ``next'' thread
  thread_id prev;       // id of the ``previous'' thread
} blocked_queue;
@ %def blocked_queue
So assume [[b]] is a variable of type [[blocked_queue]] representing
a blocked list. If both entries in [[b]] are 0, then the list is
empty.  If not, then using the thread table we can now find the first,
second etc.~element by following the [[next]] pointers.  
This way, we can traverse the entire list until
we reach an entry in which [[next==0]]. That's the \vindex{end of the
  list}.  Looking again at
Figure~\ref{fig:ready:queue:implementation}, the blocked queue
contains threads 2, 5 and 6 (in this order).

Finally, here's a useful function to initialize a blocked queue:

%nouse
<<function prototypes>>=
void initialize_blocked_queue (blocked_queue *q);
@ This is just to encapsulate the semantics of ``emptiness''.

<<function implementations>>=
void initialize_blocked_queue (blocked_queue *q) { 
  q->prev = 0;
  q->next = 0; 
}
@ %def initialize_blocked_queue


\subsubsection{Dispatcher Operations as Critical Sections}

\index{critical section}%
\index{synchronization!critical section}%
Before we actually implement queue operations we need to make a slight forward reference to Chapter~\ref{chap:synchronization} on synchronization and introduce the notion of a critical section, at least intuitively.
Briefly spoken, a \emph{\vindex{critical section}} is a sequence of code that accesses shared resources. Such a section is critical, because (as is explained in Chapter~\ref{chap:synchronization}) concurrent accesses to a shared resource can wreak havoc with these resources, potentially making them unusable. The shared resources in question here are the shared kernel queues. What we need to ensure is that no two critical sections are executed concurrently. We refrain here from explaining how this can be achieved. What we however do at this point is to mark the beginning and end of the critical sections using the code chunk [[<<begin critical section in kernel>>]] and [[<<end critical section in kernel>>]] and leave the implementation to Chapter~\ref{chap:synchronization}.


\subsubsection{Implementing the Ready Queue}

\index{ready queue!implementation}%
We now provide some convenient functions to add and remove
threads from the queues. We start with the ready queue. The
function [[add_to_ready_queue(t)]] adds the thread with
identifier [[t]] to the \emph{end} of the ready queue. It assumes
that the TCB of thread [[t]] has been set up and initialized
already.

The function [[remove_from_ready_queue(t)]] removes the thread
with identifier [[t]] from the ready queue. It assumes that
[[t]] is contained in the ready queue.

%nouse
<<function prototypes>>=
void add_to_ready_queue (thread_id t);
void remove_from_ready_queue (thread_id t);
@
Adding to the end of the ready queue is as easy since
we have a double linked list.

<<function implementations>>=
void add_to_ready_queue (thread_id t) {
  <<begin critical section in kernel>>
  thread_id last = thread_table[0].prev;
  thread_table[0].prev = t;
  thread_table[t].next = 0;
  thread_table[t].prev = last;
  thread_table[last].next = t;
  thread_table[t].state = TSTATE_READY;  // set its state to ready
  <<end critical section in kernel>>
}
@ %def add_to_ready_queue
Removing is similarly easy.

<<function implementations>>=
void remove_from_ready_queue (thread_id t) {
  <<begin critical section in kernel>>
  thread_id prev_thread = thread_table[t].prev;
  thread_id next_thread = thread_table[t].next;
  thread_table[prev_thread].next = next_thread;
  thread_table[next_thread].prev = prev_thread;
  <<end critical section in kernel>>
}
@ %def remove_from_ready_queue

We initialize the ready queue to be empty.

<<initialize kernel global variables>>=
thread_table[0].prev = 0;
thread_table[0].next = 0;
@ \black Note that we cannot use our [[initialize_blocked_queue]] function.
Even though we access the same elements ([[prev]] and [[next]]), the 
structures do not match.


\felix
\subsubsection{Implementing a Blocked Queue}
\label{sec:blocked-queue-implementation}%
\index{blocked queue!implementation}

Blocked queues are implemented similar to the ready queue, except that
the functions are parameterized with a blocked list anchor defined
above. We provide again two functions to add and remove a thread from
a blocked list. Adding to the queue happens at the ``end'' of the
queue. An additional function allows to inspect the ``front'' queue
element.

%nouse
<<function prototypes>>=
void add_to_blocked_queue          (thread_id t, blocked_queue *bq);
void remove_from_blocked_queue     (thread_id t, blocked_queue *bq);
thread_id front_of_blocked_queue   (blocked_queue bq);
@ 

We implement the easy inspector function to retrieve the front of a
blocked queue first. It is so easy that we could have avoided writing
this function altogether, but we spell it
out for students who have learnt the concept of information hiding.

<<function implementations>>=
thread_id front_of_blocked_queue (blocked_queue bq) {
  return bq.next;
}
@ %def front_of_blocked_queue
We now implement [[add_to_blocked_queue]]. Adding happens
at the \emph{end} of the queue. The following code is an adaption
of the code for the ready queue. The conditional statement at
the end is necessary since [[thread_table[0]]] is not the
anchor of a blocked queue.

<<function implementations>>=
void add_to_blocked_queue (thread_id t, blocked_queue *bq) {
  <<begin critical section in kernel>>
  thread_id last = bq->prev;
  bq->prev = t;
  thread_table[t].next = 0;    // t is ``last'' thread
  thread_table[t].prev = last;
  if (last == 0) {
    bq->next = t;
  } else {
    thread_table[last].next = t;
  }
  <<end critical section in kernel>>
}
@ %def add_to_blocked_queue

Removal is similar to the function of the ready queue, except
for again the special cases at the end.

\pagebreak

<<function implementations>>=
void remove_from_blocked_queue (thread_id t, blocked_queue *bq) {
  <<begin critical section in kernel>>
  thread_id prev_thread = thread_table[t].prev;
  thread_id next_thread = thread_table[t].next;
  if (prev_thread == 0) {
    bq->next = next_thread;
  } else {
    thread_table[prev_thread].next = next_thread;
  }
  if (next_thread == 0) {
    bq->prev = prev_thread;
  } else {
    thread_table[next_thread].prev = prev_thread;
  }
  <<end critical section in kernel>>
}
@ %def remove_from_blocked_queue


\subsubsection{Simple Dispatcher Operations}

\index{dispatcher}%
We now look at the implementations of the three simplest dispatcher
operations. These are [[add]], [[retire]] and [[deblock]]. They
are simple because they basically only move threads from one
queue to the other.

The functions [[add]] and [[retire]] take as parameter the identifier
of the thread which is newly born or about to die. The function
[[deblock]] needs another argument: The blocked queue from which the
thread is to be removed. Note that [[add]] and [[retire]] do not need to be declared as critical sections, because the queue operation already is. [[deblock]] and later [[block]] however must be executed without interruption so that kernel data structures remain consistent (see Chapter~\ref{chap:synchronization}).

\enlargethispage{1cm}
%BREAK BEFORE DEFINES
<<function implementations>>=
void add (thread_id t) {
  add_to_ready_queue (t);
}

void retire (thread_id t) {
  remove_from_ready_queue (t);
}

void deblock (thread_id t, blocked_queue *q) {
  <<begin critical section in kernel>>
  remove_from_blocked_queue (t, q);
  add_to_ready_queue (t);
  thread_table[t].state = TSTATE_READY;
  <<end critical section in kernel>>
}
@ %def add retire deblock

For blocking the current thread we provide a function [[block]] which
takes two arguments: a blocked queue that the thread shall be moved
to and the new state (e.\,g. [[TSTATE_WAITHD]]):

<<function implementations>>=
void block (blocked_queue *q, int new_state) {
  if (current_task == 0) return;
  <<begin critical section in kernel>>
  debug_printf ("[%d.%d] blocking\n",             // REMOVE_DEBUGGING_CODE
    current_task, system_ticks);                  // REMOVE_DEBUGGING_CODE
  thread_table[current_task].state = new_state;
  remove_from_ready_queue (current_task);
  add_to_blocked_queue (current_task, q);
  <<end critical section in kernel>>
}
@ %def block



Note that with the above functions we can easily write code
that deblocks the ``front'' element from a blocked queue (if it
exists) as follows:
%
\begin{center}
  [[deblock (front_of_blocked_queue (bq), &bq);]]
\end{center}

\black


\subsection{Allocating and Initializing a New TCB}
\tcbindex{creation}%

Whenever we create a new thread or process, we will need a fresh TCB
entry and initialize it. We add a [[used]] entry to the thread control 
block structure [[TCB]]

<<more TCB entries>>=
boolean used;
@ which lets us declare an entry as used.
(Since we initialize the TCB structures with null bytes, we use
[[used]] and not [[free]]: remember that [[false]]=0.)

This will allow us to quickly find a free TCB when we create a new
thread. Instead of adding such a field, we could have used a bitmap,
but since we restrict ourselves to 1024 TCBs, not much space is
wasted this way, and searching for a free TCB will be quick.

We will remember in a global variable
<<global variables>>=
thread_id next_pid = 1;
@ %def next_pid
at which thread number we will start our search (instead of always
searching from 1): this will later lead to a continuous sequence of
process/thread numbers: even if we terminate a thread, its TCB
will not be recycled immediately. 

\pagebreak

<<find free TCB entry>>=
boolean tcbfound = false;
thread_id tcbid;
for (tcbid = next_pid;  ((tcbid<MAX_THREADS) && (!tcbfound));  tcbid++) {
  if (thread_table[tcbid].used == false) {
    tcbfound = true;
    break;   // leave for loop
  }
};
@ %
However, once we've reached the
maximum number (1023), the search for a free TCB will start over,
and from that point on thread numbers will no longer indicate the
order of creation of the threads. 

<<find free TCB entry>>=
if (!tcbfound) {                                  // continue searching at 1
  for (tcbid = 1;  ((tcbid<next_pid) && (!tcbfound));  tcbid++) {
    if (thread_table[tcbid].used == false) {
      tcbfound = true;
      break;   // leave for loop
    }
  };
};

if (tcbfound) next_pid = tcbid+1;                 // update next_pid:
// either tcbfound == false or tcbid == index of first free TCB
@

Once we have a free address space (or reuse one) and also have
a free TCB, we can connect them:

<<function prototypes>>=
int register_new_tcb (addr_space_id as_id);
@ %
This function searches for a free TCB, marks it as used and enters
the address space ID which we provide as an argument. Thus, whenever
we create a new thread, we always call [[create_new_address_space]]
first and [[register_new_tcb]] afterwards:

<<function implementations>>=
int register_new_tcb (addr_space_id as_id) {
  // called by u_fork()
  <<find free TCB entry>>
  if (!tcbfound)  return -1;               // no free TCB!
  thread_table[tcbid].used       = true;   // mark as used
  thread_table[tcbid].addr_space = as_id;  // enter address space ID
  return tcbid;
}  
@ %def register_new_tcb

Note that so far we have not entered the new TCB in the ready or
one of the blocked queues. This will happen later when the thread
has been fully initialized.


\black
\section{Starting the First Process}
\label{sec:processes:start the first}%

Starting the first (\verb#init#) process\marginnote{\texttt{init} process}\index{init process@\texttt{init} process} 
is different from how all further
processes are created: We have to manually set up the memory regions
and data structures and load a first program from the disk. Of course,
this requires filesystem support which we will implement later---for
now assume that the kernel can use filesystem functions similar to
the standard Unix functions \verb#open#, \verb#read# and \verb#close#.

Once the \verb#init# process is running, all further processes
will be created using [[fork]] (see Section \ref{sec:processes:fork}). 
This is what we need to do:

\begin{itemize}\itemsep-1pt
\item Setup the TCB (thread control block) list and mark the first TCB as used.
\item Create a new address space and reserve memory for user mode (low addresses, with user access).
\item Load the process binary from disk into the new address space.
\item Reserve memory for the process' kernel stack (low addresses, without user access).
\item Enter all the information in the new TCB.
\item Update a data structure called TSS\marginnote{TSS} (Task State Segment, see Section~\ref{sec:tss}).
\item Switch from kernel mode (ring 0) to user mode (ring 3) and start executing the process' code.
\end{itemize}

<<function implementations>>=
void start_program_from_disk (char *progname) {
  <<start program from disk: prepare address space and TCB entry>>
  <<start program from disk: load binary>>
  <<start program from disk: create kernel stack>>
  <<start program from disk: set uid, gid, euid, egid>>
  <<start program from disk: activate the new process>>
};
@ %def start_program_from_disk
%
As you can see, the start routine is rather complex. We discuss the necessary tasks step by step in the following sections, with one exception: The code chunk [[<<start program from disk: set uid, gid, euid, egid>>]] will be explained much later when we discuss user and group management.


\subsection{Preparations}

\tcbindex{for the first process}%
We start with registering a new thread control block and fresh address space and entering useful data. The following code chunk contains a few instructions that will not make much sense to you right now since they deal with kernel components you have not seen yet. For example, it sets the TCB element [[cwd]] (current working directory) to \verb#"/"# and the file descriptors 0, 1 and 2 to standard input, standard output and standard error output---all of that will be discussed in Chapter~\ref{chap:ulix:fs} where we introduce the \UlixI{} filesystem.

It is important that we activate the new process' address space at this step, because right after that we will load the program binary of the \verb#init# program into the lower memory of the process, and that would be unavailable in the kernel's address space.

<<start program from disk: prepare address space and TCB entry>>=
// create new address space (64 KB + 4 KB stack) and register TCB entry
addr_space_id as   = create_new_address_space (64*1024, 4096);
thread_id     tid  = register_new_tcb (as);     // get a fresh TCB
TCB           *tcb = &thread_table[tid];

// fill TCB structure
tcb->tid = tcb->pid = tid;                      // identical thread/process ID
tcb->ppid = 0;                                  // parent: 0 (none)
tcb->terminal = 0;                              // default terminal: 0
memcpy (tcb->cwd,     "/",   2);                // set current directory
memcpy (tcb->cmdline, "new", 4);                // set temporary command line
thread_table[tid].files[0] = DEV_STDIN;         // initialize standard I/O
thread_table[tid].files[1] = DEV_STDOUT;        // file descriptors
thread_table[tid].files[2] = DEV_STDERR;
for (int i = 3;  i < MAX_PFD;  i++) tcb->files[i] = -1;
activate_address_space (as);                    // activate the new address space
@


\subsection{Loading the Program}

Loading the \verb#init# program is simple because we do not use a special file format for the file, but instead link it into a ``flat binary'', similar to the historical \verb#.COM# files that MS-DOS\index{MS-DOS operating system} and CP/M\index{CP/M operating system} used \cite[p.~171--175, 182--189]{pat1996freedos}. The loader assumes that the filesize is less than 32~KByte and simply reads the whole file (or its first 32~KByte) into the virtual memory location that starts at [[BINARY_LOAD_ADDRESS]]. We have set that constant to \hex{0} in Section~\ref{sec:processes:memory layout}.

<<constants>>=
#define PROGSIZE 32768
@ %def PROGSIZE

For reading the file it uses the \UlixI{} virtual filesystem functions [[u_open]], [[u_read]] and [[u_close]] which act like the well-known POSIX functions \verb#open#, \verb#read# and \verb#close#.

<<start program from disk: load binary>>=
int fd = u_open (progname, O_RDONLY, 0);            // open_ the file
u_read (fd, (char*)BINARY_LOAD_ADDRESS, PROGSIZE);  // load to virtual address 0
u_close (fd);                                       // close_ the file
@

The function [[start_program_from_disk]] is called with the argument [["/init"]]\marginnote{[[/init]]}, so we need an \verb#init# binary in the root directory of the root disk. That program does not do much, but only starts the \verb#login# program via the [[execv]] function.

\label{source code for init.c}%
<<lib-build/init.c>>=
#include "ulixlib.h"
void umain() {
  char *args[] = { "/bin/login", 0 };
  execv (args[0], args); 
  printf ("exec failed\n"); for (;;);
}
@ %def umain

For compiling this flat binary, we need a special linker configuration file\index{linker configuration file} that lets the GNU linker [[ld]] create such a format:

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
%nouse
<<lib-build/process.ld>>=
OUTPUT_FORMAT("binary")
phys = 0x00000000;
virt = 0x00000000;
SECTIONS {
  . = phys;
  
  .setup : AT(phys) {
    *(.setup)
  }

  .text : AT(code - virt) {
    code = .;
    *(.text)
    *(.rodata*)
    . = ALIGN(4096);
  }

  .data : AT(data - virt) {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }

  .bss : AT(bss - virt) {
    bss = .;
    *(COMMON*)
    *(.bss*)
    . = ALIGN(4096);
  }
  end = .;
}
@
\end{multicols}

In the makefile for the user mode files (\path!lib-tools/Makefile!) the \verb#init# program will later be compiled and linked with

\begin{Verbatim}
compile:
        $(CC) $(CCOPTIONS) -g -c ulixlib.c
        $(CC) $(CCOPTIONS) -c init.c
        # link it with linker script "process.ld"
        $(LD) $(LDOPTIONS) -T process.ld -o init init.o ulixlib.o
\end{Verbatim}


\subsection{Creating the Kernel Stack}

\index{kernel mode stack!creation for first process}
Next we need to provide a kernel stack for the process. So far, \UlixI{} has used the initial kernel stack defined as [[_sys_stack]] in the assembler file \path!start.asm!, but as we explained earlier, we need a separate kernel stack for every process (or thread).

We have already defined the number of kernel stack pages, [[KERNEL_STACK_PAGES]], so now we simply register as many frames and write a mapping into the page table via [[as_map_page_to_frame]].

<<start program from disk: create kernel stack>>=
unsigned int framenos[KERNEL_STACK_PAGES];        // frame numbers of kernel stack 
for (int i = 0;  i < KERNEL_STACK_PAGES;  i++) {  // pages
  framenos[i] = request_new_frame ();
  as_map_page_to_frame (current_as, 0xbffff - i, framenos[i]);
}
@

After that we need to store the information about the process kernel stack into two TCB fields [[esp0]] and [[ebp]].

<<start program from disk: create kernel stack>>=
char *kstack = (char*) (TOP_OF_KERNEL_MODE_STACK-KERNEL_STACK_SIZE);
memaddress adr = (memaddress)kstack;             // one page for kernel stack
  
tcb->esp0 = (uint)kstack + KERNEL_STACK_SIZE;    // initialize top-of-stack and
tcb->ebp  = (uint)kstack + KERNEL_STACK_SIZE;    // ebp (base pointer) values
@


\subsection{Activating the New Process}

Finally we can activate the process. We've completed all the required steps, and the program sits in the memory, waiting to be started. Let's declare the varible [[current_task]] (that always holds the ID of the currently executing process or thread)

<<global variables>>=
thread_id current_task;
@ %def current_task
%
and initialize it. We also add the \verb#init# process to the ready queue and enable the scheduler. Then the last step is switching to user mode.

<<start program from disk: activate the new process>>=
current_task = tid;                         // make this the current task  
add_to_ready_queue (tid);                   // add process to ready queue
<<enable scheduler>>
cpu_usermode (BINARY_LOAD_ADDRESS, 
              TOP_OF_USER_MODE_STACK);      // jump to user mode
@

The [[cpu_usermode]] function will be written in Assembler, we discuss it in detail in the following section.


\subsection{Configuring the TSS Structure and Entering User Mode}
\label{sec:tss}%

\index{user mode!switching to}%
The Intel processor provides no command that would let us switch
to user mode explicitly, but there is a way for \emph{returning
to user mode} which requires that the stack is set up properly
when executing an [[iret]]\marginnote{[[iret]]}\tindex{iret} instruction. That is what normally
happens when, for example, a process already runs in user mode
and an interrupt forces a jump to the interrupt handler---the
CPU modifies the stack so that when the handler executes [[iret]],
execution will continue in the process. To make the system switch
back to ring 3, the stack contains (besides other values) values
which will be loaded into the [[CS]] and [[SS]] segment registers
(which tell the CPU what segments to use for code and stack).

The segment registers always contain a value which is a multiple 
of 8, making them an offset for the GDT whose entries are eight
bytes long. Thus, the three lowest bits of a segment register
value are always 0. What we have not mentioned yet is that the
CPU modifies the lowest two bits when it pushes the register
value on the stack (on interrupt entry), and it reads them when 
it pops the registers back from the stack (during [[iret]]).
These two bits are then interpreted as the privilege level to
which the CPU shall switch (see Figure~\ref{fig:segment selector}).

\begin{figure}[bh]
  \centering
  \includegraphics[width=0.8\textwidth]{pics/segment-selector.pdf}
  \caption[Layout of a segment selector]{The Segment selector contains an index, a table indicator and the requested privilege level.}
  \label{fig:segment selector}
\end{figure}

We can now force the system into user mode by generating a stack
\index{stack!required layout for starting the first process}%
which looks just like the one that the CPU automatically generates
when an interrupt occurs. Where the segment register contents
are expected we push a value that we can calculate with
[[val = seg | 3;]] (which will set the lowest two bits; 3 = \bin{11}).

However, we cannot use the segment descriptors which we have
created during the system initialization: both the code and the
data segment descriptors\index{segment descriptor} have the entry [[flags]] (which contains a
two-bit value \emph{descriptor privilege level} (DPL\index{DPL (descriptor privilege level)}\index{descriptor privilege level}\marginnote{DPL}), describing
the necessary level for accessing this segment) set to 0---the
system would halt, because it would switch to user mode but would
not be allowed to use the memory. So we need two new segment
descriptors which are designed specifically for user mode. They
are identical to the old descriptors except for the [[flags]]
entry where they have the DPL value set to 3 instead of 0.

\label{fill kernel segment descriptors part 2}
So here's how we fill the descriptors:\index{GDT (global descriptor table)}

\pagebreak
\index{data segment (user mode)}%
\index{code segment (user mode)}%
\index{segmentation!data segment (user mode)}%
\index{segmentation!code segment (user mode)}%
\index{GDT (global descriptor table)!code segment (user mode) entry}%
\index{GDT (global descriptor table)!data segment (user mode) entry}%
\index{user mode!GDT entries}%
<<install GDTs for User Mode>>=
fill_gdt_entry (3, 0, 0xFFFFFFFF, 0b11111010, 0b1100);
fill_gdt_entry (4, 0, 0xFFFFFFFF, 0b11110010, 0b1100);
@ The numbering continues with 3 since we've already filled the null 
descriptor (0) and the kernel mode code (1) and data (2) segment
descriptors (see page \pageref{fill kernel segment descriptors}).

For a better overview, we repeat the explanation of the old (kernel mode) GDT entries and add the two new entries:

\begin{itemize}
\item \bin{10011010} for the kernel code segment \\
  (present; ring 0; fixed-1; executable; exact privilege level; allow reading;
  not accessed)
\item \bin{10010010} for the kernel data segment \\
  (present; ring 0; fixed-1; not executable; grow upwards; allow writing; not accessed)

\item \bin{1\red 11\black 11010} for the user mode code segment \\
  (present; \red ring 3\black{}; fixed-1; executable; exact privilege level; allow reading;
  not accessed)
\item \bin{1\red 11\black 10010} for the user mode data segment \\
  (present; \red ring 3\black{}; fixed-1; not executable; grow upwards; allow writing; not accessed)
\end{itemize}

In order to enter user mode we also have to create a structure
called \marginnote{TSS}\index{TSS (task state segment)}\emph{TSS} (\emph{task state segment})\index{task state segment} which is another (and 
final) entry in the GDT; we must load its GDT offset in a special
\emph{task register} (\register{TR})\index{TR register}\index{register!TR}\index{TSS (task state segment)!ltr@\texttt{ltr}}\index{task state segment!ltr@\texttt{ltr}}\marginnote{TR, [[ltr]]} using the [[ltr]]\tindex{ltr} instruction.

\intelindex{TSS (task state segment)}%
The TSS is a 104 bytes long data structure \cite[p. 303]{intel-part3},
shown in Figure~\ref{fig:tss}. The CPU designers had intended that 
operating system developers would supply such a structure for each
task (process or thread), and it is possible to simplify the task
switch by following this suggestion. However, we decided to ignore
this possibility and do the task switch without the help of the CPU
because that is more instructional.

\begin{figure}[b!]
\begin{centering}
\begin{bytefield}[bitwidth=3.8mm,bitheight=5.5mm,boxformatting={\centering\tt},endianness=big]{32}
\bitheader{0-31} \\
\bitbox{16}{\normalfont I/O Map Base Address}\bitbox{15}{\normalfont (reserved)}\bitbox{1}{T}
\,\, {\footnotesize 100} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{\normalfont LDT Segment Selector} \,\, {\footnotesize 96} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{GS} \,\, {\footnotesize 92} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{FS} \,\, {\footnotesize 88} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{DS} \,\, {\footnotesize 84} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{SS} \,\, {\footnotesize 80} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{CS} \,\, {\footnotesize 76} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{ES} \,\, {\footnotesize 72} \\
\bitbox{32}{EDI} \,\, {\footnotesize 68} \\
\bitbox{32}{ESI} \,\, {\footnotesize 64} \\
\bitbox{32}{EBP} \,\, {\footnotesize 60} \\
\bitbox{32}{ESP} \,\, {\footnotesize 56} \\
\bitbox{32}{EBX} \,\, {\footnotesize 52} \\
\bitbox{32}{EDX} \,\, {\footnotesize 48} \\
\bitbox{32}{ECX} \,\, {\footnotesize 44} \\
\bitbox{32}{EAX} \,\, {\footnotesize 40} \\
\bitbox{32}{EFLAGS} \,\, {\footnotesize 36} \\
\bitbox{32}{EIP} \,\, {\footnotesize 32} \\
\bitbox{32}{CR3 (PDBR)} \,\, {\footnotesize 28} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{SS2} \,\, {\footnotesize 24} \\
\bitbox{32}{ESP2} \,\, {\footnotesize 20} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{SS1} \,\, {\footnotesize 16} \\
\bitbox{32}{ESP1} \,\, {\footnotesize 12} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{SS0} \,\, {\footnotesize 8} \\
\bitbox{32}{ESP0} \,\, {\footnotesize 4} \\
\bitbox{16}{\normalfont (reserved)}\bitbox{16}{\normalfont Previous Task Link} \,\, {\footnotesize 0} \\[-4mm]
\end{bytefield}
\caption{The TSS (Task State Segment) structure.}
\label{fig:tss}
\end{centering}
\end{figure}

In our TSS type definition we only mention the elements which we may need and combine less interesting areas of the structure in [[long long]] elements ([[u1]], [[u2]], [[u3]]):

<<type definitions>>=
typedef struct {
  unsigned int prev_tss    : 32;  // unused: previous TSS
  unsigned int esp0, ss0   : 32;  // ESP and SS to load when we switch to ring 0
  long long u1, u2         : 64;  // unused: esp1, ss1, esp2, ss2 for rings 1 and 2
  unsigned int cr3         : 32;  // unused: page directory
  unsigned int eip, eflags : 32;
  unsigned int eax, ecx, edx, ebx, esp, ebp, esi, edi, es, cs, ss, ds, fs, gs : 32;
                                  // unused (dynamic, filled by CPU)
  long long u3             : 64;  // unused: ldt, trap, iomap
} __attribute__((packed)) tss_entry_struct;
@ %def tss_entry_struct
Most of the fields are only useful when using the TSS to perform task 
switching: they store parts of the task context so that it is not
necessary to keep track of them in the thread control block. If you 
are interested in this approach, you can read more about it in the 
Intel manual \cite{intel-part3}.

The [[esp0]] field must hold the address of the top of the kernel stack, and [[ss0]] must contain the segment number for kernel mode (\hex{10}). The CPU will automatically set the stack pointer to that value when it switches from user mode to kernel mode (ring 0). 

\enlargethispage{5mm}
We use the thread control block entry to store and retrieve
the process context. That is why we need only one TSS. (We cannot
omit the TSS completely because the CPU demands that one exists.)

<<global variables>>=
tss_entry_struct tss_entry;
@ %def tss_entry

We add the data from [[tss_entry]] to the GDT definition (see pages \pageref{fill kernel segment descriptors} and \pageref{fill kernel segment descriptors part 2}), this is the last GDT entry, and it uses number 5 since we've already used the entries 0--4.

\index{GDT (global descriptor table)!TSS (task state segment) entry}%
<<install GDTs for User Mode>>=
write_tss (5, 0x10, (void*)TOP_OF_KERNEL_MODE_STACK);   // gdt no., ss0, esp0
@

Here's the prototype of [[write_tss]] which calls [[fill_gdt_entry]] to make the GDT entry point to [[tss_entry]]:

%nouse
<<function prototypes>>=
static void write_tss (int num, word ss0, void *esp0);
@

Regular GDT entries store a base address and a limit to perform the address transformation from a logical to a linear address (which is then further translated by the paging mechanism). The TSS has a different purpose, but still gets stored in the same table. Here the base address is recycled so that it holds the address of our [[tss_entry]] structure, and the limit field stores the size of the structure, minus 1. The GDT entry type is 0, and the required access value is \hex{e9} = \bin{11101001}.

\index{task state segment!TSS descriptor}%
\index{TSS (task state segment)!TSS descriptor}%
As a reminder, Figure~\ref{fig:tss descriptor} shows the format of a regular segment descriptor at the top (this is the same as Figure~\ref{fig:segment descriptors}); below, you see the slightly modified format of the TSS descriptor \cite[p. 7-7]{intel-part3}. [[B]] (bit 9 of the third word) can be 0 or 1, and we set it to 0, the value is only relevant when using several TSS structures.

\begin{figure}[th!]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{8}{Base: 31--24}
\bitbox{1}{Gr}
\bitbox{1}{Sz}
\bitbox{2}{[[0  0]]}
\bitbox{4}{Limit: 19--16} \,\, {\tiny 7..6} \\
\bitbox{1}{P}
\bitbox{2}{DPL}
\bitbox{1}{[[1]]}
\bitbox{3}{Type}
\bitbox{1}{A}
\bitbox{8}{Base: 23--16} \,\, {\tiny 5..4} \\
\wordbox{1}{Base: 15--0} \,\, {\tiny 3..2} \\
\wordbox{1}{Limit: 15--0} \,\, {\tiny 1..0}   \\[-15pt]
\end{bytefield}

\vspace{6mm}
\begin{bytefield}[bitwidth=6mm]{16}
\bitheader[b]{0-15}\\
\bitbox{8}{Base: 31--24}
\bitbox{1}{Gr}
\bitbox{3}{[[0  0  0]]}
\bitbox{4}{Limit: 19--16} \,\, {\tiny 7..6} \\
\bitbox{1}{P}
\bitbox{2}{DPL}
\bitbox{1}{[[0]]}
\bitbox{4}{[[1  0  B  1]]}
\bitbox{8}{Base: 23--16} \,\, {\tiny 5..4} \\
\wordbox{1}{Base: 15--0} \,\, {\tiny 3..2} \\
\wordbox{1}{Limit: 15--0} \,\, {\tiny 1..0} \\[-15pt]
\end{bytefield}
\caption[Segment descriptor vs.\ TSS descriptor.]{Segment descriptor (top) vs.\ TSS descriptor (bottom).}
\label{fig:tss descriptor}
\end{centering}
\end{figure}

When we call [[fill_gdt_entry]], we have to set the bits 7--4 of the fourth word
to \bin{0000} (in the last argument [[gran]] of the function call) and the bits 15--8 of
the third word to \bin{11101001} (in the second last argument, [[access]]). This is
the interpretation of the [[access]] bitmap:

\begin{itemize}
\item \bin{11101001} for the TSS descriptor \\
  (present; ring 3; fixed-0; TSS type ([[1001]])).
\end{itemize}

\noindent
With this information, we can implement [[write_tss]]:

<<function implementations>>=
static void write_tss (int num, word ss0, void *esp0) {
   fill_gdt_entry (num, (uint) &tss_entry, sizeof (tss_entry) - 1, 
                   0b11101001, 0b0000);                // write_ TSS entry to GDT
   memset (&tss_entry, 0, sizeof (tss_entry));         // fill TSS with zeros
   tss_entry.ss0  = ss0;                               // kernel stack segment
   tss_entry.esp0 = (memaddress)esp0;                  // kernel stack pointer
} 
@ %def write_tss

Thus, all five calls of [[fill_gdt_entry]] together look like this:

\index{GDT (global descriptor table)!overview of entries}%
%nouse
<<collection of [[fill_gdt_entry]] calls>>=
//              no base      limit         access      gran
// --------------------------------------------------------------------------------
fill_gdt_entry (0, 0,        0,            0,          0     );  // null descriptor
fill_gdt_entry (1, 0,        0xFFFFFFFF,   0b10011010, 0b1100);  // kernel, code
fill_gdt_entry (2, 0,        0xFFFFFFFF,   0b10010010, 0b1100);  // kernel, data
fill_gdt_entry (3, 0,        0xFFFFFFFF,   0b11111010, 0b1100);  // user, code
fill_gdt_entry (4, 0,        0xFFFFFFFF,   0b11110010, 0b1100);  // user, data
//   write_tss (5, 0x10, (void*)TOP_OF_KERNEL_MODE_STACK);   calls...
fill_gdt_entry (5, TSS_ADDR, TSS_SIZE - 1, 0b11101001, 0b0000);  // TSS descriptor
//   with TSS_ADDR = &tss_entry and TSS_SIZE = sizeof (tss_entry)
@

Finally, we add the code for loading the \emph{task register} \register{TR}\index{TR register}\index{register!TR} to the
assembler\index{Assembler language!load TR register} file: the index of the TSS in the GDT is 5, so the proper
value to load is $5 \times 8 = 40 = $ \hex{28}. We have to write the 
requested privilege level (RPL) into the two lowest bits:
\[
\textrm{\hex{28}}\, |\, \textrm{\hex{03}} = \textrm{\hex{0b}}
\]

%BEGIN ASM CHUNK
<<start.asm>>=
[section .text]
             global tss_flush

tss_flush:   mov ax, 0x28 | 0x03
             ltr ax               ; load the task register
             ret
@ %def tss_flush
%END ASM CHUNK

As always we need to tell the C compiler that the assembler function [[tss_flush]] exists elsewhere:

%nouse
<<function prototypes>>=
extern void tss_flush ();
@



Lastly, we present the [[cpu_usermode]] routine which performs the switch from kernel mode (ring 0) to user mode (ring 3).
%nouse
<<function prototypes>>=
extern void cpu_usermode (memaddress address, memaddress stack);   // assembler
@ %
It prepares a stack that will create the first user mode process when executing [[iret]]. Since [[iret]] performs a change of privilege level (from ring 0 to ring 3), it will pop the following:

\begin{itemize}
\item instruction pointer\index{instruction pointer (EIP)|see {EIP register}}\index{register!EIP}\index{EIP register} [[EIP]]
\item code segment selector [[CS]]
\item [[EFLAGS]] register
\item stack pointer [[ESP]]
\item stack segment selector [[SS]]
\end{itemize}

The other segment selectors ([[DS]], [[ES]], [[FS]] and [[GS]]) can be
set via [[mov]] instructions. When we enter the assembler function, there are three values on the
stack:

\begin{itemize}
\item the return address in [[[esp]]] (in Assembler syntax, but note: we
will never return to that address),
\item the first argument in [[[esp + 4]]],
\item the second argument in [[[esp + 8]]].
\end{itemize}
But each time we push data on the stack, the offsets will change.
To make the following code more readable we will start with saving
the current \register{ESP} value in \register{EBP}---that register will
then point to the same address even while we push and pop data.

%BEGIN ASM CHUNK
<<start.asm>>=
              global cpu_usermode
cpu_usermode: cli                   ; disable interrupts
              mov  ebp, esp         ; remember current stack address
              mov  ax,  0x20 | 0x03 ; code selector 0x20 | RPL3: 0x03
                                    ; RPL = requested protection level
              mov  ds,  ax
              mov  es,  ax
              mov  fs,  ax
              mov  gs,  ax
              mov  eax, esp
              push 0x20 | 0x03      ; code selector 0x20 | RPL3: 0x03
              mov  eax, [ebp + 8]   ; stack address is 2nd argument
              push eax              ; stack pointer
              pushf                 ; EFLAGS
              pop  eax              ; trick: reenable interrupts when doing iret
              or   eax, 0x200
              push eax
              push 0x18 | 0x03      ; code selector 0x18 | RPL3: 0x03
              mov  eax, [ebp + 4]   ; return address (1st argument) for iret
              push eax
              iret
@ %def cpu_usermode
%END ASM CHUNK

(There are many ways to implement this switch to user mode; the version that you see here originates from an \url{osdev.org} forum post by Jens Nyberg \cite{nyberg:2011:cpuusermode}.
% http://f.osdev.org/viewtopic.php?t=23890&p=194213
We added comments and made some changes which make it easier to understand the code. The important point is to set up the stack properly for the final [[iret]] instruction.)

We're using a trick to have interrupts automatically enabled when we
execute [[iret]]: One of the values on the stack is the \register{EFLAGS}
register which contains the interrupt enable\marginnote{enabling\\ interrupts}
 flag (\register{IF}) in bit 9.
We cannot directly set that bit in \register{EFLAGS}, but we can modify
the stack.
The sequence [[pop eax;  or eax, 0x200;  push eax]] pops the
\register{EFLAGS} (which was just pushed in the previous [[pushf]] instruction)
from the stack, sets bit 9 ($2^9 = 512 = \textrm{\hex{200}}$) and
pushes the modified value onto the stack.


\section{System Calls}
\label{sec:processes:syscall}%
\label{chap:ulix:syscall}%
\index{system call}%

When the operating system is in kernel mode, it has access to all its
internal data and code: it may call any kernel function and, for example,
read sectors from a disk or change hardware settings. Processes on the other hand
cannot do the same: even though \UlixI{} maps the kernel memory in all address
spaces, processes cannot access it because the protection bits in the page
tables define that this memory area may only be used when the system runs in
ring 0---and processes run in ring 3 (user mode).

Even if a process was allowed to call kernel functions (by setting up the
page tables differently) that would not help much since privileged machine
instructions such as [[in]] and [[out]] (for talking to hardware devices)
cannot be executed in ring 3.

All operating systems provide system calls as a way to access these needed
kernel functions: on \UlixI{} they allow a controlled switch from user mode 
to kernel mode via the [[int]] instruction which switches to ring 0 and
executes a pre-defined interrupt handler. That handler finds out which
system call the process wants to execute (by looking at the system call
number that must be stored in the \register{EAX} register) and then 
proceeds by calling a system call handler function.

While we implement system calls, we will also create functions
for the standard library that user mode programs must link in order
to conveniently talk to the operating system via functions such as
[[fork]], [[open]], [[read]] etc.

There are several ways to implement system calls. Let's first look
at the way system calls can be called from user space. On 32-bit Intel
CPUs, Linux\index{Linux} does
it via software interrupt \hex{80} with arguments in registers:
\enlargethispage{1cm}

\index{system call!example on Linux}%
%BEGIN ASM CHUNK
%nouse
<<example for system calls in linux>>=
_start:                         ; tell linker entry point
      mov edx,len               ; message length
      mov ecx,msg               ; message to write
      mov ebx,1                 ; file descriptor (stdout)
      mov eax,4                 ; system call number (sys_write)
      int 0x80                  ; software interrupt 0x80
      mov eax,1                 ; system call number (sys_exit)
      int 0x80                  ; software interrupt 0x80

section	.data
msg   db 'Hello, world!',0xa    ; the string to be printed
len   equ $ - msg               ; length of the string
@ %
%END ASM CHUNK
\pagebreak

\noindent
(This example was taken from \url{http://asm.sourceforge.net/intro/hello.html};
the comments were modified.)

On a Linux machine you could assemble, link and run this file with

\begin{Verbatim}
$ nasm -f elf test.asm
$ ld test.o -o test
$ ./test
Hello, world!
\end{Verbatim}

In this program \register{EAX} always holds the system call number, the 
other registers (in this example \register{EBX}, \register{ECX} and 
\register{EDX} are
used for arguments. System call 4 is the [[sys_write]] syscall.

Other operating systems put arguments on the stack or into
specific memory areas. We will stick with the Linux\index{Linux} way
because it is simple to use registers.

Since adding assembler code to C programs for every system call
would be laborious,
standard libraries make things simpler for the application developer;
this can be done in two steps:

\begin{itemize}
\item Supplying a generic [[syscall]] function (that takes an arbitrary
number of arguments) reduces the above code to executing 

\begin{Verbatim}
char *msg = "Hello, world!\n";
syscall (4, 1, msg, strlen (msg));
\end{Verbatim}

\item But that is still unreadable, and also it is not portable because
system call numbers are not identical across different Unix versions.
Thus, for all standard system calls, some library provides the
better known functions (such as [[write]]) which allow the above code
to be written as

\begin{Verbatim}
char *msg = "Hello, world!\n";
write (STDOUT_FILENO, msg, strlen (msg));
\end{Verbatim}

(with the constant [[STDOUT_FILENO]] set to 1).
\end{itemize}

\subsection{System Calls in \UlixI{}}
\label{sec:system-calls-in-ulix}%
\index{system call!implementation in Ulix}%
\UlixI{} provides functions for adding (or modifying) system calls 
to the system and a generic system call handler. For this purpose,
we create a system call table [[syscall_table]] that contains 
pointers to functions, so for example, [[syscall_table[4]]] should
contain the address of \UlixI{}'s [[sys_write]] function. If a
system call is not defined, the table entry is a null pointer, so
we can initialize the whole table with null bytes:
\index{maximum number of system calls}

<<constants>>=
#define MAX_SYSCALLS 1024         // max syscall number: 1023
@ %def MAX_SYSCALLS

<<global variables>>=
void *syscall_table[MAX_SYSCALLS];
@ %def syscall_table

Telling \UlixI{} what function to execute when a specific system call
is made is as simple as writing the address into the proper array
entry. Nevertheless, we provide a function

\index{system call!installing a new handler}
%nouse
<<function prototypes>>=
void install_syscall_handler (int syscallno, void *syscall_handler);
@ which enters the handler address:

<<function implementations>>=
void install_syscall_handler (int syscallno, void *syscall_handler) {
  if (syscallno >= 0 && syscallno < MAX_SYSCALLS) 
    syscall_table[syscallno] = syscall_handler;
};
@ %def install_syscall_handler

So if we have already defined a function [[sys_write]] and declared
the system call number [[__NR_write]], we could
activate the [[write]] system call by calling

%nouse
<<syscall entry example>>=
install_syscall_handler (__NR_write, sys_write);
@

\enlargethispage{5mm}
\noindent
The actual system call handler simply checks if there is a handler
for the given system call number and (if so) calls it:

<<function implementations>>=
void syscall_handler (context_t *r) {
  void (*handler) (context_t*);   // handler is a function pointer
  int number = r->eax;
  if (number != __NR_get_errno) set_errno (0); // default: no error
  if (number >= 0 && number < MAX_SYSCALLS)
    handler = syscall_table[number];
  else
    handler = 0;   // illegal system call number, outside 0..1023
  if (handler != 0) {
    handler (r);
  }
  else 
    printf ("Unknown syscall no. eax=0x%x; ebx=0x%x. eip=0x%x, esp=0x%x. "
            "Continuing.\n", r->eax, r->ebx, r->eip, r->esp);
}
@ %def syscall_handler
The [[set_errno]] function sets the [[error]] field of the current TCB and can be used by system call handlers to return an error code (see Section~\ref{sec:errno}). We will later add system call handlers to a special code chunk named [[<<syscall functions>>]] and put their prototypes in
[[<<syscall prototypes>>]].
\pagebreak

<<function prototypes>>=
<<syscall prototypes>>
@

<<function implementations>>=
<<syscall functions>>
@

\index{interrupt handler!number \texttt{0x80} for system calls}%
We add a handler for interrupt \hex{80} which looks just like
our regular interrupt handlers for hardware-generated interrupts
(and also like the fault handlers).
The difference is that in this case we call neither
[[irq_handler]] nor [[fault_handler]], but our new C function
[[syscall_handler]]. Apart from that we perform the
same preparation as in the assembler\index{Assembler language} code which you've already
seen: We store the context in the proper order on the stack so
that [[syscall_handler]] which takes a [[context_t *r]] as
argument can evaluate and possibly change them.

%BEGIN ASM CHUNK
<<start.asm>>=
[section .text]
          extern syscall_handler
          global syscallh

syscallh: push byte 0       ; put 128 on the stack so it looks the same
          ; push byte 128   ; as it does after a hardware interrupt
          push byte -128    ; (getting rid of nasm error for signed byte)
          <<push registers onto the stack>>
          call syscall_handler
          <<pop registers from the stack>>
          add  esp, 8       ; undo the two "push byte" commands from the start_
          iret
@ %def syscallh
%END ASM CHUNK
(In case you have forgotten it: [[<<push registers onto the stack>>]] pushes
the general purpose registers as well as \register{DS}, \register{ES}, \register{FS}, 
\register{GS} and \register{ESP} onto the stack while
[[<<pop registers from the stack>>]] pops them back in reverse order. We used
this code when we introduced the interrupt handlers.)

In order to have the system jump to the [[syscallh]] Assembler function, we need
to register its address in the interrupt descriptor table (just like we did with
the interrupt and fault handlers):

%nouse
<<function prototypes>>=
extern void syscallh ();
@

<<install the fault handlers>>=
fill_idt_entry (128, 
                (unsigned int)syscallh, 
                0x08, 
                0b1110,   // flags: 1 (present), 11 (DPL 3), 0
                0b1110);  // type: 1110 (32 bit interrupt gate)
@ Note that we create an interrupt gate like in [[<<install the interrupt handlers>>]] (p.~\pageref{chunk:install-irqs}) and [[<<install the fault handlers>>]] (p.~\pageref{chunk:install-faults}) and not a \emph{trap gate}\marginnote{trap gate}\index{trap gate}, so interrupts will be off when we enter a system call handler. For an \emph{interruptible kernel} version of \Ulix{} (see the discussion in Chapter~\ref{sec:kernel-sync}) we would use a trap gate so that interrupts remain enabled.

% //                0b1111);  // type: 1111 (32 bit trap gate, not interrupt gate)!


\subsection{Making System Calls}

\index{system call!int 0x80@\texttt{int 0x80}}%
\tindex{int 0x80}%
\index{Assembler language!int 0x80 instruction@\texttt{int 0x80} instruction}%

Actually making a system call works just like in the Linux example
we've shown earlier: 
\vspace{-0.5mm}
\begin{itemize}
\item load the system call number in \register{EAX},
\item load arguments for the syscall in the next registers (\register{EBX},
\register{ECX}, \dots) and 
\item execute [[int 0x80]].
\end{itemize}
\vspace{-0.5mm}
The return value of
the system call can then be read from \register{EAX}. The following functions 
%nouse
<<ulixlib function prototypes>>=
inline int syscall4 (int eax, int ebx, int ecx, int edx);
inline int syscall3 (int eax, int ebx, int ecx);
inline int syscall2 (int eax, int ebx);
inline int syscall1 (int eax);
@ standardize this process. We do not need them
in the kernel, but the user mode library uses them to provide standard
functions such as [[open]], [[read]], [[write]] or [[fork]]:

\enlargethispage{1cm}
%nouse
<<ulixlib function implementations>>=
inline int syscall4 (int eax, int ebx, int ecx, int edx) {
  int result;
  asm ( "int $0x80" : "=a" (result) : "a" (eax), "b" (ebx), "c" (ecx), "d" (edx) );
  return result;
}
@ %def syscall4

The [[asm]] statement loads the \register{EAX} (\verb#"a"#), \register{EBX} (\verb#"b"#), \register{ECX} (\verb#"c"#) and \register{EDX} (\verb#"d"#) registers with the supplied values ([[eax]], [[ebx]], [[ecx]], [[edx]]), then executes the instruction ([[int $0x80]]) and finally writes back the contents of \register{EAX} (\verb#"a"#), which may have been modified, to [[result]]. For more information about this syntax see Appendix~\ref{chap:intro-to-asm}.

The other functions work identically, just with less parameters which are stored in less registers:

<<ulixlib function implementations>>=
inline int syscall3 (int eax, int ebx, int ecx) {
  int result;
  asm ( "int $0x80" : "=a" (result) : "a" (eax), "b" (ebx), "c" (ecx) );
  return result;
}

inline int syscall2 (int eax, int ebx) {
  int result;
  asm ( "int $0x80" : "=a" (result) : "a" (eax), "b" (ebx) );
  return result;
}

inline int syscall1 (int eax) {
  int result;
  asm ( "int $0x80" : "=a" (result) : "a" (eax) );
  return result;
}
@ %def syscall1 syscall2 syscall3
System calls differ in the number of arguments. Since C provides
no internal commands for accessing CPU registers and issuing
[[int]] calls, we need inline assembler code. 

As an example look at the [[write]] function which has the prototype
%nouse
<<example: [[write()]] prototype>>=
int write (int fd, const void *buf, int nbyte);
@ It takes three arguments, thus an implementation in a user mode
library would look like this:
%nouse
<<example: [[write()]] implementation>>=
int write (int fd, const void *buf, int nbyte) {
  return syscall4 (__NR_write, fd, (int)buf, nbyte);
}
@

For increased Linux\index{Linux!system call numbers} compatibility we will use the same system call numbers
as Linux does---at least for those calls that \UlixI{} does also provide.

The following definitions were taken from the 32-bit 
Linux\footnote{Ubuntu 11.10, \url{http://www.ubuntu.com/}} file 
\path!/usr/include/i386-linux-gnu/asm/unistd_32.h!:

\begin{multicols}{2}
\index{system call!numbers taken from Linux}%
<<linux system calls>>=
#define __NR_exit          1
#define __NR_fork          2
#define __NR_read          3
#define __NR_write         4
#define __NR_open          5
#define __NR_close         6
#define __NR_waitpid       7
#define __NR_link          9
#define __NR_unlink       10
#define __NR_execve       11
#define __NR_chdir        12
#define __NR_chmod        15
#define __NR_lseek        19
#define __NR_getpid       20
#define __NR_sync         36
#define __NR_kill         37
#define __NR_mkdir        39
#define __NR_rmdir        40
#define __NR_brk          45
#define __NR_signal       48
#define __NR_dup2         63
#define __NR_getppid      64
#define __NR_symlink      83
#define __NR_readlink     85
#define __NR_readdir      89
#define __NR_truncate     92
#define __NR_ftruncate    93
#define __NR_stat        106
#define __NR_chown       182
#define __NR_getcwd      183
#define __NR_setreuid32  203
#define __NR_setregid32  204
#define __NR_setuid32    213
#define __NR_setgid32    214
@ %def __NR_exit __NR_fork __NR_read __NR_write __NR_open __NR_close __NR_waitpid __NR_link __NR_unlink __NR_execve __NR_chdir __NR_chmod __NR_lseek __NR_getpid __NR_sync __NR_kill __NR_mkdir __NR_rmdir __NR_brk __NR_signal __NR_dup2 __NR_getppid __NR_symlink __NR_readlink __NR_readdir __NR_truncate __NR_stat __NR_chown __NR_getcwd __NR_setreuid32 __NR_setregid32 __NR_setuid32 __NR_setgid32
\end{multicols}

<<public constants>>=
<<linux system calls>>
<<ulix system calls>>
@

As we already mentioned, system calls return arguments by storing the value
in \register{EAX}.

Now that you have seen how system calls are implemented you might want
to turn back to Chapter~\ref{sec:address-space:enlarge} (specifically: 
to the implementation of the [[sbrk]] system call and library function on
page~\pageref{please-come-from-syscall-chapter}) because we have already
used the system call interface in that code and promised you a reminder
once you'd get here.


\subsection{Handling Errors with \texttt{errno}}

\index{system call!error handling}%
\label{sec:errno}%
Most system calls can fail: in that case they need to notify the
calling process about the cause of the error. Unix systems traditionally
use a special global variable named [[errno]] for this purpose; the
standard behavior is to make the system call return $-1$ and put a
specific (positive) value into [[errno]].

For \UlixI{} we will provide the error code via a system call (and a
corresponding user mode library function) called [[get_errno()]].
For entering an error code into the process' TCB structure, we add
the system call and function [[set_errno()]]. Every user mode
application must include the \UlixI{} standard headers which
will contain a macro that defines [[errno]] as the result of a
system call which executes [[get_errno]]. All attempts to read 
[[errno]] will generate that system call which reads the [[error]] 
field of the TCB. We haven't defined it yet, so here it is:

<<more TCB entries>>=
int error;
@ (In the TCB we use the name [[error]] instead of [[errno]] so that we
can avoid confusion about which is which.)

We also declare a variable [[startup_errno]] which will be used in
the early phase of the kernel initialization before the first process
is started:

<<global variables>>=
int startup_errno = 0;
@ %def startup_errno

Inside the kernel the two functions are easy to implement:

%nouse
<<function prototypes>>=
int get_errno ();
void set_errno (int err);
@

<<function implementations>>=
int get_errno () {
  if (scheduler_is_active)  return thread_table[current_task].error;
  else                      return startup_errno;
}

void set_errno (int err) {
  if (scheduler_is_active)  thread_table[current_task].error = err;
  else                      startup_errno = err;
}
@ %def get_errno set_errno

Now we need to turn these two functions into system calls. The
system call handlers simply call the above functions; an argument
(for [[set_errno()]]) can be found in the \register{EBX} register, and
we store a return value (for [[get_errno()]]) in the \register{EAX} 
register. Both are available via the [[context_t]] structure
which is provided as an argument to the system call handlers:

%nouse
<<syscall prototypes>>=
void syscall_get_errno (context_t *r);
void syscall_set_errno (context_t *r);
@

<<syscall functions>>=
void syscall_get_errno (context_t *r) { eax_return ( get_errno () ); };
void syscall_set_errno (context_t *r) { set_errno ((int)r->ebx); };
@ %def syscall_get_errno syscall_set_errno

Finally we need to register the system calls:
\index{get\_errno system call@\texttt{get\_errno} system call}%
\index{system call!get\_errno@\texttt{get\_errno}}%
\index{set\_errno system call@\texttt{set\_errno} system call}%
\index{system call!set\_errno@\texttt{set\_errno}}%

<<ulix system calls>>=
#define __NR_get_errno 501
#define __NR_set_errno 502
@ %def __NR_get_errno __NR_set_errno

<<initialize syscalls>>=
install_syscall_handler (__NR_get_errno, syscall_get_errno);
install_syscall_handler (__NR_set_errno, syscall_set_errno);
@

We'll collect error codes (such as [[EACCES]] which is the code
for ``permission denied'') in a new [[<<error constants>>]] chunk:

<<public constants>>=
<<error constants>>
@ and we will fill this collection with entries as we go along
and opportunities for generating errors arise.

User mode programs can access the error code via the [[errno]]
macro which just retrieves the value:

<<ulixlib constants>>=
#define errno (syscall1(__NR_get_errno))
@ %def errno

Note that most system calls do \emph{not} set an error value
because we wanted to keep the code compact. But it would be
easy to change this: After all, the system call handlers \emph{do}
check for errors and simply return $-1$ when one occurs. By 
writing a macro

%nouse
<<possible macro for readable error returns>>=
#define err_return(retval,errno) \
  set_errno (errno); \
  return retval;
@ you could replace the [[return(-1);]] lines in the current code with [[err_return (-1, ECODE);]] lines.


\section{Forking a Process}
\label{sec:processes:fork}%
\index{process!fork operation}%
\index{thread!fork operation (process)}%
\index{fork operation}%

We're getting closer to having a multitasking operating system. We
only use the function [[start_program_from_disk]] for loading the
first (initial) process---for everything else we want to implement 
the standard Unix way of creating new processes: the \verb#fork#.

Figure~\ref{fig:forking} shows how a process and its fork proceed over time; the depiction resembles a (two-pronged) fork.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{pics/forking.pdf}
  \caption[Forking a process creates an almost identical copy.]{When the system forks a process, it creates an almost identical copy.}
  \label{fig:forking}
\end{figure}

\noindent
Here's an excerpt from the \verb#fork# manpage on a Debian GNU/Linux\index{Linux} 7.1 machine \cite{fork-manpage}:

\pagebreak

%\vspace{5mm}
\hrule
\vspace{-2mm}
\begin{Verbatim}
NAME
       fork - create a child process

DESCRIPTION
       fork() creates a new process by duplicating the calling process.  The new pro-
       cess, referred to as the child, is an exact duplicate of the  calling process, 
       referred to as the parent, except for the following points:

       *  The child has its own unique process ID, and this PID does not match the ID 
          of any existing process group (setpgid(2)).

       *  The child's parent process ID is the same as the parent's process ID.
...

RETURN VALUE
       On success,  the PID of the child process is returned in the parent,  and 0 is 
       returned in the child. On failure, -1 is returned in the parent, no child pro-
       cess is created, and errno is set appropriately.
...
\end{Verbatim}
\vspace{-1mm}
\hrule
\vspace{5mm}

Basically, when a Unix process calls \verb#fork()# (and thus enters
the \verb#fork# system call), the operating system creates a duplicate
of the currently running process. After a successful \verb#fork#
operation we have two processes which are almost identical. That
means:

\begin{itemize}
\item Both processes execute the same program (i.\,e., the same
binary is loaded in their lower memory areas),
\item variables and dynamic memory have identical contents, but
the memory is duplicated since both processes may make different
changes to that memory once they continue running after the fork.
\item They also have their own copies of the user mode and kernel
mode stack.
\item Most process metadata (the contents of the thread control
block) are identical as well, with two important exceptions:
the new process has its own process ID (and thread ID), and the
new process stores the old process' thread ID in its
\emph{parent process ID}\index{parent process}\index{PPID (parent process ID)}\index{process!parent process} field ([[ppid]]).
\item After the fork, both processes return from the \verb#fork#
system call and continue execution in the instruction immediately
following the system call---so they need a way to find out
whether they are the original process (called \marginnote{Parent Process}
\emph{parent}) or the newly forked process (called 
\marginnote{Child Process}\index{child process}\index{process!child process}\emph{child}). The user mode \verb#fork#
function will return 0 in the child process and the newly created
process' ID in the parent process. 
\end{itemize}

Note that other Unix implementations do not copy the whole process
memory---instead they use a technique called 
\emph{copy-on-write}\marginnote{copy-on-write} that only creates a
copy of the page tables and marks them read-only (in both the parent
and child process). This means that initially both processes use the
same physical memory, but the read-only mode guarantees that no
problems can occur. When a process tries to modify its memory, that
will cause a page fault (due to the missing write permissions), and
the fault handler will then create a copy of \emph{that page} so
that both processes have their personal copy of the faulting page.
This copy (and the original) will have read and write permissions,
and the faulting process can repeat its write operation. \UlixI{}
copies all of the memory which is less efficient, but allows a
simpler implementation.

While we create a new process we will set its state to 
[[TSTATE_FORK]] to show that its creation is still in progress.

Our goal for this section is to implement the function

%nouse
<<function prototypes>>=
int u_fork (context_t *r);
@ %
which will later be called from the \verb#fork# system call handler
(see page \pageref{syscall:fork}).

Since we will need a lot of memory copying operations, we declare two macros
which let us copy physical memory areas ([[phys_memcpy]]) and
copy page frames ([[copy_frame]]):
\index{memory management!copying physical memory}%
\index{virtual memory!copying physical memory}%
<<macro definitions>>=
#define phys_memcpy(target, source, size) \
  (unsigned int)memcpy ( (void*)PHYSICAL(target), (void*)PHYSICAL(source), size)
#define copy_frame(out, in)  phys_memcpy (out << 12, in << 12, PAGE_SIZE)
@ %def phys_memcpy copy_frame
%
So, [[phys_memcpy]] does the same as [[memcpy]] but expects its first two
arguments to be physical addresses (instead of virtual ones), and [[copy_frame]]
provides a shortcut for copying physical frames since for that task the
number of bytes to copy is always [[PAGE_SIZE]].

Next comes the definition of [[u_fork]]. This function will be called
when the \verb#fork# system call is executed. Again, we declare everything that is done in this function as a critcal section. If you ask, why there is no [[<<end critical section in kernel>>]] in this chunk, see [[<<[[u_fork]]: branch parent and child>>]].

<<function implementations>>=
int u_fork (context_t *r) {
  <<begin critical section in kernel>>
  thread_id old_tid = current_task;
  thread_id ppid    = old_tid;
  <<[[u_fork]]: create new address space and TCB>>
  <<[[u_fork]]: fill new TCB>>
  <<[[u_fork]]: create new kernel stack and copy the old one>>
  <<[[u_fork]]: copy user mode memory>>
  <<[[u_fork]]: branch parent and child>>
}
@ %def u_fork

Now, here's the actual implementation. We will present it in several steps
and discuss what's happening. 


\subsection{Reserving Memory and a Fresh TCB}

\index{address space!for forked process}%
\tcbindex{for forked process}%
We start by creating a new address space and cloning the current TCB
into a free TCB which we first have to search for. 

This step is similar
to the first step in [[start_program_from_disk]], except that memory and 
stack size are not free parameters, but are copied from the parent process:

<<[[u_fork]]: create new address space and TCB>>=
addr_space_id old_as = current_as;
// clone kernel part of PD; reserve user part of memory
addr_space_id new_as = create_new_address_space (
  address_spaces[old_as].memend - address_spaces[old_as].memstart,
  address_spaces[old_as].stacksize );
if (new_as == -1) return -1;    // error: cannot create address space

thread_id new_tid = register_new_tcb (new_as);
if (new_tid == -1) return -1;   // error: cannot create TCB entry
@


\subsection{Filling the Child TCB}

Basically the child is an almost identical copy of the parent, so we start with copying the parent TCB to the child TCB. However, we need to modify some values, for example the process, thread and parent process ID as well as the link to the address space. We also copy the open file descriptors, but this needs more work than just copying the information in the TCB; we will explain that in the filesystem chapter where we provide the code chunk [[<<[[u_fork]]: copy the file descriptors>>]]. The new process is set to state [[TSTATE_FORK]]; it will only change to [[TSTATE_READY]] when the fork operation is complete.

<<[[u_fork]]: fill new TCB>>=
TCB *t_old = &thread_table[old_tid];   // prefer to use pointers
TCB *t_new = &thread_table[new_tid];
*t_new            = *t_old;            // copy the complete TCB
t_new->state      = TSTATE_FORK;
t_new->tid        = new_tid;
t_new->addr_space = new_as;
// t_new->new        = true;           // mark new process as new   // REMOVE_DEBUGGING_CODE
t_new->pid        = t_new->tid;        // new process; pid = tid
t_new->ppid       = old_tid;           // set parent process ID

// copy current registers to new thread, except EBX (= return value)
t_new->regs       = *r;
// t_new->regs.ebx   = 0;              // in the child fork() returns 0  // REMOVE_DEBUGGING_CODE

// copy current ESP, EBP
asm volatile ("mov %%esp, %0" : "=r"(t_new->esp0));  // get current ESP
asm volatile ("mov %%ebp, %0" : "=r"(t_new->ebp));   // get current EBP

<<[[u_fork]]: copy the file descriptors>>      // see filesystem chapter
@


\subsection{The Child's Kernel Stack}

\index{kernel mode stack!for forked process}%
The child needs a fresh kernel stack, and that also requires a new page table in which we can enter the mappings of the kernel stack pages to physical page frames.

<<[[u_fork]]: create new kernel stack and copy the old one>>=
page_table *stackpgtable = request_new_page ();
address_spaces[new_as].kstack_pt = (memaddress)stackpgtable;
memset (stackpgtable, 0, sizeof (page_table));
page_directory *tmp_pd = address_spaces[new_as].pd;
KMAPD ( &tmp_pd->ptds[767], mmu (0, (uint)stackpgtable) );
    
int i, j; // counters
for (i = 0;  i < KERNEL_STACK_PAGES;  i++)
  as_map_page_to_frame (new_as, 0xbffff - i, request_new_frame () );
@

We use the [[phys_memcpy]] macro for copying the frames of the parent's kernel stack to the child's kernel stack, we get those physical addresses from the [[mmu]] function, using [[new_as]] for the new page table and [[old_as]] for the old table. It is not possible to simply start with an empty stack (like we did when we created the first process) because the child process, once it is fully created, will be in the middle of executing the fork system call, so the stack must be there and have the same contents as in the parent.

<<[[u_fork]]: create new kernel stack and copy the old one>>=
// copy the physical frames
memaddress base = TOP_OF_KERNEL_MODE_STACK - KERNEL_STACK_SIZE;
for (i = 0;  i < KERNEL_STACK_PAGES;  i++)
  phys_memcpy ( mmu (new_as, base + i*PAGE_SIZE),
                mmu (old_as, base + i*PAGE_SIZE), PAGE_SIZE );
debug_printf ("u_fork: memcpy done\n");               // REMOVE_DEBUGGING_CODE
@

Note that the frames that we request here (both via [[request_new_page]] for the page table and [[request_new_frame]] for the kernel stack pages) will be released when the process exits.


\subsection{Copying the Process' User Mode Memory}
\index{user mode stack!for forked process}%

Copying the user mode memory means copying the first 3~GByte except the kernel
stack which we've done already.
This requires a nested loop since for each present page directory entry
we look at each present page table entry and then make a copy. We have to
look at the first 767 page tables (the $768^{\textrm{th}}$ table holds the 
entries for the kernel stack).

<<[[u_fork]]: copy user mode memory>>=
  // clone first 3 GB (minus last directory entry) of address space
  page_directory *old_pd = address_spaces[old_as].pd;
  page_directory *new_pd = address_spaces[new_as].pd;
  page_table     *old_pt, *new_pt;
  for (i = 0;  i < 767;  i++) {          // only 0..766, not 767 (= kstack)
    if (old_pd->ptds[i].present) {       // page table present?
      // walk through the entries of the page table
      old_pt = (page_table*)PHYSICAL (old_pd->ptds[i].frame_addr << 12);
      new_pt = (page_table*)PHYSICAL (new_pd->ptds[i].frame_addr << 12);
      for (j = 0;  j < 1024;  j++)
        if (old_pt->pds[j].present)      // page present?
          copy_frame ( new_pt->pds[j].frame_addr, old_pt->pds[j].frame_addr );
    };
  };
@
  

\subsection{A Child Is Born}

All the code you have seen so far is only executed in the original (parent) process. But at some point in time there will be both the parent and the child, and the question is where the child shall start execution. We make the branch right here, as the last step in [[u_fork]].

We start with querying the current instruction pointer (\register{EIP})\index{register!EIP}\index{EIP register} via the [[get_eip]] function.   This function returns the address of the instruction after the [[get_eip]] call (because it retrieves the return address from the stack, and that address is not the address of the call, but of the instruction where the [[u_fork]] function continues after returning from [[get_eip]]). That next line of code is the first line that we want to be executed by both processes, thus we store the value in the [[eip]] field of the new process' TCB. That's the whole trick behind getting the new process to start running at the correct instruction.

The rest is administrative work: In the parent process we add the new process to the ready queue, re-enable the interrupts and return the new process' thread ID. In the child process we simply return 0. We can check whether we're in the parent or child by comparing [[current_task]] with 
the [[ppid]] variable: The latter is identical in both processes, but the comparison only evaluates to [[true]] in the parent process.

<<[[u_fork]]: branch parent and child>>=
memaddress eip = get_eip ();        // get current EIP
// new process begins to live right here!
if (current_task == ppid) {
  // parent tasks
  t_new->eip  = eip;
  add_to_ready_queue (new_tid);
  debug_printf ("fork going to return %d\n", new_tid);    // REMOVE_DEBUGGING_CODE
  <<end critical section in kernel>>  // must be done in parent
  return new_tid;                   // in parent, fork_ returns child's PID
} else {
  // child tasks
  debug_printf ("fork going to return 0 \n");             // REMOVE_DEBUGGING_CODE
  return 0;                         // in child, fork_ returns 0
}
@

Since
%nouse
<<function prototypes>>=
extern memaddress get_eip ();
@ performs its trick by looking at the stack, it must be implemented in the assembler\index{Assembler language!get EIP register} file. We simply pop the return address from the stack (storing it in \register{EAX}) and push it back so that the stack is as before. The contents of \register{EAX} are always used as functions' return values, so we're done:

%BEGIN ASM CHUNK
%nouse
<<start.asm>>=
           global get_eip
           
get_eip:   pop eax       ; top of stack contains return address
           push eax      ; write it back
           ret
@ %def get_eip
%END ASM CHUNK


\subsection[The {\tt fork} System Call]{The {\tt \textbf{fork}} System Call}

\index{fork system call@\texttt{fork} system call}%
\index{system call!fork@\texttt{fork}}%
\label{syscall:fork}%
We can now add the \verb#fork# system call: As usual, [[syscall_fork]] calls [[u_fork]]
and stores the return value in \register{EAX} using [[eax_return]]:

%nouse
<<syscall prototypes>>=
void syscall_fork (context_t *r);
@

<<syscall functions>>=
void syscall_fork (context_t *r) { eax_return ((unsigned int) u_fork (r)); }
@ %def syscall_fork

We add the system call handler to the list:

<<initialize syscalls>>=
install_syscall_handler (__NR_fork, syscall_fork);
@

And here is the user mode library function:

%nouse
<<ulixlib function prototypes>>=
int fork ();
@

<<ulixlib function implementations>>=
int fork () { return syscall1 (__NR_fork); }
@ %def fork


\subsection{Testing \texttt{fork}}

The following test program creates a process tree by calling [[fork]] four times:

<<lib-build/tools/fork2.c>>=
#include "../ulixlib.h"
int main () {
  printf ("Press Return to end.\n");
  int f1 = fork (); int f2 = fork (); int f3 = fork (); int f4 = fork ();
  int pid = getpid (); int ppid = getppid (); int tid = gettid ();
  printf ("[%2d]: pid = %2d, tid = %2d, ppid = %2d, forkrets = [%2d %2d %2d %2d]\n",
    pid, pid, tid, ppid, f1, f2, f3, f4);
    
  long long int j; for (j = 0; j < 9999999ul; j++) ;   // wait
  if (f1!=0 && f2!=0 && f3!=0 && f4!=0) {
    char s[80]; ureadline ((char*)s, 79, false);
  }
  exit (0);
}
@

\noindent
When running it, we get the following output. Figure~\ref{fig:fork4times} shows the process tree that is created by the program.

\begin{Verbatim}
esser@ulix[8]:/home/esser$ fork2
Press Return to end.
[11]: pid = 11, tid = 11, ppid = 10, forkrets = [ 0 13 14 15]
[13]: pid = 13, tid = 13, ppid = 11, forkrets = [ 0  0 17 18]
[14]: pid = 14, tid = 14, ppid = 11, forkrets = [ 0 13  0 19]
[15]: pid = 15, tid = 15, ppid = 11, forkrets = [ 0 13 14  0]
[16]: pid = 16, tid = 16, ppid = 12, forkrets = [11  0  0 20]
[17]: pid = 17, tid = 17, ppid = 13, forkrets = [ 0  0  0 21]
[18]: pid = 18, tid = 18, ppid = 13, forkrets = [ 0  0 17  0]
[19]: pid = 19, tid = 19, ppid = 14, forkrets = [ 0 13  0  0]
[20]: pid = 20, tid = 20, ppid = 16, forkrets = [11  0  0  0]
[21]: pid = 21, tid = 21, ppid = 17, forkrets = [ 0  0  0  0]
[10]: pid = 10, tid = 10, ppid =  8, forkrets = [11 12 22 23]
[12]: pid = 12, tid = 12, ppid = 10, forkrets = [11  0 16 24]
[22]: pid = 22, tid = 22, ppid = 10, forkrets = [11 12  0 25]
[23]: pid = 23, tid = 23, ppid = 10, forkrets = [11 12 22  0]
[24]: pid = 24, tid = 24, ppid = 12, forkrets = [11  0 16  0]
[25]: pid = 25, tid = 25, ppid = 22, forkrets = [11 12  0  0]
esser@ulix[4]:/home/esser$ 
\end{Verbatim}

\begin{figure}[t!]
  \centering
  \includegraphics[width=0.7\textwidth]{pics/fork-tree-structure.pdf}
  \caption[\hgepolylof{Calling {\tt fork} four times creates this tree structure.}]{Calling {\tt fork} four times creates this tree structure.}
  \label{fig:fork4times}
\end{figure}

You will see similar code when you reach Chapter~\ref{chap:ulix:threads} where we discuss the creation of threads. Some operating systems use one kernel function that can create both new processes and threads, for example the Linux\index{Linux!clone function@\texttt{clone} function} kernel has a [[clone]] function that handles both types. We decided against that approach because it makes the function more complex as it often has to check what type of task it is creating.


\section{Exiting from a Process}
\label{sec:processes:exit}%
\index{process!exiting}%

In standard Unix implementations there are five ways to end the life of a process:

\begin{itemize}
\item The process calls \verb#exit()# explicitly which makes it terminate immediately.
\item The process executes \verb#return# in the \verb#main()# function or it reaches the end of that function. That will lead to an implicit call of \verb#exit()# with the same result.
\item The process receives a signal (from another process or from the kernel, see Chapter~\ref{chap:ulix:signals}). If it has not installed a handler for this signal (or the signal cannot be intercepted), this causes the termination of the process (it aborts). In that case it cannot provide an exit value, instead there's an error code.
\item Some kind of error occurs that causes a signal to be sent to the process (by the kernel). That is a special case of the one above.
\item The process calls \verb#abort()#\marginnote{abort} which makes it send a [[SIGABRT]] signal to itself. The result is the same as when that signal is sent by a different process or by the kernel.
\end{itemize}

In all of these cases the parent process can read the \emph{exit status}\marginnote{exit status} and find out whether the process terminated normally or was aborted. The argument to \verb#exit()# or \verb#return# can also be used to tell the parent process whether the process finished successfully; traditionally an exit code of 0 means success, and any other value represents a problem that caused the process to (autonomously) terminate. It is not standard practice to use the exit code as some kind of return value; mainly because the exit code is typically restricted to the integer range of 0--255.


\subsection{The \texttt{exit} System Call}

\index{exit system call@\texttt{exit} system call}%
\index{system call!exit@\texttt{exit}}%
\UlixI{} provides an \verb#exit# system call which terminates the process and stores the exit code (which is the single argument and available via \register{EBX}) in the TCB of the process.

%nouse
<<syscall prototypes>>=
void syscall_exit (context_t *r);
@

It starts with disabling the interrupts and closing all open files of the process (this will only make sense after you've read the chapter about filesystems). Then it modifies the thread table: It removes the process from the ready queue and sets the process state to [[TSTATE_EXIT]]. We cannot get rid of the TCB entry right now because the parent process must get a chance to read the exit code that we store in the [[exitcode]] field of the leaving process' TCB.

Finally, it wakes a waiting parent process, asks for destroyal of the address space (not all of that can happen at once, as we've already seen in Section~\ref{sec:address-space-destroy}), and updates the TCBs of any children it might have:

<<syscall functions>>=
void syscall_exit (context_t *r) {
  // printf ("DEBUG: syscall_exit. current_task = %d\n", current_task); // REMOVE_DEBUGGING_CODE
  // exit_ code is in ebx register:
  <<begin critical section in kernel>>  // access the thread table
  // close_ open_ files
  thread_id pid = thread_table[current_task].pid;
  int gfd;
  for (int pfd = 0;  pfd < MAX_PFD;  pfd++) {
    if ((gfd = thread_table[pid].files[pfd]) != -1)  u_close (gfd);
      // printf ("exit(): closing fd %d (gfd %d)\n", pfd, gfd);   // REMOVE_DEBUGGING_CODE
      // u_close (gfd);                                           // REMOVE_DEBUGGING_CODE
      // thread_table[pid].files[pfd] = -1;   // close (locally)  // REMOVE_DEBUGGING_CODE
    // }                                                          // REMOVE_DEBUGGING_CODE
  }

  // modify thread table
  thread_table[current_task].exitcode = r->ebx;   // store exit_ code
  thread_table[current_task].state = TSTATE_EXIT; // mark process as finished
  remove_from_ready_queue (current_task);         // remove it from ready queue
  wake_waiting_parent_process (current_task);     // wake parent
  destroy_address_space (current_as);             // return the memory
  <<remove childrens link to parent>>             // notify children

  // finally: call scheduler to pick a different task
  <<end critical section in kernel>>
  scheduler (r, SCHED_SRC_RESIGN);    
};
@ %def syscall_exit

We implement a function
%nouse
<<function prototypes>>=
void wake_waiting_parent_process (int pid);
@ that checks whether the parent process is waiting for the current process to finish; we do not provide the code as a code chunk because it will also be used by the [[u_kill]] function which can terminate arbitrary processes.

If the parent is waiting, then it will be on the [[waitpid_queue]] queue. We can then transfer it to the ready queue by calling [[deblock]]. If it is not waiting, we turn this process into a \emph{zombie}\marginnote{zombie}\index{zombie process}\index{process!zombie}: That means that the process will remain in the thread table\index{thread table!keeping zombie processes}. That way we give the parent process a chance to read the exit code, since once the TCB is gone, so is the exit code.

<<function implementations>>=
void wake_waiting_parent_process (int pid) {
  // check if we need to wake up parent process
  int ppid = thread_table[pid].ppid;
  if ( (thread_table[ppid].state == TSTATE_WAITFOR) &&
       (thread_table[ppid].waitfor == pid) ) {
    // wake up parent process
    debug_printf ("exit: remove_from_"                // REMOVE_DEBUGGING_CODE
                  "blocked_queue (%d,%x)\n",          // REMOVE_DEBUGGING_CODE
                  ppid, &waitpid_queue);              // REMOVE_DEBUGGING_CODE
    deblock (ppid, &waitpid_queue);
    thread_table[pid].state = TSTATE_EXIT;
    // thread_table[pid].used = false;                // REMOVE_DEBUGGING_CODE
  } else {
    // parent is not waiting, make this process a zombie
    thread_table[pid].state = TSTATE_ZOMBIE;
  }
}
@ %def wake_waiting_parent_process

We will remove zombie processes in the scheduler: It checks whether a zombie's parent has disappeared and (if so) deletes the zombie's TCB. You can see the code in the chunk [[<<scheduler: check for zombies>>]].

We also need to inform children processes that their parent is gone. In that case we set their parent process ID [[PPID]] to 1  (the ID of the \verb#init# process which becomes the \verb#idle# process).

<<remove childrens link to parent>>=
for (int pid = 0;  pid < MAX_THREADS;  pid++)
  if (thread_table[pid].ppid == current_task)
    thread_table[pid].ppid = 1;  // set parent to idle_ process
@


As usual, we need to enter the system call handler in the table and provide a user mode [[exit]] function that makes the right system call:

<<initialize syscalls>>=
install_syscall_handler (__NR_exit, syscall_exit);
@

%nouse
<<ulixlib function prototypes>>=
void exit (int exitcode);
@

<<ulixlib function implementations>>=
void exit (int exitcode) { syscall2 (__NR_exit, exitcode); }
@ %def exit


\subsection{The waitpid System Call}

\index{process!wait for child}%
Often a process wants to wait for the completion of a child
process, a typical example is a shell which starts an external
program by [[fork]]ing, [[exec]]uting the program inside the
child process and [[wait]]ing in the parent process.

Here we implement the [[waitpid]] system call which waits for
completion of a given child, the standard definition, taken from
the Linux man pages, is the following:

\begin{Verbatim}
pid_t waitpid (pid_t pid, int *status, int options);
\end{Verbatim}

\noindent
In that prototype

\begin{itemize}
\item [[pid]] is the process ID of a child process ([[waitpid]]
cannot be used to wait for termination of arbitrary, non-child processes),
\item [[*status]] is the address of a status value which will be
used to store the exit code of the child process (or an error
value if the child was aborted),
\item and [[options]] can be used to modify [[waitpid]]'s behavior;
our implementation will ignore any given options.
\end{itemize}

We need a blocked queue\index{blocked queue!process waits for child termination} for processes that called [[waitpid]] since
they must not be picked by the scheduler.

<<global variables>>=
blocked_queue waitpid_queue;
@ %def waitpid_queue

<<initialize system>>=
initialize_blocked_queue (&waitpid_queue);
@

Several things must be implemented for [[waitpid]] to work properly:

\begin{itemize}
\item We need the system call handler which moves the current (calling)
process from the ready queue to the new [[waitpid_queue]] and calls
[[resign]] (so that the scheduler picks a new process---the [[resign]] code
will be shown right after [[waitpid]]).
\item When a process \verb#exit#s, it must store the \verb#exit# argument
in the thread control block---this TCB must remain intact until the
parent process has had a chance to look up the value. (We've already
shown you that part.)
\item If the parent of an \verb#exit#ing process is in the [[waitpid_queue]] 
we move it back to the ready queue. (That is handled by
[[wake_waiting_parent_process]], see above.)
\item Once the parent process is picked by the scheduler, it will
continue its execution of [[waitpid]] and has to read the child's
exit code. After that [[waitpid]] it can delete the TCB entry.
\end{itemize}

As long as the parent process could not be reactivated, the child's
TCB will remain intact. Note that it is not necessary for the parent
process to actually look at the exitcode.

\tcbindex{exit code}%
First we add [[exitcode]] and [[waitfor]] entries to the 
[[TCB]] structure:

<<more TCB entries>>=
int exitcode;
int waitfor;    // pid of the child that this process waits for
@

The system call handler

%nouse
<<syscall prototypes>>=
void syscall_waitpid (context_t *r);
@

\noindent
works as follows:
\index{waitpid system call@\texttt{waitpid} system call}%
\index{system call!waitpid@\texttt{waitpid}}%

<<syscall functions>>=
void syscall_waitpid (context_t *r) {
  // ebx: pid of child to wait for
  // ecx: pointer to status
  // edx: options (ignored)
  <<begin critical section in kernel>>
  int chpid = r->ebx;  // child we shall wait for
  
  // check errors
  if (chpid < 1 || chpid >= MAX_THREADS || thread_table[chpid].state == 0) {
    <<end critical section in kernel>>
    eax_return (-1);  // error
  }
  if (!thread_table[chpid].used) {
    <<end critical section in kernel>>
    eax_return (-1);  // no such process
  }
  if (thread_table[chpid].ppid != current_task) {
    <<end critical section in kernel>>
    eax_return (-1);  // not a child of mine
  }

  int *status = (int*)r->ecx;                       // address for the status  
  thread_table[current_task].waitfor = chpid;
  block (&waitpid_queue, TSTATE_WAITFOR);
  <<end critical section in kernel>>
  syscall_resign (r);                               // here we resign_
@ %def syscall_waitpid
Calling [[block]] only moves the process to a different queue, but it does not stop its execution; for that purpose we must also call [[syscall_resign]].

When we return from [[syscall_resign]], the child must have finished.
Unblocking this process happens in [[syscall_exit()]], here we expect to be
woken up automatically.

\enlargethispage{1cm}
The return value of [[waitpid]] is the process ID of the terminated child ([[chpid]]) or $-1$ in case of an error. Since [[syscall_exit()]] has updated the [[exitcode]] field of the child's TCB, we can just read it.

<<syscall functions>>=
  *status = thread_table[chpid].exitcode;
  thread_table[chpid].used = false;  // finally remove child process
  eax_return (chpid);                // set the return value
}
@ %def syscall_waitpid

As usual, we register the new system call:

<<initialize syscalls>>=
install_syscall_handler (__NR_waitpid, syscall_waitpid);
@

Here is the user mode function:

%nouse
<<ulixlib function prototypes>>=
int waitpid (int pid, int *status, int options);
@

<<ulixlib function implementations>>=
int waitpid (int pid, int *status, int options) {
  return syscall4 (__NR_waitpid, pid, (uint)status, options);
}
@ %def waitpid


\subsection{Giving Up the CPU: The \texttt{resign} System Call}

The \verb#resign# system call allows a process to give up the
CPU, so that the scheduler picks another process immediately.

We call the scheduler with a special argument [[SCHED_SRC_RESIGN]]
which tells it that it was called from [[syscall_resign]] because
we want to be able to detect how it was called. This will be
explained in more detail in Chapter~\ref{chap:ulix:scheduling}.

\index{resign system call@\texttt{resign} system call}%
\index{system call!resign@\texttt{resign}}%
%nouse
<<syscall prototypes>>=
void syscall_resign (context_t *r);
@

\pagebreak

<<syscall functions>>=
void syscall_resign (context_t *r) {
  <<begin critical section in kernel>>
  scheduler (r, SCHED_SRC_RESIGN);
  <<end critical section in kernel>>
}
@ %def syscall_resign

We declare a syscall number for the resign system call 
<<ulix system calls>>=
#define __NR_resign       66
@ %def __NR_resign
and initialize the handler:

<<initialize syscalls>>=
install_syscall_handler (__NR_resign, syscall_resign);
@

When we want to resign from inside kernel code, we simply use the following [[<<resign>>]] code chunk which explicitly makes the system call:
%nouse
<<resign>>=
asm {
  mov eax, 66;   // System Call no. 66
  int 0x80;      // Make the System Call
}
@ and user mode processes can do the same by calling this [[resign()]] function that we supply as part of the library:
%nouse
<<ulixlib function prototypes>>=
inline void resign ();
@

<<ulixlib function implementations>>=
inline void resign () { syscall1 (__NR_resign); }
@ %def resign


\section{Information about Processes}
\label{sec:processes:information}%

In this section we implement a few library functions which enable processes and threads to query their process and thread IDs, the parent process ID and information about the overall list of tasks (so that we can write a user mode \verb#ps# program).


\subsection{The \texttt{gettid}, \texttt{getpid} and \texttt{getppid} System Calls}

Each TCB contains two IDs which describe a task: a thread ID [[tid]] (which is
what the global variable [[current_task]] uses to point to the currently executing thread and
which is identical to the index into the thread table) and also a process ID [[pid]].
Until now, thread and process IDs have always been identical, but when we
introduce threads (as parts of a process) in the next chapter, we will arrive
at a situation where these IDs differ. So we will provide three functions that
retrieve the thread and process IDs (and also the parent process ID):

\index{gettid system call@\texttt{gettid} system call}%
\index{system call!gettid@\texttt{gettid}}%
\index{getpid system call@\texttt{getpid} system call}%
\index{system call!getpid@\texttt{getpid}}%
\index{getppid system call@\texttt{getppid} system call}%
\index{system call!getppid@\texttt{getppid}}%
%nouse
<<syscall prototypes>>=
void syscall_gettid (context_t *r);   // get thread ID
void syscall_getpid (context_t *r);   // get process ID
void syscall_getppid (context_t *r);  // get parent process ID
@
Getting the thread ID is simple, because the executing thread always has the
thread ID stored in [[current_task]]. For the process ID and the the parent
process ID we need to access the TCB and fetch its [[pid]] or [[ppid]] entries,
respectively.

<<syscall functions>>=
void syscall_gettid (context_t *r)  { eax_return (current_task); }
void syscall_getpid (context_t *r)  { eax_return (current_pid); }
void syscall_getppid (context_t *r) { eax_return (current_ppid); }
@ %def syscall_getpid syscall_getppid

They use these two macros:

<<macro definitions>>=
#define current_pid  (thread_table[current_task].pid)
#define current_ppid (thread_table[current_task].ppid)
@ %def current_pid current_ppid

The system call numbers [[__NR_getpid]] and [[__NR_getppid]] have been defined earlier, they are standard numbers that you can also find on Linux\index{Linux} systems. For \verb#gettid# we need to define a number since that is no standard system call.

<<ulix system calls>>=
#define __NR_gettid  21
@

<<initialize syscalls>>=
install_syscall_handler (__NR_gettid,  syscall_gettid);
install_syscall_handler (__NR_getpid,  syscall_getpid);
install_syscall_handler (__NR_getppid, syscall_getppid);
@

The user mode [[getpid]], [[getppid]] and [[gettid]] functions

%nouse
<<ulixlib function prototypes>>=
int gettid ();
int getpid ();
int getppid ();
@ simply make the appropriate system calls:

<<ulixlib function implementations>>=
int gettid ()  { return syscall1 (__NR_gettid);  }
int getpid ()  { return syscall1 (__NR_getpid);  }
int getppid () { return syscall1 (__NR_getppid); }
@ %def getpid getppid gettid

Note that we have not implemented corresponding [[u_getpid]], [[u_gettid]] and [[u_getppid]] functions in the kernel as we normally do; querying the current thread's IDs is too simple to justify extra functions for that purpose; if we need this information inside a kernel function, we can just use the macros [[current_pid]] and [[current_ppid]].


\subsection{The \texttt{getpsinfo} and \texttt{setpsname} System Calls}

\index{getpsinfo system call@\texttt{getpsinfo} system call}%
\index{system call!getpsinfo@\texttt{getpsinfo}}%
The \verb#getpsinfo# system call lets a process read its
thread control block (the [[TCB]] structure). That way, a
non-privileged [[ps]] program can show the process list.
It is not possible to modify a TCB, but the TCB may contain
information that should be kept private. In a security-aware
operating system the information must be filtered if some of
the data are considered confidential.

<<ulix system calls>>=
#define __NR_getpsinfo 503
@ %def __NR_getpsinfo

%nouse
<<syscall prototypes>>=
void syscall_getpsinfo (context_t *r);
@

<<syscall functions>>=
void syscall_getpsinfo (context_t *r) {
  unsigned int retval, pid;
  // ebx: thread ID
  // ecx: address of TCB block
  pid = r->ebx;
  if (pid > MAX_THREADS || pid < 1) {      // legal argument?
    retval = 0; goto end;
  }
  if (thread_table[pid].used == false) {   // do we have this thread?
    retval = 0; goto end;
  }
  
  // found a process: copy its TCB  
  memcpy ((char*)r->ecx, &thread_table[pid], sizeof (TCB));
  retval = r->ecx;

  end: eax_return (retval);
};
@ %def syscall_getpsinfo

<<initialize syscalls>>=
install_syscall_handler (__NR_getpsinfo, syscall_getpsinfo);
@

\index{setpsname system call@\texttt{setpsname} system call}%
\index{system call!setpsname@\texttt{setpsname}}%
We also allow processes to set their own name via the \verb#setpsname#
system call. In most cases this happens automatically (because [[u_execv]] writes
the name into the appropriate field of the TCB entry, see below), but for some
cases like the swapper daemon, we want to change the default name.

%nouse
<<syscall prototypes>>=
void syscall_setpsname (context_t *r);
@

<<syscall functions>>=
void syscall_setpsname (context_t *r) {
  strncpy (thread_table[current_task].cmdline, (char*)r->ebx, CMDLINE_LENGTH-1);
};
@ %def syscall_setpsname

<<ulix system calls>>=
#define __NR_setpsname 504
@ %def __NR_setpsname

<<initialize syscalls>>=
install_syscall_handler (__NR_setpsname, syscall_setpsname);
@

These functions let user mode programs access the process list:

<<ulixlib function implementations>>=
uint getpsinfo (int pid, TCB* tcb) {
  return syscall3 (__NR_getpsinfo, pid, (uint)tcb);
}

uint setpsname (char *psname) {
  return syscall2 (__NR_setpsname, (uint)psname);
}
@


\section{ELF Loader}
\label{sec:elf-loader}%
\index{ELF (executable and linking format)!loader}%
\index{process!ELF loader}%

In this section we look at \UlixI{}'s [[execv]] function which is able to
load ELF binaries (Executable and Linking Format) \cite{ELF-Spec:1995} 
from disk.\footnote{Note that there is an alternative implementation of
the \UlixI{} ELF loader by Frank Kohlmann that he developed as part of his 
Bachelor's thesis \cite{Kohlmann:2013:Bachelor} which was supervised by 
Hans-Georg E\ss{}er. It is available on the \UlixI{} website and shows
more details, however the language is German.}
Classically, Unix systems provide several variants of [[exec]] functions
([[execl]], [[execle]], [[execlp]], [[execv]], [[execvp]], [[execvpe]] and [[execve]])
which differ in the way that arguments for the new program are provided.
For the kernel one of these functions is sufficient, all other variants
can be supplied by library functions which convert between the various
syntaxes.

The standard procedure for launching an application on a Unix machine is to first [[fork()]] the current process and then load a new program binary in the child process. That way, the parent process remains intact. (Note that non-Unix systems typically provide a different mechanism, for example Windows\index{Windows operating system} has a [[CreateProcess]] function which combines the creation of a new process and the loading of the program; it does not support [[fork]].)


\subsection{ELF File Format}

\index{ELF (executable and linking format)}\index{executable and linking format (ELF)|see {ELF}}%
Let's look at a simple ELF binary that we create on a Linux\index{Linux} machine. We use
assembler code since that allows us to create a very compact binary:

<<example elf program [[test.asm]]>>=
bits 32
global main

main:
  mov eax, 1
  mov ebx, 42
  int 0x80
@

The equivalent C code would only contain [[exit(42)]]: these assembler
commands make a system call (with system call number 1 which is
[[__NR_exit]]) and the argument 42.

We can assemble this program with [[nasm -f elf32 test.asm]] which creates
[[test.o]]; then we link it with [[gcc test.o -nostdlib -e main -o test]],
creating the binary [[test]].

Let's check that this program works as expected and see what kind of 
information we can gather about it:

\begin{Verbatim}
linux$ ./test ; echo $?
42
linux$ file test
test: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), statically linked, 
BuildID[sha1]=0xa45ecc892186bae9977605e0c3d6757bdef2861b, not stripped
linux$ stat -c "%s" test    # filesize?
631
linux$ readelf -e test
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF32
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           Intel 80386
  Version:                           0x1
  Entry point address:               0x80480a0
  Start of program headers:          52 (bytes into file)
  Start of section headers:          224 (bytes into file)
  Flags:                             0x0
  Size of this header:               52 (bytes)
  Size of program headers:           32 (bytes)
  Number of program headers:         2
  Size of section headers:           40 (bytes)
  Number of section headers:         6
  Section header string table index: 3

Section Headers:
  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al
  [ 0]                   NULL            00000000 000000 000000 00      0   0  0
  [ 1] .note.gnu.build-i NOTE            08048074 000074 000024 00   A  0   0  4
  [ 2] .text             PROGBITS        080480a0 0000a0 00000c 00  AX  0   0 16
  [ 3] .shstrtab         STRTAB          00000000 0000ac 000034 00      0   0  1
  [ 4] .symtab           SYMTAB          00000000 0001d0 000080 10      5   4  4
  [ 5] .strtab           STRTAB          00000000 000250 000027 00      0   0  1
Key to Flags:
  W (write), A (alloc), X (execute), M (merge), S (strings)
  I (info), L (link order), G (group), T (TLS), E (exclude), x (unknown)
  O (extra OS processing required) o (OS specific), p (processor specific)

Program Headers:
  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
  LOAD           0x000000 0x08048000 0x08048000 0x000ac 0x000ac R E 0x1000
  NOTE           0x000074 0x08048074 0x08048074 0x00024 0x00024 R   0x4

 Section to Segment mapping:
  Segment Sections...
   00     .note.gnu.build-id .text 
   01     .note.gnu.build-id 
\end{Verbatim}

\pagebreak
The ELF format and the [[readelf]]\marginnote{[[readelf]]} tool (which is available via the [[binutils]] package on Linux\index{Linux!readelf package@\texttt{readelf} package} distributions) are discussed in detail in the book ``Professional Linux Kernel Architecture'' \cite[p.~1241 ff.]{Mauerer:2008:PLK:1502342}.

In order to read ELF files we need to understand the two kinds of headers which they contain, the ELF header\marginnote{ELF headers} ([[Elf32_Ehdr]]) and the ELF program header ([[Elf32_Phdr]]). We have copied the following type definitions from the Linux header file \path!/usr/include/elf.h!.

\index{ELF (executable and linking format)!file format type declarations}%
%nouse
<<type definitions>>=
typedef uint16_t Elf32_Half;
typedef uint32_t Elf32_Word;
typedef uint32_t Elf32_Addr;
typedef uint32_t Elf32_Off;

typedef struct {
  byte          e_ident[16];            // Magic number and other info
  Elf32_Half    e_type;                 // Object file type
  Elf32_Half    e_machine;              // Architecture
  Elf32_Word    e_version;              // Object file version
  Elf32_Addr    e_entry;                // Entry point virtual address
  Elf32_Off     e_phoff;                // Program header table file offset
  Elf32_Off     e_shoff;                // Section header table file offset
  Elf32_Word    e_flags;                // Processor-specific flags
  Elf32_Half    e_ehsize;               // ELF header size in bytes
  Elf32_Half    e_phentsize;            // Program header table entry size
  Elf32_Half    e_phnum;                // Program header table entry count
  Elf32_Half    e_shentsize;            // Section header table entry size
  Elf32_Half    e_shnum;                // Section header table entry count
  Elf32_Half    e_shstrndx;             // Section header string table index
} Elf32_Ehdr;

typedef struct {
  Elf32_Word    p_type;                 // Segment type
  Elf32_Off     p_offset;               // Segment file offset
  Elf32_Addr    p_vaddr;                // Segment virtual address
  Elf32_Addr    p_paddr;                // Segment physical address
  Elf32_Word    p_filesz;               // Segment size in file
  Elf32_Word    p_memsz;                // Segment size in memory
  Elf32_Word    p_flags;                // Segment flags
  Elf32_Word    p_align;                // Segment alignment
} Elf32_Phdr;
@ %def Elf32_Half Elf32_Word Elf32_Addr Elf32_Off Elf32_Ehdr Elf32_Phdr


\pagebreak
\subsection{Implementation of the ELF Loader}

The default functions which can launch programs on Unix systems are named [[exec*]], and typically there is a variety of them. They differ in the way that users can provide arguments. For example, on a Linux\index{Linux} machine the man pages for [[exec]] and [[execve]] list the following seven functions:

\begin{Verbatim}
int execl   (const char *path, const char *arg, ...);
int execlp  (const char *file, const char *arg, ...);
int execle  (const char *path, const char *arg, ..., char *const envp[]);
int execve  (const char *file, char *const argv[], char *const envp[]);
int execv   (const char *path, char *const argv[]);
int execvp  (const char *file, char *const argv[]);
int execvpe (const char *file, char *const argv[], char *const envp[]);
\end{Verbatim}

\noindent
The functions with an [[envp[]]] argument allow the caller to supply a modified \marginnote{environment}\emph{environment} (a list of exported variables) which we do not support on \UlixI{}: neither the shell nor other application programs can set or query such environment variables.

The functions [[execlp]], [[execvp]] and [[execvpe]] need not be called with the absolute path of the program but can also accept a simple program name. In that case they will scan the [[$PATH]]\marginnote{[[$PATH]]} variable and search all the listed directories that can contain binaries for the program file. Again, since \UlixI{} does not support environment variables, there is also no [[$PATH]] variable.

That leaves only the two basic functions [[execl]] and [[execv]]. These two differ in how arguments for the program can be supplied: [[execl]] takes as many arguments as needed (behind the program path), whereas [[execv]] takes only two arguments and the second argument points to a list of arguments. For \UlixI{} we have deviced to provide the [[execv]] variant, both in the kernel (as [[u_execv]]) and in the user mode library (as [[execv]]):


%nouse
<<function prototypes>>=
int u_execv (char *filename, char *const argv[], memaddress *newstack);
@ Our kernel function takes a third argument [[newstack]] that will be filled with the address of the new process' user mode stack. It also always returns (and provides the entry address of the newly loaded program if loading it was successful). Note that the user mode library function [[execv]] has a different semantics: it only returns if loading the program failed, otherwise the old program is gone and the loaded program starts.

\index{ELF (executable and linking format)!execv function@\texttt{execv} function}%
\index{process!loading a program file}%
<<function implementations>>=
int u_execv (char *filename, char *const argv[], memaddress *newstack) {
  // returns start_ address of the loaded binary; or -1 if exec fails
  Elf32_Ehdr elf_header;  Elf32_Phdr program_header;
  <<[[u_execv]]: check that the executable exists>>
  <<[[u_execv]]: check permissions>>   // see chapter on Users and Groups
  <<[[u_execv]]: prepare arguments on stack>>
  <<[[u_execv]]: zero out the memory>>
  <<[[u_execv]]: load executable, return entry address>>
}
@ %def u_execv


\subsubsection{Step 1: Checking the Executable File}

\enlargethispage{5mm}%
It takes four steps to load and run the program inside the current process.
We start with checking that the file we shall load actually is an ELF binary: We open it, read the ELF header which should be right at the beginning of the file and then check whether it contains the magic string that is used to recognize ELF files.
  
<<[[u_execv]]: check that the executable exists>>=
int fd = u_open (filename, 0, 0);
if (fd == -1)  return -1;   // error
int sz = u_read (fd, &elf_header, sizeof (elf_header));
// check for ELF header
if (sz != sizeof (elf_header) || strncmp (elf_header.e_ident, "\x7f" "ELF", 4) != 0) {
  u_close (fd);
  return -1;
}
@


\subsubsection{Step 2: Preparing the Stack}

The next step is to prepare the stack: Since programs can be called with arguments, we need to push them onto the stack so that when the program initializes, it can find the arguments where they are expected. We allow up to 512 bytes for such arguments, and the user mode stack always starts at the fixed address [[TOP_OF_USER_MODE_STACK]]. If the total length of the arguments is too long, the surplus arguments are lost.

\index{user mode stack!prepare for loading a program}%
Remember that the \verb#main()# function of every program has this prototype:
%nouse
<<main prototype>>=
int main (int argc, char** argv);
@ When this function starts it expects to access its arguments on the stack like every other function does. The stack contents have to start with the return address, and then the arguments follow. Since we launch a new program we can start with an empty stack. The first address which can be used is \hex{afffffff} (as we've set [[TOP_OF_USER_MODE_STACK]] to \hex{b0000000}). We want to reserve 512 bytes for the argument strings.

Let's assume that you start a program from the shell by issuing the command
\begin{Verbatim}
esser@ulix[6]:/home/esser$ args This is an example 1 2 3 verylongstring
\end{Verbatim}
(\verb#args# is a \UlixI{} program that displays the list of all supplied arguments with their addresses.) This would mean that at the start of \verb#args#, the \verb#argc# parameter is set to 9, and \verb#argv# points to an array of strings (i.\,e., an array of character pointers). What kind of data do we need to store?

\begin{itemize}
\item First of all, we need all the strings (\verb#argv[0]# to \verb#argv[8]#) which contain the characters that the arguments consist of, plus a null terminator for each argument.
\item Then we need the list of addresses of these strings.
\item Finally we need a pointer to the start of this list and the number of arguments.
\end{itemize}

Each address needs four bytes of storage, so in this example we need $9 \cdot 4 = 36$ bytes for the addresses, and the address of the list itself needs another four bytes.

We start with the result and show the output of \verb#args#:

\begin{Verbatim}
esser@ulix[6]:/home/esser$ args This is an example 1 2 3 verylongstring
argc: 9, &argc: 0xaffffdf8, argv: 0xaffffe00, &argv: 0xaffffdfc
len(argv[0]) =  4, &(argv[0]) = affffe24, argv[0] = args
len(argv[1]) =  4, &(argv[1]) = affffe29, argv[1] = This
len(argv[2]) =  2, &(argv[2]) = affffe2e, argv[2] = is
len(argv[3]) =  2, &(argv[3]) = affffe31, argv[3] = an
len(argv[4]) =  7, &(argv[4]) = affffe34, argv[4] = example
len(argv[5]) =  1, &(argv[5]) = affffe3c, argv[5] = 1
len(argv[6]) =  1, &(argv[6]) = affffe3e, argv[6] = 2
len(argv[7]) =  1, &(argv[7]) = affffe40, argv[7] = 3
len(argv[8]) = 14, &(argv[8]) = affffe42, argv[8] = verylongstring
esser@ulix[6]:/home/esser$
\end{Verbatim}

We can also request a hex dump of the memory area (thanks to the \verb#hexdump# command in the kernel mode shell, see Chapter~\ref{chap:ulix:debugging}):

\begin{Verbatim}
affffdf8  09 00 00 00 00 fe ff af  24 fe ff af 29 fe ff af  ........$...)...
affffe08  2e fe ff af 31 fe ff af  34 fe ff af 3c fe ff af  ....1...4...<...
affffe18  3e fe ff af 40 fe ff af  42 fe ff af 61 72 67 73  >...@...B...args
affffe28  00 54 68 69 73 00 69 73  00 61 6e 00 65 78 61 6d  .This.is.an.exam
affffe38  70 6c 65 00 31 00 32 00  33 00 76 65 72 79 6c 6f  ple.1.2.3.verylo
affffe48  6e 67 73 74 72 69 6e 67  00 00 00 00 00 00 00 00  ngstring........
\end{Verbatim}

\noindent
Note that the byte order is \emph{little-endian}\marginnote{little-endian} which means that an integer is stored in RAM with the lower bytes coming first. So, for example, the first four bytes of the second line of that hex dump, \verb#2e fe ff af#, store the address \hex{affffe2e} (and not \hex{2efeffaf}).

\begin{table}[t!]
\centering
\begin{tabular}{|l|c|l|l|}
\hline
\textbf{Address}              & \textbf{Type} & \textbf{Contents}      & \textbf{Interpretation} \\
\hline
\hexrange{affffdf8}{affffdfb} & \verb#int# & \hex{00000009}            & \verb#argc# \\
\hexrange{affffdfc}{affffdff} & \verb#int# & \hex{fafffe00}            & \verb#&argv# \\         
\hexrange{affffe00}{affffe03} & \verb#int# & \hex{fafffe24}            & \verb#&argv[0]# \\
\hexrange{affffe04}{affffe07} & \verb#int# & \hex{fafffe29}            & \verb#&argv[1]# \\
\hexrange{affffe08}{affffe0b} & \verb#int# & \hex{fafffe2e}            & \verb#&argv[2]# \\
\hexrange{affffe0c}{affffe0f} & \verb#int# & \hex{fafffe31}            & \verb#&argv[3]# \\
\hexrange{affffe10}{affffe13} & \verb#int# & \hex{fafffe34}            & \verb#&argv[4]# \\
\hexrange{affffe14}{affffe17} & \verb#int# & \hex{fafffe3c}            & \verb#&argv[5]# \\
\hexrange{affffe18}{affffe1b} & \verb#int# & \hex{fafffe3e}            & \verb#&argv[6]# \\
\hexrange{affffe1c}{affffe1f} & \verb#int# & \hex{fafffe40}            & \verb#&argv[7]# \\
\hexrange{affffe20}{affffe23} & \verb#int# & \hex{fafffe42}            & \verb#&argv[8]# \\
\hline
\hexrange{affffe24}{affffe28} & String     & \verb#"args\0"#           & \verb#argv[0]# \\
\hexrange{affffe29}{affffe2d} & String     & \verb#"This\0"#           & \verb#argv[1]# \\
\hexrange{affffe2e}{affffe30} & String     & \verb#"is\0"#             & \verb#argv[2]# \\
\hexrange{affffe31}{affffe33} & String     & \verb#"an\0"#             & \verb#argv[3]# \\
\hexrange{affffe34}{affffe3b} & String     & \verb#"example\0"#        & \verb#argv[4]# \\
\hexrange{affffe3c}{affffe3d} & String     & \verb#"1\0"#              & \verb#argv[5]# \\
\hexrange{affffe3e}{affffe3f} & String     & \verb#"2\0"#              & \verb#argv[6]# \\
\hexrange{affffe40}{affffe41} & String     & \verb#"3\0"#              & \verb#argv[7]# \\
\hexrange{affffe42}{affffe50} & String     & \verb#"verylongstring\0"# & \verb#argv[8]# \\
\hexrange{affffe51}{afffffff} & ---        & ---                    & (unused) \\
\hline
\end{tabular}
\caption[\hgepolylot{Analysis of the initial stack of a process after calling \texttt{exec()}.}]{Analysis of the initial stack of a process after calling \texttt{exec()}.}
\label{table:stack-analysis}
\end{table}

From there we can understand the stack layout and work backwards to arrange the stack that way. Table~\ref{table:stack-analysis} shows a detailed analysis of the stack's contents. We work with a temporary variable [[stack]] which is a pointer to [[unsigned int]]; we set it to \verb#TOP_OF_USER_MODE_STACK# \verb#-512# (which is \hex{affffe00}) so that it points to the beginning of the reserved area. That way we can use pointer arithmetic (\verb#stack--;#) to move to the next address when we want to write (four-byte) addresses to the stack. The statement \verb#*(--stack) = address;# is a push operation: it substracts 4 from the stack address (pointer arithmetic) and \emph{then} writes \verb#address# to the new location. The number of arguments (\verb#argc#) is not known yet, because [[execv]] accepts a null-terminated array of strings---in the example that is
\begin{Verbatim}
[ "args", "This", "is", "an", "example", "1", "2", "3", "verylongstring", 0 ]
\end{Verbatim}
---so we need to walk through the list to find the number:

\pagebreak

<<[[u_execv]]: prepare arguments on stack>>=
uint *stack = (uint*) (TOP_OF_USER_MODE_STACK - 512);
// find number of arguments
word argc = 0;
while ( (memaddress)(argv+argc) < TOP_OF_USER_MODE_STACK && argv[argc] != 0 )
  argc++;
@

Now that we know the number of arguments, we can reserve space for their addresses. We use two variables in the following loop:

\begin{itemize}
\item \verb#target# always points to the memory location where the next argument (string) is to be stored. After each step we add the last argument's length to it.
\item \verb#stack# still points to the start of the reserved 512 bytes. In each step [[i]] we write the argument address into the location [[stack + i]]. Note again that due to pointer arithmetic, [[stack + i]] is [[(int)stack + 4*i]].
\end{itemize}

\pagebreak

<<[[u_execv]]: prepare arguments on stack>>=
// copy arguments into the reserved 512 bytes
memaddress target = (memaddress)stack;
memaddress args_start = target;
target += argc*4;
for (int i = 0;  i < argc;  i++) {
  int size = strlen (argv[i])+1;           // string length plus terminator
  memcpy ((void*)target, argv[i], size);   // copy i-th argument
  *(stack + i) = target;                   // store its address
                                                                        // REMOVE_DEBUGGING_CODE
  // printf ("DEBUG: argv[%d] = %s (at 0x%08x) --> %s (at 0x%08x)\n",   // REMOVE_DEBUGGING_CODE
  //         i, argv[i], argv[i], (char*)target, target);               // REMOVE_DEBUGGING_CODE
  target += size;
}
                                                     // REMOVE_DEBUGGING_CODE
// unsigned int args_end = target;                   // REMOVE_DEBUGGING_CODE
// printf ("DEBUG: args_start = %x\n", args_start);  // REMOVE_DEBUGGING_CODE
// printf ("DEBUG: args_end   = %x\n", args_end);    // REMOVE_DEBUGGING_CODE
@

Finally, we push the arguments for \verb#main(int argc, char **argv)# and the null return address onto the stack. These will be stored just below the reserved area.
<<[[u_execv]]: prepare arguments on stack>>=
// finish stack preparation  
*(--stack) = args_start;  // push pointer to argument list
*(--stack) = argc;        // push number of arguments
*(--stack) = 0;           // push return address (set to 0)
*newstack = (memaddress)stack;
@

\noindent
If the \verb#main()# function of a program simply returns (and does not call [[exit]]) the normal behavior would be an implicit execution of [[exit]]. We do not provide this feature. However, we have to store some value on the stack that tells where to return to. The start address of [[exit]] would be a candidate, but in our \UlixI{} implementation we do not know that address, so we just write 0. If you write an application program that leaves \verb#main()# via \verb#return# you will see that it just starts over (or jumps into whatever function was compiled to address 0). Thus, \UlixI{} programs \emph{must} leave via an explicit [[exit]] call.


\subsubsection{Step 3: Clearing the Memory}

\index{memory management!clear memory for newly loaded program}%
\index{virtual memory!clear memory for newly loaded program}%
The process memory will still contain data that was stored there before the process called [[execv]]. We do not want the new program to be able to read its predecessor's data, so we delete that data by setting the whole user mode memory to zero:

<<[[u_execv]]: zero out the memory>>=
memset ((void*)address_spaces[current_as].memstart, 0, 
        address_spaces[current_as].memend - address_spaces[current_as].memstart);   
@


\subsubsection{Step 4: Load the Program}

Now everything is prepared for loading the program. We walk through the program headers of the ELF file and load the program code. The ELF header may point us to several ELF program headers\index{ELF (executable and linking format)!program header}, so we perform a loop: [[elf_header.e_phnum]] tells us how many ELF program headers there are.

Each such ELF program header must be read in separately, and then we have to check its type [[program_header.p_type]]: If it is [[ELF_PT_LOAD]],

<<constants>>=
#define ELF_PT_LOAD 1
@ %def ELF_PT_LOAD
then we read program code from the file, otherwise we ignore it.

<<[[u_execv]]: load executable, return entry address>>=
int phoffset = elf_header.e_phoff;
for (int i = 0;  i < elf_header.e_phnum;  i++) {
  u_lseek (fd, phoffset + i * elf_header.e_phentsize, SEEK_SET);
  u_read (fd, &program_header, sizeof (program_header));
  if (program_header.p_type == ELF_PT_LOAD) {
    <<[[u_execv]]: reserve sufficient memory>>
    u_lseek (fd, program_header.p_offset, SEEK_SET);
    u_read (fd, (char*)program_header.p_vaddr, program_header.p_filesz);
  }
}    
u_close (fd);
return elf_header.e_entry;  // success. when coming back, set EIP to entry address
@

For each chunk that we need to load we find all the relevant information in the ELF program header:

\begin{itemize}
\item [[program_header.p_offset]] tells us the offset \emph{in the ELF file}, so we can [[u_lseek]] to the right file location,
\item [[program_header.p_vaddr]] contains the virtual address where the chunk is to be placed \emph{in memory}, and
\item [[program_header.p_filesz]] is the size of the chunk.
\end{itemize}
With these three values we can directly [[u_lseek]] and [[u_read]] the chunk without using an intermediate location.

If the loaded program is too big for the currently reserved memory or has a big BSS area (for zero-initialized variables), the loader must acquire more virtual memory via the [[u_sbrk]] function. It finds the total amount of required memory in the [[p_memsz]] element of the program header:

<<[[u_execv]]: reserve sufficient memory>>=
int needed_memsize = program_header.p_memsz;
int current_memsize = address_spaces[current_as].memend 
                    - address_spaces[current_as].memstart;
if (needed_memsize > current_memsize) {
  // printf ("u_exec: calling u_sbrk (%d)\n", needed_memsize-current_memsize);  // REMOVE_DEBUGGING_CODE
  u_sbrk (needed_memsize-current_memsize);
}
@
  

\subsubsection{System Call Handler for \texttt{execv}}

The system call handler is a little more complicated than usual because it has to deal with two possible situations: loading the program may succeed or fail. 

\begin{itemize}
\item If it fails, no changes should be made to the current process, and it should receive a return value of $-1$ from calling \verb#execv#.
\item If it succeeds we need to update the process context so that it will (re-)start execution at the start address of the new program. Normally, that is 0. We also update the [[cmdline]] entry of the TCB.
\end{itemize}

Thus the function
\index{execv system call@\texttt{execv} system call}%
\index{system call!execv@\texttt{execv}}%
%nouse
<<syscall prototypes>>=
void syscall_execv (context_t *r);
@ has the following implementation:

<<syscall functions>>=
void syscall_execv (context_t *r) {
  // generate command line in one string
  char *path  = (char*)r->ebx;            // path argument of execv_ () 
  char **argv = (char**)r->ecx;           // argv argument of execv_ ()
  int i = 0;  char cmdline[CMDLINE_LENGTH] = "";
  while (argv[i] != 0) {
    strncpy (cmdline + strlen(cmdline), argv[i], CMDLINE_LENGTH-strlen(cmdline)-1);
    strncpy (cmdline + strlen(cmdline), " ", CMDLINE_LENGTH-strlen(cmdline)-1);
    i++;
  }
  if (cmdline[strlen(cmdline)-1] == ' ')  
    cmdline[strlen(cmdline)-1] = '\0';    // remove trailing blank

  // call u_execv()
  memaddress stack;
  memaddress startaddr = (memaddress) u_execv (path, argv, &stack);  // sets stack
  if (startaddr == -1)  eax_return (-1);  // error

  // update context and process commandline
  r->eip     = startaddr;                 // start_ running at address e_entry
  r->useresp = (memaddress)stack;         // from ELF header
  r->ebp     = (memaddress)stack;
  strncpy (thread_table[current_task].cmdline, cmdline, CMDLINE_LENGTH); 
};
@ %def syscall_execv

We have not yet defined the [[cmdline]] entry in the thread control block; we'll add it now:

\pagebreak
<<public constants>>=
#define CMDLINE_LENGTH 50   // how long can a process name be?
@ %def CMDLINE_LENGTH

<<more TCB entries>>=
char cmdline[CMDLINE_LENGTH];
@

Finally we register the system call handler and provide a user mode function [[execv]] that makes the system call:

<<initialize syscalls>>=
install_syscall_handler (__NR_execve, syscall_execv);
@

%nouse
<<ulixlib function prototypes>>=
int execv (const char *path, char *const argv[]);
@

<<ulixlib function implementations>>=
int execv (const char *path, char *const argv[]) {
  return syscall3 (__NR_execve, (uint)path, (uint)argv);
}
@ %def execv


\subsection{User Mode Binaries}

We use a linker configuration\marginnote{linker\\ configuration}\index{linker configuration file} file [[process.ld]] to build our user mode applications
and make the compiler use it via the command line option
[[-T process.ld]]. Here's the configuration file:

\begin{multicols}{2}
<<Application Linker Config File>>=
OUTPUT_FORMAT("elf32-i386")
ENTRY(main)
virt = 0x00000000;
SECTIONS {
  . = virt;
  
  .setup : AT(virt) {
    *(.setup)
  }

  .text : AT(code) {
    code = .;
    *(.text)
    *(.rodata*)
    . = ALIGN(4096);
  }

  .data : AT(data) {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }

  .bss : AT(bss) {
    bss = .;
    *(COMMON*)
    *(.bss*)
    . = ALIGN(4096);
  }
  end = .;
}
@
\end{multicols}

\noindent
The file tells the compiler to create ELF binaries
\index{ELF (executable and linking format)!linker configuration file}%
with virtual addresses 
starting at address 0. 
We store the C source code files for our applications in a separate folder
([[lib-build/tools/]]) and use the following makefile to automatically
compile the binaries and copy them to a folder which will be put onto the
data disk image:

%BEGIN NOSYNTAX
%nouse
<<lib-build/tools/Makefile>>=
LD=ld
CC=/usr/bin/gcc-4.4
OBJDUMP=objdump
CCOPTIONS=-nostdlib -ffreestanding -fforce-addr -fomit-frame-pointer   \
  -fno-function-cse -nostartfiles -mtune=i386 -momit-leaf-frame-pointer
LDOPTIONS=-Tprocess.ld -static -s --pie
OBJECTS = $(patsubst %.c, %, $(wildcard *.c))

all: $(OBJECTS) copy

%: %.c
	$(CC) $(CCOPTIONS) -g $(LDOPTIONS) $^ ../ulixlib.o -o $@
	$(OBJDUMP) -M intel -D $@ > $@.dump

clean:
	rm $(OBJECTS)

copy:
	cp $(OBJECTS) ../diskfiles/bin/
@
%END NOSYNTAX

There's some magic in this makefile: the line [[OBJECTS = $(patsubst %.c, %, $(wildcard *.c))]]
searches for all [[*.c]] files (with [[wildcard]]) and replaces each
source filename with the filename without [[.c]] (e.\,g.\ \path!hexdump.c!
with \path!hexdump!).
Then the lines

\begin{Verbatim}
%: %.c
	$(CC) $(CCOPTIONS) $(LDOPTIONS) $^ ../ulixlib.o -o $@
\end{Verbatim}

\noindent
tell [[make]] the rule for creating binaries from source code files,
and the [[all]] target gets a list of all the binaries that are to be
created. [[$^]] always refers to the source file (e.\,g.\ \path!hexdump.c!),
and [[$@]] refers to the target file (\path!hexdump!). Thus the expanded
command for \path!hexdump! is

\begin{Verbatim}
gcc-4.4 -nostdlib -ffreestanding -fforce-addr -fomit-frame-pointer -fno-function-cse \
  -nostartfiles -mtune=i386 -momit-leaf-frame-pointer -T process.ld -static -s --pie \
  hexdump.c ../ulixlib.o -o hexdump
\end{Verbatim}


\pagebreak
\section{Exercises}
% Uebung 6

In the \path!tutorial/05/!\marginnote{Tutorial 5} folder you find a version of the \UlixI{} kernel which contains the new code for handling system calls and also a sample solution for the keyboard interrupt handler exercise. It is a literate program (\path!ulix.nw!).

In this and the following two exercises you will implement and test some system calls. While you work on the solution, try to stick to the literate programming paradigm, i.\,e., integrate code and documentation into the document.

\begin{enumerate}
%start with no. 20
\setcounter{enumi}{19}

\item \textbf{Writing strings with \texttt{printf}}
\label{exercise:printf}%

The [[printf()]] function is available inside the kernel, but processes cannot call it. In the restricted tutorial version of \UlixI{} there is user mode [[printf]] function. You will now implement a system call handler which lets processes call the kernel's [[printf]] function. To make things easier, the goal is that you can later use a [[userprint()]] function which accepts exactly one string as an argument. ([[printf]] takes a format string and an arbitrary number of further arguments, but that requires more effort and is not necessary for this exercise.)

\begin{enumerate}
\item Start with defining a syscall number for the \verb#printf# system call in the [[<<constants>>]] code chunk, e.\,g.
\begin{Verbatim}
#define __NR_printf   1
\end{Verbatim}
\item Next you write a syscall handler with the prototype
\begin{Verbatim}
void syscall_printf (struct regs *r);
\end{Verbatim}
which calls the kernel function [[printf]]. Make sure that you pass the proper arguments: Which of the registers (reachable via [[r->eax]], [[r->ebx]], [[r->ecx]] und [[r->edx]]) holds the address of the string?
\item Enter the new syscall handler into the system call table.
\item Write a (user mode) function
\verb#void userprint (char *s);#
which takes a string as argument and then uses one of the four [[syscall*()]] functions to perform the system call.
\item Verify that your code works correctly by adding the line
\begin{Verbatim}
userprint ("Testausgabe\n");
\end{Verbatim}
to your \verb#main# function.
\end{enumerate}

\item \textbf{Reading Memory Locations with \texttt{kpeek}}

The goal of this exercise is to let processes look at any (existing) memory location, even those that belong to the kernel. Of course, no proper operating system would supply such a function since it completely breaks all security mechanisms. Still, it can be done and shows you how to access data structures which are invisible in user mode. With some additional code this might be turned into a useful tool that, for example, lets only the system administrator access the memory.

You will need a function
\verb#int kpeek (unsigned int address);#
which takes an address as argument, reads the byte that is stored at that address (a value between 0 and 255) and returns it. If the address is not available, the function shall return $-1$ (which is why its type is [[int]] and not [[unsigned char]] which would otherwise be the proper type for a byte).

If this was only about writing a kernel function for the task, you could implement [[kpeek]] like this:
\begin{Verbatim}
int kpeek (unsigned int address) {
  int page = address / 4096;
  if (pageno_to_frameno (page) == -1)
    return -1;
  else
    return  *(char*)address;
}
\end{Verbatim}

But again, this function would only be usable by the kernel (which is the same problem that we had with \verb#printf# in the previous exercise). Instead you have to implement [[kpeek]] via a system call. The general steps are the same as for \verb#printf#:
\begin{itemize}
\item Assign and [[#define]] a system call number.
\item Implement a syscall handler which contains a variation of the above [[kpeek]] code, but which performs parameter and return value passing via registers.
\item Enter the new handler in the system call table.
\item Write a function [[kpeek]] that uses the new system call (with the help of one of the [[syscall*()]] functions).
\end{itemize}

You can check whether your code works properly by adding the following lines to your \verb#main()# function:
\begin{Verbatim}
unsigned int address = 0xc0000000;
*(char*)(address) = 123;
printf ("Testing kpeek: %d\n", kpeek (address));
\end{Verbatim}

The middle line writes 123 into the memory location \verb#address#, and the last line should write ``Testing kpeek: 123'' to the screen. Try the same with an invalid address, e.\,g.
\begin{Verbatim}
printf ("Testing kpeek/fail: %d\n", kpeek (0x90000000));
\end{Verbatim}

(This time you should get a ``Testing kpeek/fail: -1'' output.)
\vspace{3mm}


\item \textbf{Writing to Memory Locations with \texttt{kpoke}}

Reading is one side of the coin, writing is the other. Now you'll add a [[kpoke]] function that your processes can use to modify the contents of arbitrary kernel memory locations. It has the following prototype:

\begin{Verbatim}
void kpoke (unsigned int address, unsigned char value);
\end{Verbatim}

\pagebreak
If \verb#address# is a valid address, the \verb#value# byte shall be written to that memory location, otherwise the function shall simply return. Again, if this was only about adding functionality to the kernel, the implementation would be as simple as

\begin{Verbatim}
void kpoke (unsigned int address, unsigned char value) {
  if ( ... )   // check for availability
    *(char*)(address) = value;
  return;
}
\end{Verbatim}

But again, that does not help a process. Implement [[kpoke]] by writing a system call handler and test the code with the following lines:

\begin{Verbatim}
unsigned int address = 0xc0000000;
kpoke (address, 123);
printf ("Testing kpoke: %d\n", kpeek (address));
\end{Verbatim}

This is the same test as in the last exercise, but this time you use [[kpoke]]. The implementation details are very similar to those of [[kpeek]], so this time we don't provide detailed steps.

\end{enumerate}

Note that for \emph{proper} testing of the new \verb#printf#, [[kpeek]] and [[kpoke]] functions we would need user mode which is not available in this tutorial's version of the kernel. But you'll add that feature in the following exercises.
\vspace{3mm}

% Uebung 7

\noindent
The \path!tutorial/06/!\marginnote{Tutorial 6} folder contains a version of the \UlixI{} kernel which implements the switch to user mode. Again, it is a literate program (\path!ulix.nw!).

\begin{enumerate}
%start with no. 23
\setcounter{enumi}{22}

\item \textbf{User Mode Applications}
\label{exercise:user-mode-apps}%

With this exercise you will create the first user mode application and make it run. As usual: try to write a literate program.

\begin{enumerate}
\item \emph{Test program}: First you will write a simple test program for \UlixI{} so that you can see where all of this leads. Your program file \path!test.c! should only contain a \verb#main()# routine as follows:

\begin{Verbatim}
int main () {
  printf ("Hello - User Mode!\n");
  for (;;) ;   // infinite loop
}
\end{Verbatim}

You must add the implementation of \verb#printf#: Add one of the [[syscall*]] functions ([[syscall1]], [[syscall2]] etc.) to the file. Our simple \verb#printf# implementation accepts only one string argument, it works just like [[userprint]] (from Exercise~\ref{exercise:printf}). You must also [[#define]] the constant [[__NR_printf]] (1).

Note: In the user mode program source files you must always place the \verb#main# function at the very top. All other functions that you might want to call from \verb#main# must be declared \emph{above} the \verb#main# function (by writing down the prototype), but implemented \emph{below} \verb#main#. If you do not follow that rule, program execution will start in the wrong function (the one whose implementation comes first). The real \UlixI{} does not suffer from this limitation because it has an ELF binary file loader, and ELF binaries contain the start address in the header; for this exercise we're keeping things simple.

The \path!Makefile! already contains the necessary [[gcc]] invocation, you need not change it:

\begin{Verbatim}
$(CC) -nostdlib -ffreestanding -fforce-addr -fomit-frame-pointer \
-fno-function-cse -nostartfiles -mtune=i386 -momit-leaf-frame-pointer \
-T process.ld -static -o test test.c
\end{Verbatim}

By running [[make]] you generate the executable binary file \path!test! from the source code.

\item \emph{Install the disassembler}\index{Assembler language!disassembler}\index{disassembler}: You will need a disassembler which translates a binary file back to readable assembler code. Install the disassembler package [[x86dis]] with the following command:

\begin{Verbatim}
sudo apt-get install x86dis
\end{Verbatim}

\item Then disassemble the generated binary file \path!test! by running

\begin{Verbatim}
x86dis -e 0 -s intel < test | sort -u
\end{Verbatim}

The output should begin as follows:

\begin{Verbatim}
00000000 8D 4C 24 04                  lea  ecx, [esp+0x4]
00000004 83 E4 F0                     and  esp, 0xF0
00000007 FF 71 FC                     push [ecx-0x4] 
0000000A 51                           push ecx
0000000B 83 EC 08                     sub  esp, 0x08
0000000E 83 EC 0C                     sub  esp, 0x0C
00000011 68 A2 00 00 00               push 0x000000A2
00000016 E8 77 00 00 00               call 0x00000092
...
\end{Verbatim}

This is the start of the translated \verb#main()# function; the \verb#call# instruction calls the \verb#printf# function.

\item Since we have no filesystem in the current miniature \UlixI{} kernel, we cannot load the program from disk. Instead we use a trick: We write the binary file directly into the kernel and later copy it into user mode memory. If you remember the [[start_program_from_disk]] function from Section~\ref{sec:processes:start the first}, you will soon see a similar function [[start_program_from_ram]] that replaces it in the absence of disk access.

For copying the binary into the kernel we use the tool \verb#hexdump# whose output format you can set via a format string:

\begin{Verbatim}
hexdump -e '8/1 "0x%02X, "' -e '8/1 """\n"' test
\end{Verbatim}

creates an output of the following form:

\pagebreak
\begin{Verbatim}
0x8D, 0x4C, 0x24, 0x04, 0x83, 0xE4, 0xF0, 0xFF,
0x71, 0xFC, 0x51, 0x83, 0xEC, 0x08, 0x83, 0xEC,
0x0C, 0x68, 0xA2, 0x00, 0x00, 0x00, 0xE8, 0x77,
[...] 
0x6F, 0x64, 0x65, 0x21, 0x0A, 0x00, 0x00, 0x00,
0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
*
\end{Verbatim}

\noindent
(Compare these hexadecimal numbers with the numbers that the disassembler has shown: they are identical.)

You can copy the output directly to the kernel source (and add it to the [[<<global variables>>]] chunk). Declare and initialize a variable \verb#usermodeprog# like this:

\begin{Verbatim}
unsigned char usermodeprog[] = {
  0x8D, 0x4C, 0x24, 0x04, 0x83, 0xE4, 0xF0, 0xFF,
  0x71, 0xFC, 0x51, 0x83, 0xEC, 0x08, 0x83, 0xEC,
  0x0C, 0x68, 0xA2, 0x00, 0x00, 0x00, 0xE8, 0x77,
  [...]
};
\end{Verbatim}

You only have to add the first and last line to the \verb#hexdump# output and remove the line with the single asterisk. If there is a line at the end that has only zeroes (\hex{00}), you can delete it.

Now it's time to write the function which loads the program.

\item Locate the chunk [[<<kernel main: user-defined tests>>]] in the source code and add
\begin{Verbatim}
start_program_from_ram ((unsigned int)usermodeprog, sizeof(usermodeprog));
\end{Verbatim}
as its new last line (before the terminating \verb#@# line). 

The function [[start_program_from_ram]] (which you're going to implement) will load and start the program which involves a switch from kernel mode (ring 0) to user mode (ring 3).
\end{enumerate}


\item \textbf{User Mode Activation}

Now you will implement some of the functions required for loading and starting a program. You have already seen how this works in this chapter, but here you can create your own implementation of a program loader (that loads from memory, not disk). Many code parts from the regular \UlixI{} kernel are already present in the source code file.

\begin{enumerate}
\item The central function is [[start_program_from_ram()]]: As already mentioned, it takes the place of [[start_program_from_disk()]] from the real kernel. A further difference between \UlixI{} and this version is that there is no scheduler; we start one single process and have no multi-tasking. 

\pagebreak
\begin{Verbatim}
void start_program_from_ram (unsigned int address, int size) {
  addr_space_id as;
  thread_id tid;
  @<<start program from ram: prepare address space and TCB entry>>
  @<<start program from ram: load binary>>
  @<<start program from ram: create kernel stack>>
  current_task = tid;                      // make this the current task
  cpu_usermode (BINARY_LOAD_ADDRESS,
                TOP_OF_USER_MODE_STACK);   // jump to user mode
};
\end{Verbatim}

You need not type in this code, it is already included in [[ulix.nw]].

\item In order to implement the missing chunks, follow these steps:

In [[<<start program from ram: prepare address space and TCB entry>>]] write appropriate values into the two variables \verb#as#, \verb#tid# by calling [[create_new_address_space()]] and [[register_new_tcb()]]. These function are similar to the ones in the real kernel, they're already contained in the [[ulix.nw]] file for this exercise. Note that the order in which you call these two functions is important: [[register_new_tcb()]] takes the address space ID as an argument. Give the new process 64~KByte of memory and a 4~KByte user mode stack.

As a further task for the first code chunk you need to assign some values to the TCB elements. Give the new process a PPID (parent process ID) of 0.

The chunk [[<<start program from ram: create kernel stack>>]] is almost identical to [[<<start program from disk: create kernel stack>>]] and is also included in [[ulix.nw]] already.

What's missing is the code chunk [[<<start program from ram: load binary>>]]: Here you can use \verb#memcpy()# to copy the [[usermodeprog]] array (whose start address and length you have provided via the \verb#address# and \verb#size# parameters) to address 0.

\verb#cpu_usermode()# is an assembler function that you can find in \verb#start.asm#.

\item Test your code (calling [[make]] and [[make run]])---after the old ``Hello World'' message \UlixI{} should also print the line from the user mode program (``Hello -- User Mode!'').
\end{enumerate}

\item \textbf{More Features for User Mode}

In the final exercise of this chapter you add an input mechanism so that your user mode programs can interact with the user. The goal is to let the application read text from the keyboard with \verb#readline()#. This requires several additions:

\begin{enumerate}
\item Write a syscall handler which calls the kernel function \verb#kreadline()#. Like all syscall handlers it has the prototype

\begin{Verbatim}
void syscall_readline (struct regs *r);
\end{Verbatim}

\pagebreak
When it is called, [[r->eax]] contains the syscall number (which you can ignore), and [[r->ebx]] holds the address of a string (that was declared in the user mode program). In the application source file [[test.c]] declare a string variable which can hold 256 characters. We do not provide the string length; when calling \verb#kreadline# you can ask that the returned string be no longer than 256 characters. In the handler you have to enable interrupts before calling \verb#kreadline()# because the system deactives them upon handler entry. Add the following line:

\begin{Verbatim}
asm volatile ("sti");   // before kreadline() !
\end{Verbatim}

Assign a syscall number \verb#__NR_readline# and register the handler function in the syscall table.

\item Now add a function [[void readline (char *s);]] to [[test.c]] that uses one of the [[syscall*]] functions to make the system call. You will have to define the constant \verb#__NR_readline# in that file. Remember to put function prototypes in front of \verb#main()# and implementations behind it so that process execution starts with the first command in \verb#main()#.

\item Modify the \verb#main()# function in \verb#test.c# so that it continuously reads in text and prints it on the console, like this:

\begin{Verbatim}
int main () {
  char s[256];
  printf ("Hello - User Mode!\n");
  for (;;) {
    printf ("> ");  readline (s);
    printf ("Input was: ");  printf (s);
  }
}
\end{Verbatim}

\item Test your program. After compiling [[test.c]] with [[make]] you will again have to convert the binary file into an array of hexadecimal numbers (as you did in Exercise~\ref{exercise:user-mode-apps}~d--e) and integrate it in the kernel file [[ulix.nw]]. Then call [[make]] once more to generate the modified kernel.

The output function of this exercise's kernel is able to scroll so that you can simply go on printing even after you've reached the bottom of the screen. In order to understand how scrolling was implemented, look at the \verb#scroll()# function and the two places from where it gets called.

\item The \verb#scroll()# function determines the right memory address to write data to by looking at the \verb#VIDEO# variable: Search for all the lines in the code that change \verb#VIDEO#---the variable takes three different values (\hex{c00b8000}, \hex{b8000}, \hex{d00b8000}) during system initialization---why is that so? As a reminder, the physical addresses that are used for the text mode framebuffer start at \hex{b8000}.

\item Copy the code from [[test.c]] into the literate program [[ulix.nw]] and modify the \path!Makefile! so that [[test.c]] will be extracted from it. Name the code chunk [[<<test.c>>]]. You will need an extra invocation of [[notangle]], analogous to

\begin{Verbatim}
notangle -Rulix.c ulix.nw >ulix.c
\end{Verbatim}

where the option [[-R]] is followed by the new chunk name and output redirection writes to the right file. Note that all commands in the \path!Makefile! must be indented by a tabulator character.

Search for code that appears identically in both [[ulix.c]] and [[test.c]] and combine it by creating code chunks which will be written to both files. As a result the literate program will be free of duplicates.

\end{enumerate}

\end{enumerate}




%------------------------------------------------------------------------------------



\chapter{Implementation of Threads}
\label{chap:ulix:threads}%

\index{thread}
\felix
In Chapters \ref{chap:memory:theory} and \ref{chap:ulix:boot} we looked into 
a fundamental abstraction
offered by the operating system: virtual memory. It abstracts physical 
memory, one of the main hardware resources. The second such resource is
\emph{processor time}, i.\,e., machine cycles or computation power
offered by the CPU. The abstraction which encapsulates processor time
in an operating system \black was traditionally called a \emph{process},
in newer systems \emph{threads} have taken over that job. We have just
discussed the implementation of processes in the previous 
Chapter~\ref{chap:ulix:processes}.

\index{thread!process vs.\ thread}%
\index{process!process vs.\ thread}%
\felix Up\marginnote{``process''\\ vs. ``thread''}
to now, we used the more historic term \emph{process} in parts of
this book instead of the term \emph{thread}. Briefly spoken, a
\vindex{process} is a virtual address space (defined by a page
directory and page tables) plus exactly one
thread. Thus, the term process alludes to the classical
\emph{\vindex{Unix process}}\marginnote{Unix process}. Today, modern operating systems offer
multiple threads within one virtual address space, \black and so
does \UlixI{}.

Thus, a summary of the differences between classical operating systems
that are based on processes and newer systems with threads can be
given as follows:

\begin{itemize}
\item In classical systems, process management provides a common
abstraction for both processor time and memory. Switching from one
process to another always means that the used address space changes,
too.

\item In modern systems, thread management and memory management
are decoupled: It is possible to switch from one thread to another
\emph{without also changing the address space}. A process is simply
a collection of one or more threads which share a common address
space.
\end{itemize}

Note that some operating systems allow variations of the thread and
process concepts which are something in-between. For example, the Linux\index{Linux!clone function@\texttt{clone} function}
kernel provides a [[clone]] function which can create new processes,
new threads and other kinds of tasks which are neither.

\felix 


\section[Threads, Teams of Threads and Virtual Processors]{Threads, Teams of Threads and\\ Virtual Processors}
\label{sec:threads:teams:virtual:processors}

A thread\footnote{The theory Sections~\ref{sec:threads:teams:virtual:processors} and \ref{sec:kernel:vs:user:level:threads} of this chapter are heavily based on the ``Threads'' chapter of Nehmer and Sturm's book \cite{Nehmer:2001:SGM}.}
can be regarded quite literally as an execution thread within
the operating system. Threads are abstractions of
processing time, \emph{virtual processors}\marginnote{virtual\\ processor}. They are implemented by
multiplexing virtual processors (the threads) onto the physical
processors (CPUs). A thread always has an associated
\emph{\vindex{program}}, i.\,e., a sequence of machine instructions
which it executes. When a thread starts its operation, execution
starts at a pre-defined address in this sequence.

Threads and address spaces are two abstractions which are orthogonal
but nevertheless closely tied together. Whenever a virtual address space
is created, a first thread is also created within the address space.
This results in what is often called a \emph{process}. In most cases
(as in early Unix) this is absolutely sufficient to perform all
the classical application tasks programmed on top of the operating
system, \black and it is what you have seen when we described the
[[u_fork]] implementation of the fork mechanism. 
\felix However, it sometimes makes sense to create multiple
threads within a single address space, as we now explain.

\subsection{Teams of Threads}

We call multiple threads within a single address space a
\emph{team}\marginnote{team of\\ threads} (or \emph{\vindex{team of threads}}\index{thread!team}).  Why does
it make sense to create multiple threads within one address space?
There are several answers to this question. 

The first block of answers refers to performance issues: 

\begin{itemize}
\item If within an application one
thread invokes a system call which blocks for an I/O operation to
succeed, then the whole application will block if the application is
carried on just this one single thread. If more than one thread would
carry the application, these other threads could continue to operate,
giving the user a better quality of service. 

\item Also, if an application
runs on multiple threads, it is possible to distribute the machine
cycles onto \emph{physically distinct} processors. This (of course)
is not an issue in a monoprocessor system. However, in a dual
processor system for example an application which is carried only by a
single thread will never be able to bring the power of the two CPUs
into the application.
\end{itemize}

\noindent
The second block of answers refers mainly to software engineering
aspects, i.\,e., the way we write programs. 

\begin{itemize}
\item Multiple threads within one
address space allow to program those applications which contain
inherent parallel activities in a much more natural way. The result is
a \emph{concurrent model of programming}\pindex{concurrent programming} which includes both the fields of distributed and
parallel programming.  Concurrent programming refers to programming
multiple independent threads of execution in general. 

\item Parallel
programming\pindex{parallel programming} on the one side refers rather
to more dependent threads, e.\,g., threads which operate in strongly
synchronized ``lock-step'' mode. 

\item Distributed
programming\pindex{distributed programming} on the other side refers
to concurrent programming where the aspect of geographic distribution
plays a role (like in the Internet).
\end{itemize}


\subsection{Natural Concurrency}

Many of today's operating systems already support multiple threads
in one address space and so it is becoming more and more natural to
use them. It is especially natural if the application which is
implemented already contains \emph{inherent} concurrency\marginnote{inherent\\ concurrency}\index{thread!inherent concurrency}\index{inherent concurrency}.
As an example (taken from Nehmer and Sturm \cite{Nehmer:2001:SGM}) consider
a weather reporting application. It consists of a huge database in
which new measurements of humidity, temperature etc.~are regularly logged
from different sensing stations. From this database the application
computes in a continuous manner weather reports for different areas
of the country using complex weather models. Additionally, the
application has a graphical interface through which users can
inspect data, query weather reports and visualize measurement data.

Looking at the application from a concurrent programming viewpoint, it
has three rather independent streams of activity:
%
\begin{enumerate}
\item The measurement and logging activity of data into the database.
\item The continuous weather prediction and reporting computation.
\item The graphical user interface.
\end{enumerate}
%
Note that each stream of activity by itself is sequential. 

Let's make things simple and just look at the last two
activities: computation and user interface. As both are
sequential activities, we can program them separately and
enclose each activity within a thread. The pseudocode
could look like this:

%nouse
<<weather reporting example: thread pseudocode>>=
void Compute () {                      // activity 1: computation
  while (true) {
    // do the actual computation
  }
}

void GUI() {                           // activity 2: graphical user interface
  while (true) {
    Event e = ReceiveEvent ();
    ProcessEvent (e);
  }
}

int main () {
  start_thread (Compute ());           // Start concurrent threads
  start_thread (GUI ());
}
@ Note that the sequential activities are encoded within 
simple sequential functions which are both started within
separate threads in the \verb#main# routine and thereafter
run separately. Here we assume that the entire application
exits when all of its threads have exited. 

How would we program this application traditionally (i.\,e., without
threads)? We would have to split the activities into small slices and
run them alternately. Assume we can divide the function [[Compute()]]
into small parts called [[ComputeStep]]. Then after computing such a
step we would need to check whether user input must be handled. If
yes, we handle it, if not, we compute the next step. The pseudocode
could look like this:

%nouse
<<weather reporting example: traditional pseudocode>>=
int main () {
  while (true) {
    ComputeStep ();          // compute the next step
    if (QueryEvent ()) {     // do we have to process an event?
      e = ReceiveEvent ();
      ProcessEvent (e);
    }
  }
}
@ This approach should also work, but only under the assumption that
we can in fact split [[Compute]] into [[ComputeStep]]. In many cases
this is not as easy as it seems, sometimes it might even be
impossible. Another disadvantage of the traditional approach is that
the computation is interrupted regularly even if there are no events
to be processed. In this case the code for [[QueryEvent]] should be
very efficient so that it doesn't cost too many CPU cycles. It goes
without saying that functions like [[QueryEvent]] should not block
(e.\,g., until user input arrives) because this would block the entire
application. 

There are more downsides of the traditional approach. For example, the
program structure without threads determines the reaction time to user
input. If [[ComputeStep]] may take up to a couple of seconds of
execution time, then reaction to user input can also take this time.
The execution time of [[ComputeStep]] should therefore be rather short
to guarantee \emph{responsiveness}\marginnote{responsiveness}. However, a short execution time implies
that the overhead of [[QueryEvent]] increases in relation. So we have
a non-trivial tradeoff here.  Finally, but this is a matter of taste,
we find the traditional code much harder to read and understand than the
code using threads.

\subsection{Advantages of Concurrent Programming}

Threads allow to create an unbounded number of virtual processors, no
matter how many physical processors exist in the system. This lets us
distribute applications over as many virtual processors as are
necessary to serve their inherent concurrency. Threads therefore allow
to abstract from the actual number of physical processors in the
system and to depart from the traditional sequential programming
model. If an application has inherent, natural concurrency, then
it should be expressed in the program. 

\looseness=1 Threads do not only make programs with inherent concurrency easier to
read and understand, they also may make the execution of the
application more efficient since only concurrent applications can
exploit the power of truly concurrent hardware available in
multiprocessor systems. But even on monoprocessor systems a concurrent
program can be more efficient than its sequential counterpart because
the periods in which one thread is blocked (e.\,g., due to lack of
user input) can be used by other threads more effectively.

\subsection{Virtual vs.~Physical Processors}
\enlargethispage{5mm}

As mentioned above, a thread can be regarded as a
\emph{\vindex{virtual processor}}. Therefore, a team of threads can be
regarded as a \emph{\vindex{virtual multiprocessor}}\marginnote{virtual\\ multiprocessor}. Ideally, every
virtual processor is backed up from below by exactly one physical
processor and the assignment of virtual to physical processors is
fixed. However, the normal case is rather different: Many virtual
processors need to be executed on few physical processors. The task of
the operating system is to distribute the physical processor cycles as
effectively as possible between the virtual processors in a kind of
\emph{\vindex{time division multiplex}} mode of operation. This is
depicted in Figure~\ref{fig:time:multiplex}.

\begin{figure}[b!]
  \centering
  %\includegraphics[width=0.8\textwidth]{figures/time-multiplex.jpg}
  \includegraphics[width=0.8\textwidth]{pics/time-multiplex.pdf}
  \caption[Assignment of virtual to physical processors.]{The assignment of virtual to physical processors can change over time.}
  \label{fig:time:multiplex}
\end{figure}

As an example, consider the case where one physical processor carries
two virtual processors (threads). In this case the threads would be
assigned alternately to the physical processor by the operating
system. The change from one thread to the other is called a
\emph{\vindex{context switch}}\marginnote{context switch}. Within the context switch, the
execution of the current thread is interrupted, the processor context
(registers, stack pointer etc.) is saved somewhere, the processor
context of the next thread is loaded from somewhere onto the processor
and the next thread then continues execution at the point in its
program where it was previously interrupted. 

In a sense, the operating system pretends that every thread has
exclusive access to the physical processor. During a context switch,
the previously running thread is ``frozen'' and saved somewhere.  The
next thread is selected and ``unfrozen'' by loading its state into the
CPU. During the times in which they are frozen, threads do not
operate. In fact, since they don't operate, they are not aware that
time is passing. After unfreezing the new thread, it continues
operation as if it had never been interrupted. This can remotely
be compared with becoming unconscious after a knock out in boxing.

\pagebreak

If there is more than one candidate for the next running thread,
the operating system has to make a choice. The operating system
component which is responsible for making this decision is called the
\emph{\vindex{scheduler}}\marginnote{scheduler}. As we will see later 
(in Chapter~\ref{chap:ulix:scheduling}) there
exist many different strategies to make this scheduling decision.


\section{Thread Requirements and Thread Types}
\label{sec:kernel:vs:user:level:threads}

\black
Before we delve into the implementation, let's take a closer look at why threads are so useful. They help the operating system reach a higher degree of concurrency for the applications it runs.

\felix
\subsection{Thread Requirements}

If an operating system supports threads, it must offer at least two
types of functionality: On the one hand, a user should be able to
create a new address space with a \emph{single} thread. On the other
hand, the user should be able to assign a new program to this
thread. Often these two functionalities are assembled within one
single system call offered by the kernel.

To offer more flexibility, it should be possible to create
\emph{multiple} threads within one address space. Good operating
systems therefore offer functionality to create a new thread within
the same address space at runtime and to assign a new program to
this thread. 

\subsection{Utility of Threads}

\black
Normally, several threads wait for the same processor to become free. Let's assume that each thread, once activated, uses $k$ units of time for completion and would run until it is finished. The first thread starts at once, the second thread after $k$ units of time, etc. That leads to an average response time of

\[ \frac{1}{n} \sum_{i=1}^n (i-1) \cdot k = \frac{n-1}{2} \cdot k  \]

units of time \cite[p.~101]{Nehmer:2001:SGM}. However, this ignores that threads typically alternate between CPU and I/O bursts:

\begin{itemize}
\item A \emph{CPU burst}\marginnote{CPU burst}\index{CPU burst} is a time range during which a thread uses the CPU, i.\,e., it is active and executes instructions.
\item An \emph{I/O burst}\marginnote{I/O burst}\index{I/O burst} is a time range during which a thread waits for the completion of an I/O operation that it initiated. The burst begins in the moment where the thread is put on a blocked queue (as a direct result of requesting the I/O operation) and it ends when the I/O operation completes and the thread is moved to the ready queue.
\end{itemize}

If there is only one single thread, then the system switches between CPU and I/O bursts of that thread. With several threads and a scheduler the situation becomes more complicated since the scheduler can interrupt an active thread in the middle of a CPU burst. Also, whenever an I/O burst begins, the CPU is reassigned to a different thread (which continues its CPU burst).

If I/O was handled completely asynchronously (i.\,e., we ignore the times required to process I/O requests), the CPU burst times would lead to an average response time of 
\[ \frac{n-1}{2} \cdot t_{\textrm{\,burst}}  \]
where $t_{\textrm{\,burst}}$ is the average length of a CPU burst \cite[p.~102]{Nehmer:2001:SGM}.

Nehmer and Sturm measured the length of bursts and looked at their statistical distribution which resulted in the image shown in Figure~\ref{fig:burst-distribution-nehmer} \cite[p.~102]{Nehmer:2001:SGM}. This shows that typically CPU bursts are very short---much shorter than I/O bursts. Using the time that a thread waits for I/O completion for other threads (which continue their CPU bursts) creates a considerable degree of concurrency, even on a monoprocessor. Thus, it is important to pause threads which wait for I/O (which is precisely what we've been doing for processes in Chapter~\ref{chap:ulix:processes}), and with threads it improves the behavior of processes by allowing CPU-burst threads of a process to continue while I/O-burst threads are blocked. This improves response times for those processes.

\begin{figure}[ht!]
\centering
\input{pics/burst-distribution-nehmer}
\caption[Distribution of the CPU burst length.]{Distribution of the CPU burst length: A length of 2~ms occurred most often (as measured by Nehmer and Sturm).}
\label{fig:burst-distribution-nehmer}
\end{figure}

However, once the number of threads becomes very large, too many of them will be in their CPU bursts simultaneously, and then the overall execution speed and responsiveness will shrink.


\felix
\subsection{Types of Threads}
\label{sec:types:of:threads}
\enlargethispage{3mm}

Two different types of threads are usually distinguished:
\emph{kernel-level threads} and \emph{user-level threads}.
\index{kernel level thread}\index{user level thread}%
The ``classical'' threads (i.\,e., the threads in Unix
processes) are kernel-level threads. The distinction is based on the
mode in which the \vindex{context switch} is performed. In
kernel-level threads the context switch happens in system mode, in
user-level threads it happens in the user mode thread library.

Kernel-level threads can be regarded as virtual processors\index{virtual processor}
running directly on physical processors. User-level threads can be
regarded as virtual processors running on kernel-level threads.  In
this sense, a team of kernel-level threads running in the same virtual
memory can be regarded as a \emph{\vindex{virtual multiprocessor}}\marginnote{virtual\\ multiprocessor} for
user-level threads.  

\begin{figure}[b!]
  \raggedleft
  \hspace{-0.20\textwidth}%
  \includegraphics[width=1.20\textwidth]{pics/processor-hierarchy.pdf}
  \centering
  \caption[Schematic view of the processor hierarchy.]{Schematic view of the processor hierarchy. Arrow colors (on one level) express the order of allocation of a virtual (top) or physical (bottom) processor, but the top and bottom arrows have their own times.}
  \label{fig:processor:hierarchy}
\end{figure}

The techniques used to implement and synchronize
virtual processors (i.\,e., kernel-level threads) on physical processors are
the same as those used to implement and synchronize virtual processors
(user-level threads) on virtual processors (kernel-level
threads). Therefore people sometimes speak of a
\emph{\vindex{processor hierarchy}}\marginnote{processor\\ hierarchy}. Virtual processors run on virtual
processors that run on physical processors. (Note that in principle it
is even possible to run user-level threads on user-level threads,
extending the processor hierarchy.) The multiplexing of higher-level
processors to lower-level processors is performed by a software layer
(see Figure~\ref{fig:processor:hierarchy}).  In case of kernel-level
threads implemented on physical processors this software layer is the
operating system; in case of user-level threads implemented on
kernel-level threads this software layer is usually called the
\emph{\vindex{user-level threads library}}.

\black

In the example shown in Figure~\ref{fig:processor:hierarchy} the green and
blue arrows describe the order in which a virtual/physical processor is
assigned to a user-level/kernel-level thread. If we assume that the time slices
for user and kernel level threads are identical, then the example thread
might execute as shown in Table~\ref{table:thread-execution-order}, but in
practice switch times for user-level threads will not be synchronized with
switch times for kernel-level threads.

\begin{table}[ht]
\centering
\begin{tabular}{|l|r|r|}
\hline
\textbf{Time} & \textbf{KLT} & \textbf{ULT} \\
\hline
$n$    & 1 & 1 \\
$n+1$  & 2 & 3 \\
$n+2$  & 3 & 4 \\
$n+3$  & 1 & 2 \\
$n+4$  & 2 & 4 \\
$n+5$  & 3 & 5 \\
$n+6$  & 1 & 1 \\
$n+7$  & 2 & 3 \\
$n+8$  & 3 & 4 \\
$n+9$  & 1 & 2 \\
$n+10$ & 2 & 4 \\
\hline
\end{tabular}
\caption[\hgepolylot{Possible order of execution for the threads shown in Figure~\ref{fig:processor:hierarchy}.}]{Possible order of execution for the threads shown in Figure~\ref{fig:processor:hierarchy}.}
\label{table:thread-execution-order}%
\end{table}


\felix
\subsubsection{Kernel Level Threads}

\index{kernel level thread}%
Kernel-level threads are managed in system mode, i.\,e., the context
switch of one kernel-level thread to the next requires \black
some action by the operating system's scheduler. \felix
This is why kernel-level threads are often called \emph{heavy-weight}
threads\marginnote{heavy-weight\\ thread}, because entering and leaving the scheduler incurs a large performance
overhead. For example, if the context switch from one kernel-level
thread to the next also causes a switch of one virtual memory to
another (i.\,e., the process changes), the effect of caching in the 
\vindex{TLB} or in any other local cache is destroyed.


\subsubsection{User-Level Threads}

\index{user-level thread}%
User-level threads run on kernel-level threads. From the point of view
of user-level threads, kernel-level threads are virtual processors
that carry the user-level thread library.
In contrast to kernel-level threads, user-level threads are managed
entirely in user mode. This implies that the context switch of
user-level threads does not incur a context switch of the kernel-level
thread that carries it. This in turn implies that there is no switch
of virtual memories and no performance penalty. Therefore, user-level
threads are often called 
\emph{light-weight}\marginnote{light-weight\\ thread} threads.

\black 
\UlixI{} only implements kernel-level threads. We show the code in the
following section.

\pagebreak


\section{Implementation of Threads in \UlixI{}}

\index{kernel level thread!implementation in Ulix}%
\index{thread!implementation in Ulix}%
So far, we have been talking about threads all the time, e.\,g., when we discussed the structure of the \emph{thread} control block, but all the previous code actually dealt with processes. That changes now: we are about to introduce true threads which can be created inside processes.


\subsection{Creating Threads Instead of Processes}

Creating a kernel-level thread (belonging to an already existing process)
is very similar to forking a process.
The original idea was to let [[u_fork]] perform its usual tasks, but with
two exceptions---it should not copy the user mode memory, and it should
provide two new stacks (for kernel and user mode) which exist in the
same address space. This approach is used in the
Linux\index{Linux!clone function@\texttt{clone} function}\index{clone function (Linux)@\texttt{clone} function (Linux)}\index{process!clone function (Linux)@\texttt{clone} function (Linux)}\index{thread!clone function (Linux)@\texttt{clone} function (Linux)} kernel's [[clone]] function which can generate both new threads and
new processes \cite[pp.~22--27]{Love:2003:Linux-Kernel}.
\index{task|see {thread, process}}%

However, our first attempts led to many if-then-else constructions in the
[[u_fork]] function which reduced the readability of the code, and we also
wanted to describe process forking and thread creation separately, so we
decided against the combined treatment inside [[u_fork]]. Instead we
explain thread creation in this section, and we will provide a separate
function [[u_pthread_create]] which is loosely based on the POSIX user mode
function \verb#pthread_create#.

We're going to implement (parts of) the POSIX thread API \cite{IEEE:1995:IITa} 
inside the kernel, and the user mode library functions will simply access these 
kernel functions via system calls.

POSIX threads\index{thread!POSIX}\index{POSIX thread} need a thread identifier of some type [[pthread_t]]. We define
this public type as a pointer to a kernel-internal data structure whose
definition we will not export to user land, so we declare:

<<public type definitions>>=
typedef void *pthread_t;
typedef void pthread_attr_t;   // attributes not implemented
@ %def pthread_t pthread_attr_t

As already mentioned, a new thread differs from a new process by
sharing its creator's address space\index{address space!shared by threads of the same process}, but it still needs its own
kernel and user mode stacks---in the same
address space which the calling process currently uses.

Our implementation of the kernel's

\index{thread!creation}
%nouse
<<function prototypes>>=
int u_pthread_create (pthread_t *restrict thread, const pthread_attr_t *restrict attr,
                      memaddress start_address, void *restrict arg);
@ %
function looks similar to [[u_fork]]:

\pagebreak 

<<function implementations>>=
int u_pthread_create (pthread_t *restrict thread, const pthread_attr_t *restrict attr,
                      memaddress start_address, void *restrict arg) {
  <<begin critical section in kernel>>  // access the thread table
    thread_id old_tid = current_task;
    <<[[u_pthread_create]]: create new TCB>>
    <<[[u_pthread_create]]: fill new TCB>>
    <<[[u_pthread_create]]: create new stacks>>
  <<end critical section in kernel>>
  return 0;
}
@ %def u_pthread_create

Where [[u_fork]] starts with creating a fresh address space and reserving
a TCB, the thread only needs a TCB:

\tcbindex{for new thread (in the same process)}%
<<[[u_pthread_create]]: create new TCB>>=
thread_id new_tid = register_new_tcb (current_as);
address_spaces[current_as].refcount++;
address_spaces[current_as].extra_kstacks++;   // see below
@ %
%
We increase the [[refcount]] and [[extra_kstacks]] elements of the address 
space which lets us keep track of how often this address space is in use: 
As long as [[refcount]] is non-zero, we must not reuse the address space.
[[extra_kstacks]] has a similar but slightly different function that we
will explain further below.

Entering data in the TCB is similar to the respective step in [[u_fork]]:

<<[[u_pthread_create]]: fill new TCB>>=
TCB *t_old = &thread_table[old_tid];
TCB *t_new = &thread_table[new_tid];
*t_new = *t_old;     // copy the complete TCB
                     // note: this destroys data set in register_new_tcb_ ()
memset (&t_new->regs, 0, sizeof (context_t));
t_new->state      = TSTATE_FORK;
t_new->tid        = new_tid;
t_new->addr_space = current_as;
t_new->new        = true;         // mark new thread as new
t_new->pid        = old_tid;      // thread; pid != tid
t_new->ppid       = t_old->ppid;  // new thread has same parent as caller
@

\enlargethispage{5mm}
We need two new TCB entries to mark a thread as new and to store its
kernel stack address:
%nouse
<<more TCB entries>>=
boolean   new;                    // is this thread new?
void      *top_of_thread_kstack;  // extra kernel stack for this thread
@

\pagebreak

\index{kernel mode stack!for a new thread}%
We will give only one page of kernel stack memory to each new thread,
and we put those just under the regular kernel stack.

Remember that we've defined [[TOP_OF_KERNEL_MODE_STACK]] and
[[KERNEL_STACK_PAGES]]. We can now calculate
[[TOP_OF_KERNEL_MODE_STACK - KERNEL_STACK_PAGES * PAGE_SIZE]]
to find the lowest possible address that may be used by the
kernel stack. In principle we could have our first thread's 
kernel stack start just below, but we want to provide a
\marginnote{protective\\ buffer}protective buffer of unmapped memory: That way, whenever one
of the threads exceeds its kernel stack it will generate a
page fault (and in turn the process will be stopped).

We will provide each thread with just one page of kernel stack
memory whereas the initial process always gets four pages of
them---this is just intended to simplify the clean-up of a
process with several threads (Figure \ref{fig:kernel stacks for threads}).

\begin{figure}[b!]
\centering
\includegraphics[width=11.5cm]{pics/kernel-stacks.pdf}
\caption[\hgepolylof{Multiple kernel stacks and protective buffers.}]{Each new thread gets a single page for its kernel stack---just below the regular kernel stack but with one-page buffers of non-mapped virtual memory between the stacks.}
\label{fig:kernel stacks for threads}
\end{figure}

\pagebreak

This leads to the address calculation
\vspace{3mm}

{ \centering
[[TOP_OF_KERNEL_MODE_STACK - (KERNEL_STACK_PAGES + 2 * thread) * PAGE_SIZE]]

}
\vspace{3mm}

\noindent
where [[thread]] is 1, 2, etc.\ for the first, second, etc.\ \emph{new} thread (and it is 0 for the original kernel thread of the process). For example, for the first new thread (and assuming that [[TOP_OF_KERNEL_MODE_STACK]] = \hex{c0000000}, [[KERNEL_STACK_PAGES]] = 4) we get \hex{c0000000} $ - (4 + 2 \cdot 1) \cdot 4096 = $ \hex{c0000000} $ - 6 \cdot 4096 = $ \hex{bfffa000} which is the start address for the new stack.

We could use the address space's [[refcount]] element in our
formula (but would need to subtract 1 since it starts counting with the
initial, thread-less process). However, this only works if we assume that
a process will create several new threads and then enters a stage in which
threads will only terminate until none is left.

If thread creation is more dynamic, with new threads coming and old threads
going away, we cannot use this approach because a leaving thread will
decrease [[refcount]]. So we introduce a new [[address_space]] entry 
[[extra_kstacks]]:

\index{address space!extra entries for multiple kernel stacks}%
<<more [[address_space]] entries>>=
byte extra_kstacks;
@ which counts the number of extra kernel stacks. In a pure process (without
extra threads) its value will always be 0. We will update [[refcount]] by
increasing and decreasing it as threads come and go, but we will only
increase [[extra_kstacks]] when we add a new thread. That way, for every
new thread we can get a fresh kernel stack.

(As a side effect all extra kernel stacks will continue to exist until
the process finally terminates; more about that at the end of this chapter.)

This finally lets us calculate the bottom of the new kernel stack:

<<bottom of new kernel stack>>=
TOP_OF_KERNEL_MODE_STACK 
- ( KERNEL_STACK_PAGES + 2 * (address_spaces[current_as].extra_kstacks) ) 
  * PAGE_SIZE
@

Now we have everything that we need for stack creation. For the new user mode stack we simply increase the process' heap (via [[u_sbrk]]), and for the kernel stack we reserve a frame and update the address space. 

\index{user mode stack!for a new thread}%
<<[[u_pthread_create]]: create new stacks>>=
// create user stack
void *ustack = u_sbrk (PAGE_SIZE);
memset (ustack, 0, PAGE_SIZE);

// create kernel stack
int kstack_frame = request_new_frame ();                             // get a frame
uint kstack_start = <<bottom of new kernel stack>>;
// printf ("DEBUG: NEW THREAD STACK, frame = 0x%0x,"   // REMOVE_DEBUGGING_CODE
//         " VA = 0x%0x-0x%0x\n", kstack_frame,        // REMOVE_DEBUGGING_CODE
//         kstack_start, kstack_start+PAGE_SIZE);      // REMOVE_DEBUGGING_CODE
as_map_page_to_frame (current_as, kstack_start >> 12, kstack_frame); // map it

uint *STACK = (uint*) (kstack_start+PAGE_SIZE);     // top of new stack
t_new->top_of_thread_kstack = STACK;

*(--STACK) = 0x20 | 0x03;               // push ss (selector 0x20 | RPL3: 0x03)
*(--STACK) = (uint)ustack + PAGE_SIZE;  // push esp (for user mode)
*(--STACK) = t_old->regs.eflags;        // push eflags
*(--STACK) = 0x18 | 0x03;               // push cs (selector 0x18 | RPL3: 0x03)
*(--STACK) = start_address;             // push eip (for user mode)

t_new->esp0 = (memaddress)STACK;
add_to_ready_queue (new_tid);
@

\label{stack preparation for new thread was here}%
Compare the values that we push on the stack to the values we push in the assembler function [[cpu_usermode]] that is invoked when the very first process starts: These are the same data, except for the start address which is 0 for the initial process and the address of the thread function in case of a new thread. The reason why we need this stack setup is the same in both cases: When the [[iret]] instruction is executed, the stack has to contain the information that lets the system go back to user mode and continue execution at the right address.


\subsection{System Call for Thread Creation}

\index{thread!system call for thread creation}%
We provide a simplified user mode implementation of thread creation which ignores thread IDs and simply provides the start address of the thread function. This is possible because we will not provide a [[pthread_join]] function (that lets a thread wait for the termination of a specific other thread). The system call handler

%nouse
\index{pthread\_create system call@\texttt{pthread\_create} system call}%
\index{system call!pthread\_create@\texttt{pthread\_create}}%
<<syscall prototypes>>=
void syscall_pthread_create (context_t *r);
@ %
just calls [[u_pthread_create]] with the start address in the right place and all other arguments set to [[NULL]].

<<syscall functions>>=
void syscall_pthread_create (context_t *r) {
  // ebx: address of thread function
  memaddress address = r->ebx;
  // printf ("DEBUG: syscall_pthread_create called; "    // REMOVE_DEBUGGING_CODE
  //         "start address = 0x%08x\n", address);       // REMOVE_DEBUGGING_CODE
  u_pthread_create (NULL, NULL, address, NULL);
  // printf ("returning from pthread_create syscall\n"); // REMOVE_DEBUGGING_CODE
};
@

The next free system call number is

<<ulix system calls>>=
#define __NR_pthread_create 506
@ %def __NR_pthread_create
and we add a syscall table entry:

\pagebreak

<<initialize syscalls>>=
install_syscall_handler (__NR_pthread_create, syscall_pthread_create);
@

For the user mode library we stick with the POSIX prototype

%nouse
<<ulixlib function prototypes>>=
int pthread_create (pthread_t *thread, const pthread_attr_t *attr,
                    void *address, void *arg);
@ but as mentioned above, the only thing we pass along is the start address:

<<ulixlib function implementations>>=
int pthread_create (pthread_t *thread, const pthread_attr_t *attr,
                    void *address, void *arg) {
  return syscall2 (__NR_pthread_create, (memaddress)address);
}
@ %def pthread_create



\subsection{Terminating Threads}

\index{thread!exiting}%
In a complete POSIX thread implementation a thread can call [[pthread_exit]] to terminate, and another thread may call [[pthread_join]] to wait for that specific thread to finish. Describing [[pthread_join]] in this book would be a repetition of the code that we've shown when we discussed the process mechanisms provided by [[waitpid]] and [[exit]]: We would add another blocked queue to the system and move a thread that calls [[pthread_join]] to that queue; then the [[pthread_exit]] function would check whether there is a thread that waits for this thread and wake it up.

Since no deeper understanding is gained by this repetition, we only provide the

\index{pthread\_exit system call@\texttt{pthread\_exit} system call}%
\index{system call!pthread\_exit@\texttt{pthread\_exit}}%
%nouse
<<function prototypes>>=
void syscall_pthread_exit (context_t *r);
@ %
%
function. Note that this means that many multi-threaded code examples will not work with \UlixI{}, but from our explanation it should be clear how you could extend the \UlixI{} code so that it supports threads properly.

There is a special case we need to consider: The last thread\marginnote{last thread\\ leaving} of a multi-threaded process has two options for terminating.

\begin{itemize}
\item It can call the regular process exit function [[exit]]. This will typically be the case if it was the ``master process'' that executes the \verb#main()# function. In that case all other threads have already left via [[pthread_exit]].
\item It can alternatively call [[pthread_exit]]. The man page for [[pthread_exit]] states:

    ``After  the  last thread in a process terminates, the process terminates
    as by calling \verb#exit(3)# with an exit status of zero; thus, process-shared
    resources  are  released  and  functions registered using \verb#atexit(3)# are
    called.'' \cite{pthread-exit-manpage}
     
So in this special case (which we can detect by checking [[refcount == 1]] in the current address space) we simply call [[syscall_exit]] and let it do the work.
\end{itemize}

<<function implementations>>=
void syscall_pthread_exit (context_t *r) {
  if (address_spaces[current_as].refcount == 1) {
    // last thread leaves: use normal exit_ mechanism
    r->ebx = 0;                                 // set process exit_ code to 0
    syscall_exit (r); return;                   // and leave
  }

  <<begin critical section in kernel>>  // access the thread table
  thread_table[current_task].state = TSTATE_EXIT;
  remove_from_ready_queue (current_task);
  address_spaces[current_as].refcount--;
  thread_table[current_task].used = false;    // release TCB
  <<end critical section in kernel>>
  <<resign>>
}
@ %def syscall_pthread_exit

Again we register a system call and provide a user mode function which needs no further explanation since it simply makes the system call (and need not provide any arguments).

<<ulix system calls>>=
#define __NR_pthread_exit 507
@

<<initialize syscalls>>=
install_syscall_handler (__NR_pthread_exit, syscall_pthread_exit);
@

%nouse
<<ulixlib function prototypes>>=
void pthread_exit ();
@

<<ulixlib function implementations>>=
void pthread_exit () { syscall1 (__NR_pthread_exit); }
@ %def pthread_exit

\looseness=1
Note that the POSIX prototype for [[pthread_exit]] provides an exit value argument which we omit because in our implementation there is no way for another thread to access it.

%nouse
<<POSIX [[pthread_exit]] prototype>>=
void pthread_exit (void *value_ptr);
@


\subsubsection{Getting Rid of the Extra Kernel Stacks}

\index{kernel mode stack!getting rid of thread stacks}%
\index{address space!getting rid of thread stacks}%
In [[<<scheduler: free old kernel stacks>>]] we had included a code chunk named [[<<remove extra thread kernel stacks>>]] and given no further explanation (because at that time we only dealt with processes). Now the time has come to explain how to get rid of the extra kernel stacks.

In the overall kernel stack deletion chunk, we're in the middle of a loop (over the elements of the [[kstack_delete_list]]), and [[id]] is the ID of the current address space that we need to delete. In a regular process [[address_spaces[id].extra_kstacks]] will be 0, we don't want to touch such an address space any further. But if the value is larger than 0, we remove the extra pages:

<<remove extra thread kernel stacks>>=
if (address_spaces[id].extra_kstacks > 0)
//  printf ("DEBUG: remove extra kernel stacks, extra_kstacks = %d\n", // REMOVE_DEBUGGING_CODE
//          address_spaces[id].extra_kstacks);                         // REMOVE_DEBUGGING_CODE
while (address_spaces[id].extra_kstacks > 0) {
  uint stack = TOP_OF_KERNEL_MODE_STACK -
    (KERNEL_STACK_PAGES + 2 * (address_spaces[id].extra_kstacks)) * PAGE_SIZE;
  int frameno = mmu_p (id, stack/PAGE_SIZE);
  if (frameno != -1)  release_frame (frameno);
  address_spaces[id].extra_kstacks--;
}
@ (Note that we cannot use [[release_page]] because the address space is not active; the current page table does not point to the frames we want to free.)

For determining the start of each kernel stack we use the same formula that we used when we created the stack (see [[<<bottom of new kernel stack>>]]).


\subsection{Thread Synchronization}

We will also provide [[pthread_mutex_*]] functions for thread
synchronization. You can find the code in Chapter~\ref{sec:sync:pthread-mutex}
(which is part of the \emph{Synchronization} chapter).
\index{thread!synchronization|see {synchronization}}%



% --------------------------------------------------------------------------



\chapter{Scheduling}
\label{chap:ulix:scheduling}%

\index{scheduler}%
Every multi-tasking operating system needs a scheduler: It is the
primary OS component that allows the quasi-parallel execution of
several programs. Scheduling actually encompasses two separate tasks:

\begin{itemize}
\item deciding when to switch from one process or thread to another 
  and picking that new task
\item and actually performing the task switch (also called context witch).
\end{itemize}

The first problem is what scheduling strategies\index{scheduling strategy} are about, and this
is where researchers regularly develop new schedulers. In the introductory
theory part
(Sections~\ref{sec:monoprocessor:scheduling} and \ref{sec:multiprocessor:scheduling})
we look at some classical strategies.

For \UlixI{} we will implement the \emph{Round Robin}\marginnote{Round Robin} 
scheduling strategy,
but picking the next process or thread according to this strategy is
rather simple, so the implementation part (Section \ref{sec:task-switch})
of this chapter focuses on the context switch: Switching from one task 
to the other without breaking the system is complex.


\felix
\section{Monoprocessor Scheduling}
\label{sec:monoprocessor:scheduling}

\black
For this book we focus on scheduling strategies that work on systems
with exactly one CPU: \UlixI{} does not support more than one processor.
With several CPUs or cores (and even with hyperthreading) things get
more interesting, and multiprocessor machines can profit from 
specialized scheduling strategies (even though most standard
schedulers can be adapted to use more than one CPU, as well).


\felix
\subsection{Quality Metrics}

\index{scheduler!quality metrics}%
Scheduling is one of the best understood parts of operating systems
because it has such an important impact on system
performance. However, it is not so easy to say what the ``best
scheduler'' is because it depends very much on the definition of
quality used in a particular situation. Here are several common
quality metrics for scheduling algorithms, the more historical ones
are listed first:
%
\begin{itemize}

\index{scheduler!quality metrics!CPU usage}%
\item The metric of \emph{\vindex{CPU usage}}\marginnote{CPU usage} is one of the simplest
  notions of quality in the literature. It basically gives the
  percentage of time in which the CPU actually executed application
  instructions (in contrast to operating system instructions or being
  idle). The CPU usage is important if CPUs are very expensive (as it
  was in earlier times). Today, the CPU usage of common desktop
  computers is usually very low, since they are idle most of the time.

\index{scheduler!quality metrics!throughput}%
\item The \emph{\vindex{throughput}}\marginnote{throughput} of a system usually counts the
  number of tasks that the system executed per time unit. This metric
  depends on the definition of ``task''. It comes from a time in which
  computers did batch processing: A number of computation jobs were
  ready in a physical entry queue (for example in the form of punched
  cards). The computer then started the processing of these jobs. The
  throughput counted the number of such jobs that the system could
  execute per hour (for example).

\index{scheduler!quality metrics!turnaround time}%
\item The \emph{\vindex{turnaround time}}\marginnote{turnaround\\ time} of a thread is the time it
  takes for the thread to be scheduled again. In other words, it is
  the time between two successive selections of the thread by the
  scheduler. The turnaround time of the entire system is the average
  turnaround time of all threads. It can be regarded
  as a refined throughput metric. 

\index{scheduler!quality metrics!waiting time}%
\item The \emph{\vindex{waiting time}}\marginnote{waiting time} of a thread is the average time
  it has to wait in the ready queue before it is scheduled. This is
  not the same as throughput since times when the thread is blocked do
  not count in the waiting time.

\index{scheduler!quality metrics!response time}%
\item The \emph{\vindex{response time}}\marginnote{response time} of a thread is the time it
  takes for the thread to respond to user input. This is similar to
  the turnaround and waiting time, only that responses to user inputs
  are counted instead of being scheduled again.

\index{scheduler!real time}%
\item Finally, a scheduler is \emph{\vindex{real time}}\marginnote{real time} if it manages to
  satisfy real time constraints. \black There is a further differentiation
  into \emph{hard real time} and \emph{soft real time} which is basically 
  about the question whether it is acceptable to occasionally miss a 
  deadline. \felix

\end{itemize}

\subsection{Preemptive vs.~Non-preemptive Scheduling}

\index{scheduler!preemptive vs.\ non-preemptive}%
There are two main classes of scheduling algorithms: \emph{preemptive}
ones and \emph{non-preemptive} ones.\pindex{preemptive~scheduling}
\pindex{non-preemptive scheduling} Roughly speaking, preemptive
scheduling algorithms allow that a thread is thrown off the processor
even if that thread does not want to be thrown off. In practice, all
scheduling algorithms are usually preemptive in order to prevent that
threads (accidentally or willingly) monopolize the system.

The precise definition is as follows: A scheduling algorithm is
\emph{preemptive} if an
asynchronous interrupt can cause a thread to be taken off from the
processor.


\black
\subsection{First-Come First-Served}

\index{scheduler!first-come first-served}%
\index{first-come first-served scheduler}%
The most simple approach to scheduling processes is to have a single queue for all ready processes. Whenever the CPU is not busy, the scheduler picks the first process in the queue and lets it compute until it either terminates or blocks. After a process becomes unblocked, it is appended to the end of the queue.

This is a non-preemptive strategy that is called \emph{First Come, First Served} (\emph{FCFS}) and that can be used on old machines which do not support timer interrupts. The most important problem with this approach is that it requires cooperation of all the running processes: If one process never freely gives up the CPU, it can go on forever.

A further analysis shows that the order in which processes enter the queue influences the average \emph{service time}\marginnote{service time} (the time between entering the CPU and finishing the calculation) heavily. For example, let's assume that there are three processes P1, P2 and P3 that simultaneously come into existence. P1 needs 15 units of time, P2 and P3 need four and three units, respectively. Figure~\ref{img:sched-fcfs} shows three of the six possible ordering in which the processes can enter the queue (and thus start computing).

\begin{figure}[ht!]
\centering
\includegraphics[width=10cm]{pics/sched-fcfs.pdf}
\caption[Service times for the FCFS scheduler.]{The FCFS scheduler's service time statistics depend heavily on the processes' order of system entry.}
\label{img:sched-fcfs}
\end{figure}

In the first execution sequence, P1, P2 and P3 finish after 15, 19 and 22 units of time, respectively. That means an average service time of $(15+19+22)/3 \approx 18.7$ units of time. In the second sequence, the times are 3, 7, 22, leading to $(3+7+22)/3 \approx 10.7$ units of time, and in the last sequence, times 3, 18, 22 result in $(3+18+22)/3 \approx 14.3$ units of time. Instead of the service time we could also look at the wait time (which would be the service time minus the burst time of the process) which gives a similar result.

So, if our goal was to minimize the average service time (or wait time), it would make sense to pick the ordering in the middle which sorts processes by their runtime.


\subsection{Shortest Job First}

\index{scheduler!shortest job first}%
\index{shortest job first scheduler}%
There is a hypothetical strategy that does just that: The \emph{Shortest Job First} (\emph{SJF}) strategy always picks the job that has the shortest runtime. Thus, of all the possible orderings it will always choose the one in the middle of Figure~\ref{img:sched-fcfs}.

Why did we call it hypothetical? The problem is that in almost every case the system has no way to find out how long the next CPU burst of some process is going to be. In some rare cases where a system only executes specially prepared applications which announce their next burst length in advance, this strategy might actually be implemented, but for multi-purpose operating systems which run arbitrary programs, it is not possible. Still, it is possible to approximate this strategy. For example the operating system could collect statistical data about each process by monitoring the length of each CPU burst. Then it could calculate averages for all the bursts of a process and order the processes by their average burst times. Programs might change their behavior over time; consider a program that performs heavy calculations on a large set of data: It would start by reading in a big chunk of data (resulting in very short CPU bursts). Once the data are there, it would start the calculation (with very long bursts). Afterwards it might write them back, returning to short bursts. So in order to cater for that variability, it would make sense to discard older statistical burst data and only use the last $N$ burst times for calculating the average.

Also, once a process terminates, the system could store the collected statistical data about it in the filesystem: When starting the program again, it can make a better guess at what is about to happen.

Like FCFS, SJF is a non-preemptive strategy which does not interrupt processes. Both strategies are acceptable in non-interactive systems. But if a machine has a live user sitting in front of the machine who expects that several programs work seemingly in parallel, this is not good enough.


\subsection{Round Robin}

\index{scheduler!round robin}%
\index{round robin scheduler}%
The idea behind the \emph{Round Robin} (\emph{RR}) scheduler is the same as that for FCFS---but with interrupts which force a process off the CPU once a time limit has been reached. The maximum time that a process is allowed to execute is called a \emph{time slice}\marginnote{time slice}, and its length is an adjustable parameter of the RR strategy.

Figure~\ref{img:sched-rr} shows how an RR scheduler would treat the three sample processes from above. At the top you see the order of execution with the time slice set to four units of time, the lower part shows the sequence for a time slice of two units.

\begin{figure}[b!]
\centering
\includegraphics[width=10.5cm]{pics/sched-rr.pdf}
\caption[Time slices for a Round Robin scheduler.]{The Round Robin scheduler works with configurable time slices. Here it uses slices of four (top) and two units of time.}
\label{img:sched-rr}
\end{figure}

\pagebreak 

If a system already has an FCFS scheduler, it can easily be upgraded to an RR system: Just add a timer handler that checks how long a process has been active; if it exceeds the time slice, call the scheduler.

An open question is: What should the time slice (also called the \emph{time slot} or the \marginnote{quantum}\emph{quantum}) be? There are two adverse properties which make it non-trivial to make a decision:

\begin{itemize}
\item On the one hand, we would like the time slice as small as possible because that guarantees that each process in the ready queue will wait only a short amount of time until it can start running. That is an important property for interactive systems that want to give their users the feeling that ``things happen instantaneously''. So this should lead to the rule: Make it short.
\item On the other hand, after each time slice a context switch to the next process in the ready queue occurs (which is what we want). The downside is that this switch costs time. Let's assume that the context switch takes $n$ units of time and that we have chosen the time slice to be the same $n$ units of time. As a consequence the CPU time would be equally distributed between all the processes and the scheduler, resulting in a setup that runs with only half the possible speed because the other half is wasted by the scheduler. Obviously that is bad, so the time slice should be much larger than the context switch time. Here we get the rule: Make it long.
\end{itemize}

The answer must be some kind of compromise between the two. For interactive systems there is one property that we might be able to observe and that helps us pick the right amount: it is the typical time required to service a user interaction (like a pressed key or mouse button).

\index{scheduler!quality metrics!average interaction time}%
\index{average interaction time}\index{interaction time}%
We define the \emph{average interaction time}\marginnote{average inter-\\ action time} as follows: Assume that a process is currently blocked because it waits for an I/O event (such as a key being pressed). Once the key is actually pressed, the keyboard handler will move the process to the ready queue. The next time this process runs it will evaluate the character that was read in, and will act on that information somehow. The consequence of the pressed key will become visible, for example, an editor will display the character and move the cursor position, another program might open a menu or perform some other action. Once this observable reaction has occurred we stop the clock: The time between the reactivation of the process and now is the \emph{interaction time} for this specific interaction. Now make a collection of several representative programs (those that are typically run on the operating system) and for each such program a collection of the typical interactions. For all those interactions measure the interaction time and then calculate the average. Add a few percent to that value to be on the safe side and use that final value as the length of the RR time slice.

Figure~\ref{img:sched-rr-interaction} visualizes why this approach is helpful: It shows the treatment of one interaction by the RR scheduler; once with a time slice that was set as described above, once with a time slice that is just a bit too small. The yellow and green boxes represent the interactive process and a second process, and the striped black box shows the rest of a time slice which remained unused because the interactive process finished handling the interaction and blocked (waiting for the next key stroke). In the top part you can see the behavior that we want: The time slice is slightly larger than the interaction time which means that the process can finish treatment of the interaction in that single slice. The bottom shows the alternative with a time slice that is just a bit too small: The process is interrupted before finishing its work on the interaction, then another process executes. We have created a benign example because there are only two processes; normally you would have to expect that there are several more so the picture would be spread much wider with \emph{all} of the other process using their time slices before the interactive process gets its next chance to finish the task.

\begin{figure}[t!]
\centering
\includegraphics[width=14cm]{pics/sched-rr-interaction.pdf}
\caption[Determining time slices that serve interactive processes.]{Picking a time slice that is too small has a bad influence on interactive processes (bottom). With the right choice handling an interaction can complete in one time slice.}
\label{img:sched-rr-interaction}
\end{figure}


\subsection{Virtual Round Robin}

\index{scheduler!virtual round robin}%
\index{virtual round robin scheduler}%
\index{round robin scheduler!virtual round robin}%
There is one problem with the RR strategy: It is unfair to \marginnote{I/O-bound}\emph{I/O-bound processes}. (We define a process to be I/O-bound if it performs I/O very often and thusly uses only small parts of each of its time slices, quickly blocking again. The opposite is a \marginnote{CPU-bound}\emph{CPU-bound process} which typically uses up its time slice completely. Obviously there is a gray are between I/O-bound and CPU-bound where is process can be called neither.)

Back to the point: RR treats I/O-bound processes unfairly because they typically use just a tiny fraction of their time slice and then block. Whatever I/O activity they perform, we can assume it to take quite some time (for example, disk access is pretty slow in comparison to CPU instructions, and waiting for a key stroke takes an indefinite amount of time). Once the I/O has completed, RR adds the process to the end of the ready queue. Then it has to wait until all other processes that stand before it in the queue have either used up their time slices or blocked. If you compare the ratio between the needed CPU time (the time that the process actually executes instructions on the CPU) with the wait time, then I/O-bound processes get a much smaller value than CPU-bound ones.

There is a modification of RR that alleviates this effect, and it is called \emph{Virtual Round Robin} (\emph{VRR}). It adds a second, privileged ready queue to the scheduler that only contains processes which had not fully used up their time slices when they ran the last time. If that queue is non-empty, a VRR scheduler will always pick a process from that priority queue when the current process' time slice runs out. However, it will not grant the newly chosen process a full time slice but only the rest that was not used up the last time. 

\subsection{Priority-Based Scheduling}

\index{scheduler!priority-based}%
\index{priority-based scheduler}%
We've already used the word ``priority'' when we discussed the extra queue of the VRR scheduler. Priority-based scheduling allows each process to be treated differently by making it more or less important than a process with default settings. This can be implemented in several ways. A priority-based scheduler might give an important process a longer time slice or it might pick it more often than other processes. Depending on how fine-grained priorities can be assigned to processes, there are several choices for handling the processes (see Figure~\ref{img:sched-priority}):

\begin{figure}[t!]
\centering
\includegraphics[width=14cm]{pics/sched-priority.pdf}
\caption[Two types of priority schedulers.]{Priority-based schedulers have several possible implementations to pick from.}
\label{img:sched-priority}
\end{figure}

\begin{itemize}
\item If the number of different priorities is low, we could manage a separate queue for each priority. In that case the scheduler would always start looking for the next process in the queue with the highest priority. Only if such a queue is empty it would look down to the next queue. This can lead to \emph{starvation}\marginnote{starvation} when one of the higher queues never empties, and there are mechanisms to solve that problem, such as increasing the priority of processes which have been waiting too long.

\item Alternatively, if there are too many different priorities and we don't want the overhead of a corresponding queue collection, we can just store the priority as a numerical value in the process control block. Then the scheduler must search through the whole process table in order to find the (or one) process with the highest priority, and the queue is no longer a proper queue because the ordering in the queue is ignored by the scheduler (or only recognized if there are several processes with the highest priority). Again, such a system can lead to starvation and needs to provide a mechanism that prevents this.
\end{itemize}

Furthermore, priorities can be static or dynamic: A scheduler with \marginnote{static\\ priorities}\emph{static priorities} assigns a fixed priority to each process when it is created. It may be changed by a system call, but otherwise it remains constant throughout the lifetime of the process. When the scheduler uses \marginnote{dynamic\\ priorities}\emph{dynamic priorities} it regularly recalculates the priorities based on a set of rules. For example, such a scheduler may punish or reward a process for some specific observed behavior. Increasing the priority of processes which have been waiting for a long time (in order to avoid starvation) is an example for the use of dynamic priorities.

On Unix systems priorities are often expressed with a \marginnote{nice value}\emph{nice value}. This does sometimes lead to confusion, because the ``nicer'' a process is, the lower is its priority. Unix provides a [[nice]] system call that can set an integer value that is roughly in the interval $-20$ \dots\ 20. We write ``roughly'' because the exact values can differ from one Unix system to another; for example on a Linux\index{Linux!nice values} machine the values $-20$ to 19 are valid, on OS X the range goes from $-20$ to 20. The nice value is used by each Unix system to calculate an internal priority, and often it is not possible to set a process to the highest internal priority by changing its nice value.

\UlixI{} does not support priorities, but in Exercise~\ref{exercise:priorities} you can add that feature to the kernel.


\subsection{Multi-Level Scheduling}

\index{scheduler!multi-level}%
\index{multi-level scheduler}%
Multi-level schedulers combine the characteristics of two or more other scheduling strategies. An example is a priority scheduler that uses three queues for standard, important and urgent processes (like the one in Figure~\ref{img:sched-priority}, top) and then handles each of the queues like a Round Robin scheduler does.

A \emph{Multi-Level Feedback Scheduler} for \UlixI{} has been implemented by Markus Felsner as part of his Bachelor's thesis \cite{Felsner:2013:Bachelor} which is available online (in German). The code is based on Chapter 8 of the textbook by Remzi H.\ and Andrea C.\ Arpaci-Dusseau \cite{ArpaciDusseau14-Book}.

\pagebreak

\section{Multiprocessor Scheduling}
\label{sec:multiprocessor:scheduling}
\index{scheduler!for multiprocessors}%
\index{multiprocessor scheduler}%

If a machine has more than one CPU (or the processor has several cores, even virtual ones via hyperthreading), then things get more complicated for the scheduler. The first question is: Where should it run?

It is possible to restrict the whole kernel to run on a single, dedicated CPU that performs all the tasks which require ring 0 permissions. That would include the scheduler which would be activated regularly (via a timer, as on monoprocessor systems), and it could look at the processes running on all the CPUs and decide which processor needs a context switch to a different process. Models like these are also called \marginnote{master-slave-\\ scheduling}\emph{Master-Slave-Scheduling} because the dedicated (master) processor controls all the the other CPUs and distributes the workload. Such systems are useful for high-performance computing where machines sometimes have a large number of processors and applications require a specific numbers of CPUs to execute program threads simultaneously. In that case a scheduler will let the whole application (which needs to announce its processor requirements beforehand) wait until a sufficient number of slave processors becomes available and then create the requested number of threads and let them execute exclusively on the assigned CPUs. This is called \emph{Gang Scheduling}.\marginnote{gang scheduling}\index{gang scheduling}
\index{scheduler!gang scheduler}%

The alternative is that all processors are equals. In that case the operating system will still boot from a single processor, but during initialization it will start copies of the scheduler on each CPU. Those copies could all use the same strategy to find a new process for their local CPU, but special care must be taken so that the process queues remain consistent. For example, if two copies of the scheduler simultaneously look at the front of the ready queue, pick the same process and activate it, that process would execute twice.

Locking and other synchronization tasks become more complex when several CPUs are involved, and there's also the problem of \marginnote{cache coherence}\emph{cache coherence }\index{cache coherence problem}: In short, all CPUs have their own local cache and if those caches contain copies of the same memory region, then the system must make sure that changing the memory contents on one CPU invalidates the corresponding cache entries on all other processors.

Another important point that a multiprocessor scheduler must consider is the fact that moving a process from one processor to another one is costly because the old processor may still have parts of the process' memory in its cache (which would speed up memory access for that process) whereas the new processor's cache does not contain that memory. Modern operating systems provide the property \emph{CPU affinity}\marginnote{CPU affinity}\index{CPU affinity}\index{scheduler!CPU affinity} that tells the scheduler to keep a process assigned to a CPU. However, the more constraints are added to a system (such as: process $A$ must always run on CPU $X$), the harder it becomes to generate an equal load on all processors, and a load balancing algorithm is needed that may decide to move a process to a different CPU (with low load) even though this has some cost.

The short introduction to scheduling on multiprocessors shall suffice for this book since we focus on  monoprocessors and \UlixI{} uses only one CPU as well.


\addtocontents{toc}{\protect\parttocpagebreak}
\section{Implementation of the \UlixI{} Scheduler}
\label{sec:task-switch}%

\index{scheduler!implementation in Ulix}%
Thanks to the forking mechanism of Section~\ref{sec:processes:fork}, we can 
already have more than one process in \UlixI{}---but we still have to write 
code which lets \UlixI{} switch between several tasks. This section is mainly
about the task switch; the scheduling strategy that we use is Round Robin.
\index{task switch|see {context switch}}%
\index{context switch}

Understanding the switch basically means looking at the functions
and stacks. When switching from process $A$ to process $B$, we expect
the following to happen:

\begin{enumerate}
\item Process $A$ is executing, it runs in user mode, using its
user mode stack.
\item A timer interrupt (IRQ 0) occurs. The CPU switches to kernel mode;
this also switches the stack to the kernel stack. (Its address is
stored in the TSS structure.)
The CPU then jumps to the interrupt handler registered for interrupt 0 which
does the following:

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
\begin{Verbatim}
irq0:
    push  byte 0
    push  byte 32
    jmp   irq_common_stub

irq_common_stub:
    pusha
    push  ds
    push  es
    push  fs
    push  gs
    push  esp

    call irq_handler

    pop  esp
    pop  gs
    pop  fs
    pop  es
    pop  ds
    popa
    add  esp, 8
    iret
\end{Verbatim}
\end{multicols}

So after pushing 0 (an empty error code) and 32 (that is 32+0, where
0 is the IRQ number) onto the stack, it saves all relevant registers
on the stack and then calls [[irq_handler]] which is a C function:

\begin{Verbatim}
void irq_handler (context_t *r) {
  ...
  handler = interrupt_handlers[r->int_no - 32];
  if (handler != NULL)  handler (r);
}
\end{Verbatim}

The generic [[irq_handler]] looks up the correct interrupt service
routine for the timer (it calculates [[r->int_no-32]] which in this
case is $32-32=0$, finds the entry in [[interrupt_handlers]]
(that is [[timer_handler]]) and then calls it.

\item Next, the [[timer_handler]] checks whether it is time to call
the scheduler and (if so) calls it:

\begin{Verbatim}
if (system_ticks % 5 == 0) {
  ...
  scheduler (r, SCHED_SRC_TIMER);
  ...
}
\end{Verbatim}

The extra argument [[SCHED_SRC_TIMER]] tells the scheduler that is was
called from the timer (which is the standard case).

\item So if it decides to call the scheduler, it enters

\begin{Verbatim}
void scheduler (context_t *r, int source) {
  ...
}
\end{Verbatim}

which is the function that we have to implement.
\end{enumerate}

The sequence is similar if the interrupted process was not in user mode
but in kernel mode (in most cases because it was executing a system call),
but in that case there is no switch from ring 3 to ring 0 since the
system is already running in kernel mode. That is reflected by slightly
different stack contents since an [[iret]] (interrupt return) from the
timer handler must restore the mode that the process was operating in.


\subsection{Stack Usage}
We need to keep track of which stacks are in use and what contents
are stored on these stacks. Every process has a private user mode stack
and a private kernel mode stack.

\begin{enumerate}

\item When the current process runs (in user mode) and a timer interrupt
occurs at time $t=0$, the CPU checks the Task State Segment (TSS) to find the current
top of the stack for kernel mode: it is stored in the [[ESP0]] entry.
(It also retrieves the new value for the \register{SS} register; remember that
we have different code/data segment descriptors for user and kernel mode.)
It switches to the new stack (by changing the \register{ESP} and \register{SS} registers)
and pushes the old values of \register{SS} and \register{ESP} as well as the contents 
of \register{EFLAGS}, \register{CS} and \register{EIP} onto the new stack. \register{EIP}\index{register!EIP}\index{EIP register}
is already set to the address of the next instruction of the process: the one that
will be executed once we return to the process.
Then it starts
executing the interrupt handler code.

The kernel stack now looks like in Figure~\ref{fig:stack scheduler early}.

\begin{figure}[ht!]
\centering
\includegraphics[width=7.5cm]{pics/stack-handler-entry-2.pdf}
\caption[Kernel stack after timer interrupt occurs.]{At $t=1$ the kernel stack contains these values.}
\label{fig:stack scheduler early}
\end{figure}

\item Then, at time $t=1$, the interrupt handler entry function [[irq0]] (for IRQ 0) pushes 0 and 32 
onto the stack and jumps to [[irq_common_stub]] which pushes
\register{EAX}, \register{ECX}, \register{EDX}, \register{EBX}, 
\register{ESP} ($t=1$), \register{EBP}, \register{ESI}, \register{EDI}, 
\register{DS}, \register{ES}, \register{FS} and \register{GS}.

Finally, at time $t=2$, it pushes the current \register{ESP} which is now properly set up as the 
address of the [[context_t]] structure holding all the registers (see Figure~\ref{fig:stack scheduler entry}, also compare this to Figure~\ref{fig:stack handler entry} on page \pageref{fig:stack handler entry}).

\begin{figure}[ht!]
\centering
\includegraphics[width=9.5cm]{pics/stack-handler-entry-3.pdf}
\caption[\hgepolylof{Kernel stack before calling \texttt{irq\_handler}.}]{These are the stack contents just before executing \texttt{call irq\_handler}.}
\label{fig:stack scheduler entry}
\end{figure}

At $t=3$, the instruction [[call irq_handler]] pushes the return address and jumps
to the entry address of the C function's code.

\item When [[irq_handler]] starts, it expects to find two values on
the stack: the return address and one argument. It takes a 
[[context_t *]] as argument and we have just prepared the stack so 
that it exactly fits this structure:

\begin{Verbatim}
typedef struct {
  uint gs, fs, es, ds;
  uint edi, esi, ebp, esp, ebx, edx, ecx, eax;
  uint int_no, err_code;
  uint eip, cs, eflags, useresp, ss;
} context_t;
\end{Verbatim}

The function can then access the elements of the [[context_t]] structure.

\item [[irq_handler]] calls the C function [[timer_handler]] and passes
the pointer to our [[context_t]] structure as its single argument.

\item Lastly, [[timer_handler]] calls [[scheduler]] (passing that
pointer once more).

\item Now, [[scheduler]] is executing and it can access the register values
which we've set up on the stack early in the assembler code and passed down
all the way to the scheduler. Since we've only passed a pointer all the
time (\emph{call by reference}), the scheduler can modify the register
values. After the whole call stack unwinds later and we're back in
[[irq_common_stub]], the [[pop]]
instructions will write the modified values into the appropriate registers.
Note however that somewhere inside [[scheduler]] an address space change
will occur \emph{that will also exchange the current kernel stack with
the kernel stack that exists in the new address space} which needs to
be prepared so that the whole stack unwinding works as if no switch
had occurred. That is why we took special care to create the stack
properly in the implementation of the forking mechanism.
\end{enumerate}

Let's first assume that we do \emph{not} enter the scheduler
(because [[system_ticks % 5]] $\neq 0$). In that case we just return
and do not modify anything relevant to scheduling---we expect the
current process to continue running, as it does after other
interrupt treatments.

If we've just entered the [[scheduler]], what does the stack look like
right now? In comparison to Figure~\ref{fig:stack scheduler entry}, there
will be further return addresses and references to the [[context_t]]
structure on the stack, since each function passes it, but we don't 
really have to care because all the important information is available 
via the pointer [[r]] to the [[context_t]].

Note again that at the beginning of the interrupt handling we stored the
contents of all registers on the stack, in just the order which
conveniently fits the [[context_t]] structure definition. We also
pass the pointer to this structure to all further functions which
get called (when calling [[handler(r)]] and then [[scheduler(r)]]).
So within the [[scheduler]] we can look at [[r]] to see the state
as it was before the timer interrupt occurred. 

Whether we've come from user mode or from kernel mode (e.\,g. from
a process that was executing a system call when the timer interrupt
fired) does not matter since all relevant registers have been saved 
and will be restored.


\subsection{The Implementation}

When we schedule, we select the new process and then store all 
registers (the data that [[r]] points to) in the old TCB. Then we switch 
the address space (the CPU's pointer to the page directory), and then 
we load the new TCB contents in the registers. After that we can
return.

Our scheduler has the protoype
%nouse
<<function prototypes>>=
void scheduler (context_t *r, int source);
@ %
which---as expected---takes a [[context_t]] pointer as its first
argument. We introduce the second argument [[source]] because we
also call the scheduler from within other kernel functions.
(Right now we only discuss how it is called from the timer handler,
but you have already seen us calling it from [[syscall_resign]]
which was needed by [[syscall_waitpid]].)

The following two macros will allow the system to temporarily
disable (and reenable) scheduling. During system initialization
we've set [[scheduler_is_active]] to [[false]]; it is changed
to [[true]] in the [[start_program_from_disk]] function which
creates the first process.

<<enable scheduler>>=
scheduler_is_active = true;   _set_statusline ("SCH:ON ", 16);
@

<<disable scheduler>>=
scheduler_is_active = false;  _set_statusline ("SCH:OFF", 16);
@

We declare two global variables in the kernel address space which
will later come in handy when we have to remember information about
the current and next process:

<<global variables>>=
TCB *t_old, *t_new;
@ %def t_old t_new

\noindent
These are not affected by changing the address space because they
are in the region above \hex{c0000000} which is identical in all
address spaces. This is important! If those variables were defined
locally in the [[scheduler]] function, they would reside in the
\index{context switch!losing values on the stack}%
\index{kernel mode stack!during context switch}%
kernel stack and get lost when the address space changes. Note
that the scheduling code is a critical section, and there are two
further exit points in the function at which we explicitly leave
the critical section.

<<function implementations>>=
void scheduler (context_t *r, int source) {
  // debug_printf ("*");                    // REMOVE_DEBUGGING_CODE
  debug_printf ("ENTER scheduler\n");       // REMOVE_DEBUGGING_CODE
  <<begin critical section in kernel>>
  <<scheduler implementation>>
  debug_printf ("LEAVE scheduler\n");       // REMOVE_DEBUGGING_CODE
  <<end critical section in kernel>>
  return;
}
@ %def scheduler

Our implementation starts with checking whether there are any 
\emph{zombie} processes and tries to get rid of them (see further down).
Then it looks at the global variable
<<global variables>>=
int scheduler_is_active = false;
@ %def scheduler_is_active
to determine whether it shall try to actually attempt a context switch.

\pagebreak

<<scheduler implementation>>=
<<scheduler: check for zombies>>     // deal with zombies if we have any
if (!scheduler_is_active) {          // check if we want to run the scheduler_
  <<end critical section in kernel>>
  return;
}
@

\noindent
With all obstacles removed, the real scheduling process can begin. The scheduler
lets [[t_old]] point to the current process and then finds out which process
it should switch to, storing the result in [[t_new]]. Then it performs the
context switch, and before returning to the new current process it checks 
whether that process has any pending signals and whether there is some clean-up
to be done for terminated processes. (This last step could be handled elsewhere,
for example via one of the [[<<timer tasks>>]].)

<<scheduler implementation>>=
t_old = &thread_table[current_task];
debug_printf ("SCHED: enter find next\n");
<<scheduler: find next process and set [[t_new]]>>
debug_printf ("SCHED: leave find next\n");
if (t_new != t_old) { 
  <<scheduler: context switch>> 
}
<<scheduler: check pending signals>> // see chapter on signals
<<scheduler: free old kernel stacks>>  // if there are any 
@

\noindent
We will implement the code chunk [[<<scheduler: check pending signals>>]] in
Chapter~\ref{chap:ulix:signals} where we introduce signals. Note that the
[[<<scheduler: find next process and set [[t_new]]>>]] chunk implements
the scheduling logic, whereas all the other code is about technical details
of the context switch.


\subsubsection{A Simple Round-Robin Strategy}

\index{round robin scheduler!implementation in Ulix}%
\index{scheduler!round robin!implementation in Ulix}%

\UlixI{} does not attempt any sophisticated scheduling strategy; we will just use a simple Round Robin system. The search for the next process will normally use the [[next]] pointer in the current TCB since it will point to the next TCB in the ready queue. However there's a special case when the scheduler was activated because the current process called [[waitpid]]; in that case the former current process has already been moved to a blocked queue and we need to start over. We can recognize that case by evaluating the [[source]] argument and looking at the state of the current process. If it is not [[TSTATE_READY]] then we must start over (with the first element of the ready queue which is stored in [[tid = thread_table[1].next]]).

We also might come across the idle process (which has the thread ID 1); if so we skip it in the search of ``real'' processes that need some work done. (We could have left that process completely out of any queues since it will never block but always be ready.)

\pagebreak

<<scheduler: find next process and set [[t_new]]>>=
thread_id tid;
search:  // goto label
if (source == SCHED_SRC_RESIGN && t_old->state != TSTATE_READY) {
  // printf ("DEBUG: resigner not active; state=%d, "      // REMOVE_DEBUGGING_CODE
  //         "old->next.state = %d\n", t_old->state,       // REMOVE_DEBUGGING_CODE
  //         thread_table[t_old->next].state);             // REMOVE_DEBUGGING_CODE
  // we cannot use the ->next pointer
  debug_printf ("scheduler called from "                   // REMOVE_DEBUGGING_CODE
    "syscall_waitpid(). tid(old) = %d, ", tid);            // REMOVE_DEBUGGING_CODE
  tid = thread_table[0].next;   
  debug_printf ("tid(new) = %d\n", tid);                   // REMOVE_DEBUGGING_CODE
} else {
  tid = t_old->next;
}
if (tid == 1) tid = thread_table[1].next;    // ignore idle_ process
@

If [[tid]] is 0, we have reached the end of the queue---or the queue may be completely empty (in which case we activate the [[idle]] process):

<<scheduler: find next process and set [[t_new]]>>=
if (tid == 0)                    // end of queue reached
  tid = thread_table[1].next;
if (tid == 0)                    // still 0? run idle_ task
  tid = 1; // idle_
t_new = &thread_table[tid];
if (tid > 1 && (t_new->addr_space == 0 || t_new->state != TSTATE_READY)) {
  goto search; // continue searching
}
// found it
@


\subsubsection{The Context Switch}

Before implementing the actual context switch, let's first observe the 
following facts:

\begin{itemize}
\item We only enter the scheduler (and thus also the context switcher) via
timer interrupts or when a functions resigns (i.\,e., freely gives up the CPU
by calling [[resign]]) or calls [[waitpid]].

\item Once we're running inside the scheduler, we know that the kernel
stack has been set up in a way that will allow the system to continue
operation of the interrupted process---whether it was running in user mode
or kernel mode before the interrupt occurred.

\item When we switch the address space, we also switch the kernel stack.
However, the stack pointer register \register{ESP} will still point to the
top of the old process' kernel stack. We need to remedy that and have it
point to the top of the new process' kernel stack.

\item If we switch between threads (within one process) we need not change
the address space.
\end{itemize}

\noindent
To make the code more readable, we provide some macros which copy values
between variables and the \register{ESP}, \register{EBP} and 
\register{CR3}\index{CR3 register}\index{register!CR3}\index{context switch!store new page directory address in CR3} registers. They require the use of inline assembler code
(see Appendix~\ref{sec:assembler:inline}).

\pagebreak

<<macro definitions>>=
#define COPY_VAR_TO_ESP(x)  asm volatile ("mov %0, %%esp" :         : "r"(x) )
#define COPY_VAR_TO_EBP(x)  asm volatile ("mov %0, %%ebp" :         : "r"(x) )
#define COPY_ESP_TO_VAR(x)  asm volatile ("mov %%esp, %0" : "=r"(x)          )
#define COPY_EBP_TO_VAR(x)  asm volatile ("mov %%ebp, %0" : "=r"(x)          )
#define WRITE_CR3(x)        asm volatile ("mov %0, %%cr3" :         : "r"(x) )
@ %def COPY_VAR_TO_ESP COPY_VAR_TO_EBP COPY_ESP_TO_VAR COPY_EBP_TO_VAR WRITE_CR3

Now we can present the code that handles the actual context switch. It is only 
executed if we truly switch, i.\,e., if [[t_new]] $\neq$ [[t_old]]. In principle, 
we would expect something along the lines of
%nouse
<<scheduler: context switch (simplified version)>>=
t_old->regs = *r;                    // store old:   registers
COPY_ESP_TO_VAR (t_old->esp0);       //              esp (kernel)
COPY_EBP_TO_VAR (t_old->ebp);        //              ebp

current_task = t_new->tid;           // update values of current_{task,as,pd}
current_as   = t_new->addr_space;
current_pd   = address_spaces[t_new->addr_space].pd;
WRITE_CR3 ( mmu (0, current_pd) );   // activate address space
  
COPY_VAR_TO_ESP (t_new->esp0);       // restore new: esp
COPY_VAR_TO_EBP (t_new->ebp);        //              ebp
*r = t_new->regs;                    //              registers
@ but it is a little more complicated since we also have to check whether we do want to change the address space (if not, then we can save some CPU time by omitting that step), and we also need to change the TSS's \verb#esp0# entry and handle some special cases for newly created processes or threads. So the actual code is a bit more complex:

<<scheduler: context switch>>=
t_old->regs = *r;                    // store old:   registers
COPY_ESP_TO_VAR (t_old->esp0);       //              esp (kernel)
COPY_EBP_TO_VAR (t_old->ebp);        //              ebp
current_task = t_new->tid;
if (current_as != t_new->addr_space) {
  // we need to change the address space (switching process, not thread)
  current_as   = t_new->addr_space;
  current_pd   = address_spaces[t_new->addr_space].pd;
  WRITE_CR3 ( mmu (0, (memaddress)current_pd) );   // activate address space
}
// else {                                                                  // REMOVE_DEBUGGING_CODE
// debug_printf ("thread switch, tid %d -> %d, esp: 0x%08x -> 0x%08x\n",   // REMOVE_DEBUGGING_CODE
// t_old->tid, current_task, t_old->esp0, t_new->esp0);                    // REMOVE_DEBUGGING_CODE
// }                                                                       // REMOVE_DEBUGGING_CODE
COPY_VAR_TO_ESP (t_new->esp0);       // restore new: esp
COPY_VAR_TO_EBP (t_new->ebp);        //              ebp       chunk continues ->
@

\index{TSS (task state segment)!update during context switch}%
\index{task state segment!update during context switch}%
\index{context switch!update TSS}%
We must update the TSS structure and enter the address of the kernel stack; that is either [[TOP_OF_KERNEL_MODE_STACK]] (for a pure process or the primary thread of a multi"=threaded process, i.\,e., one with [[pid == tid]]) or it is [[t_new->top_of_thread_kstack]] for a non-primary thread ([[pid != tid]]):

<<scheduler: context switch>>=
// set TSS entry esp0 to top of current kernel stack and flush TSS
if (t_new->pid != t_new->tid) {
  // thread kstack information is stored in the TCB
  write_tss (5, 0x10, t_new->top_of_thread_kstack);       // non-primary thread
} else {
  // process kstack is a fixed value
  write_tss (5, 0x10, (void*)TOP_OF_KERNEL_MODE_STACK);   // primary thread
}
tss_flush ();

// show thread ID in status line
if (t_new->tid != 1) {  // ignore switch to idle_
  char msg[4]; sprintf (msg, "%03x", t_new->tid);
  _set_statusline (msg, 20);
}

<<scheduler: switching to a fresh thread?>>    // check special case
*r = t_new->regs;               // restore new: registers
@

Remember: [[write_tss]] sets the [[ESP0]] element of the TSS
structure. It is only used when the CPU switches
from ring 3 to ring 0 (in general: whenever it switches from
ring 1--3 to ring 0, but \UlixI{} does not use rings 1 and 2),
and that means we can always start with an empty kernel stack
in those situations: Thus we can always write the address of
the stack's top into that element.

Finally, we need to consider the special case of switching to a freshly created thread: On page~\pageref{stack preparation for new thread was here} we have prepared the new thread so that we can immediately leave with the [[iret]] instruction.

<<scheduler: switching to a fresh thread?>>=
if (t_new->new && t_new->tid != t_new->pid) { 
  // new thread
  debug_printf ("DEBUG: new thread (not process), new ESP: 0x%08x\n", t_new->esp0);  // REMOVE_DEBUGGING_CODE
  t_new->new = false;
  <<end critical section in kernel>>
  asm ("iret");     // return from interrupt handler, do not update r
}
@

In this case the rest of the [[scheduler]] function (the code chunks [[<<scheduler: check pending signals>>]] and [[<<scheduler: free old kernel stacks>>]]) is not executed, but that is no problem; we can handle that with the next invocation of the scheduler.


\subsubsection{Treating Zombie Processes}

\index{scheduler!remove zombie process}%
\index{zombie process!removal in the scheduler}%
\index{process!zombie!removal in the scheduler}%
We still need to check for \emph{zombies}: A zombie is a terminated process whose parent 
process has not yet been able to retrieve the return value (supplied via [[exit]]).
There are two possible cases:

\begin{enumerate}
\item The parent is waiting. This means that it has called [[waitpid]] \emph{after} this process turned into a zombie, because otherwise it would not exist anymore. In that case we deblock the parent process and delete the zombie's entry in the thread table.

\item The [[ppid]] ID of the zombie process was set to 1. That means that its true parent exited without calling [[waitfor]]. Here, we can also remove the zombie, and there is nothing else to do: No process is waiting (or will ever be) for that process.
\end{enumerate}

<<scheduler: check for zombies>>=
for (thread_id pid = 0;  pid < MAX_THREADS;  pid++) {
  if (thread_table[pid].state == TSTATE_ZOMBIE) {
    thread_id ppid = thread_table[pid].ppid;
    
    // case 1: parent is waiting
    if ( (thread_table[ppid].state == TSTATE_WAITFOR) &&
         (thread_table[ppid].waitfor == pid) ) {
      debug_printf ("exit: remove_from_blocked_"       // REMOVE_DEBUGGING_CODE
                    "queue (%d,%x)\n",                 // REMOVE_DEBUGGING_CODE
                    ppid, &waitpid_queue);             // REMOVE_DEBUGGING_CODE
      deblock (ppid, &waitpid_queue);
      thread_table[pid].state = TSTATE_EXIT;
      thread_table[pid].used = false;
    }
    
    // strange case                                     // REMOVE_DEBUGGING_CODE
    if ( (thread_table[ppid].state == TSTATE_WAITFOR) && // REMOVE_DEBUGGING_CODE
         (thread_table[ppid].waitfor != pid) ) {        // REMOVE_DEBUGGING_CODE
      // output debug message                           // REMOVE_DEBUGGING_CODE
      debug_printf ("Strange: process %d has "          // REMOVE_DEBUGGING_CODE
                    "parent %d, but parent waits "      // REMOVE_DEBUGGING_CODE
                    "for process %d\n", pid, ppid,      // REMOVE_DEBUGGING_CODE
                    thread_table[ppid].waitfor);        // REMOVE_DEBUGGING_CODE
    }                                                   // REMOVE_DEBUGGING_CODE
    // case 2: parent ID was set to 1 (idle_)
    if ( ppid == 1 ) {
      thread_table[pid].state = TSTATE_EXIT;
      thread_table[pid].used = false;
    }
  }
}
@



\subsection{Letting the \texttt{init} Process Idle}
\label{sec:processes:idle}%

As a last topic for this chapter we discuss the \verb#idle# process with process ID 1. It starts as the [[init]]\marginnote{\texttt{init} $\rightarrow$ \texttt{idle}} process, but once it has spawned some other processes, it will turn into the \verb#idle# process. If it becomes active it shall do nothing. However, if we interpret ``nothing'' as an empty infinite loop ([[for(;;);]]) then the system will always actively spin in this loop whenever no other process is ready---that uses processor power.

There is a better way: The assembler\index{Assembler language!hlt instruction@\texttt{hlt} instruction} instruction [[hlt]] (halt) can stop the CPU until the next interrupt occurs. We provide a system call that executes this instruction and use it in the \verb#idle# process:

\pagebreak
\index{idle system call@\texttt{idle} system call}%
\index{system call!idle@\texttt{idle}}%
%nouse
<<syscall prototypes>>=
void syscall_idle (context_t *r);
@

<<public constants>>=
#define __NR_idle 505
@ %def __NR_idle

<<syscall functions>>=
void syscall_idle (context_t *r) {
  <<enable interrupts>>
  asm ("hlt");
  <<disable interrupts>>
}
@ %def syscall_idle

<<initialize syscalls>>=
install_syscall_handler (__NR_idle, syscall_idle);
@

In the user mode library we add an [[idle]] function:

%nouse
<<ulixlib function prototypes>>=
inline void idle ();
@

<<ulixlib function implementations>>=
inline void idle () { syscall1 (__NR_idle); }
@ %def idle

When the system starts, [[start_program_from_disk]] loads the \verb#/init# program from disk whose source code we have already shown on page~\pageref{source code for init.c}. It starts the program \path!/bin/login! (via [[execv]]) which in turn launches some new processes (\verb#/bin/swapper#, see  page~\pageref{source code for swapper.c}, and a few login processes that let users log in on the virtual consoles). When that is done it becomes the \verb#idle# process via

\index{init process@\texttt{init} process!becomes the \texttt{idle} process}%
\index{idle process@\texttt{idle} process}%
<<init to idle transformation>>=
setpsname ("[idle]");
for (;;) {
  idle ();   // if we don't call idle, we will have 100% CPU usage
} 
@


\pagebreak
\section{Exercises}

\begin{enumerate}
% start with ex. 26 
\setcounter{enumi}{25}

\item \textbf{Scheduling with the [Esc] Key}

The \path!tutorial/07/!\marginnote{Tutorial 7} folder contains a new version of the mini \UlixI{} kernel which includes the \verb#fork()# and \verb#schedule()# functions. Again, it is a literate program (\path!ulix.nw!). However the scheduler is never called: Normally the timer handler would have to do that, but it is not part of that kernel version. In this exercise you introduce a manual scheduling that can be initiated by pressing the [Esc] key.
\vspace{-3mm}

\begin{enumerate}
\item Look at the user mode program \path!test.c! whose machine code version is already part of the kernel sources. Its \verb#main()# function creates a new process via \verb#fork()#, afterwards parent and child write ``P'' (for parent) or ``C'' (child) on the screen in infinite loops:

\begin{Verbatim}
int main () {
  printf ("Hello - User Mode!\n");
  int pid = fork ();
  for (;;) {
    if (pid == 0) printf ("C");  // child
    else          printf ("P");  // parent
  }	
}
\end{Verbatim}

Start the \UlixI{} version (using [[make]] and [[make run]]). You will see that the system displays only ``V''s, the child process does not run. (If you compile the same program for Linux\index{Linux} and run it, you see alternating sequences of ``P''s and ``C''s.)

\item The scheduler is implemented in the \verb#scheduler()# function, just like it is in the real \UlixI{} kernel. You can test it by adding a check for a pressed [Esc] key to the keyboard handler. That key has scan code 1. Locate the \verb#keyboard_handler()# function and add the following test for scan code 1 right after it was read with \verb#inportb()#:

\begin{Verbatim}
  if (s == 1) {
    scheduler (r, 0);
    return;
  }
\end{Verbatim}

When you recompile and start the kernel, you will see ``P''s again. But pressing [Esc] will switch to the child process, so that the output sequence changes to ``C''s. Every further time you press [Esc], the process will switch again.
\end{enumerate}

\item \textbf{Calling the Scheduler from the Timer Handler}

Now you add a timer handler which will regularly call the scheduler and thus automatize the multi-tasking.
\vspace{-3mm}

\begin{enumerate}
\item Start with removing the scheduler call from the keyboard handler that you added in the previous exercise; you can simply turn it into a comment.

\item We also need the timer handler to update a global \verb#ticks# variable so that we can see how long the system has been running. Define it like this:

\begin{Verbatim}
unsigned long int ticks
\end{Verbatim}

and initialize it to 0. (Which code chunk to you have to append to in order to declare and initialize variables?) Don't add this code in earlier definitions of the chunks but create your own section at the end of the document where you put additions to the earlier chunk definitions.

Implement a function \verb#timer_handler# with the same prototype that all the other interrupt handlers have, e.\,g., the keyboard handler. Its first task is to increment the \verb#ticks# variable. Afterwards call the scheduler:

\begin{Verbatim}
scheduler (r, 0);
\end{Verbatim}

With these changes the timer is already functional, but you still have to register it and enable the timer interrupt. Write an addition to the code chunk [[<<kernel main: initialize system>>]] where you put appropriate function calls. (You can check how \UlixI{} does that for the keyboard handler.) The interrupt number for the timer is defined as [[IRQ_TIMER]] (and has the value 0).

Compile and start the modified kernel. Now the output of ``V''s und ``S''s should switch automatically: Every time the hardware generates a timer interrupt, \UlixI{} will switch between the two processes.

\item As we discussed in this chapter, task switches cost time. It makes sense to let a process run for a longer time before the scheduler takes away the CPU and gives it to another process. You can achieve this behavior by only calling the scheduler if \verb#ticks# is some multiple of a given number, e.\,g.\ 5. With

\begin{Verbatim}
(ticks % 5 == 0)
\end{Verbatim}

you can check whether \verb#ticks# is a multiple of 5. Call the scheduler only when that condition evaluates to true. That reduces the amount of scheduler invocations (per time) to a fifth of what it was before. You can also test how different values (e.\,g.\ 25, 100) change the overall behavior.

\item The current code in \verb#scheduler()# supports exactly two processes which use the TCBs 1 and 2. That makes it rather simple to determine which process comes next. How would you have to modify the function so that it supports exactly four processes instead of two?

\end{enumerate}

\end{enumerate}

\noindent
Until\marginnote{Tutorial 8} now all exercises used a stripped-down version of the \UlixI{} kernel which evolved from exercise to exercise, mimicking the progress throughout the book. For the following two tasks you will work with real kernel sources. This is not the version that is presented in the book (because the exercises were developed before the \UlixI{} implementation was complete), but it is a usable system with full user mode and filesystem support. You will now add new capabilities to the system.

Use the code that you find in the \path!/home/ulix/ulix/! folder for the following two exercises.

\begin{enumerate}
% start with ex. 28 
\setcounter{enumi}{27}


\item \textbf{Boost: Run Only This Process}
% Projekt-Aufgabe W3

The scheduler which is called by \verb#timer_handler# every five ticks chooses the next process in the ready queue. In this exercise you give a process a chance to prevent this switch (so that it can go on longer). By using the function 

\begin{Verbatim}
void boost (int n);
\end{Verbatim}

it shall be able to set a global variable (global in the \UlixI{} kernel). The timer handler shall then use one of the [[<<timer tasks>>]]) to check whether this value is 0. If not, it decrements the variable and performs no context switch.

\begin{enumerate}
\item Declare a global variable \verb#int boost_count# and initialize it to 0. As in the last exercise you need to find the appropriate code chunks for these two actions.

\item Move the [[<<timer tasks>>]] code chunk that calls \verb#scheduler()# into your own section of the literate program file so that you can document the changes to the chunk. It is this chunk:

\begin{Verbatim}
@<<timer tasks>>=
// Every 5 clocks call the scheduler
if (system_ticks % 5 == 0) {
  [...]
  scheduler (r, SCHED_SRC_TIMER);  // defined in the process chapter
  [...]
\end{Verbatim}

\item Modify the [[if]] clause; the extra condition [[boost_count == 0]] must also be fulfilled. You will also need to add an [[else]] case which decrements [[boost_count]].

\item Write a syscall handler

\begin{Verbatim}
void syscall_boost (context_t *r);
\end{Verbatim}

that reads the right processor register (which one is that?) and copies its value to [[boost_count]] (if it is positive or 0). Define a syscall number constant [[__NR_boost]] (using a syscall number that is not yet in use) and add an [[install_syscall_handler()]] call to the right code chunk.

\item Write a user mode library function

\begin{Verbatim}
void boost (int n);
\end{Verbatim}

that uses [[syscall2()]] to make the system call. You can look at the implementation of \verb#open()# to see how that can be done.

\item Finally, write a small user mode application that lets you test the effect of calling [[boost()]].
\end{enumerate}

(Note that you need not implement a corresponding [[u_boost]] function which gets called by [[syscall_boost]]: It would just contain the one line

\begin{Verbatim}
void u_boost (int n) { boost_count = n; }
\end{Verbatim}

so there is no point in writing an extra function for that task.)


\item \textbf{Process Prioritization}
% Projekt-Aufgabe B2
\label{exercise:priorities}
\index{scheduler!priority-based}%
\index{priority-based scheduler}%

All \UlixI{} processes (or threads) receive equal treatment by the \UlixI{} scheduler because the system does not know priorities. In this exercise you add the classical priority mechanism present in all Unix systems.

\begin{enumerate}
\item Add a nice value ([[int nice]]) to the thread control block that will hold values between $-20$ and 19, the default value is 0. If a process forks, it will pass the nice value on to the child process.

\item Implement a function [[int u_setpriority (int nice)]] that can be used for changing the current process' nice value to the supplied value. You will also need corresponding functions [[syscall_setpriority]] in the kernel and [[int setpriority (int nice)]] in the user mode library. (The return value of [[u_setpriority]] or [[setpriority]] is the new nice value.) The prototype differs from the [[setpriority()]] function on Linux\index{Linux!setpriority function@\texttt{setpriority} function} systems, but looking at the man page on a Linux box can still be helpful.

\item In the [[<<timer tasks>>]] chunk, modify the code block

\begin{Verbatim}
if (system_ticks % 5 == 0) {
  [...]  
  scheduler (r, SCHED_SRC_TIMER);  // defined in the process chapter
  [...]
\end{Verbatim}

so that the decision whether the scheduler is called depends on the current process' nice value (that you can find in [[thread_table[current_task].nice]]). You have several options for doing this, but the result should be that a process with a lower nice value receives a longer time slice than a process with a larger nice value.

\item Write a test program that lets you check whether changing the nice values really changes the behavior of the process. You will need at least two processes (one that calls [[setpriority]] and one that does not) in order to observe any effect.
\end{enumerate}

\end{enumerate}



%------------------------------------------------------------------------------------


\chapter{Handling Page Faults}

\index{page fault}\index{page fault handler}\index{fault handler!page fault handler|see {page fault handler}}%
\label{chap:pagefault}%
Recall what happens every time the machine accesses a memory address, either for receiving the next instruction or for reading or storing data: the address that the processor asks for is a virtual address, and it must first be translated to a physical address by the MMU. Special register \register{CR3} tells the MMU\index{memory management unit} what page directory to use, and that directory reveals the location of a page table which is in turn accessed to (finally) find the physical frame number and calculate the complete physical address by adding the offset (within the page).

In many cases this procedure will fail at some point, typically because either the page directory or the page table contains an entry which tells the MMU that the page does not exist in memory. This means that address translation cannot continue, and the CPU raises a 
\emph{page fault}\marginnote{page fault}.

Every operating system needs to handle such page faults, the minimum action that is required is either killing a process (which has tried to access an illegal address) or halting the operating system (if the faulting instruction occurred inside code which was not executed on behalf of some process). But we expect our fault handler to be better than that and also handle the following situations:

\begin{itemize}
\item \textbf{User mode stack grows:} When a user mode program uses recursion or makes extensive use of the stack  for other reasons, it will soon cross into a memory range just below the reserved stack space and cause a page fault. In that case the process can rightly expect the stack to grow automatically\marginnote{automatic\\ stack growth}. Thus, \UlixI{} will check whether a memory area just below the current end of the stack was accessed---and if so, increase the stack by one page. Afterwards, execution of the process can resume.

\pagebreak

\item \textbf{Access to page which was paged out:} In Sections \ref{sec:swapfile} ff.{} we will introduce a swap file\footnote{Note that we use the term ``swap file'' and not ``page file''. \UlixI{} does not implement swapping which is an older technique where whole processes are removed from memory. Instead we move single pages to disk and back, but historically a file or a partition used for swapping was called swap file/swap partition, and that name lives on in paging systems, e.\,g.{} in Linux\index{Linux!swap file} and other Unix-like systems.} and show code for moving pages of memory to disk and back. That will become necessary when the whole physical memory is in use and there are no further free page frames.
\end{itemize}


\section{The \UlixI{} Page Fault Handler}
\label{sec:page fault handler}%

\index{page fault handler!implementation in Ulix}%
In this section we present the page fault handler that we implemented for \UlixI{}. The handler function has the prototype of all other fault handlers:
%nouse
<<function prototypes>>=
void page_fault_handler (context_t *regs);
@ and we originally started by taking code from James Molloy's kernel tutorial \cite[Ch. 6.4.5]{molloy:2008:kernel-tutorial} (which just gives some information about the faulting reason and address) and then added some features which make it usable in \UlixI{}.

The \register{CR2}\marginnote{\register{CR2}, \texttt{err\_code}} register holds the virtual address which caused the page fault, and the [[err_code]] element of the context tells us more about why the access to this address failed, so this is the first information we need to gather. Individual bits of [[err_code]] describe whether the page that was accessed is present, read-only or only accessible in kernel mode.

Then we check the possible reasons for a page fault and handle them as well as we can:

\begin{itemize}
\item First, if the page was paged out to disk (see next section), we bring the page back in. In that case we can simply leave the fault handler with [[return]], and the running process will resume its operation, repeating the instruction that caused the fault at the first attempt. (Actually [[return]] jumps back into the generic [[fault_handler]] function which then returns to [[fault_common_stub]] in \path!start.asm!, and the transition back to the process occurs in the assembler\index{Assembler language!iret instruction@\texttt{iret} instruction} code via the [[iret]] instruction.) 
\item Then we check whether the process tried to access an address directly below the user mode stack. That will often occur when a function calls itself recursively. In that case we increase the stack and also [[return]].
\end{itemize}

These two conditions are recoverable, but there are other situations in which we either have to kill the faulting process or---worst case---permanently disable user mode and jump to a safe kernel function such as the kernel shell that we have included for debugging purposes.
\begin{itemize}
\item If a process tried to access an invalid address, and we can neither bring it back by paging in a paged-out page nor can we help the situation by increasing the user mode stack, then it was likely caused by a programming error and we need to kill the process. We check that condition by testing whether the faulting instruction's address is below the kernel's memory address range ([[r->eip < 0xc0000000]]). In that case the system can continue running, minus the killed process.
\item Last, we must assume that an error in the kernel caused the page fault. Then there's nothing to do since the failed instruction is part of the kernel code and there is no simple way to resume after such a problem. We might try to write a memory dump to disk or provide some other means that might help debugging the code, but here we just jump to the kernel shell (from which we cannot return to user mode anymore). If that kernel shell was not available, we would simply halt the machine completely.
\end{itemize}

Our implementation of the page fault handler

<<function implementations>>=
void page_fault_handler (context_t *r) {
  <<page fault handler implementation>>
}
@ %def page_fault_handler
%
starts with gathering all the available information:

<<page fault handler implementation>>=
memaddress faulting_address;
asm volatile ("mov %%cr2, %0" : "=r" (faulting_address));   // read_ address
int present   = !(r->err_code & 0x1);   // page present?
int rw = r->err_code & 0x2;             // attempted to write_?
int us = r->err_code & 0x4;             // CPU in user-mode (ring 3)?
int reserved = r->err_code & 0x8;       // overwritten CPU-reserved bits of 
                                        // page entry?
int id = r->err_code & 0x10;            // caused by an instruction fetch?

<<page fault handler: check if page was paged out>>   // see next section
@ %
%
In the last line from above it checks whether the page was paged out to disk; we will describe that in the following section where we introduce the swap file.

The second benign case of a page fault occurs when the user mode stack needs to grow. We can check that condition by looking at the current end of the user mode stack and calculating whether adding one extra page would solve to problem---if so, we give the process that extra page. Otherwise (if the address is too far away from the stack) we cannot help this process:

<<page fault handler implementation>>=
if (faulting_address <= TOP_OF_USER_MODE_STACK && 
    faulting_address >= 
    TOP_OF_USER_MODE_STACK-address_spaces[current_as].stacksize - PAGE_SIZE) {
  <<page fault handler: enlarge user mode stack>>  // user mode, stack
  return;
}
@ Note that this restricts user mode processes in the way they use the stack. For example, you cannot write a function that takes so many (or so large) arguments that its invocation would increase the stack by more than one page. So depending on the kinds of applications you want to run on \UlixI{}, you might want to modify the above code chunk.

If neither of the first two cases is applicable, then there's a real problem. With the rest of the code we try to determine how big that problem is: It may be sufficient to kill the current process, or we may have to halt the system. First we write an error message to the screen. Here, we also use the old code chunk [[<<fault handler: display status information>>]] from the generic fault handler that we implemented earlier in Chapter~\ref{sec:faults}.

The same chapter also contains the [[<<fault handler: terminate process>>]] chunk that we recycle when we decide to kill the current process. We do that if the faulting address is in the user space of virtual memory, i.\,e., below \hex{c0000000}. The old code chunk simply removes the process from the ready queue and calls [[syscall_exit]]. The \verb#exit# system call handler will then return the process' resources and launch the scheduler which finally picks another process.


<<page fault handler implementation>>=
printf ("Page fault! ( ");              // write_ error message.
if (present) printf ("present ");    if (rw) printf ("re" "ad-only ");
if (us)      printf ("user-mode ");  if (id) printf ("instruction-fetch ");
printf (")\n");
<<fault handler: display status information>>
printf ("address = 0x%08x. current_task = %d. current_as = %d.\n", 
        faulting_address, current_task, current_as);     
hexdump (r->eip & 0xFFFFFFF0, (r->eip & 0xFFFFFFF0)+128 );

if ((memaddress)(r->eip) < 0xc0000000) { <<fault handler: terminate process>> }
@ %
%
(If you are curious why the string \verb#"read-only"# is split into \verb#"re" "ad-only"# in the above chunk, read the footnote.\footnote{Sometimes we need to outwit the automatic cross"=referencer of the literate programming software. For example, it would detect \texttt{read} and misinterpret it as a reference to the [[read]] function and thus add an entry to the ``Uses:'' block. We avoid this by either splitting strings or, in case of comments, adding an underscore: \texttt{read\_} will not be (mis-)detected as [[read]].})

Finally, if the page fault was not caused by a process that tried to access an illegal address, then we must assume we've come across a kernel bug. There's no way to recover, because where should the system continue execution? Our last remaining option is to stop the system. \UlixI{} provides a kernel mode shell that can be used for debugging, instead of a real full stop we jump into that function, but the user mode is gone for good.

<<page fault handler implementation>>=
// error inside the kernel; cannot fix, leave user mode
<<disable scheduler>> 
<<enable interrupts>>
printf ("\n"); asm ("jmp kernel_shell");   // jump to the kernel shell
@


\subsection{Enlarging the Stack}

\index{page fault handler!enlarge user mode stack}%
\index{user mode stack!enlarged by page fault handler}%
\index{stack!enlarged by page fault handler}%
When we notice that the stack's size is causing the problem, we can grow it. In the above code detection of necessary stack growth uses the fact that the stack grows linearly; we assume that an illegal access to the stack (i.\,e., to a page that has not been mapped to a frame yet) always occurs directly below the last valid stack page. So, the address has to be below the top of the stack, but above the lowest valid address minus [[PAGE_SIZE]].

We can then simply grow the stack by mapping the next page (remembering that the stack grows downwards) to a fresh frame:
 
<<page fault handler: enlarge user mode stack>>=
// printf ("DEBUG: enlarging stack, addr = 0x%x\n", faulting_address);  // REMOVE_DEBUGGING_CODE
memaddress new_stack = TOP_OF_USER_MODE_STACK;
new_stack -= address_spaces[current_as].stacksize;
int pageno = new_stack / PAGE_SIZE - 1;
int frameno;
if ((frameno = request_new_frame ()) < 0) {
  printf ("\nERROR: no free frame, cannot grow user mode stack\n");  // error
  <<fault handler: terminate process>>
};

as_map_page_to_frame (current_as, pageno, frameno);   // update page table and
address_spaces[current_as].stacksize += PAGE_SIZE;    // TCB stack size entry
@ %
Note that this code only works for a thread-less process. If a process consists of several threads, and one of the non-primary threads exceeds its user mode stack, this code will not be executed because it only checks for problems with the primary thread's stack. Our design does not allow growable stacks for the extra stacks because we have placed those stacks close to each other in virtual memory. We could increase the free spaces between thread stacks to make the problem a little smaller, but in the end there must always be a limit to the threads' stack sizes---after all we do not know beforehand how many threads a process is going to create.


The \UlixI{} disk provides 
\begin{itemize}
\item a \verb#fault-mem# application which accesses an illegal address (and will subsequently be killed) and
\item a \verb#recurse# program that recursively calls a function (and thus forces stack growth): In early versions of the \UlixI{} kernel it would eventually run out of memory and then be killed; with the final \UlixI{} code it can go on rather long because the kernel will start paging out memory in order to free frames.
\item There is also a \verb#tp# program that explicitly pages out a page of its memory and then accesses it (so that it will be brought back in; see the next sections).
\end{itemize}


\pagebreak

\section{The Swap File}
\label{sec:swapfile}%
\index{swapping}\index{swap file}\index{paging!swap file (paging file)|see {swap file}}
\index{paging file|see {swap file}}%
\index{swap file!implementation in Ulix}%
\UlixI{} uses a 64 MByte swap file which is stored on the hard disk. This is also just a little less than the maximum file size that our Minix filesystem implementation supports (see Chapter \ref{chap:ulix:fs}): With six direct block addresses, one single indirect block (leading to 256 blocks) and one double indirect block (leading to $256 \times 256$ blocks) as well as a block size of 1 KByte, files can be no larger than 65798 KByte $\approx$ 64.26 MByte.

The swap file stores only the contents of pages, all administrative data is kept in memory. 64 MByte allow \UlixI{} to double the available RAM (since it works with a fixed amount of 64 MByte of RAM as well), providing up to 128 MByte of virtual memory to the system and processes.

Internally we will store information about pages which have been written to disk. For each such page we need to know the address space ID and the page number, thus an internal paging record has the following form:

<<type definitions>>=
struct paging_entry {
  int as         : 10;    // 10 bits for address space, values from [0..1023]
  int pageno     : 20;    // 20 bits for the page number
  int used       :  1;    // 2 bits for two flags
  int reserved   :  1;
} __attribute__((packed));
@ %def paging_entry
This is just small enough to fit in a 32-bit integer. As the page size is 4 KByte, we need 64 MByte / 4 KByte = 16\,384 such entries:

<<constants>>=
#define MAX_SWAP_FRAMES 16384
@ %def MAX_SWAP_FRAMES

<<global variables>>=
struct paging_entry paging[MAX_SWAP_FRAMES] = { { 0 } };
@ %def paging

If [[paging[i].used]] is 0 ([[false]]), the corresponding swap file entry [[i]] is free which fits our initialization of the data structure.

We assume that a swap file \verb#/tmp/swap# of size 64 MByte already exists.

\begin{Verbatim}
root@ulix[7]:/root# ls -l /tmp
[...]
 5 -rw-------  1    0    0 67108864  3 May 11:53 swap                          
\end{Verbatim}

\noindent
During the system initialization we open this file and keep it open throughout the whole system runtime.

<<global variables>>=
int swap_fd;
@ %def swap_fd

<<initialize swap>>=
swap_fd = u_open ("/tmp/swap", O_RDWR, 0);
if (swap_fd != -1) {
  int size = u_lseek (swap_fd, 0, SEEK_END);
  printf ("swapon: enabling /tmp/swap (%d MByte)\n", size/1024/1024);
  u_lseek (swap_fd, 0, SEEK_SET);
} else
  printf ("swapon: error opening /tmp/swap!\n");
@

We provide two simple functions which write a page to the file and read it back in. Both need to walk through (parts of) the paging array in order to find out whether the page is (already) on the disk and which free entry can be used if that is not the case.

\index{swap file!writing and reading pages to/from disk}%
%nouse
<<function prototypes>>=
int write_swap_page (int as, int pageno, int frameno);
int read_swap_page  (int as, int pageno, int frameno);
@ %
We give these functions an extra argument [[frameno]]: If we already know the physical address where a page is stored in memory, we will provide its frame number so that the functions need not calculate it. (Actually we're not using the feature where [[write_swap_page]] or [[read_swap_page]] would manually calculate the frame number. However it would be useful for an enhanced paging mechanism that might page out pages but still keep them in memory as well or page in pages from the swap file and still keep them on the disk. We do neither in our implementation.)

We do not expect these functions to alter a page table of the involved process---that happens in the functions [[page_out]] and [[page_in]] which we present in the next section.

<<function implementations>>=
int write_swap_page (int as, int pageno, int frameno) {
  // get frame number, if it was not supplied
  if (frameno == -1) frameno = mmu_p (as, pageno);
  if (frameno == -1) return -1;                    // error: page not available
  
  // get index
  int index      = -1;
  int free_index = -1;
  for (int i = 0;  i < MAX_SWAP_FRAMES;  i++) {
    if (free_index == -1 && !paging[i].used)  free_index = i;
    if (paging[i].used && paging[i].as == as && paging[i].pageno == pageno) {
      index = i;  // already on disk!
      break;      
    }
  }
  if (index == -1 && free_index == -1) return -1;  // not found + no free space
  if (index == -1 && free_index != -1) { 
    index = free_index;                            // create new entry
    paging[index].used   = true;
    paging[index].as     = as;
    paging[index].pageno = pageno;
  }
  // note: if (index != -1) we do not modify paging[]; this is an update
  
  // write_ to disk
  debug_printf ("DEBUG: [%d] write_swap_page: going to seek & write\n",  // REMOVE_DEBUGGING_CODE
          current_task);                                                 // REMOVE_DEBUGGING_CODE
  u_lseek (swap_fd, index*PAGE_SIZE, SEEK_SET);
  u_write (swap_fd, (char*)PHYSICAL(frameno*PAGE_SIZE), PAGE_SIZE);
  debug_printf ("DEBUG: [%d] write_swap_page: finished seek & write\n",  // REMOVE_DEBUGGING_CODE
          current_task);                                                 // REMOVE_DEBUGGING_CODE
  return 0;                                        // success
}
@ %def write_swap_page
Note that [[u_write]] will use the buffer cache (see Chapter~\ref{sec:buffer cache}), thus calling the function [[write_swap_page]] may at first only result in copying a page to a different memory area.

Reading a page back in is simpler because we need not distinguish between updates and initial write operations: When we try to read, the page is either there or it is not. We do not check the case that a requested page might be missing in the swap file because we only call this function when we know that the page must be there.

<<function implementations>>=
int read_swap_page (int as, int pageno, int frameno) {
  // get frame number, if it was not supplied
  if (frameno == -1) frameno = mmu_p (as, pageno);
  if (frameno == -1) return -1;       // error: page not available
  
  int index = -1;                                            // get index
  for (int i = 0;  i < MAX_SWAP_FRAMES;  i++) {
    if (paging[i].used && paging[i].as == as && paging[i].pageno == pageno) {
      index = i;  // found the entry!
      break;      
    }
  }

  u_lseek (swap_fd, index*PAGE_SIZE, SEEK_SET);              // read from disk
  u_read (swap_fd, (char*)PHYSICAL(frameno*PAGE_SIZE), PAGE_SIZE);
  return 0;                           // success
}
@ %def read_swap_page


\subsection{Paging Out and In}

\index{swap file!paging out and in}%
\index{paging!paging out and in (swap file)}%
The [[write_swap_page]] and [[read_swap_page]] functions simply copy a page frame from memory to the swap file or vice versa. But real paging requires more than that: we need to modify a page table whenever we remove or add a page. This is what the two functions

%nouse
<<function prototypes>>=
int page_out (int as, int pageno);
int page_in  (int as, int pageno);
@ %
are for. Some other kernel function (which we will describe soon) makes the decision to remove page X of process Y and then calls [[page_out]] which in return saves the page (via [[write_swap_page]]) and updates the relevant process' page table to indicate that the page is no longer in RAM (but could be gotten from the swap file). When that process tries to access the page the next time, a page fault will occur which must be handled by the page fault handler which brings the needed page back in and lets the process reattempt the last instruction.

Let us first recall the data structure [[page_desc]] for the page descriptor:
%nouse
<<[[page_desc]] structure definition (repeated)>>=
typedef struct {
  unsigned int present         :  1;  //  0
  unsigned int writeable       :  1;  //  1
  unsigned int user_accessible :  1;  //  2
  unsigned int pwt             :  1;  //  3
  unsigned int pcd             :  1;  //  4
  unsigned int accessed        :  1;  //  5
  unsigned int dirty           :  1;  //  6
  unsigned int zeroes          :  2;  //  8.. 7
  unsigned int unused_bits     :  3;  // 11.. 9
  unsigned int frame_addr      : 20;  // 31..12
} page_desc;
@ %
If the [[present]] bit is set to 0, any attempt to access the page will lead to a page fault. Thus, when we want to page out a page, we can simply reset the page descriptor's [[present]] bit. But how is the fault handler to know whether a ``genuine'' page fault has occurred (i.\,e., the page does not exist at all) or whether the kernel paged out the page and is capable of getting it back? The bits 9--11 of the descriptor, called [[unused_bits]] above, are completely ignored by the MMU. This is our starting point: We use one of these three bits for keeping the paged out state:

<<type definitions>>=
typedef struct {
  unsigned int present         :  1;  //  0
  unsigned int writeable       :  1;  //  1
  unsigned int user_accessible :  1;  //  2
  unsigned int pwt             :  1;  //  3
  unsigned int pcd             :  1;  //  4
  unsigned int accessed        :  1;  //  5
  unsigned int dirty           :  1;  //  6
  unsigned int zeroes          :  2;  //  8.. 7
  unsigned int paged_out       :  1;  //  9       <- new
  unsigned int unused_bits     :  2;  // 11..10
  unsigned int frame_addr      : 20;  // 31..12
} new_page_desc;
@ %def new_page_desc
%
Since [[page_desc]] and [[new_page_desc]] have the same layout, we can cast them into one another without corrupting data. So when we want to find out whether the new [[paged_out]] bit is set, we can check that with \verb#if ( ((new_page_desc*)pd)->paged_out ) { ... }#.

Now we can present the [[page_out]] and [[page_in]] functions which perform the same calculations as the [[mmu_p]] function which we introduced earlier. [[page_out]] does four things:

\begin{itemize}
\item it calls [[write_swap_page]] to do the transfer from memory to disk,
\item it resets the page descriptor's [[present]] bit and sets its [[paged_out]] bit,
\item it invalidates the TLB entry with the [[invlpg]]\marginnote{[[invlpg]]} instruction in order to make sure that the next access to this page will cause a page fault (instead of accessing the old frame which may no longer hold the page) \cite[p.~21]{Intel:2008:TLB} (or \cite[p.~4-56--4.57]{intel-part3}),
\item and it releases the frame, thus increasing the free physical memory.
\end{itemize}

<<function implementations>>=
int page_out (int as, int pageno) {
  uint pdindex = pageno/1024; uint ptindex = pageno%1024;
  page_directory *pd = address_spaces[as].pd;
  if ( ! pd->ptds[pdindex].present ) {
    return -1;                                    // fail: page table not found
  } else {
    page_table *pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
    if ( pt->pds[ptindex].present ) {             // found the page
      new_page_desc *pdesc = (new_page_desc*) &pt->pds[ptindex];
      int frameno = pdesc->frame_addr;
      printf ("DEBUG: paging out page 0x%x, "                 // REMOVE_DEBUGGING_CODE
              "AS %d, frame 0x%x\n", pageno,                  // REMOVE_DEBUGGING_CODE
              as, frameno);                                   // REMOVE_DEBUGGING_CODE
      write_swap_page (as, pageno, frameno);      // write_ to swap file
      printf ("DEBUG: back from write_swap_page\n");          // REMOVE_DEBUGGING_CODE
      pdesc->present = false;                     // mark page non-present
      pdesc->paged_out = true;                    // mark page paged-out
      asm volatile ("invlpg %0" : : "m"(*(char*)(pageno<<12)) );
      release_frame (frameno);                    // mark phys. frame as free
      return 0;                                   // success
    } else {
      return -1;                                  // fail: page not found
    };
  }
}
@ %def page_out

The [[page_in]] function expects that we try to page in a page which was paged out with [[page_out]] earlier. That is, the page descriptor must exist and have its [[paged_out]] bit set. It will then do the following three things:

\begin{itemize}
\item it reserves a new physical frame which will soon hold the page and writes its address to the page descriptor,
\item it calls [[read_swap_page]] to do the transfer from disk to memory,
\item and it resets the page descriptor's [[paged_out]] bit,
\end{itemize}

<<function implementations>>=
int page_in (int as, int pageno) {
  uint pdindex = pageno/1024;
  uint ptindex = pageno%1024;
  page_directory *pd = address_spaces[as].pd;
  if ( ! pd->ptds[pdindex].present ) {
    printf ("DEBUG: page_in: page table not present\n");
    return -1;                                    // fail: page table not found
  } else {
    page_table *pt = (page_table*) PHYSICAL(pd->ptds[pdindex].frame_addr << 12);
    if ( !pt->pds[ptindex].present ) {
      // found the page descriptor
      new_page_desc *pdesc = (new_page_desc*) &pt->pds[ptindex];
      if (!pdesc->paged_out) {
        printf ("DEBUG: page_in: page 0x%0x not marked paged out!\n", pageno);
        return -1;                                // fail: page was not paged out
      }
      int frameno = request_new_frame ();         // reserve a phys. frame
      if (frameno == -1) return -1;               // fail: no free memory
      printf ("DEBUG: paging in page 0x%x, "      // REMOVE_DEBUGGING_CODE
              "AS %d, frame 0x%x\n",              // REMOVE_DEBUGGING_CODE
              pageno, as, frameno);               // REMOVE_DEBUGGING_CODE
      read_swap_page (as, pageno, frameno);       // read_ from swap file
      pdesc->present = true;                      // mark page present
      pdesc->paged_out = false;                   // mark page not paged-out
      pdesc->frame_addr = frameno;                // write_ new phys. frame number
      // asm volatile ("invlpg %0" : : "m"(*(char*)(pageno<<12)) );   // not needed
      return 0;                                   // success
    } else {
      printf ("DEBUG: page_in: page not found\n");
      return -1;                                  // fail: page not found
    };
  }
}
@ %def page_in
When we page in, we need not invalidate a TLB entry since it does not store information about non-present pages \cite[p.~21]{Intel:2008:TLB} (or \cite[p.~4-58]{intel-part3}):

\pagebreak

\begin{quotation}
If a paging-structure entry is modified to transition the present bit from 0 to 1, no invalidation is necessary. This is because no TLB entry or paging-structure cache entry will be created with information from a paging-structure entry that is marked ``not present''. (If it is also the case that no invalidation was performed the last time the present bit was transitioned from 1 to 0, the processor may use a TLB entry or paging-structure cache entry that was created when the present bit had earlier been 1.)
\end{quotation}

\noindent
This is all the code we need for paging in and out a page. Now we need to decide when to page out a page and how to pick that page.


\subsection{Letting the Page Fault Handler Page In a Page}

\index{page fault handler!paging in a paged-out page}%
We can now add the missing code chunk [[<<page fault handler: check if page was paged out>>]]. Recall that the faulting address is stored in [[faulting_address]]. All we need to do here is attempt to page in the corresponding page ([[faulting_address / PAGE_SIZE]])---if we are successful we can leave the page fault handler, and the process will re-execute the last instruction.

<<page fault handler: check if page was paged out>>=
int pageno = faulting_address / PAGE_SIZE;
// printf ("DEBUG: trying to page in page 0x%x, AS %d\n", pageno, current_as);  // REMOVE_DEBUGGING_CODE
if (page_in (current_as, pageno) == 0) {
  return;           // success, leave fault handler
}
@


\subsection{Testing}

At this step of the implementation task we should check whether our code works as intended. For that purpose we will provide a temporary system call with which a process can force the kernel to page out a page. (Note that in general it is a bad idea to allow processes to take that kind of control over the memory management.)

A test program will then try to access data in the paged-out page which should in turn have the page fault handler bring the page back. We know that we're successful if the program executes without errors.

<<public constants>>=
#define __NR_page_out 508
@ %def __NR_page_out

\index{page\_out system call@\texttt{page\_out} system call}%
\index{system call!page\_out@\texttt{page\_out}}%
%nouse
<<syscall prototypes>>=
void syscall_page_out (context_t *r);
@

<<syscall functions>>=
void syscall_page_out (context_t *r) {
  // ebx: page number
  eax_return (page_out (current_as, r->ebx) );
}
@ %def syscall_page_out

<<initialize syscalls>>=
install_syscall_handler (__NR_page_out, syscall_page_out);
@

The user mode program will use the following library function

%nouse
<<ulixlib function prototypes>>=
int lib_page_out (int pageno);
@ %
which just makes the system call
<<ulixlib function implementations>>=
int lib_page_out (int pageno) { return syscall2 (__NR_page_out, pageno); }
@ %def lib_page_out

Here is the code for a simple test program:

%nouse
<<lib-build/tools/tp.c>>=
#include "../ulixlib.h"
char test[4096] __attribute__ ((aligned (4096)));

int main () {
  printf ("Testing paging\n");
  test[5] = 'X';
  unsigned int address = (unsigned int)(&test[5]);
  printf ("test[5] = '%c', address = 0x%x\n", test[5], address);
  lib_page_out (address >> 12);
  printf ("test[5] = '%c', address = 0x%x\n", test[5], address);
  exit (0);
}
@

Now we need to discuss \emph{when} the operating system should page out a page and \emph{which} page it should choose. We enter the realm of \emph{page replacement strategies}---the topic of the following section.

\pagebreak


\section{Page Replacement Strategy}
\label{sec:page:replacement}%

\index{paging!page replacement strategy|see {page replacement strategy}}%
\index{page replacement strategy}%
%----  ab hier Text aus alter Diss
When memory gets full, eventually the system will have to move pages to the disk in order to make room for other processes' memory demands. Paging out a page (i.\,e., writing it to disk and releasing the page frame that held the page) and assigning a different process' page to this page frame is called page replacement. 
\felix
Paging the
information in and out of main memory is extremely simple because of
the fixed size data chunks%
\black{}---as you have seen in the implementation of [[page_in]] and 
[[page_out]].
\felix

Access to secondary storage is very slow, while access to main memory
is rather fast. At time of writing, good hard disks have an average
access time of about eight milliseconds, main memory of about eight
nanoseconds. This is a difference of $10^6$, i.\,e., six orders of
magnitude. To make this huge difference more evident, assume that
access to main memory needs one \emph{second}. Then the access to
secondary storage would have to take $10^6$ seconds, which is roughly
11.5 days, to stay in the same relation.

Well-tuned paging systems can achieve a performance which is very
close to the speed of main memory. The decisive parameter is the
probability $p$ of not finding the requested information in RAM
(i.\,e., the probability of a page fault).  Given that $t_{mm}$ is the
time necessary to access main memory and $t_{pf}$ the time to handle a
page fault, the average time $t_{vm}$ to access virtual memory using
a paging system is:
%
$$t_{vm} = (1-p)\cdot t_{mm} + p\cdot t_{pf}$$
%
Since $t_{pf}$ is dominated by the access time to secondary storage,
we need to keep $p$ as low as possible.

\black
The algorithm that decides which page to page out is called a page replacement algorithm, and it implements a page replacement strategy. The chosen strategy is a part of the memory management system's design, and several choices are available.

One possible choice would be a random selection: Whenever there is need for a free page frame (and none available) just pick any odd page frame and page out its contents. This strategy would not be much good, but we can think of even worse ones, e.\,g. always pick the very first page frame in the RAM.

The selection process has no consequences on the overall functioning of memory management: Even the worst strategy (and ``pick the first page frame'' is a good candidate for that) will lead to a working memory management system. However, the selection process decides how efficiently the resulting system behaves.

Before going into details, let us note that there is no direct equivalent to page replacement in filesystems---unless you had another layer of the memory hierarchy that is above disk access, e.\,g. an automatic tape backup system with a tape robot that can write files to a tape and delete them on disk when disk space gets low. If you had such a setup, you would move from a CPU--cache--RAM--disk memory hierarchy to a CPU--cache--RAM--disk--tape one, and accessing a file currently on tape would cause something that could be called a file access fault, resulting in the system automatically fetching the file back from tape (and keeping the requesting process blocked during all the time until the file becomes available again). Strategies for deciding which files to temporarily transfer from the disk to a tape would be called a file replacement strategy and be somewhat similar to the page replacement strategies. Distributed filesystems (or distributed network filesystems) that allow files to either exist on a local machine or on a remote host's disk do something similar if they make file access transparent, no matter whether things are stored locally or remotely. We will not look any further into this. A true analog of page replacement would operate on disk block level, i.\,e. remove individual blocks from the disk in order to store them elsewhere, and that is something that does not make much sense since files are typically accessed fully when they are accessed at all. It might however make sense to keep the first block of a file on disk when removing the file, because often only the first block of a file is read in order to find out its filetype (think of ``magic numbers'').

A way of measuring a page replacement strategy is the average number of page faults that it causes. It is not possible to truly calculate this number, because it depends on so many things, e.\,g.:

\begin{itemize}
\item The absolute memory demands depend on all the processes currently running on a system.
\item Even if sample situations (test cases) are created that consist of predefined processes with fixed start times and memory requirements (such as: process will access its page number $n$ at instruction $i$) it is not possible to predict when precisely this process will execute this instruction---scheduling the processes will always result in slightly different orders of execution each time the test case is run.
\end{itemize}

\noindent
\looseness=-1
So all we can do is think of theoretical properties of replacement strategies and, when implementing a strategy, observe its effects on a number of test cases which are tested several times in order to calculate an average number of page faults for each test case. Looking at the design of a strategy will however allow us to make some principle predictions.


\felix
\subsection{Page Locking}

\index{page locking}%
\index{page replacement strategy!page locking}%
Page replacement is a good idea, but some pages must sometimes be
protected from being paged out. For example, certain parts of the
operating system are so critical that they should never be paged out
to secondary storage. The most striking example is the code that
contains the interrupt handlers. If a page fault occurs and the code
for the page fault handler is not be present, then we are be in big
trouble. Also, most parts of the page tables for the kernel
should always be present, as well as pages that are located
in special frames for \vindex{memory-mapped I/O}. In such cases
the pages should be \emph{locked} into their frames and page
replacement algorithms should ignore these pages.

\black

\UlixI{} does not explicitly support page locking, but it considers the upper 1 GByte of each address space as locked: kernel memory will never be paged out, so we only have to deal with the memory of processes which avoids all the problems that otherwise call for page locking.


\subsection{Page Replacement Strategies}

We describe a few classical replacement strategies before showing you the implementation in the \UlixI{} kernel.


\subsubsection{FIFO Page Replacement}

\index{page replacement strategy!FIFO}%
\index{FIFO page replacement strategy}%
A simple approach to page replacement is using a FIFO (first in, first out) list that keeps record of pages as they come into memory (either by being newly created, e.\,g. because a new process was started, or by being brought back in from disk after they had been paged out earlier). For \UlixI{} we could modify the [[as_map_page_to_frame]] and [[page_in]] functions in order to keep track of new pages.

The list can grow up to a size that is determined by the number of available page frames in the system's memory. When this limit is reached, the list will be chopped from the top: The page that is first in the list is removed from the list and also paged out. If the owning process tries to access this (paged-out) page again, a page fault occurs, and the memory manager has to page it back in, adding it at the end of the FIFO list.

This approach is simple because administering a FIFO list is simple, and selecting the next page to be paged out only requires reading the list head and removing it. However it has the problem of totally ignoring that some pages are accessed much more frequently than others. All pages travel from the list end to the list head at equal speed as pages are continuously paged out and back in, and for constantly and frequently used pages this means they will be paged out and in very often. It would make sense to be informed about the access frequency and keep the more frequently used pages in memory all the time, resulting in a much increased overall performance (with less page faults).


\subsubsection{Second Chance Algorithm}

\index{page replacement strategy!second chance}%
\index{second chance algorithm (page replacement strategy)}%
An attempt to bring the frequency of page access into the FIFO strategy is the introduction of a ``second chance'': The idea is to set an \emph{access bit}\marginnote{access bit} for a page each time it is accessed by its owning process. This is something that the MMUs of most processors do automatically---which is important because otherwise it would be very hard to detect memory access manually.

The modification of the FIFO strategy is the following:
\begin{itemize}
\item A simple FIFO list of all pages works in principle as in the FIFO case.
\item The MMU sets bits for each page access, as described above.
\item When a page frame has to be freed, the system looks at the first list entry (as before). If that page has its access bit set, it is \emph{not} paged out, but instead moved to the end of the list, and its access bit is cleared: it gets a second chance.
\end{itemize}
So the Second Chance algorithm selects the first page in the FIFO list that does not have its access bit set. ``Not using the chance'' then means that after being spared when first found at the list head, it will travel all the way from the end to the head of the list without being accessed one single time. Then the memory manager will page it out.


\subsubsection{Clock}

\index{page replacement strategy!clock}%
\index{clock algorithm (page replacement strategy)}%
The Clock algorithm does the same as the Second Chance algorithm but does not require the reordering of the list (by taking away the head element and appending it to the list). Instead it uses a circular list (where the last element points back to the head) and uses a ``clock hand'' which points to the current head of the list.

When the algorithm needs to pick the candidate it starts with the list element that the clock hand points to. If its access bit is not set, that page is paged-out and removed from the list; the clock hand turns forward to the next element in the list.

If, however, the access bit is set, the algorithm clears it, moves the clock hand to the next location and starts over. It may eventually come full circle and arrive at the element whose access bit it had just reset; then it will pick that page.

\begin{figure}[h!]
\centering
\includegraphics[width=14cm]{pics/clock-algorithm.pdf}
\caption[\hgepolylof{The ``Clock'' page replacement algorithm.}]{The Clock algorithm resets the access bits in the first three entries (pages 26, 4, 72) and picks the fourth entry (page 1) because its access bit is not set.}
\label{fig:clock-algorithm}
\end{figure}

Figure~\ref{fig:clock-algorithm} shows an example of the Clock algorithm at work: When it starts, its clock hand points to page 26 (left part of figure). It sees that the page has its access bit set, so it resets it and moves on (clock-wise). The same repeats twice for pages 4 and 72, but when it reaches page 1 which does not have its access bit set, it picks that page as the candidate for removal.


\subsubsection{Least-Frequently Used}

\index{page replacement strategy!least-frequently used}%
\index{least-frequently used (page replacement strategy)}%
The Second Hand or Clock strategy suffers from the fact that the only observed property of a page is whether it has been accessed recently or not. However some pages are used much more often than others, and those much-used pages should be avoided when choosing a candidate for paging because they will be used again soon with high probability.

What we would like to have is an access log for each page so that we can pick a page which both was not accessed recently and in general was not accessed a lot further ago. A true access log (that picks up every single access) is very hard to implement. For example, one could modify all page descriptors so that they cause a page fault. Then every access would generate a page fault, the page fault handler could temporarily grant access to that page and resume the process, only to remove the access permissions as soon as possible. While we would still not register all page accesses (since a process might access the same page several times in short sequence) it would give a good overview of the actual usage patterns. But this would be extremely expensive in terms of CPU time as the system would permanently generate page faults.

We can, however, do something that approximates such an access log: The Least"=Frequently Used strategy counts page accesses by regularly checking and resetting the access bit. Every time it notices a set access bit it increments the access counter for that page. From time to time the counters need to be scaled down so that they don't exceed the limit of their datatype. When the time comes to page out a page, the page with the lowest counter value is chosen.

For \UlixI{}, with its fixed 64~MByte of RAM, this would mean keeping records for up to 16\,384 pages. If we used the maximum possible amount of RAM (4~GByte) and all its frames were in use, there would be more than a million pages to look after, and we might want to grow or shrink the list dynamically (according to the number of existing pages) so that we don't waste too much memory for it. Also, the larger the list of pages becomes, the longer it takes to search for a minimum.


\section{Page Replacement Implementation in \UlixI{}}
\label{sec:page replacement implementation}%

\index{page replacement strategy!implementation in Ulix}%
We will use access counters, but not for individual (process/page) pairs, but for \index{hash}\emph{hashes} of them. This will let us use a fixed-size counter table which need not grow or shrink over time when new processes are created or old ones removed.

Each page can be identified by an ([[as]], [[pageno]]) pair. [[pageno]] is a 20 bit number, and [[as]] is a 10 bit number (since we only allow up to $1024 = 2^{10}$ address spaces).

We map this to an array index by calling

<<pseudo code for calculating the index into the hash table>>=
index = hash ((address_space << 20) | pageno)
@

This [[index]] number points to entry [[counter_table[index]]] which stores a used flag and a counter. We will regularly update the counter table \dots
%nouse
<<pseudo code for counter updates>>=
for (as in used_address_spaces, pageno in user_page_numbers(as)) {
  n = get_and_reset_referenced_bit (as, pageno);  // 0 or 1
  index = hash ((address_space << 20) | pageno);
  if (n==1) {
    counter_table[index].used = true;
    counter_table[index].count++;
  }
}
@ \dots and (less often) rescale the counters by halving them if the maximum counter is above some threshold:

%nouse
<<pseudo code for counter rescaling>>=
// get maximum count
themax = 0;
for (index in 0..maxindex)
  if (counter_table[index].used)
    themax = max (themax, counter_table[index].count);
if (themax < THRESHOLD) return;  // do nothing

// halve all counters
for (index in 0..maxindex)
  if (counter_table[index].used) {
    counter_table[index].count /= 2
    counter_table[index].count += 1;  // add 1 to avoid 0 value
  }
@

This automatically leads to some kind of aging: when the maximum reaches the
threshold value, all entries will be halved.
Now, picking a page with minimum counter for replacement goes like this:

%nouse
<<pseudo code for picking a page>>=
pick = NULL;
for (as in used_address_spaces, pageno in user_page_numbers(as)) {
  index = hash ((address_space << 20) | pageno);
  if (pick==NULL && counter_table[index].used) {
    // initialize minimum, pick
    pick = (as, pageno);
    themin = counter_table[index].count;
  } else {
    if (counter_table[index].count < themin) {
      themin = counter_table[index].count
      pick = (as, pageno);
    }
  }
}
if (pick != NULL) page_out (pick.as, pick.pageno);
@

\index{page replacement strategy!dirty page}%
\index{memory management!dirty page}%
\index{dirty page}\index{dirty bit (D bit), page descriptor}%
\index{paging!dirty page}%

This algorithm does not check whether a page is \emph{dirty}\marginnote{dirty page}, i.\,e., modified. In more advanced paging systems, a page may simultaneously exist in memory and on the disk (for example when it was paged out and paged back in but the swap file entry was not deleted). In that case it would make sense to pick a page which is still on disk \emph{and} has not been changed in memory since it was brought back in the last time. Since our implementation does not keep pages both in RAM and on disk, we can ignore the dirty flag (or consider every page dirty; we always have to write to disk, whatever page we pick).

Note that the algorithm may pick a wrong page if there are pages with the same hash as the chosen one. In that case we have no way to decide which of those pages had the fewest accesses, but all of them at least had very few accesses, so this is good enough.

Here's the actual implementation. We define the counter table as an array of simple structures:

<<constants>>=
#define PG_MAX_COUNTERS 1024
@ %def PG_MAX_COUNTERS

<<global variables>>=
struct { boolean used; int count; } counter_table[PG_MAX_COUNTERS] = { { 0 } };
lock paging_lock;
@ %def counter_table paging_lock

We also provide a lock to protect access to that table:

\index{kernel lock!for page replacement}%
<<initialize kernel global variables>>=
paging_lock = get_new_lock ("paging");
@

And we regularly update the table via timer tasks.
\nextchunklabel{timer-tasks-counters}
<<timer tasks>>=
if (scheduler_is_active && ((system_ticks % 10) == 0)) {     
  <<page replacement: update counters>>   // Every 10 ticks (~ 0.1 seconds)
}
if (scheduler_is_active && ((system_ticks % 50) == 5)) {     
  <<page replacement: rescale counters>>   // Every 50 ticks (~ 0.5 seconds) 
}
@

As mentioned above, we need a \index{hash}\emph{hash function}\marginnote{hash function} for mapping all the possible
(address space, page number) combinations onto our array. Hashing is a science
in its own right, and we do not attempt to provide a clever or useful
hashing algorithm in this book. Instead we implement our hash function

%nouse
<<function prototypes>>=
int hash (int val, int maxval);
@ %
%
\looseness=-1
in a very simple fashion: We assume that the [[val]] argument was created from an address space ID [[as]] and a page number [[pageno]] by calculating [[(as @<< 20) | pageno]]. Our hash function can then restore the original values via the formulas [[as = val @>> 20]] and [[pageno = val & 0b1111111111]]. We multiply the address space ID with 32 and add the page number. Since that sum may exceed [[PG_MAX_COUNTERS]], we use a modulo operation to make it fit:

<<function prototypes>>=
int hash (int val, int maxval) {
  // return val % maxval;   // ridiculous hash
  return ((val >> 20)*32 + (val & 0b1111111111)) % maxval;
}
@ %def hash


The update code does not disable interrupts or use a lock; we do not really care if data are changed while we assemble the statistical data, since a small error in the statistics (which might result from parallel access to a page table entry) will not change the overall behavior.

The double loop over address space IDs and page numbers that we've shown above in the [[<<pseudo code for counter updates>>]] code chunk turns into a triple loop (over address space IDs, page table descriptors and page descriptors) since we cannot directly access the page descriptor for some page $n$ without inspecting the right page table (number $n/1024$) first. We only look at the first 768 page tables---beyond that kernel memory starts, and we have decided to never page out memory that belongs to the kernel. That way we need not deal with \emph{sticky bits}\index{sticky bit (page descriptor)}\index{page descriptor!sticky bit}\index{page locking}\marginnote{sticky bit,\\ locked} (\emph{locked} bits) in the page descriptors. Instead, the simple rule is: If a page belongs to process memory, it is a candidate for removal; otherwise not.

<<page replacement: update counters>>=
if (mutex_try_lock (paging_lock)) {
  for (int as = 1;  as < MAX_ADDR_SPACES;  as++) {
    if (address_spaces[as].status != AS_FREE) {
      page_directory *pd = address_spaces[as].pd;
      for (int i = 0;  i < 100;  i++) {      // < 768: only work on process memory
        if (pd->ptds[i].present) {           // directory entry in use
          page_table *pt = (page_table*)(PHYSICAL ((pd->ptds[i].frame_addr)<<12));
          for (int j = 0;  j < 1024;  j++) {
            if (pt->pds[j].present) {        // table entry in use
              <<page replacement: update counter for page $i \cdot 1024 + j$>>
            }
          }
        }
      }
    }
  }
  mutex_unlock (paging_lock);
}
@

For updating the counter for page $1024 \cdot i + j$ we look at its page descriptor. If the accessed bit is set 

<<page replacement: update counter for page $i \cdot 1024 + j$>>=
int pageno = i*1024 + j;
int n = pt->pds[j].accessed;   // get and ...
pt->pds[j].accessed = false;   // reset access flag
int index;
if (n == 1 && 
    (index = hash ((as << 20) | pageno, PG_MAX_COUNTERS)) < PG_MAX_COUNTERS) {
  counter_table[index].used = true;
  counter_table[index].count++;
}
@

The implementation of the rescaling operation is only slightly more complex than the pseudocode:

<<page replacement: rescale counters>>=
// get the maximum count
int themax = 0;
if (mutex_try_lock (paging_lock)) {
  for (int index = 0; index < PG_MAX_COUNTERS; index++) {
    if (counter_table[index].used) {
      int val = counter_table[index].count;
      if (val > themax) themax = val;
    }
  }

  if (themax > PG_COUNTER_THRESHOLD) {
    // rescale all counters
    for (int index = 0; index < PG_MAX_COUNTERS; index++) {
      if (counter_table[index].used) {
        counter_table[index].count /= 2;
        counter_table[index].count += 1;  // avoid 0 value
      }
    }
  }
  mutex_unlock (paging_lock);
}
@

We still need to define the counter threshold:

<<constants>>=
#define PG_COUNTER_THRESHOLD 100000
@ %def PG_COUNTER_THRESHOLD

Once at least one page has been access counted more than 100\,000 times, the counter values will be rescaled.


Finally this is the code which frees a frame. It looks at all the pages in all address spaces, generates the hash and looks up the counter for that hash (if it exists). It initializes [[pick_as]] and [[pick_pageno]] to the first address space and page number for whose hash it finds a counter and then updates these variables whenever it finds a smaller counter.

\index{page replacement strategy!freeing a frame}%
\index{frame!freeing a frame}%
<<page replacement: free one frame>>=
/*                                                                    // REMOVE_DEBUGGING_CODE
printf ("DEBUG: COUNTER TABLE\n");                                    // REMOVE_DEBUGGING_CODE
for (int i = 0; i < PG_MAX_COUNTERS; i++) {                           // REMOVE_DEBUGGING_CODE
  if (counter_table[i].used && counter_table[i].count != 0) {         // REMOVE_DEBUGGING_CODE
    printf ("DEBUG: %8d: count = %3d\n", i, counter_table[i].count);  // REMOVE_DEBUGGING_CODE
  }                                                                   // REMOVE_DEBUGGING_CODE
}                                                                     // REMOVE_DEBUGGING_CODE
*/                                                                    // REMOVE_DEBUGGING_CODE
addr_space_id pick_as      = -1;
int           pick_pageno, themin;
// printf ("\nDEBUG:  starting search for page to evict\n");          // REMOVE_DEBUGGING_CODE
while (!mutex_try_lock (paging_lock)) ;    // active waiting for lock
for (int as = 1;  as < MAX_ADDR_SPACES;  as++) {
  if (address_spaces[as].status == AS_USED) {
    page_directory *pd = address_spaces[as].pd;
    for (int i = 0;  i < 768;  i++) {      // < 768: only work on process memory
      if (pd->ptds[i].present) {           // directory entry in use
        page_table *pt = (page_table*) (PHYSICAL ((pd->ptds[i].frame_addr) << 12));
        for (int j = 0;  j < 1024;  j++) {
          if (pt->pds[j].present) {        // table entry in use
            int pageno = i*1024 + j;
            int index = hash ((as << 20) | pageno, PG_MAX_COUNTERS);
            if (pick_as==-1 && counter_table[index].used) {
              // initialize minimum, pick
              pick_as     = as;
              pick_pageno = pageno;
              themin = counter_table[index].count;
              //printf ("INIT:   pick (%d,%d)\n", as, pageno);        // REMOVE_DEBUGGING_CODE
            } else {
              if (counter_table[index].count < themin) {
                  // && address_spaces[as].status == AS_USED) {       // REMOVE_DEBUGGING_CODE
                themin = counter_table[index].count;
                pick_as     = as;
                pick_pageno = pageno;
                // printf ("UPDATE: pick (%d,%d)\n", as, pageno);     // REMOVE_DEBUGGING_CODE
              }
            }
          }
        }
      }
    }
  }
}
mutex_unlock (paging_lock);

if (pick_as != -1) {
  debug_printf ("DEBUG: BEFORE calling page_out (as=%d, pageno=%d)\n", pick_as, pick_pageno);  // REMOVE_DEBUGGING_CODE
  mutex_lock (paging_lock);
  page_out (pick_as, pick_pageno);
  mutex_unlock (paging_lock);
  // debug_printf ("DEBUG: AFTER  calling page_out (as=%d, pageno=%d)\n", pick_as, pick_pageno);  // REMOVE_DEBUGGING_CODE
} else {
  printf ("\nERROR: cannot pick a page to evict!\n");
//  inside_req_frame--;   // for debugging, REMOVE ME!!!              // REMOVE_DEBUGGING_CODE   
}
@

Again, instead of the double loop from the [[<<pseudo code for picking a page>>]] code chunk, we need a  triple loop to access all page tables referenced by all page directories for all address spaces.



\subsection{The Swapper Process}

We provide two system calls that retrieve the number of free frames and issue a request to free a page:

\index{get\_free\_frames system call@\texttt{get\_free\_frames} system call}%
\index{system call!get\_free\_frames@\texttt{get\_free\_frames}}%
\index{free\_a\_frame system call@\texttt{free\_a\_frame} system call}%
\index{system call!free\_a\_frame@\texttt{free\_a\_frame}}%
%nouse
<<syscall prototypes>>=
void syscall_get_free_frames (context_t *r);
void syscall_free_a_frame (context_t *r);
@

<<syscall functions>>=
void syscall_get_free_frames (context_t *r) {
  // no parameters
  mutex_lock (swapper_lock);    // lock_, see below
  eax_return (free_frames);
}

void syscall_free_a_frame (context_t *r) {
  // no parameters
  <<page replacement: free one frame>>
}
@ %def syscall_get_free_frames syscall_free_a_frame

<<ulix system calls>>=
#define __NR_get_free_frames   509
#define __NR_free_a_frame      510
@

<<initialize syscalls>>=
install_syscall_handler (__NR_get_free_frames, syscall_get_free_frames);
install_syscall_handler (__NR_free_a_frame,    syscall_free_a_frame);
@

We also need user mode library functions which can make the two system calls:

%nouse
<<ulixlib function prototypes>>=
int get_free_frames ();
void free_a_frame ();
@

<<ulixlib function implementations>>=
int get_free_frames () { return syscall1 (__NR_get_free_frames); }
void free_a_frame ()   { syscall1 (__NR_free_a_frame); }
@ %def get_free_frames free_a_frame

The swapper process should not work permanently, so we use a trick: We let it block on a lock and add a timer task that unlocks that lock every 0.1 seconds.

<<global variables>>=
lock swapper_lock;
@ %def swapper_lock

\index{kernel lock!for the swapper (paging)}%
<<initialize kernel global variables>>=
swapper_lock = get_new_lock ("swapper");
@

\nextchunklabel{timer-tasks-remove-swapper-lock}
<<timer tasks>>=
if (scheduler_is_active && ((system_ticks % 10) == 0)) {     
  // Every   10 clocks (approx. 0.1 seconds) 
  if (swapper_lock->bq.next)
    mutex_unlock (swapper_lock);
}
@

The swapper program switches to the last virtual console. In an infinite loop it queries the number of free frames using [[get_free_frames]], and that function will block because [[syscall_get_free_frames]] locks the [[swapper_lock]]. The function returns after the timer handler releases the lock, so the loop is only executed every 0.1 seconds.

If the number of frames gets too low, the program calls [[free_a_frame]].

\label{source code for swapper.c}%
<<lib-build/tools/swapper.c>>=
#include "../ulixlib.h"
#define THRESHOLD init_frames - 500
int main () {
  setterm (9);
  int init_frames = get_free_frames ();
  int last_free_frames;
  int free_frames = init_frames;
  int pid = getpid ();
  unsigned int counter = 0;
  
  for (;;) {
    last_free_frames = free_frames;
    free_frames = get_free_frames ();
    if (free_frames != last_free_frames) {
      printf ("[%d.%d] swapper: %d free frames. threshold = %d.", 
        pid, counter++, free_frames, THRESHOLD);
      if (free_frames < THRESHOLD) {
        printf ("calling free_a_frame (%d < %d)\n", free_frames, init_frames - 500);
        free_a_frame ();
      } else {
        printf ("\n");
      }
    }    
  }
}
@

We will start this swapper process right from the \verb#init# process; it will run with process ID~2. In order to stop arbitrary processes from calling [[free_a_frame]], the system call handler should verify that it was called by this process (and no other one).




%------------------------------------------------------------------------------------



\chapter{Talking to the Hardware}
\label{chap:ulix:hardware}%

\index{hardware}%
In this chapter we provide the code which talks to various kinds
of hardware. In most cases this will include an interrupt handler
which gets called when a device generates a hardware interrupt.


\section{Keyboard}

\index{hardware!keyboard}%
\UlixI{} does not provide a graphical user interface, and it does not recognize a mouse. Thus, the keyboard is the only available input device. Since there will be up to ten virtual consoles (on which users can log on with different user accounts), we need several keyboard input buffers and keep track of where to store a new character when a key was pressed.


\subsection{Scan Code Tables}

The keyboard interrupt handler must recognize which key was pressed,
while also checking if any of the \index{modifier key}\emph{modifier keys}\marginnote{modifier keys} (such as shift, control
or alt) was held down at the same time.

The array [[scancode_table]] maps the \emph{key codes}\index{scan code}\index{key code|see {scan code}}\marginnote{key codes} of a standard US keyboard (as generated by the keyboard controller) to ASCII characters. We started with the code in Bran's Kernel Development tutorial \cite{brans-tutorial:200x} (the table is on the \url{http://www.osdever.net/bkerndev/Docs/keyboard.htm} page), but modified it.

Similarly, [[scancode_up_table]] holds the characters for the same key codes, but with one of the shift keys pressed. Since we alternated between US and German keyboards during the development of \UlixI{}, we also provide corresponding tables for the German layout which you can find in [[scancode_DE_table]] and [[scancode_DE_up_table]].

% trim: left bottom right top
\begin{figure}[h!]
\centering
\includegraphics[trim=6mm 6mm 4mm 4mm,clip=true,width=\textwidth]{pics/keyboards/tastatur-us.png}
\caption[Layout of a US-American keyboard.]{Layout of a US keyboard with additional Windows keys (without the number pad)}
\label{fig:keyboard-us}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[trim=1mm 1mm 1mm 1mm,width=\textwidth]{pics/keyboards/tastatur-deutsch.pdf}
\caption[Layout of a German keyboard.]{Layout of a German keyboard with additional Windows keys (without the number pad)}
\label{fig:keyboard-de}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[trim=6mm 6mm 6mm 6mm,width=\textwidth]{pics/keyboards/tastatur-scancode.png}
\caption[\hgepolylof{Scancodes for the US-American keyboard.}]{Scancodes for the US keyboard; on a German keyboard ``[[<]]'' generates the key code 41.}
% or < generates 86, see http://www.blitzforum.de/help/Scancodes ?? 
% on my Mac, < generates 41.
\label{fig:keyboard-scancodes}
\end{figure}

Figure~\ref{fig:keyboard-us} shows the layout of a standard US-American PC keyboard, and Figure~\ref{fig:keyboard-de} shows the German layout. In the third figure (Figure~\ref{fig:keyboard-scancodes}) you can find the key codes.

Both pressing and releasing a key generate a key code (that way the operating
system can see whether the user holds a key pressed). The key codes for pressing
and releasing any specific key are identical except for the upper bit: If a
key was pressed, the key code's upper bit is unset (0); if it was released it
is set (1). Thus [[scancode & 0x80]] is 0 if the event is a key press event, it
is non-zero otherwise. In the latter case [[scancode-0x80]] (or [[scancode & ~0x80]])
calculates the key code of the corresponding key press event.

There are some exceptions for newer keys which did not exist on the original PC XT keyboard \cite[pp.~1-65--1-69]{ibm-xt-reference:1983}, and they use combinations which are initiated with an escape character (\hex{e0} = 224 or \hex{e1} = 225). Figure~\ref{fig:keyboard-scancodes} shows this for the two Windows keys, the (Windows) menu key and the right Alt and Ctrl keys. Note how Left-Alt and Right-Alt (or Left-Ctrl and Right-Ctrl) only differ in that the right keys generate the escape code and then the same code as the corresponding left key, e.\,g., 29 for Left-Ctrl and 224 / 29 for Right-Ctrl. This way a driver that is unaware of escape codes will just ignore the escape code and interpret the second code (almost) correctly.

In the ``Keyboard scancodes'' list \cite{brouwer2009scancodes}, Brouwer describes the newer keys, too. He also notes:
\begin{quotation}
``The prefix \verb#e0# was originally used for the grey duplicates of keys on the original PC/XT keyboard. These days \verb#e0# is just used to expand code space. The prefix \verb#e1# used for Pause/Break indicated that this key sends the make/break sequence at make time, and does nothing upon release.''
\end{quotation}

The terms \emph{scan codes}\marginnote{scan codes} and \emph{key codes} are sometimes used interchangeably, but there are other encodings of key-press and key-release events. We only discuss the key codes that are transmitted by the keyboard controller. They are also called ``set 1'' or ``IBM PC XT'' scan codes. A complete overview of ``set 1'' and ``set 2'' scan codes can also be found in a Microsoft specification document \cite{Microsoft:2000:Scancodes}.

All 0 entries in the map make \UlixI{} ignore a key. We also enter 0 in the map
for modifier keys (Shift, Ctrl, Alt etc.) since we handle them separately. For the Escape and cursor 
keys we provide names because we will use them later:

<<public constants>>=
#define KEY_ESC     27
#define KEY_UP     191
#define KEY_DOWN   192
#define KEY_LEFT   193
#define KEY_RIGHT  194
@ %def KEY_UP KEY_DOWN KEY_LEFT KEY_RIGHT

This is the table for the US keyboard:

\pagebreak

\index{scan code!US keyboard}%
<<global variables>>=
byte scancode_table[128] = {
  /*  0.. 9 */    0,  KEY_ESC, '1', '2', '3', '4', '5', '6', '7', '8',
  /* 10..19 */   '9', '0', '-', '=', '\b',	 /* Backspace */
                 '\t', /* Tab */   'q', 'w', 'e', 'r',
  /* 20..29 */   't', 'y', 'u', 'i', 'o', 'p', '[', ']', 
                 '\n', /* Enter */  0, /* Control */
  /* 30..39 */   'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', ';',
  /* 40..49 */   '\'', '`', 0, /* Left shift */  '\\', 'z', 'x', 'c', 'v', 'b', 'n',
  /* 50..59 */   'm', ',', '.', '/', 0, /* Right shift */
                 '*', 0, /* Alt */  ' ', /* Space bar */
                 0, /* CapsLock */  0, /* F1 */
  /* 60..69 */   0, 0, 0, 0, 0, 0, 0, 0, 0, /* F2..F10 */  0, /* NumLock */
  /* 70..79 */   0, /* Scroll Lock */  0, /* Home */  KEY_UP, 0, /* Page Up */
                 '-', KEY_LEFT, 0, KEY_RIGHT,  '+', 0, /* End */
  /* 80..89 */   KEY_DOWN, 0, /* Page Down */  0, /* Insert */  0, /* Delete */
                 0, 0, 0, 0, /* F11 */  0, /* F12 */   0,
  /* 90..127     not defined */
};

byte scancode_up_table[128] = {
  /*  0.. 9 */    0,  KEY_ESC, '!', '@', '#', '$', '%', '^', '&', '*',
  /* 10..19 */   '(', ')', '_', '+', '\b',	 /* Backspace */
                 '\t', /* Tab */   'Q', 'W', 'E', 'R',
  /* 20..29 */   'T', 'Y', 'U', 'I', 'O', 'P', '{', '}', 
                 '\n', /* Enter */  0, /* Control */
  /* 30..39 */   'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ':',
  /* 40..49 */   '"', '~', 0, /* Left shift */  '|', 'Z', 'X', 'C', 'V', 'B', 'N',
  /* 50..59 */   'M', '<', '>', '?', 0, /* Right shift */
                 '*', 0, /* Alt */  ' ', /* Space bar */
                 0, /* CapsLock */  0, /* F1 */
  /* 60..69 */   0, 0, 0, 0, 0, 0, 0, 0, 0, /* F2..F10 */  0, /* NumLock */
  /* 70..79 */   0, /* Scroll Lock */   0, /* Home */  KEY_UP, 0, /* Page Up */
                 '-', KEY_LEFT, 0, KEY_RIGHT, '+', 0, /* End */
  /* 80..89 */   KEY_DOWN, 0, /* Page Down */  0, /* Insert */  0, /* Delete */
                 0, 0, 0, 0, /* F11 */  0, /* F12 */   0,
  /* 90..127     not defined */
};
@ %def scancode_table scancode_up_table
\UlixI{} does not support German special characters (äöüÄÖÜß§), so the keys which would generate those characters are mapped to standard ASCII characters which can then be entered via two keys, for example, pressing [Ä] or [Shift-Ä] will generate the [[']] and [["]] characters. Users can switch between the US and German layouts by pressing [Ctrl-L].

\pagebreak

\index{scan code!German keyboard}%
<<global variables>>=
byte scancode_DE_table[128] = {
  /*  0.. 9 */   '^',  KEY_ESC, '1', '2', '3', '4', '5', '6', '7', '8',
  /* 10..19 */   '9', '0', '-', '\'', '\b',	 /* Backspace */
                 '\t', /* Tab */  'q', 'w', 'e', 'r',
  /* 20..29 */   't', 'z', 'u', 'i', 'o', 'p', '[', '+', 
                 '\n', /* Enter */  0, /* Control */
  /* 30..39 */   'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', ';',
  /* 40..49 */   '\'', '<', 0, /* Left shift */  '#', 'y', 'x', 'c', 'v', 'b', 'n',
  /* 50..59 */   'm', ',', '.', '-', 0, /* Right shift */
                 '*', 0, /* Alt */  ' ', /* Space bar */
                 0, /* CapsLock */  0, /* F1 */
  /* 60..69 */   0, 0, 0, 0, 0, 0, 0, 0, 0, /* F2..F10 */  0, /* NumLock */
  /* 70..79 */   0, /* Scroll Lock */   0, /* Home */  KEY_UP, 0, /* Page Up */
                 '-', KEY_LEFT, 0, KEY_RIGHT, '+', 0, /* End */
  /* 80..89 */   KEY_DOWN, 0, /* Page Down */  0, /* Insert */    0, /* Delete */
                 0, 0, 0, 0, /* F11 */  0, /* F12 */   0,
  /* 90..127     not defined */
};

byte scancode_DE_up_table[128] = {
  /*  0.. 9 */   '^',  KEY_ESC, '!', '"', '#', '$', '%', '&', '/', '(',
  /* 10..19 */   ')', '=', '?', '`', '\b',	 /* Backspace */
                 '\t', /* Tab */   'Q', 'W', 'E', 'R',	
  /* 20..29 */   'T', 'Y', 'U', 'I', 'O', 'P', '{', '*', 
                 '\n', /* Enter */  0, /* Control */
  /* 30..39 */   'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', ':',
  /* 40..49 */   '"', '>', 0, /* Left shift */  '\'', 'Z', 'X', 'C', 'V', 'B', 'N',
  /* 50..59 */   'M', ';', ':', '_', 0, /* Right shift */
                 '*', 0, /* Alt */  ' ', /* Space bar */
                 0, /* CapsLock */  0, /* F1 */
  /* 60..69 */   0, 0, 0, 0, 0, 0, 0, 0, 0, /* F2..F10 */  0, /* NumLock */
  /* 70..79 */   0, /* Scroll Lock */   0, /* Home */  KEY_UP, 0, /* Page Up */
                 '-', KEY_LEFT, 0, KEY_RIGHT, '+', 0, /* End */
  /* 80..89 */   KEY_DOWN, 0, /* Page Down */  0, /* Insert */    0, /* Delete */
                 0, 0, 0, 0, /* F11 */  0, /* F12 */   0,
  /* 90..127     not defined */
};
@ %def scancode_DE_table scancode_DE_up_table


\subsection{Virtual Consoles}

\index{virtual console}%
\index{hardware!virtual console}%
We provide ten virtual consoles (terminals), each of which has its own keyboard buffer. Such a buffer can store up to 32 characters---if an application does not react fast enough to key-press events, the buffer can become full: in that case further key-presses are lost.

<<constants>>=
#define SYSTEM_KBD_BUFLEN 32
#define TERMINALS 10
@ %def SYSTEM_KBD_BUFLEN TERMINALS

For each buffer we also store the current position (where the next character will be entered) and the last read position (which character was last read):
<<type definitions>>=
typedef struct {
  char kbd[SYSTEM_KBD_BUFLEN+1];
  int kbd_pos;
  int kbd_lastread;
  int kbd_count;
} terminal_t;
@ %def terminal_t
The [[kbd_count]] field is redundant but makes checking the buffer status simpler.

<<global variables>>=
terminal_t terminals[TERMINALS] = { { { 0 } } };
@ %def terminals

Terminal 0 is also used as the system terminal. \UlixI{} provides a kernel mode shell that can be activated with Shift-Esc. It always uses the first terminal and keeps its own set of position variables.

<<global variables>>=
char *system_kbd = terminals[0].kbd;
int system_kbd_pos;
int system_kbd_lastread;
int system_kbd_count;
@ %def system_kbd system_kbd_pos system_kbd_lastread system_kbd_count

They need to be initialized when the system boots:

<<setup keyboard>>=
system_kbd_pos = 0;
system_kbd_lastread = -1;
system_kbd_count = 0;
for (int i = 0;  i < 10;  i++) 
  terminals[i].kbd_lastread = -1;
@


\subsection{Keyboard Interrupt Handler}

\index{keyboard interrupt handler}%
\index{interrupt handler!keyboard|see {keyboard interrupt handler}}%
The keyboard handler deals will all press and release events:

%nouse
<<function prototypes>>=
void keyboard_handler (context_t *r);
@

It checks the variable [[LANG_GERMAN]] to decide whether it shall use the German or the US keyboard layout:
<<global variables>>=
boolean LANG_GERMAN = 1;   // default: german keyboard
@ %def LANG_GERMAN

The implementation is rather simple, the function is only long because it needs to handle key presses differently when one of the modifier keys (Left-Shift, Right-Shift, Ctrl, Alt) is held while another key is pressed. Other than that, the handler reads a scan code from the keyboard I/O port.

\index{port!keyboard controller}
<<constants>>=
#define IO_KEYBOARD 0x60
@ %def IO_KEYBOARD
and interprets it. For standard keys it looks up the assigned character using one of the scan code tables. Key-release events are ignored unless one of the modifier keys was released: in that case the status of [[shift_pressed]], [[alt_pressed]] etc.\ must be updated. We declare those variables as [[static]] in the function so that they keep their values between several invocations of the handler.

<<function implementations>>=
void keyboard_handler (context_t *r) {
  char *lower_table; char *upper_table;
  if (LANG_GERMAN) {  
    lower_table = scancode_DE_table; upper_table = scancode_DE_up_table;
  } else {
    lower_table = scancode_table;    upper_table = scancode_up_table;
  }
    
  static boolean shift_pressed = false;  static boolean left_shift_pressed  = false;
  static boolean alt_pressed   = false;  static boolean right_shift_pressed = false;
  static boolean ctrl_pressed  = false;
  <<keyboard handler implementation>>
}
@ %def keyboard_handler

After initializing the keyboard mapping and the states of the modifier keys the real work begins. We read the scan code from the I/O port [[IO_KEYBOARD]]. Then we check if the scan code corresponds to a key release event (i.\,e., the highest bit is set). That situation is only of interest for the modifier keys: If Shift, Ctrl or Alt were released, we update the corresponding static variable and return immediately. The release of regular keys is ignored. We also give the modifier key numbers names to make the code more readable:

<<constants>>=
#define KEY_CTRL     29
#define KEY_L_SHIFT  42
#define KEY_R_SHIFT  54
#define KEY_ALT      56
@ %def KEY_CTRL KEY_L_SHIFT KEY_R_SHIFT KEY_ALT

<<keyboard handler implementation>>=
byte scancode = inportb (IO_KEYBOARD);   // read_ scan code from keyboard
// printf ("SCANCODE: %d = 0x%x\n", scancode, scancode);    // REMOVE_DEBUGGING_CODE
if (scancode & 0x80) {                   // release key event
  switch (scancode & ~0x80) {
    case KEY_CTRL:    ctrl_pressed        = false; break;
    case KEY_L_SHIFT: left_shift_pressed  = false; break;
    case KEY_R_SHIFT: right_shift_pressed = false; break;
    case KEY_ALT:     alt_pressed         = false; break;
  }
  shift_pressed = left_shift_pressed || right_shift_pressed;
  return;
}
@

Otherwise we deal with a key press event. To keep things ordered nicely, we start with checking whether one of the modifier keys was pressed: Again, we can update a state variable and return from the handler. If that was not the case, we look up the character in the right scan code table (either [[upper_table]] or [[lower_table]]):

<<keyboard handler implementation>>=
// press key event
debug_printf ("KEYCODE: %d\n", scancode);             // REMOVE_DEBUGGING_CODE
switch (scancode) {
  case KEY_CTRL:    ctrl_pressed  = true;                       return;
  case KEY_L_SHIFT: shift_pressed = left_shift_pressed  = true; return;
  case KEY_R_SHIFT: shift_pressed = right_shift_pressed = true; return;
  case KEY_ALT:     alt_pressed   = true;                       return;
}

byte c = (shift_pressed ? upper_table[scancode] : lower_table[scancode]);
@

Then we check for special key combinations: Alt-0 to Alt-9 let us switch to a different terminal, Ctrl-C kills the current process,\marginnote{kernel mode\\ shell} Ctrl-L changes the keyboard layout, and Shift-Escape starts the \emph{kernel mode shell} (which can be used for debugging, see Chapter~\ref{chap:ulix:debugging}).

\pagebreak
\index{keyboard interrupt handler!kill process (Ctrl-C)}%
<<keyboard handler implementation>>=
// Alt-0 to Alt-9: switch terminal
if (alt_pressed && '0' <= c && c <= '9') {
  vt_activate ((int)((c-'0')+9)%10);   // activate virtual console
  vt_move_cursor ();                   // update cursor on new terminal
  return;
};
    
// Ctrl-C: kill and reset input
if (ctrl_pressed && c == 'c') {
  <<keyboard handler: find active process, set [[target_pid]]>>
  u_kill (target_pid, SIGKILL);        // kill the process
  return;
}

// Ctrl-L: change keyboard layout
if (ctrl_pressed && c == 'l') {
  switch (LANG_GERMAN) {
    case 0:  LANG_GERMAN = 1;  _set_statusline ("de", 44);  return;
    case 1:  LANG_GERMAN = 0;  _set_statusline ("en", 44);  return;
  }
}

// Shift-Escape: start_ kernel mode shell
if (shift_pressed && c == KEY_ESC && scheduler_is_active) {
  <<disable scheduler>>
  printf ("\nGoing to kernel shell\n");
  vt_activate (0);                     // must run on vt0
  kernel_shell ();
  printf ("returning from kernel shell\n");
  return;
};
@

With all special cases handled, only the default case remains:
If a regular character was entered, we need to store it in one of the
keyboard buffers---as long as it is not filled already. So we first check
whether the buffer can carry the new character:

\index{keyboard interrupt handler!wake waiting process}%
\index{process!wakes on key-press event}%
<<keyboard handler implementation>>=
terminal_t *term = &terminals[cur_vt];
if (term->kbd_count < SYSTEM_KBD_BUFLEN) {
  if (ctrl_pressed && c >= 'a' && c <= 'z') c -= 96;  // Ctrl
  term->kbd[term->kbd_pos] = c;
  term->kbd_pos = (term->kbd_pos + 1) % SYSTEM_KBD_BUFLEN;
  term->kbd_count++;
  if (scheduler_is_active) { <<keyboard handler: wake sleeping process>> }
}
@

We still need to discuss what happens when a process is sleeping
(while waiting for input from its terminal). We search the 
[[keyboard_queue]] (that we will define in the following section)
for a process which waits for input and uses
the currently active terminal [[cur_vt]]. If we find one (and we
assume that for each terminal at most one process can wait for
key entry) we wake it up, i.\,e., move it to the ready queue using
the [[deblock]] function:

<<keyboard handler: wake sleeping process>>=
thread_id start_pid = keyboard_queue.next;
if (start_pid != 0) {               // only if the queue is not empty
  thread_id search_pid = start_pid;
  do {
    if (thread_table[search_pid].terminal == cur_vt) {
      deblock (search_pid, &keyboard_queue);
      break;
    } else {
      search_pid = thread_table[search_pid].next;
    }
  } while (search_pid != start_pid && search_pid != 0);
}
@

A Ctrl-C key combination should make the system deliver a [[SIGKILL]] signal
to the process that uses the current terminal. There may be several such
processes; we will pick the first one which has no child process:

<<keyboard handler: find active process, set [[target_pid]]>>=
int target_pid = 0;
for (int i = 3;  i < MAX_THREADS;  i++) {
  if (thread_table[i].used && (thread_table[i].terminal == cur_vt)) {
    int is_candidate = true;
    for (int j = 3;  j < MAX_THREADS;  j++) {
      if (thread_table[j].used && (thread_table[j].ppid == i)) {
        // thread j has parent i - not a candidate
        is_candidate = false;
        break;   // leave inner loop
      }
    }
    if (is_candidate) {
      target_pid = i;
      goto end_of_search;
    }
  }
}
end_of_search:
;  // label needs a statement
@


\pagebreak
During system initialization we register the keyboard handler:

%nouse
<<function prototypes>>=
void keyboard_install ();
@

<<function implementations>>=
void keyboard_install () {
  install_interrupt_handler (IRQ_KBD, keyboard_handler);
  enable_interrupt (IRQ_KBD);
}
@ %def keyboard_install

We add calling [[keyboard_install]] to the general chunk that installs
interrupt handlers:


<<install the interrupt handlers>>=
keyboard_install ();
@


\subsection{The Keyboard Queue}

\index{blocked queue!keyboard}%
We provide several blocked queues---one for each different reason that
a process may block for. Here we define the queue for processes that
wait for a keystroke (on their terminal).

<<global variables>>=
blocked_queue keyboard_queue;   // processes which wait for a keystroke
@ %def keyboard_queue

We must initialize the queue:

<<initialize system>>=
initialize_blocked_queue (&keyboard_queue);
@

Now we can provide two functions which read in a character or a whole 
string:

%nouse
<<function prototypes>>=
void kgetch    (char *c);
void kreadline (char *s, int maxlength);
@

They are only used for the kernel mode shell, processes have their own
way of reading characters from the keyboard; they use the regular
file [[read]] function with the [[STDIN_FILENO]] file descriptor because
their input might be redirected to a file. We will describe this in
Chapter~\ref{chap:ulix:fs}.

In kernel mode we can just run a loop that waits for a new character to
appear in the keyboard buffer.

\pagebreak

<<function implementations>>=
void kgetch (char *c) {
  int t = thread_table[current_task].terminal;
  if (t < 0 || t > TERMINALS-1) {
    t = 0;  printf ("ERROR: terminal not set! setting to 0\n");
  }
  terminal_t *term = &terminals[t];

  *c = 0; 
  while (*c == 0) {
    if (term->kbd_count > 0) {
      term->kbd_count--;
      term->kbd_lastread = (term->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
      *c = term->kbd[term->kbd_lastread];
    } else {
      *c = 0;
    };
  };
};
@ %def kgetch

The [[kreadline]] function repeatedly calls [[kgetch]] until a newline character
is read (which terminates the input).

<<function implementations>>=
void kreadline (char *s, int maxlength) {
  char c;
  int pos = 0;
  for (;;) {
    <<enable interrupts>>
    kgetch (&c);                                // read_ one character
    if (c == 0x08 && pos > 0) {                 // backspace
      pos--;
      kputch (c); kputch (' '); kputch (c);
    } else if ( c == '\n' ) {                   // newline: end of input
      kputch ('\n');
      s[pos] = (char) 0;
      return;
    } else if (c != 0x08 && pos < maxlength) {  // other character
      kputch (c);
      s[pos++] = c;
    };
  };
};
@ %def kreadline





\section{Terminals}

\label{chap:ulix:virtualconsoles}%
\index{hardware!terminal}%
\index{hardware!VGA graphics adapter}%
\index{terminal}\index{VGA graphics adapter}%
\index{virtual terminal}%

We want \UlixI{} to provide \emph{several terminals} so that we can run a few
login shells and execute programs on them.

Conceptually, providing terminals is not complicated: we need

\begin{itemize}
\item memory to store the contents of the terminals -- roughly 80 x 25 x 2
bytes per terminal (the size of the textmode video buffer),
\item a way to make \Ulix{} switch the active terminal,
\item a modification of the [[write()]] functions so that they will
either write to the current terminal or a specified terminal.
\item When writes to a terminal occur, the terminal's screen buffer
is updated---if it is the active terminal, the screen is updated at
the same time.
\item When switching to a different terminal, its screen buffer is
copied to the screen.
\end{itemize}

We start with the required memory. Since \UlixI{} uses the last line on
the screen for displaying a status line, we consider it not to be part
of any terminal buffer; for example scrolling shall always ignore the
last line, and from a process' point of view the 25th line does not 
exist. So we can define

<<constants>>=
#define VT_WIDTH  (80)
#define VT_HEIGHT (24)
#define VT_SIZE   (VT_WIDTH * VT_HEIGHT * 2)
@ %def VT_WIDTH VT_HEIGHT VT_SIZE

<<type definitions>>=
typedef struct {
  char mem[VT_SIZE];
  int x,y;
} term_buffer;
@ %def term_buffer

Two bytes are required for each character; the first one holds the
ASCII value of the symbol to be displayed, the second is used for
foreground and background colors.

We want the system to use up to ten virtual consoles (numbered from
0 to 9), so we create an array for them:
\index{maximum number of virtual terminals}

<<constants>>=
#define MAX_VT 9
@ %def MAX_VT

<<global variables>>=
term_buffer vt[MAX_VT+1];
int cur_vt = 0;
@ %def vt cur_vt

[[vt[i].mem]] is the buffer of console [[i]], and [[vt[i].x]] and
[[vt[i].y]] hold the current cursor position in console [[i]]. We
initialize the current terminal to number 0.

To start with proper contents, we initialize each of the ten 
text buffers with blanks. A blank character is actually a
[[word]] with the low byte containing the ASCII value
of the blank symbol (\hex{20}) and the high byte containing the
color information (\hex{0F} for white on black).

<<public constants>>=
#define VT_NORMAL_BACKGROUND (0x0F << 8)
#define VT_BLUE_BACKGROUND   (0x1F << 8)
#define VT_RED_BACKGROUND    (0x4F << 8)
@ %def VT_NORMAL_BACKGROUND VT_BLUE_BACKGROUND VT_RED_BACKGROUND



<<initialize system>>=
int vtno;
word *memptr;
unsigned blank = 0x20 | VT_NORMAL_BACKGROUND;  // blank character
for (vtno = 1;  vtno < 10;  vtno++) {
  memptr = (word*)vt[vtno].mem;
  memsetw (memptr, blank, VT_SIZE/2);
}
printf ("VT:  Initialized ten terminals (press [Alt-1] to [Alt-0])\n");
@  Note that we do \emph{not} initialize the first terminal's buffer [[vt[0]]] because it will obtain a copy of the current screen when we switch to a different terminal.

We also need a way to tell a process what terminal it runs on, so we
add a new [[TCB]] entry:

<<more TCB entries>>=
int terminal;
@

A regular Unix system would allow for a more complex setup, but
for \UlixI{} we restrict ourselves to using ten text consoles.

Activating a console via
%nouse
<<function prototypes>>=
int vt_activate (int i);
@ is the simplest of all the operations:

\pagebreak

<<function implementations>>=
int vt_activate (int new_vt) {
  if (new_vt < 0 || new_vt > MAX_VT)  return -1;        // no such console
  else {
    memcpy (vt[cur_vt].mem, (void*)VIDEORAM, VT_SIZE);  // save old contents
    vt[cur_vt].x = csr_x; vt[cur_vt].y = csr_y; 
    memcpy ((void*)VIDEORAM, vt[new_vt].mem, VT_SIZE);  // load new contents
    cur_vt = new_vt;
    csr_x = vt[new_vt].x; csr_y = vt[new_vt].y;
    vt_move_cursor ();
    return 0;
  }
}
@ %def vt_activate

Here we're using the address [[VIDEORAM]] to access the text mode frame buffer of the graphics card; [[csr_x]] and [[csr_y]] store the cursor position on the visible terminal. We have not defined the variables yet, so here they are:

\index{video RAM}%
<<global variables>>=
uint VIDEORAM = 0xB8000;
byte csr_x = 0; byte csr_y = 0;   // Cursor position
@ %def VIDEORAM csr_x csr_y

It is initially set to \hex{b8000} but changes its value to \hex{d00b8000} during
system initialization (when we set up paging). We can also use [[textmemptr]] which was \verb!#define!d as [[((word*)VIDEORAM)]].

With [[vt_move_cursor]] we update the cursor location\marginnote{update cursor\\ location}, since it will need to be
in a different position on the new terminal.
The cursor location can be controlled by sending $80 \cdot x + y$ (where $x$ is the line number and $y$ is the column number) to the VGA cursor location register. This is a 16 bit value---it must be sent in two chunks. First the control code [[IO_VGA_CURSOR_LOC_HIGH]] is sent to the [[IO_VGA_TARGET]] port (which signals that the high byte of the cursor location follows), then that high byte is sent to the [[IO_VGA_VALUE]] port. A similar sequence follows, using [[IO_VGA_CURSOR_LOC_LOW]] and the lower byte.

\index{port!VGA graphics adapter}%
<<constants>>=
#define IO_VGA_TARGET           0x3D4
#define IO_VGA_VALUE            0x3D5
#define IO_VGA_CURSOR_LOC_HIGH  14
#define IO_VGA_CURSOR_LOC_LOW   15
@ %def IO_VGA_TARGET IO_VGA_VALUE IO_VGA_CURSOR_LOC_HIGH IO_VGA_CURSOR_LOC_LOW

%nouse
<<function prototypes>>=
void vt_move_cursor ();
@

<<function implementations>>=
void vt_move_cursor () {
  unsigned position = csr_y * 80 + csr_x;
  // high byte:
  outportb (IO_VGA_TARGET, IO_VGA_CURSOR_LOC_HIGH);
  outportb (0x3D5, position >> 8);
  // low byte:
  outportb (IO_VGA_TARGET, IO_VGA_CURSOR_LOC_LOW);
  outportb (0x3D5, position & 0xff);  // low byte
}
@ %def vt_move_cursor

Let's define what terminal we expect to display kernel messages.
We initialize the variable [[KERNEL_VT]] to 0 (for the first terminal), 
though it may later be changed.

<<global variables>>=
short int KERNEL_VT = 0;
@ %def KERNEL_VT

Back to terminal selection, we provide a system call that lets a process choose which terminal to use.

\index{setterm system call@\texttt{setterm} system call}%
\index{system call!setterm@\texttt{setterm}}%
<<function implementations>>=
void syscall_setterm (context_t *r) {
  int vt = r->ebx;                             // argument in ebx register
  if (vt<0 || vt>MAX_VT) { return; }           // check if proper number...
  thread_table[current_task].terminal = vt;
  debug_printf ("DEBUG: current_task = %d\n",              // REMOVE_DEBUGGING_CODE
                current_task);                             // REMOVE_DEBUGGING_CODE
  debug_printf ("DEBUG: terminal     = %d\n", vt);         // REMOVE_DEBUGGING_CODE
};
@ %def syscall_setterm

We define the system call number and register the syscall:

<<public constants>>=
#define __NR_setterm  511
@ %def __NR_setterm

<<initialize syscalls>>=
install_syscall_handler (__NR_setterm, syscall_setterm);
@

The user mode library gains a new function as well:

%nouse
<<ulixlib function prototypes>>=
void setterm (int vt);
@

<<ulixlib function implementations>>=
void setterm (int vt) { syscall2 (__NR_setterm, (uint) vt); }
@ %def setterm

We also need functions to clear the screen, set the cursor and get
the current cursor location:

%nouse
<<function prototypes>>=
void vt_clrscr ();
void vt_get_xy (char *x, char *y);
void vt_set_xy (char x, char y);
@

Clearing\marginnote{clearing the\\ screen} the screen means writing a blank character to each location. We need to consider that each character byte is followed by a format byte and---if calling the function from the kernel---we want to format the last line with a blue background so that the status line can be recognized.

[[vt_clrscr]] just overwrites the terminal buffer of the current process with blank characters and then calls [[vt_set_xy]] to set the cursor to the top left position. If the current process is also working on the currently visible terminal, the function updates the physical screen as well. (Otherwise the change will only become visible when the user switches to that terminal.)

<<function implementations>>=
void vt_clrscr () {
  word blank    = 0x20 | VT_NORMAL_BACKGROUND;
  word blankrev = 0x20 | VT_BLUE_BACKGROUND;
  int process_term;
  if (scheduler_is_active) {
    process_term = thread_table[current_task].terminal;
    word *memptr = (word*)vt[process_term].mem;
    memsetw (memptr, blank, VT_SIZE/2);                     // lines 1-24
    vt_set_xy (0, 0);
  }
  
  // current terminal?
  if ((!scheduler_is_active) || (scheduler_is_active && process_term == cur_vt))
    memsetw (textmemptr, blank, VT_SIZE/2);                 // lines 1-24
    
  // kernel mode? clear status line, set cursor
  if (!scheduler_is_active) {
    memsetw (textmemptr + VT_SIZE/2, blankrev, VT_WIDTH);   // line  25
    csr_x = csr_y = 0;
    vt_move_cursor ();
  }
}
@ %def vt_clrscr

\pagebreak

The [[vt_get_xy]] and [[vt_set_xy]] read respectively set the [[x]] and [[y]] members of the current terminal's [[term_buffer]] structure. We will only call them from processes, so we need not check for as many special cases as we did in [[vt_clrscr]]. The only condition we have to check is whether we're changing the cursor location of the currently active terminal---then we also need to update the hardware cursor.

<<function implementations>>=
void vt_get_xy (char *x, char *y) {
  int process_term = thread_table[current_task].terminal;
  *x = vt[process_term].x;
  *y = vt[process_term].y;
}

void vt_set_xy (char x, char y) {
  int process_term = thread_table[current_task].terminal;
  vt[process_term].x = x;
  vt[process_term].y = y;
  
  // current terminal?
  if (process_term == cur_vt) {
    csr_x = x; csr_y = y;
    vt_move_cursor ();
  }
}
@ %def vt_get_xy vt_set_xy

We provide three system calls 

%nouse
<<syscall prototypes>>=
void syscall_clrscr (context_t *r);
void syscall_get_xy (context_t *r);
void syscall_set_xy (context_t *r);
@ for these functions:

<<ulix system calls>>=
#define __NR_clrscr   512
#define __NR_get_xy   513
#define __NR_set_xy   514
@ %def __NR_clrscr __NR_get_xy __NR_set_xy

As usual, the system call handlers evaluate the parameters by looking at the registers \register{EBX} and \register{ECX} (if there are any), then they call the above functions.

\pagebreak

<<syscall functions>>=
void syscall_clrscr (context_t *r) {
  // no parameters, no return value
  vt_clrscr ();
}

void syscall_get_xy (context_t *r) {
  // ebx: address of x position (char)
  // ecx: address of y position (char)
  vt_get_xy ((char*)r->ebx, (char*)r->ecx);
}

void syscall_set_xy (context_t *r) {
  // ebx: x position (char)
  // ecx: y position (char)
  vt_set_xy ((char)r->ebx, (char)r->ecx);
}
@ %def syscall_clrscr syscall_get_xy syscall_set_xy

And we add those system calls to the system:

<<initialize syscalls>>=
install_syscall_handler (__NR_clrscr, syscall_clrscr);
install_syscall_handler (__NR_get_xy, syscall_get_xy);
install_syscall_handler (__NR_set_xy, syscall_set_xy);
@

Via the user mode library we provide the functionality to processes:

%nouse
<<ulixlib function prototypes>>=
void clrscr ();
void get_xy (char *x, char *y);
void set_xy (char x, char y);
@

<<ulixlib function implementations>>=
void clrscr ()                 { syscall1 (__NR_clrscr);                   }
void get_xy (char *x, char *y) { syscall3 (__NR_get_xy, (int) x, (int) y); }
void set_xy (char x, char y)   { syscall3 (__NR_set_xy, (int) x, (int) y); }
@ %def clrscr get_xy set_xy

\enlargethispage{5mm}
To make life easier for the application programmer (who cannot access
the screen memory directly) we also provide functions which allow
reading or writing the whole screen (that is: 24 lines of 80 characters;
the last line on the $80 \times 25$ display is reserved for the operating 
system). For this purpose we implement the [[read_screen]] and
[[write_screen]] functions and let applications call them via system
calls.

\pagebreak

%nouse
<<function prototypes>>=
void read_write_screen (char *buf, boolean read_flag);
void read_screen (char *buf);
void write_screen (char *buf);
@

<<function implementations>>=
void read_write_screen (char *buf, boolean read_flag) {
  // if read_flag == true: read_ from screen, otherwise write_
  int process_term = thread_table[current_task].terminal;
  char *video_address = (char*) vt[process_term].mem;
  
  if (read_flag) {
    memcpy (buf, video_address, VT_SIZE);    // read_ the screen
  } else {
    memcpy (video_address, buf, VT_SIZE);    // write_ the screen
    // current terminal?
    if (process_term == cur_vt)
      memcpy ((char*)VIDEORAM, video_address, VT_SIZE);
  }
}

void read_screen (char *buf)  { read_write_screen (buf, true);  }
void write_screen (char *buf) { read_write_screen (buf, false); }
@ %def read_write_screen read_screen write_screen

In the system call handlers we call [[read_write_screen]] instead of
[[read_screen]] and [[write_screen]] to save the extra function call:

<<ulix system calls>>=
#define __NR_read_screen   515
#define __NR_write_screen  516
@

<<syscall functions>>=
void syscall_read_screen (context_t *r) {
  // ebx: buffer address
  read_write_screen ((char *) r->ebx, true);
}

void syscall_write_screen (context_t *r) {
  // ebx: buffer address
  read_write_screen ((char *) r->ebx, false);
}
@ %def syscall_read_screen syscall_write_screen

<<initialize syscalls>>=
install_syscall_handler (__NR_read_screen,  syscall_read_screen);
install_syscall_handler (__NR_write_screen, syscall_write_screen);
@

Again, we add these to the library:

%nouse
<<ulixlib function prototypes>>=
void read_screen (char *buf);
void write_screen (char *buf);
@

<<ulixlib function implementations>>=
void read_screen (char *buf)   { syscall2 (__NR_read_screen, (uint) buf);  }
void write_screen (char *buf)  { syscall2 (__NR_write_screen, (uint) buf); }
@ %def read_screen write_screen

Applications can use [[read_screen]] and [[write_screen]] for 
scrolling.\marginnote{scrolling in\\ user mode}\index{scrolling!user mode}
Here's a simple [[scroll]] function which scrolls the user
mode part of the screen (lines 1--24) one line ``up''
(that means: the first lines disappears, and all other lines
move up one line, leaving one blank line at the bottom)

%nouse
<<ulixlib function prototypes>>=
void scroll_up ();
void scroll_down ();
@

<<ulixlib function implementations>>=
void scroll_up () {
  char buffer[80*25*2];  // we reserve space for 25 (!) lines
  word blank = 0x20 | VT_NORMAL_BACKGROUND; // blank character
  read_screen ((char*)buffer);
  memsetw ((word*)((char*)buffer + 80*24*2), blank, 80);
  write_screen ((char*)buffer + 160);
}

void scroll_down () {
  char buffer[80*25*2];  // we reserve space for 25 (!) lines
  word blank = 0x20 | VT_NORMAL_BACKGROUND; // blank character
  read_screen ((char*)buffer + 160);
  memsetw ((word*)((char*)buffer), blank, 80);
  write_screen ((char*)buffer);
}
@ %def scroll_up scroll_down

For scrolling from inside the kernel\index{scrolling!kernel mode}\marginnote{scrolling in\\ kernel mode}, we provide a helper function that can ``scroll'' any screen-sized chunk of memory. In our case that is an area of 24 lines à 80 characters, each of which is 2 bytes large ($24 \times 80 \times 2 = 3840$ bytes), and scrolling it means to move lines 2--24 to lines 1--23 and empty line 24.

<<function implementations>>=
void vt_scroll_mem (word *address) {
  word blank = ' ' | VT_NORMAL_BACKGROUND;  // space + format
  memcpy  (address, address + VT_WIDTH, (VT_HEIGHT-1) * VT_WIDTH * 2);
  memsetw (address + (VT_HEIGHT-1) * VT_WIDTH, blank, VT_WIDTH);
}
@ %def vt_scroll_mem
Note that this function uses pointer arithmetic: [[address]] is of type [[word*]], i.\,e., a pointer to a 16-bit wide integer. That means that when we add e.\,g.\ [[VT_WIDTH]] to [[address]], the resulting address is actually [[2 * VT_WIDTH]] higher.

<<function implementations>>=
void vt_scroll () {
  term_buffer *term;
  short int target_vt;
  if (scheduler_is_active) {
    target_vt = thread_table[current_task].terminal;
    term = &vt[target_vt];
  } else {
    target_vt = KERNEL_VT;   // kernel: default write_ to 0
  }

  if (cur_vt == target_vt && csr_y >= VT_HEIGHT) {
    vt_scroll_mem ((word*)VIDEORAM);
    csr_y = VT_HEIGHT-1;
  }

  if (scheduler_is_active && term->y >= VT_HEIGHT) {
    vt_scroll_mem ((word*)term->mem);
    term->y = VT_HEIGHT-1;
  }
}
@ %def vt_scroll


\pagebreak
\subsection{Terminal Output}

The next two functions

%nouse
<<function prototypes>>=
void kputch (byte c);
void kputs (char *text);
@ %
%
write a character or a string to the screen. 

% more about VGA hardware:
% http://www.opensource.apple.com/source/xnu/xnu-792.13.8/osfmk/console/i386/text_console.c

The [[kputch]] function is based on the [[scrn.c]] function of Bran's kernel tutorial \cite{brans-tutorial:200x} but was modified a lot.

<<function implementations>>=
void kputch (byte c) {
  // check if we're writing to current terminal
  term_buffer *term;
  short int target_vt;
  word *where;
  if (scheduler_is_active) {
    target_vt = thread_table[current_task].terminal;
    term = &vt[target_vt];
  } else {
    target_vt = KERNEL_VT;   // kernel: default write_ to 0
  }

  switch (c) {
    case '\b': // backspace, move cursor back
               if (cur_vt == target_vt) { if (csr_x   != 0) csr_x--;   }
               if (scheduler_is_active) { if (term->x != 0) term->x--; }
               break;

    case '\r': // carriage return, go back to first column
               if (cur_vt == target_vt) { csr_x = 0;   }
               if (scheduler_is_active) { term->x = 0; }
               break;

    case '\n': // newline, go to next line, first column
               if (cur_vt == target_vt) { csr_x = 0;    csr_y++;   }
               if (scheduler_is_active) { term->x = 0;  term->y++; }
               break;
  }

  if (c >= ' ') {   // normal character
    if (cur_vt == target_vt) {
      where = textmemptr + (csr_y * 80 + csr_x);
      *where = c | VT_NORMAL_BACKGROUND;
      csr_x++;
    }
    if (scheduler_is_active) {
      where = (word*)term->mem + (term->y * 80 + term->x);
      *where = c | VT_NORMAL_BACKGROUND;
      term->x++;
    }
  }

  if (csr_x >= 80) {   // end of line reached
    if (cur_vt == target_vt) { csr_x = 0;    csr_y++;   }
    if (scheduler_is_active) { term->x = 0;  term->y++; }
  }

  vt_scroll ();   // scroll if necessary
  if (cur_vt == target_vt) { vt_move_cursor (); };
    
  // write_ to serial console
  if (c == '\b') {  //  backspace
    uartputc ('\b'); uartputc (' '); uartputc ('\b');
  } else uartputc (c);
  // bochs_putch (c);   // also write_ on BOCHS terminal  // REMOVE_DEBUGGING_CODE
}

void kputs (char *text) {
  while (*text != 0) 
    kputch (*(text++));
}
@ %def kputch kputs

\index{hardware!serial console}%
\index{serial console}%
For writing to the serial console, [[kputch]] uses the helper function
%nouse
<<function prototypes>>=
void uartputc (int c);
@ which sends a character to the I/O port [[IO_COM1]]. This is useful for running \UlixI{} in the [[qemu]] PC emulator \cite{QEMU} which can display serial line output in the terminal window of the host machine, see also Section~\ref{sec:hardware:serialports} on serial ports.
\label{function:uartputc}

<<function implementations>>=
void uartputc (int c) {
  // taken from the xv6 operating system [CKM12], uart.c
  if (!uart[0]) return;      // leave if we have no first serial port
  // wait until COM1 is ready to receive another byte
  for (int i = 0; i < 128 && !(inportb (IO_COM1+5) & 0x20); i++) ;
  outportb (IO_COM1+0, c);   // write_ the byte
}
@ %def uartputc


\subsection{Status Line Management}

The last line on the screen\marginnote{kernel status\\ messages} is reserved for the \UlixI{} status line. We provide two functions which let the kernel display status messages:

%nouse
<<function prototypes>>=
void set_statusline (char *text);
void _set_statusline (char *text, int offset);
@

The first function, [[set_statusline]], always writes to the start of the status line, whereas [[_set_statusline]] takes an extra position argument and can be used to update a small location somewhere in the middle of the line.

\black
<<function implementations>>=
void set_statusline (char *text) { _set_statusline (text, 0); }

void _set_statusline (char *text, int offset) {
  int i = 0;
  uint videoaddress = VIDEORAM + VT_SIZE+2*offset;  // last line of video
  while ((*text != 0) && (i < 80)) {
    POKE (videoaddress + 2*i, *text);
    i++; text++;
  }
}
@ %def _set_statusline set_statusline


\subsection{Initializing the Screen}

When we described the kernel initialization in the [[main]] function, we 
promised to define the code chunk [[<<setup video>>]] in this chapter---here
it is: We use [[vt_clrscr]] to clear the screen and [[set_statusline]] to
display the OS name and version. 

<<setup video>>=
vt_clrscr ();
set_statusline (UNAME);
printf ("%s                           Build: %s\n", UNAME, BUILDDATE); 
@

Remember that we've set [[UNAME]] and [[BUILDDATE]] at the very beginning.

\pagebreak

\section{System Timer}

\index{hardware!timer}%
\index{timer}%
\index{clock chip}%
A central hardware component is the \emph{clock chip}\marginnote{clock chip\\ timer interrupt} which regularly causes a \emph{timer interrupt}. By adding a timer handler, the kernel can regularly check whether some administrative action is necessary. The most important action is calling the scheduler: Without the timer handler we would have to live without preemptive multi-tasking.

There are many other tasks for the timer handler, for example we will use it to keep track of time in our system. Every time the timer handler runs, we will increment a [[system_ticks]] variable that must be initialized at system start. [[system_time]] will be set to Unix time (the seconds since the \emph{Unix epoch}\marginnote{Unix epoch}, 1 January 1970, 00:00:00 UTC) so that we can properly display the date and time and update timestamps in the filesystem.

<<global variables>>=
unsigned int system_ticks = 0; // updated 100 times a second
unsigned int system_time;      // unix time (in seconds)
@ %def system_ticks system_time


\subsection{Setting the Frequency}

\index{frequency (timer chip)}%
Initially the clock chip is pre-set to a weird frequency\marginnote{timer frequency} ($\approx 18.222$~Hz), we change that to 100~Hz when the system starts. The function

%nouse
<<function prototypes>>=
void timer_phase (int hz);
@ adjusts the timer's frequency: It first announces that it wants to set the frequency by sending \hex{36} to port [[IO_CLOCK_COMMAND]] and then sends the lower and the higher eight bits of the divisor [[1193180 / hz]] to the port [[IO_CLOCK_CHANNEL0]] which is responsible for configuring timer 0 (the system timer) \cite[p.~794]{Gilluwe:1995:UndocumentedPC}.

<<function implementations>>=
void timer_phase (int hz) {
  // source: http://www.osdever.net/bkerndev/Docs/pit.htm
  int divisor = 1193180 / hz;                    // calculate divisor
  outportb (IO_CLOCK_COMMAND,  0x36);            // set command byte 0x36
  outportb (IO_CLOCK_CHANNEL0, divisor & 0xFF);  // set low byte of divisor
  outportb (IO_CLOCK_CHANNEL0, divisor >> 8);    // set high byte of divisor
};
@ %def timer_phase

with

\index{port!timer chip}%
<<constants>>=
#define IO_CLOCK_COMMAND   0x43
#define IO_CLOCK_CHANNEL0  0x40
@ %def IO_CLOCK_COMMAND IO_CLOCK_CHANNEL0

When the kernel runs through the initialization steps, we let it set the frequency and install the timer interrupt handler (whose implementation we will discuss soon) for interrupt number [[IRQ_TIMER]] (0). While we're at it, we also query the current date and time.

<<install the timer>>=
timer_phase (100);   // set timer to 100 Hz (100 interrupts/second)
install_interrupt_handler (IRQ_TIMER, timer_handler);
enable_interrupt (IRQ_TIMER);
<<read date and time from CMOS>>
@


\subsection{Reading the Date and Time}

Since it is a somewhat related task, we also query the PC's CMOS chip to find out what date and time it is \cite[p.~746--747]{Gilluwe:1995:UndocumentedPC}:

\index{CMOS chip}%
\index{hardware!CMOS chip}%
\index{time (CMOS chip)}%
\index{date (CMOS chip)}%
\index{port!CMOS chip}%
<<constants>>=
#define IO_CMOS_CMD  0x70
#define IO_CMOS_DATA 0x71
@ %def IO_CMOS_CMD IO_CMOS_DATA

<<global variables>>=
unsigned long system_start_time = 0;
@ %def system_start_time

<<read date and time from CMOS>>=
// code adapted from http://wiki.osdev.org/CMOS
outportb (IO_CMOS_CMD,    0); byte second =  inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD,    2); byte minute =  inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD,    4); byte hour =    inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD,    7); byte day =     inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD,    8); byte month =   inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD,    9); word year =    inportb (IO_CMOS_DATA);
outportb (IO_CMOS_CMD, 0x32); word century = inportb (IO_CMOS_DATA);
@

\index{BCD (binary-coded decimal)}%
The values that the CMOS chip returns are \emph{BCD}\marginnote{BCD}-encoded (binary-coded decimal; each half-byte encodes a decimal digit, from 0 = \bin{0000} to 9 = \bin{1001}), so they have to be converted so that they make sense: To convert one BCD byte into a proper number, take the upper half times 10 ([[(bcd @>> 4) * 10]]) and add the lower half ([[bcd & 0x0f]]):

\pagebreak

<<macro definitions>>=
#define CONVERT_BCD(bcd) (((bcd @>> 4) * 10) + (bcd & 0x0f))
@ %def CONVERT_BCD

<<read date and time from CMOS>>=
second = CONVERT_BCD (second);  minute  = CONVERT_BCD (minute);
hour   = CONVERT_BCD (hour);    day     = CONVERT_BCD (day);
month  = CONVERT_BCD (month);   century = CONVERT_BCD (century);
year   = CONVERT_BCD (year) + 100 * century;
system_start_time = unixtime (year, month, day, hour, minute, second);
printf ("Current time: %4d/%02d/%02d %02d:%02d:%02d\n", 
        year, month, day, hour, minute, second);
@

The year is only stored with two digits (e.\,g., 14 for the year 2014), so we have to add \linebreak [[100 * century]].
Some CMOS chips return the hour in ``12 hour time''. For example, they would represent the hour value 23 as 11 and set the highest bit to indicate ``pm'' time. A formula that can cope with both types of BIOS is

%nouse
<<alternative hour transformation>>=
hour = ( (hour & 0x0F) + (((hour & 0x70) / 16) * 10) ) | (hour & 0x80);
@

\noindent
---we do not use it since [[qemu]] returns ``24 hour time''.
We need functions 

%BREAK BEFORE DEFINES
%nouse
<<function prototypes>>=
ulong unixtime (int year, int month, int day, int hour, int minute, int second);
void rev_unixtime (ulong unixtime, short *year, char *month, char *day,
                   char *hour, char *minute, char *second);
@ that convert between Unix time\index{Unix time (epoch)}\index{epoch (Unix time)} (seconds since 01/01/1970) and a time structure with year, month, day, hour, minute and second. You can skip the implementation of the following two functions since they are neither pretty to look at nor do they tell you anything about operating systems. 

<<function implementations>>=
ulong unixtime (int year, int month, int day, int hour, int minute, int second) {
  // Source code taken from http://de.wikipedia.org/wiki/Unixzeit,
  // variable and function names translated to english
  const short days_since_start_of_year[12] = 
    {0,31,59,90,120,151,181,212,243,273,304,334};
  unsigned long years=year-1970;
  int leapyears=((year-1)-1968)/4 - ((year-1)-1900)/100 + ((year-1)-1600)/400;
 
  ulong unix_time = second + 60*minute + 60*60*hour +
                    (days_since_start_of_year[month-1]+day-1)*60*60*24 +
                    (years*365+leapyears)*60*60*24; 
  if ( (month>2) && (year%4==0 && (year%100!=0 || year%400==0)) )
    unix_time+=60*60*24;   // leap day?
  return unix_time;
}
@ %def unixtime

The function [[rev_unixtime]] is not used in the \UlixI{} kernel at all, however the user mode program [[ls]] uses it, so we show it here for completeness. [[yearlength]] is a helper function that returns the length of a year (either 364 or 365 for a leap year).

<<function implementations>>=
short yearlength (short year) {
  int res = 364;
  if ( ((year % 4 == 0) && ( year % 100 != 0)) || (year % 400 == 0) )  res++;
  return res;
}
 
void rev_unixtime (ulong utime, short *year, char *month, char *day,
                   char *hour, char *minute, char *second) {
  char days_per_month[] = {0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};
  int days = utime / (60*60*24);    char sec = utime % 60;
  char min = (utime/60) % 60;       char hou  = (utime/(60*60)) % 24;
  
  int yy = 1970;
  if (days > 15706) {   // speed up calculation for 2013 or later
    days -= 15706;
    yy += 43;
  }

  for (;;) {
    int l = yearlength (yy);
    if (days >= l) {
      yy++;
      days -= (l+1);    // distance between two years is l+1, not l
    } else break;
  }
      
  int mon = 1;
  for (;;) {
    int l = days_per_month[mon];
    if ((l == 2) && (yearlength (yy) == 365)) l++;
    if (days >= l) {
      mon++;
      days -= l;
    } else break;
  }
  
  days++;
  *year = yy;   *month  = mon; *day    = days;   // return results
  *hour = hou;  *minute = min; *second = sec;
}
@ %def yearlength rev_unixtime


\pagebreak
\subsection{Implementation of the Timer Handler}

This is our timer interrupt handler\index{timer interrupt handler}\index{interrupt handler!timer}:

\label{chunk:timer-handler}
%nouse
<<function prototypes>>=
void timer_handler (context_t *r);
@ It executes all the timer tasks (as defined in the code chunk [[<<timer tasks>>]] and updates the status line.

<<function implementations>>=
void timer_handler (context_t *r) {
  char buf[80];   // temporary buffer, can be used by all timer tasks
  <<timer tasks>>
  
  // show current terminal, free frames, current_as
  sprintf ((char*)&buf, "tty%d  FF=%04x  AS=%04d", cur_vt, free_frames, current_as);
  _set_statusline ((char*)&buf, 48);  
}
@ %def timer_handler


\subsection{Tasks for the Timer}

\index{timer tasks}%
\index{task for the timer}%
We need the timer handler to do several things which we collect in the [[<<timer tasks>>]] code chunk. The first and easiest task is to modify the system uptime:

<<timer tasks>>=
system_ticks++;    // one more timer interrupt
system_time = (uint)(system_ticks/100) + system_start_time;  // frequency: 100 Hz
@

Next, it calls the scheduler. It also displays a quickly changing progress character in the right top corner of the screen so that users can check that the scheduler is still active. If those signs stop spinning, something has gone wrong.

<<timer tasks>>=
char sched_chars[] = "|/-\\";   // scheduler activity
static short sched_c = 0;       // next character to display

if (system_ticks % 5 == 0) {
  // cycle |/-\\- to show scheduler calls in upper right corner
  POKE (VIDEORAM + 79*2, sched_chars[sched_c]);
  sched_c++; sched_c %= 4;
  scheduler (r, SCHED_SRC_TIMER);
};
@

\pagebreak
As mentioned earlier, the timer handler does not call [[scheduler]] if a resign action is currently active. When it does call the scheduler, it provides a second [[SCHED_SRC_TIMER]] argument to indicate that it was him who called. (The alternative is that [[syscall_resign]] called the scheduler which it announces by using [[SCED_SRC_RESIGN]].)

<<constants>>=
#define SCHED_SRC_TIMER   0
#define SCHED_SRC_RESIGN  1
@ %def SCHED_SRC_TIMER SCHED_SRC_RESIGN

In the status line at the bottom of the screen we display the current
time; we want to update this display approximately every other second:

<<timer tasks>>=
short int sec,min,hour;

if (system_ticks % 100 == 0) {          // Every 100 clocks (approx. 1 second) 
  hour = (system_time/60/60)%24;        // display the time
  min = (system_time/60)%60;
  sec = system_time%60;
  sprintf ((char*)&buf, "%02d:%02d:%02d", hour, min, sec);
  _set_statusline ((char*)&buf, 72);
}
@

There are only two further places in the book where [[<<timer tasks>>]] gets an addition; we have decided not to place them in this chapter but at the places where the need for them arises. These are the chunks:

\begin{itemize}
\item Updating the counters for the page replacement code, p.~\pageref{timer-tasks-counters}
\item Releasing the [[swapper_lock]] so that the \verb#swapper# process can enter the next loop, p.~\pageref{timer-tasks-remove-swapper-lock}
\end{itemize}


\section{Serial Ports}
\label{sec:hardware:serialports}%
\index{hardware!serial port}%
\index{serial port}%

\UlixI{} supports two serial ports. It uses the first one to copy the regular output to a serial console and also writes kernel debug messages to that console. When running in a PC emulator which can redirect serial ports, these messages can be displayed in the terminal window from which \UlixI{} was started. The \path!Makefile! in the \path!bin-build/! directory calls [[qemu]] with a [[-serial]] option and a pipe into the [[tee]] command

\begin{Verbatim}
-serial mon:stdio | tee ulix.output
\end{Verbatim}

\noindent
to simultaneously display the serial output in the terminal window and write it into a log file \path!ulix.output!.

The following code is borrowed from the xv6\index{xv6 operating system} operating
system \cite{xv6Draft}, especially from source files \path!uart.c! and 
\path!console.c!. We modified the [[uartinit]] function so that it can deal with
two serial ports.

Several I/O ports are used for sending data to the serial ports or reading from them, the base port numbers are the following:

\index{port!serial port}%
<<constants>>=
#define IO_COM1    0x3f8
#define IO_COM2    0x2f8
@ %def IO_COM1 IO_COM2 

We use the array [[uart]] to keep track of available ports.

<<global variables>>=
static int uart[2];    // do we have serial ports?
@ %def uart

<<function implementations>>=
void uartinit (int serport) {
  char *p;
  word io_com, irq;
  switch (serport) {
    case 1: io_com = IO_COM1; irq = IRQ_COM1; break;
    case 2: io_com = IO_COM2; irq = IRQ_COM2; break;
    default: return;
  }

  outportb (io_com+2, 0);       // Turn off the FIFO
  // set 9600 baud, 8 data bits, 1 stop bit, parity off.
  outportb (io_com+3, 0x80);    // Unlock divisor
  outportb (io_com+0, 115200/9600);
  outportb (io_com+1, 0);
  outportb (io_com+3, 0x03);    // Lock divisor, 8 data bits.
  outportb (io_com+4, 0);
  outportb (io_com+1, 0x01);    // Enable receive interrupts.

  // If status is 0xFF, no serial port.
  if (inportb (io_com+5) == 0xFF) { return; }
  uart[serport-1] = 1;

  // Acknowledge pre-existing interrupt conditions; enable interrupts.
  inportb (io_com+2);
  inportb (io_com+0);
  enable_interrupt (irq);
}
@ %def uartinit  

We start the serial port when booting:

<<setup serial port>>=
uartinit (1);
@ 

To simplify disk access, we provide something we call a \emph{serial hard disk}\marginnote{serial\\ hard disk}
(see Chapter \ref{sec:serial hard disk}).
Using the second serial port (of a virtual machine) we allow \UlixI{} to
connect to an external process which imitates a hard disk controller.
\UlixI{} can send simple commands to that process and in return will be
served with data (1024 byte sectors) out of a hard disk image file.

%nouse
<<function prototypes>>=
void uart2putc (int);
@

<<function implementations>>=
void uart2putc (int c) {
  // taken from the xv6 operating system [CKM12], uart.c
  if (!uart[1]) return;      // leave if we have no second serial port
  // wait until COM2 is ready to receive another byte
  for (int i = 0;  i < 128 && !(inportb (IO_COM2+5) & 0x20);  i++) ;
  outportb (IO_COM2+0, c);   // write_ the byte
}
@ %def uart2putc

(This function is almost identical to [[uartputc]] except that it uses [[IO_COM2]] instead of [[IO_COM1]], see page~\pageref{function:uartputc}.)

<<setup serial hard disk>>=
uartinit (2);
@

The interrupt handler for the second serial port will be implemented in Chapter \ref{sec:serial hard disk}. We need no handler for the first port because we only write to it.



% ----------------------------------------------------------------------


\addtocontents{toc}{\protect\parttocpagebreak}
\chapter{Synchronization}
\label{chap:synchronization}%
\label{chap:ulix:sync}%
\index{synchronization}%

\felix

In previous chapters, we had a look at the basic abstractions
implemented by the operating system: virtual memory abstracting
physical memory and virtual processors (threads) abstracting physical
processors. Virtual processors may now execute concurrent programs
in which the concurrent threads often have to interact in some
specific way. There are two basic \vindex{interaction patterns}:
%
\begin{itemize}

\item A \emph{\vindex{competitive interaction pattern}}\marginnote{competitive\\ interaction} occurs when
  two threads want to perform the same operation, however only one of
  them is permitted to do so at the same time. This means that one
  thread must go first and the other must wait until the first has
  finished his operation. Classic examples of this interaction pattern
  are accesses to exclusive resources or critical code sections. In this
  interaction pattern, the competing threads often don't know of each
  other so that some mediator (i.\,e., the operating system) has to
  synchronize the threads in a convenient and fair manner.

\item A \emph{\vindex{cooperative interaction model}}\marginnote{cooperative interaction} occurs when two
  threads know each other and want to exchange information in a
  well-defined way. This interaction pattern occurs for example in
  client/server-type systems where one thread requests information
  which another thread provides.  

\end{itemize}
%
The question for \Ulix{} is: Which thread synchronization abstractions
make sense and how can they be implemented? 

Depending on the basic implementation mechanisms, we distinguish
between memory-based synchronization abstractions and message-based
synchronization abstractions. The most relevant ones for us are the
former ones which are based on the availability of shared memory
between threads. They can therefore be utilized in those operating
systems using service combinations which primarily depend on the
availability of shared memory. 


\subsection*{Outline}

We first present the central abstraction of competitive thread
synchronization in Section~\ref{sec:critical:sections}. Then we go
through different ways of implementing critical sections. 
\black
While there are some purely software-based methods for achieving
mutual exclusion that require no hardware support, they are rarely
used; thus we immediately turn to \felix more low-level and more practical
synchronization techniques based on special hardware operations in
Section~\ref{sec:hardware:based:synchronization}. 

We then climb again up the abstraction ladder and look at a
higher-level concepts: \emph{Semaphores} can
be regarded as an operating system service which is more useable than
low-level hardware. They are treated in
Section~\ref{sec:semaphores}. 
We will discuss the implementation of these concepts in \Ulix{} as we
go along. We present a standard implementation of semaphores based on
atomic\index{atomic} hardware operations.

\black
Then we look at a specialization of semaphores, the \emph{mutexes} (or 
\emph{locks}),
and show their implementation in \UlixI{} in Sections~\ref{sec:ulix:locks}
(for the kernel) and \ref{sec:sync:pthread-mutex} (for threads in user
mode).
Finally, Section~\ref{sec:kernel-sync} discusses the important topic of
kernel-level synchronization which is needed in situations where
interrupt handlers and threads share common data---in those situations
we cannot use blocking mutexes or semaphores because an interrupt handler
must not block.

\felix
\section{Critical Sections}
\label{sec:critical:sections}
\index{critical section}%
\index{synchronization!critical section}%

We start with explaining the central concept: the \emph{critical section}.

\subsection{The Case of the Lost List Element}

Consider an implementation of a linked list. This \emph{could} for
example be the implementation of the \vindex{ready queue} within the
dispatcher (for the real implementation see
Section~\ref{sec:implementing:lists:of:threads}). Imagine a list
element consists of the real content of the element together with a
pointer to the next list element. Adding an item to the front of the
queue is usually implemented \black like [[add_to_front]] does it in the
following example program and as is illustrated in Figure~\ref{fig:linked:list}.

\begin{figure}[b!]
  \centering
  \includegraphics[width=0.95\textwidth]{pics/linked-list.pdf}
  \caption{Example of adding an element to the front of a linked list.}
  \label{fig:linked:list}
\end{figure}

\pagebreak

%nouse
<<code example: adding an item to a linked list>>=
typedef struct element {
  int            value;
  struct element *next;
} element;

void add_to_front (element **first, element *e) {
  e->next = *first;  // operation 1
  *first  = e;       // operation 2
}

void show (element *first) {
  int i = 0; while (first != 0) {
    printf ("%d: contains %d\n", i++, first->value);  first = first->next;
  }
}

int main () {
  element a, b, c;  a.value = 100; a.next = &b; b.value = 101; b.next = 0;
  element *list = &a;        show (list);  // list = [ 100, 101 ]
  c.value = 102;
  add_to_front (&list, &c);  show (list);  // list = [ 102, 100, 101 ]
}
@ \felix First, the \verb#next# pointer of the new element
is set to the ``old'' front of the list. Second, the global \verb#list# pointer
is set to the ``new'' front of the list. If you follow the final pointer
structure you will see that the new list element has been correctly
inserted at the front of the list.

The claim is now that the list implementation from above can cause
problems if multiple threads try to put different elements into the
list at the same time.  To see this, consider
Figure~\ref{fig:linked:list:problems}. There, two threads $T_1$ and $T_2$
invoke the implementation of [[add_to_front]] from above at almost the same
time. The scheduling of the two threads is somewhat unfortunate in
that $T_1$ is interrupted after the first operation, then $T_2$ adds its
element, and then thread $T_1$ can finalize its insertion by executing
the second operation. In total there are four pointer assignments,
which are reflected in the figure. If you follow the final pointer
structure of the ready queue, you will see that one element (namely
that of thread $T_2$) has been lost: It is not contained in the list
anymore.

The reason for this is the unfortunate scheduling of the machine
instructions. Operation 2 of thread $T_1$ overwrites the effect of the
two operations of thread $T_2$, because it implicitly assumes that 
nothing has happened after it executed its own operation 1. These
problems would have been avoided if there were a guarantee that
whenever some thread executes operation 1 it can also execute
operation 2 without being interrupted.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{pics/linked-list-problems.pdf}
  \caption[Concurrent threads losing a linked list element.]{Concurrent threads trying to add two elements to a linked
    list: The list can lose elements when operations are interleaved
    in a special way.}
  \label{fig:linked:list:problems}
\end{figure}

\subsection{Defining Critical Sections}

\index{critical section}%
\index{synchronization!critical section}%
A \emph{\vindex{critical section}} is a sequence of instructions of a
program which access shared resources. In the example above, the
linked list is the \emph{shared resource}\marginnote{shared resource}. Manipulation of shared resources
should be protected by an \emph{entry}\pindex{entry protocol} and
\emph{\vindex{exit protocol}}\marginnote{entry/exit\\ protocol}. These should guarantee \vindex{mutual
  exclusion} between critical sections. This is defined as follows:

\index{mutual exclusion}%
\index{synchronization!mutual exclusion}%
\begin{definition}[mutual exclusion]
%
At any time there is at most one thread
executing within its critical section.
%
\end{definition}

Note that critical sections are something very abstract. They have a
meaning at almost any level of abstraction, be it operating system,
user program or programming language level. When dealing with
critical sections it is merely necessary to mark the beginning and
the end of the critical sections. The runtime system must then guarantee
that no two critical sections at the same level of abstraction are
executed concurrently.

In the following code examples, we mark beginning and end of critical sections with
the two macros [[ENTER_MUTEX]] and [[EXIT_MUTEX]]. This is an
abbreviation for entering and exiting mutual exclusion. So if we write 
our list operation from above again, we should mark the critical 
section in the following way:

%nouse
<<code example: adding an item to a linked list within a critical section>>=
void add_to_front (element **first, element *e) {
  ENTER_MUTEX ();
  e->next = *first;  // operation 1
  *first  = e;       // operation 2
  EXIT_MUTEX ();
}
@ We will learn about many ways to implement critical sections in this
chapter. For the time being, imagine a global token which must be
acquired before a thread can enter its critical section. 

\black
What we want to achieve is the behavior that you can see in Figure~\ref{fig:mutual:exclusion:preliminary:example}: Assume that there are two threads
which share a resource, e.\,g., a memory location in the process that both
threads belong to. Both threads contain code that performs an update on
that memory address: It reads the value stored at the address, performs
some calculation and then writes back a new value to the same location.
The whole code range from reading it in to writing it back is the critical
section, and we want to make sure that they cannot overlap, turning the
code block into an atomic\index{atomic} action.

One of the threads (in the figure, it is thread A) will first reach the 
entry point of its critical section. Before it enters, it calls [[ENTER_MUTEX]]. 
Since at that time no other thread is in its own critical section, it can 
enter. Shortly afterwards, the other thread (thread B) also arrives at the
entry point of its critical section: It must not pass, because thread A is
still executing inside the critical section. Since it cannot continue, it
will block.

After some time has passed, thread A finishes the work in the critical section
and calls [[EXIT_MUTEX]]. Now we can let thread B pass and enter its critical
section. Later it finishes the work and also leaves, calling [[EXIT_MUTEX]], too.

You can think of the mutex as some global token that only one of the threads
can possess and which is required to enter the critical section. Application
programmers arrive at this situation all the time when they write multi-threaded
programs, they use the synchronization features that the operating system 
provides, and our task is to implement this mechanism.


\begin{figure}
  \centering
  \includegraphics[width=0.85\textwidth]{pics/mutexes.pdf}
  \caption[Mutual exclusion between two threads.]{Simple example of mutual exclusion between two
    threads. Using a global token, one thread has to wait until the
    other thread returns the token to enter its critical section.}
\label{fig:mutual:exclusion:preliminary:example}
\end{figure}

\pagebreak


\felix
\section{Hardware-based Synchronization}
\label{sec:hardware:based:synchronization}

In this section we will consider synchronization based on explicit
hardware support. We will look at the simplest thinkable mechanism
first and then at more refined ways which are based on special CPU 
operations.


\subsection{Disabling Interrupts}
\label{sec:disabling:interrupts}
\index{interrupt!disabling for synchronization}%
\index{synchronization!disabling interrupts}%

The simplest way to achieve mutual exclusion on a single CPU is to
switch off the interrupts\pindex{switch off interrupts}\pindex{disable interrupts},
which is also often called \emph{\vindex{interrupt masking}}.\marginnote{interrupt\\ masking} Every modern
multi-purpose CPU which has an interrupt mechanism allows to disable
certain or all interrupts. The effect is that the interrupt handler is
not invoked when the interrupt is signaled. Hence, asynchronous
interrupts, which are usually the source for non-atomicity\index{atomic} in critical
sections, can be effectively eliminated.

Conceptually, every CPU should
offer instructions like [[INTERRUPTS_OFF]] and [[INTERRUPTS_ON]].
We have already defined code chunks  [[<<disable interrupts>>]] and 
[[<<enable interrupts>>]] which perform these tasks on an Intel x86
processor via the assembler instructions [[cli]]\marginnote{[[cli]], [[sti]]} (clear interrupt
flag) and [[sti]] (set interrupt flag).

Whenever a kernel programmer needs to ensure mutual exclusion of
a critical section in system mode, he will now have to write
the following.

<<example: mutual exclusion using interrupt masking>>=
<<disable interrupts>>
// critical section
<<enable interrupts>>
@ Note that masking interrupts can only be performed in system
mode. (If normal programs could invoke the interrupt masking
operations in user mode then they could monopolize the CPU.) Also,
interrupts should only be disabled for relatively short periods of
time. Otherwise, interrupts which are only flagged for a certain period of
time like asynchronous I/O interrupts could be missed, \black 
leading to a possible \emph{\vindex{lost wakeup}} (discussed later in Section~\ref{sec:lost:wakeup}).\index{interrupt!lost wakeup}
\felix
So overall,
disabling interrupts is only advisable for rather short code sections
within the kernel.  Another disadvantage of this mechanism is that it
only works for monoprocessor systems since turning off interrupts on
one CPU does not affect the code executed on another CPU which could access shared memory data structures concurrently.

A trick makes is possible to improve the situation slightly: Using
a global bit [[busy]] as a lock, we can extend the duration
within a critical section without losing interrupts. The idea is to
use the global lock bit as an indication whether some thread is
within the critical section and just use interrupt masking to access
this bit. The entry and exit protocols [[ENTER_MUTEX]] and
[[EXIT_MUTEX]] for critical sections can then be programmed as
follows.

\pagebreak

%nouse
<<example: mutual exclusion using global lock bit and interrupt masking>>=
global boolean busy = false;      // no thread in critical section

void ENTER_MUTEX () {
  <<disable interrupts>>
  while (busy == true) {          // someone else in critical section
    <<enable interrupts>>
    NOP;                          // briefly leave interrupts on
    <<disable interrupts>>
  }
  busy = true;                    // I am in the critical section
  <<enable interrupts>>
}

void EXIT_MUTEX () {
  busy = false;                   // I've left the critical section
}
@ Two processes wishing to enter their critical sections will
``race'' for the lock bit during the entry protocol. The process
which is able to switch off interrupts first will be able to
grab the lock bit (in case it is free). If it
is not free, some other process is in its critical section.
So we have to turn on the interrupts at least for a short period
of time to allow that process to interrupt and exit the critical
section.


\subsection{Using Special Hardware Instructions}
\label{sec:using:special:hardware:instructions}
\index{synchronization!via CPU instructions}%

Most processors today offer machine instructions which are specially
tailored towards synchronization so that it can be achieved without
having to mess around with the interrupts. The most common such
instructions are either called \emph{test-and-set} or
\emph{lock}. They are designed
is such a way that mutual exclusion can be achieved by ``grabbing a
token''---that is similar to the use of the global lock bit above.


\subsubsection{Test-and-Set}
\label{sec:sync:test-and-set}%
\index{test and set (synchronization)}%
\index{synchronization!test and set}%

Assume you have a global lock bit [[busy]] which is initially
[[false]]. The test-and-set instruction takes two arguments: the first
is the name (or address) of the global lock bit, the second is a local
variable. Invoking 
%
[[Test-and-Set (&busy, &local)]]  
%
then results in the following two actions performed as one atomic\index{atomic}
(i.\,e., uninterrupted) operation:
%
\begin{enumerate}
\item The value of [[locked_bit]] is copied into [[local]] (``test''), and
\item the [[locked_bit]] is set to [[true]] (``set'').
\end{enumerate}
%
In pseudocode this can be expressed as:

\begin{Verbatim}
void Test-and-Set (*busy, *local) { 
  *local = *busy;  
  *busy = true; 
}
\end{Verbatim}

The idea of this operation is that after it has been performed you can
safely check whether you have ``grabbed the token'' or not. If you
have grabbed the token, then the result of the operation (i.\,e., the
value stored in [[local]]) should be [[false]] since it reflects the
value of [[busy]] \emph{before} it was set to [[true]].

\black

As an example for a ``real'' Test-and-Set operation, here is
the description of the [[gcc]] built-in function [[__sync_lock_test_and_set]] \cite[section 7.4.5, p. 61]{intel-itanium-abi} which can be used in the way described above. The semantics of the function is as follows:

<<compiler-internal functions>>=
int __sync_lock_test_and_set (int *variable, int value) {
  int tmp = *variable;   // save old value
  *variable = value;     // set new value
  return tmp;            // return old value
}
@ %def __sync_lock_test_and_set
The compiler (and in the end the processor) guarantees that all of this is executed atomically\index{atomic}.

\felix

\subsubsection{Lock Instruction}
\index{lock (hardware instruction, for synchronization)}%
\index{synchronization!lock (hardware instruction)}%
\label{code:lock:instruction}%

Another common machine instruction you can find is called [[Lock]].
Our presentation here follows Nehmer and Sturm \cite{Nehmer:2001:SGM}
who introduce it in the form of a boolean function which implicitly
refers to the global lock bit [[busy]].

In pseudocode, [[Lock]] does the following:

\begin{Verbatim}
boolean Lock () { 
  tmp = busy; 
  busy = true; 
  return tmp;
}
\end{Verbatim}
%
\looseness=1
In effect, [[Lock]] does the same as [[Test-and-Set]] in that it
copies the value of [[busy]] \emph{before} it is set to [[true]] and
then returns this value. Note again that all this is done 
in an un"-inter"-rupt"-ible way.

\subsubsection{Spin Locks}
\index{spin lock}%
\index{synchronization!spin lock}%

Now we can implement [[ENTER_MUTEX]] and [[EXIT_MUTEX]] without having
to use privileged hardware instructions. We first have a look at
the implementations based on [[Test-and-Set]].

%nouse
<<example: synchronization using [[Test-and-Set]]>>=
boolean busy = false;

void ENTER_MUTEX() {
  repeat {
    Test-and-Set (&busy, &local);
  } until (local == false);
}

void EXIT_MUTEX() {
  busy = false;
}
@ Here is the implementation based on [[Lock]].

%nouse
<<example: synchronization using [[Lock]]>>=
void ENTER_MUTEX() {
  while (Lock () == true) ; // loop over empty instruction
}

void EXIT_MUTEX() {
  busy = false;
}
@ Note that both implementations do not require privileged machine
instructions, \black thus such a mechanism could be
implemented completely in user mode, for example as part of a
library that supplies service functions for threads. \felix

The construction using [[Test-and-Set]] and [[Lock]] in the preceding
examples is called a \marginnote{spin lock}\emph{\vindex{spin lock}}. In such a spin lock,
threads waiting to enter their critical section must ``spin'' in a
loop until they are allowed to enter. A spin lock is a form of
\emph{\vindex{busy waiting}}\marginnote{busy waiting} which is often encountered in low-level
synchronization. Busy waiting however is a very inefficient form of
waiting since CPU cycles are used up without actually contributing to
any form of computation. Imagine how many machine instructions a 
3~GHz CPU spinning in a loop could have donated to some
computation. So similar to interrupt masking, spin locks are only
allowed if critical sections are relatively short. The advantage of
spin locks over interrupt masking however is that they can be
performed without switching to kernel mode.


\subsection{Monoprocessor vs.~Multiprocessor Synchronization}
\label{sec:multiprocessor:synchronization}

\index{spin lock}
\index{multiprocessor synchronization}
To achieve mutual exclusion on a monoprocessor system, it is
sufficient to turn interrupts off when entering and turning them on
again when leaving the critical section. 
\black
We will illustrate this strategy for performing mutual exclusion within \Ulix{} in Section~\ref{sec:kernel-sync}.
\felix
As noted above, however, simply turning interrupts off 
is not sufficient on a multiprocessor system because disabling interrupts on one CPU does not prevent another CPU from accessing a shared data structure. In a multiprocessor
system we additionally have to use spin locks. The strategy
is as follows:
%
\begin{enumerate}
\item First we achieve \emph{local mutual exclusion per CPU} by
 disabling interrupts.
\item Then we go into a spin lock to achieve \emph{global mutual
   exclusion over all CPUs}.
\end{enumerate}

Is achieving mutual exclusion at the lowest level in multiprocessor systems necessarily as complicated as this? Find out yourself by solving exercise~\ref{ex:kernel:sync}.

It is generally advisable to avoid busy waiting whenever possible. At
the lowest level of abstraction (e.\,g., synchronizing CPUs on the
hardware level) busy waiting cannot be totally avoided. However, on
higher levels of abstraction it generally can be avoided using more abstract
synchronization primitives like semaphores.


\subsection{Nested Critical Sections}
\label{sec:nested:critical:sections}

\index{interrupt level}
\index{nested critical sections}
\index{critican section!nested}
In processor systems that support multiple \emph{interrupt levels} turning off interrupts is not as easy as it may seem because interrupt handlers (and therefore critical sections) can be invoked in a nested fashion.

Assume for example, an interrupt handler at interrupt level 3 is
executed on a CPU. During execution of that handler all interrupts at
level 3 or lower are disabled, however, an interrupt at higher
priority 5 may kick in and its handler be executed. It disables interrupts up to
level 5. However, when this interrupt handler returns, it would be a
bad idea to enable interrupts altogether. It rather must
\emph{restore the interrupt level} that was active \emph{before} the
interrupt occured.

A similar situation happens if (on purpose or by accident) one
critical section is declared within another such as in the following
code example:

%nouse
<<example: nested critical sections>>=
f() { 
  // higher level critical section
  ENTER_MUTEX ();
  g();
  EXIT_MUTEX ();
}

g() {
  // lower level critical section
  ENTER_MUTEX ();
  // do something critical
  EXIT_MUTEX ();
}
@
If we use interrupt masking as synchronization primitive and these markers are nested, it must be assured that [[EXIT_MUTEX]] enables interrupts  only when it is called in [[f()]] and not in [[g()]]. The general rule is: The [[EXIT_MUTEX]] must restore the interrupt level that was active before its corresponding [[ENTER_MUTEX]] was called. In systems such as \Ulix{} that do not distinguish interrupt levels (i.\,e., interrupts are either on or off completely), inner critical sections are superseded by outer critical sections, i.\,e., the outermost critical section disables interrupts and finally enables them again. All inner critical sections do not change anything with the interrupt settings.

\black

We now show how to realize such a ``nestable'' [[ENTER_MUTEX]] and [[EXIT_MUTEX]] in code. We assume a system (such as \Ulix{}) that does not distinguish interrupt levels (i.\,e., interrupts are either on or off completely). In such environments storing the prior interrupt level burns down to storing a counter representing the nexting level. We use a global variable to store the current level of nesting.

\pagebreak
<<global variables (unused)>>=
int if_nested_level = 0; 
@ %def if_nested_level
\felix
Whenever we enter and exit a critical section, we flag that code appropriately. Here is a first implementation that assumes that interrupts are on when calling the chunk for the first time.
It disables the interrupts and increments the nesting level. Note that disabling interrupts using [[cli]] is idempotent. We only turn interrupts back on again if the nesting level has reached its initial value again.

<<nestable begin critical section (first version)>>=
<<disable interrupts>>        // invoke cli
if_nested_level++;
@
<<nestable end critical section (first version)>>=
if_nested_level--;
if (if_nested_level == 0) {
  <<enable interrupts>>      // invoke sti
}
@

\black
In case we do not know whether interrupts were on or off before we invoke the chunk for the first time, we can use the following (slightly better) code. It remembers the state of the first invocation of the chunk and sets the value that was active during that instance when returning for the last time.

<<nestable begin critical section>>=
{  // create scope for scope-local variable eflags
  int eflags;
  asm volatile (
    "pushf                 \n"     // push EFLAGS
    "cli                   \n"     // disable interrupts
    "movl   (%%esp), %0    \n"     // copy to eflags variable
    "addl   $4,      %%esp \n"     // restore stack pointer
  : "=r"(eflags) );
  if (if_nested_level == 0)
    if_state = (eflags >> 9) & 1;  // bit 9 of EFLAGS is IF
  if_nested_level++;
}
@

<<nestable end critical section>>=
if_nested_level--;
if (if_nested_level == 0 && if_state == 1) {
  <<enable interrupts>>
}
@

\felix
In exercise~\ref{ex:nestable:cs:multiprocessor} we discuss the case of nestable critical sections on multiprocessor systems.


\section{Semaphores}
\label{sec:semaphores}
\index{semaphore}%
\index{synchronization!semaphore}

\begin{figure}[b!]
  \centering
  \includegraphics[width=\textwidth]{pics/mutexes-2cpu.pdf}
  \caption[\hgepolylof{Avoiding busy waiting by running a different thread.}]{Avoiding busy waiting by running a different thread.}
  \label{fig:avoiding:busy:waiting}
\end{figure}

As seen above in
Section~\ref{sec:using:special:hardware:instructions}, the simplest
way of implementing blocking is \emph{\vindex{busy waiting}}. However,
that is a rather inefficient way to implement blocking as it
consumes CPU cycles that could have been used for threads that are
ready to run. We can avoid it by offering the right
synchronization abstractions within the operating system. The
operations [[ENTER_MUTEX]] and [[EXIT_MUTEX]] can, for example, then
directly influence the state of threads. This is depicted in
Figure~\ref{fig:avoiding:busy:waiting} where three threads are
scheduled onto two CPUs. In the example, thread $A$ enters its
critical section while running on CPU 1 and thread $B$
running on CPU 2 calls [[ENTER_MUTEX]]. Because $A$ is
already in its critical section, $B$ must block. Instead of waiting
actively in a loop, it could go to sleep (change its state to
[[blocked]]) and allow a different ready-to-run thread $C$ to run on
CPU 2.

The most popular abstraction for synchronization in operating systems
is the \marginnote{semaphore}\emph{\vindex{semaphore}}. The name stems from a
special type of signal used in railway systems. There, a critical
section is a single track railway line. At any time, at most one train
is allowed to run on such a line and so entering and exiting this part
is governed by special signals.  Note that designing proper semantics
for such signals is not as easy at it seems because the signals at both
ends must be synchronized. For example, it must be ensured that
of two trains concurrently approaching the signals from opposite ends 
only one is allowed to pass. Also, leaving the critical section on
one end must allow another follow-up train waiting at the opposite end
to enter the track, too.

Inspired by real-world semaphores, Edsger W.\ Dijkstra\pindex{Dijkstra,
  Edsger W.} introduced semaphores as a synchronization abstraction
in his ``THE'' operating system\pindex{THE (operating system)} in
1968 \cite{Dijkstra:1968:SMS}. The name ``THE'' stands for
``Technische Hogeschool Eindhoven'' (Eindhoven University of Technology) 
where Dijkstra was a professor at
that time. Ever since, Dijkstra evolved into one of the most prominent
and fascinating figures in computer science. Not only did he influence
many of today's programming languages through his work on the language
ALGOL (Algorithmic Language), but he also invented a lot of clever 
algorithms (like the famous shortest path algorithm for graphs).


\subsection{Semantics of Semaphores}

A semaphore is an operating system abstraction offering two primitive
operations called $P$ and $V$. The operation $P$ (which can be read as
``pass'', \black originally: dutch \emph{prolaag, probeer te verlagen}; try to
reduce) \cite{wikipedia:semaphore,dijkstra:semaphore}\felix{}
 is invoked by a thread when it wishes to enter its critical
section. Conversely, the operation $V$ (which can be read as ``leaVe'',
\black originally: dutch \emph{verhogen}, increase\felix{}) is invoked when a process 
leaves its critical section. 

A semaphore guarantees \marginnote{$k$-mutual\\ exclusion}\emph{$k$-mutual exclusion}\pcindex{k-mutual exclusion}{$k$-mutual exclusion}\index{mutual exclusion!k-mutual@$k$-mutual}\index{synchronization!k-mutual exclusion@$k$-mutual exclusion}. The formal statement of this concept can be defined as follows.

\begin{definition}[\emph{k}-mutual exclusion]
  % 
  If all threads properly encapsulate their critical section with $P$
  and $V$, then the semaphore guarantees that at most $k$ threads are
  in their critical sections at the same time.
  % 
\end{definition}

The concept of $k$-mutual exclusion is a generalization of simple
\marginnote{mutual\\ exclusion}\emph{mutual exclusion} for which $k=1$. The actual value of $k$ must be
passed to the semaphore upon initialization.

It is possible to break down $k$-mutual exclusion to specific
semantics of the individual semaphore operations $P$ and $V$ as
follows:
\index{semaphore!P operation@$P$ operation}%
\index{semaphore!V operation@$V$ operation}%

\begin{definition}[semantics of $P$ and $V$\,]
  %
  Assume semaphore $S$ is initialized with $k$. Then the operations
  $P$ and $V$ on $S$, written $P\,(S\,)$ and $V\,(S\,)$, have the following
  meaning:
  % 
  \begin{itemize}

  \item $P\,(S\,)$ blocks in case exactly $k$ threads have passed $P\,(S\,)$
    without passing $V\,(S\,)$.

  \item $V\,(S\,)$ deblocks a thread which is blocked at a $P\,(S\,)$ in case
    such a thread exists.

  \end{itemize}
  % 
\end{definition}

For $k=1$, the operations $P$ and $V$ therefore clearly resemble the
semantics of a mechanism necessary to protect a single track railway
line. More generally, they resemble the semantics for protection
signals of a $k$-track railway line segment.


\subsection{Single Mutual Exclusion}

\index{single mutual exclusion|see {mutual exclusion}}%
The notion of $k$-mutual exclusion for $k=1$ is often simply called
\emph{\vindex{mutual exclusion}} or \emph{\vindex{mutex}}\marginnote{mutex} for short.
The name ``mutex'' is also used for the semaphore that protects a
simple critical section where at most one thread is allowed to enter.
Such a critical section can be implemented easily with semaphores as
follows.

%nouse
<<example: classical mutual exclusion with semaphores>>=
Semaphore Mutex = 1; // initialization
// code of the thread
P (Mutex);               // enter critical section
// critical section
V (Mutex);               // leave critical section
// continued code of the thread
@ Incidentally, this is exactly what we would need if we want to
implement [[ENTER_MUTEX]] and [[EXIT_MUTEX]] without busy waiting
at the operating system level. The question of course is: Can we
implement semaphores without busy waiting? 


\subsection{Initialization of Semaphores}

\index{kernel semaphore}%
\index{semaphore!implementation in Ulix}%
\index{Ulix!kernel semaphores}%
We now look at a simple implementation of semaphores at the operating
system level. These semaphores are consequently called
\emph{\vindex{kernel level semaphores}}\marginnote{kernel level\\ semaphores}. Semaphores at that level
basically encapsulate a counter and a list of threads. This list can
be thought of as being at the same level as the \vindex{ready queue}
in the \vindex{dispatcher}. In fact, it implements one type of
\vindex{blocked queue} in the system (see
Section~\ref{sec:thread:queues}).

We first declare the semaphore type, a structure consisting of a
counter and a queue. All declarations and functions on this type of
semaphore are prefixed with [[kl_]] to identify them as kernel level
semaphores and clearly separate them from \vindex{user level semaphores}.
We allow for additional ``implementation'' fields 
at the end of the semaphore structure which are not of interest for
the general idea of semaphores.

\index{blocked queue!for kernel semaphores}%
<<type definitions>>=
typedef struct {
  int counter;
  blocked_queue bq;
  <<more [[kl_semaphore]] entries>>
} kl_semaphore;
@ %def kl_semaphore
The structure [[kl_semaphore]] is the internal representation of
semaphores. In later code we will refer to semaphores by a unique
identifier instead of a pointer to such a structure. Basically, this
identifier will serve as a pointer into a global semaphore table 
implemented later.

<<type definitions>>=
typedef int kl_semaphore_id;
@ %def kl_semaphore_id
The function [[get_new_semaphore(k)]] returns the identifier of a new
semaphore initialized with [[k]]. The return value $-1$ is used as an
\vindex{error code} meaning that something went wrong during
allocation. This usually means that the internal table is full,
which is a bad sign. 

We also provide a function to release a semaphore. Releasing it 
implies that all threads which may be blocked on that
semaphore are deblocked.

Here are the prototypes:

\pagebreak
%nouse
<<function prototypes>>=
kl_semaphore_id get_new_semaphore (int k);
void release_semaphore (kl_semaphore_id s);
@

\subsection[Implementing $P$ and $V$]{Implementing P and V}
\label{sec:implementing:p:and:v}

The idea of the implementation of $P$ and $V$ is as follows. The
counter of the semaphore represents the remaining ``potential'' of the
semaphore, i.\,e., the number of threads which are still allowed to pass
without being blocked. To actually block and deblock threads, we can
simply use the operations provided by the kernel level dispatcher
(see Section~\ref{sec:simple:state:model} for the general description
and Section~\ref{sec:blocked-queue-implementation} for the
implementation).

We will name the functions [[wait_semaphore]] (for $P$\,) and
[[signal_semaphore]] (for $V$\,):

\index{semaphore!implementation of P and V@implementation of $P$ and $V$}%
%nouse
<<function prototypes>>=
void wait_semaphore (kl_semaphore_id sid);
void signal_semaphore (kl_semaphore_id sid);
@

The idea of the operation $P$ is to check the remaining potential of
the semaphore and block in case the potential is used up. To
understand the condition under which a thread is blocked
([[counter < 0]]), remember that a semaphore initialized with 1
allows one thread to pass. Since the counter is decremented before the
check, a condition [[counter < 1]] would not be correct. 

Note that we mark the body of the implementations of $P$ and $V$ as critical sections. To see why, you should explore the case of interrupts happening after the counter manipulation and the test of the counter value (or solve exercise~\ref{ex:semaphore:critical:section}). Since semaphores are synchronization techniques on a higher level of abstraction than hardware mechanisms, it would also be counter-intuitive if we could implement them without referring to \emph{any} lower-level synchronization primitive.

\black
<<function implementations>>=
void wait_semaphore (kl_semaphore_id sid) {
  kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  <<begin critical section in kernel>>
  sem.counter--;
  if (sem.counter < 0) {
    block (&sem.bq, TSTATE_LOCKED);
    debug_printf ("sem_LOCK going to call resign()\n");  // REMOVE_DEBUGGING_CODE
    <<resign>>
  }
  <<end critical section in kernel>>
}
@ %def wait_semaphore 
%
\felix
The operation $V$ is slightly simpler than $P$ because there is
no danger of a context switch. The function just checks whether
a thread is still blocked on the semaphore queue and deblocks
this thread if there is one.

\pagebreak
\black

<<function implementations>>=
void signal_semaphore (kl_semaphore_id sid) {
  kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  <<begin critical section in kernel>>
  sem.counter++;
  if (sem.counter < 1) {
    blocked_queue *bq = &(sem.bq);
    thread_id head = bq->next;
    if (head != 0) {
      deblock (head, bq);
    } 
  }
  <<end critical section in kernel>>
}
@ %def signal_semaphore

\felix
The above implementation of semaphores is probably the simplest
one but still leaves some room for variation. For example, the
implementation of the semaphore queue can be performed in different
ways, e.\,g. as a simple FIFO queue,
but priority queues can be used, too. The FIFO processing order
is likely the one which is implicitly assumed most often
when using semaphores, because it guarantees that the thread
which has waited longest is deblocked first.


\subsection{User-Level Semaphores}

\index{kernel-level thread}
\index{user-level thread} 
\index{user-level semaphore}
Until now, we have discussed the implementation of \emph{kernel-level}
semaphores, i.\,e., semaphores that have the power to block and deblock
\emph{kernel-level} threads. If you are implementing a user-mode
thread library to realize user-level threads, you also may need a
synchronization abstraction such as semaphores. You could use
kernel-level semaphores for this purpose, but it is also possible to
realize synchronization primitives that are tailored to handle
\emph{user-level} threads: \emph{user-level semaphores}.

\index{virtual processor}
\index{virtual multiprocessor}
\index{user-level thread library}
To recapitulate the difference between kernel-level threads and user-level threads, have a look again at Figure~\ref{fig:processor:hierarchy} on page~\pageref{fig:processor:hierarchy}. Kernel-level threads are \emph{virtual processors} for user programs, and it is even possible to map a user program to multiple kernel-level threads (resulting in a \emph{virtual multiprocessor}). But the power of such a virtual multiprocessor can only be unfolded if the user mode program supports a multiprogramming abstraction in user mode, such as a user-level thread library. 

User-level semaphores are semaphores that block and deblock \emph{user-level} threads. Their design and implementation is equivalent to those at kernel level, however, they are implemented in user mode, i.\,e., one step up the abstraction hierarchy. User-level semaphores have counters, blocked queues etc.~in a similar way as kernel-level semaphores. However, these counters are simple integers in user space and the queues are the queues manipulated in user space by the thread library. To build user-level semaphores, you can therefore simply take the implementation of kernel-level semaphores and copy them into your user program, at least in large parts. The only notable difference is the implementation of critical sections. This will be discussed later when we discuss the general notion of kernel synchronization.


\felix
\subsection{Semaphores in \Ulix{}}

The main effort to implement kernel level semaphores has already been
done above. Here we fill in the final gaps. 

Although semaphores (like threads and virtual address spaces) can be
allocated and freed, we want to implement them without dynamic memory.
Thus semaphores are held in a large \vindex{semaphore table} called
[[kl_semaphore_table]]. It is an array of [[kl_semaphore]]
structures. 

<<constants>>=
#define MAX_SEMAPHORES 1024
@ %def MAX_SEMAPHORES

<<global variables>>=
kl_semaphore kl_semaphore_table[MAX_SEMAPHORES];
@ %def kl_semaphore_table

There's a \vindex{maximum number of semaphores} that can
be allocated in the kernel.

Since both used and unused semaphores are held in a table, we need
additional information to distinguish both. So each 
semaphore has a counter and a queue, but it also has
an additional field storing the semaphore state. The value
[[false]] (0) means that the semaphore entry is free.

<<more [[kl_semaphore]] entries>>=
boolean used; 
@ Now it's also clear how we can initialize the fields.

<<initialize kernel global variables>>=
for (int i = 0;  i < MAX_SEMAPHORES;  i++) {
  kl_semaphore_table[i].counter = 0;
  initialize_blocked_queue (&kl_semaphore_table[i].bq);
  kl_semaphore_table[i].used = false;
}
@ Since we didn't mention the semaphore table earlier, we need
to fill in the mapping between the semaphore identifier  [[sid]]
and the semaphore structure in the table.

<<semaphore structure with identifier [[sid]]>>=
kl_semaphore_table[sid]
@ Finally, we have to implement the two functions [[get_new_semaphore]]
for acquiring 
and [[release_semaphore]] for releasing semaphores. Allocation is done
in a round robin fashion (like in the FIFO allocation scheme for
pages). We use a counter [[next_kl_semaphore]] to point to the
next semaphore entry in the table which can be allocated.

<<global variables>>=
kl_semaphore_id next_kl_semaphore = 0;
@ %def next_kl_semaphore
To allocate a new semaphore we check the next table entry and
use it if it is free. While looking for a free entry in the table
we use a check counter to catch the case where the semaphore table
is full.

<<function implementations>>=
kl_semaphore_id get_new_semaphore (int k) {
  int check = MAX_SEMAPHORES;
  while (kl_semaphore_table[next_kl_semaphore].used == true) {
    next_kl_semaphore = (next_kl_semaphore + 1) % MAX_SEMAPHORES;
    check--;
    if (check <= 0)  return -1;
  }
  kl_semaphore_table[next_kl_semaphore].used    = true;
  kl_semaphore_table[next_kl_semaphore].counter = k;
  initialize_blocked_queue (&kl_semaphore_table[next_kl_semaphore].bq);
  return next_kl_semaphore;
}
@ %def get_new_semaphore
Releasing a semaphore is a little tricky. Just resetting
the state field in the semaphore table is not enough since threads
may be blocked in the semaphore queue. These threads must be
released to the ready queue.

<<function implementations>>=
void release_semaphore (kl_semaphore_id s) {
  kl_semaphore_table[s].used = false;
  while (front_of_blocked_queue (kl_semaphore_table[s].bq) != 0) {
    thread_id t = front_of_blocked_queue (kl_semaphore_table[s].bq);
    remove_from_blocked_queue (t, &kl_semaphore_table[s].bq);
    add_to_ready_queue (t);
  }
}
@ %def release_semaphore
%

%\black
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\special{color pop}%
\black
\section{\Ulix{} Locks}
\label{sec:ulix:locks}%

\index{lock (kernel lock)|see {kernel lock}}%
\index{kernel lock}%
\index{mutex|see {kernel lock}}%
\index{kernel mutex|see {kernel lock}}%
Locks could be treated as a special case of semaphores (which are initialized to 1), but we have decided to provide a separate implementation for kernel locks and a user mode interface. 

For locks, we use the following type which resembles the definition of the semaphore type [[kl_semaphore]]:

\index{blocked queue!for kernel locks}%
<<type definitions>>=
typedef struct {
  short int     l;             // the lock
  boolean       used;          // are we using this lock?
  blocked_queue bq;            // queue for this lock
  char          lockname[20];  // name
} lock_t;
typedef lock_t *lock;
@ %def lock_t lock
As we make a lot of use of locks in the kernel, we provide the [[lockname]] field so that we can generate more helpful debugging output.

We allow up to 1024 locks\index{maximum number of kernel locks}
<<constants>>=
#define MAX_LOCKS 1024
@ %def MAX_LOCKS
and reserve a table for them---as with the semaphores, we want to avoid dynamic allocation of memory in the kernel.
<<global variables>>=
lock_t kernel_locks[MAX_LOCKS];
@ %def kernel_locks
We reserve the first lock ([[kernel_locks[0]]]) for locking the lock table itself.


\subsection{Locking, Unlocking and Just Wishing}
\label{sec:locking:unlocking:just:wishing}


We provide three functions that can be used by user mode processes or threads (via corresponding library functions that we introduce in the next section):

%nouse
<<function prototypes>>=
void    mutex_lock     (lock lockvar);
boolean mutex_try_lock (lock lockvar);
void    mutex_unlock   (lock lockvar);
@

[[mutex_lock]] and [[mutex_unlock]] have the expected behavior: The first function tries to acquire the lock, and if that fails, it will block the active process and place it on the queue that belongs to this lock. The unlocking function returns the lock and wakes the first waiting process. In addition to these, [[mutex_try_lock]] does what its name implies: It \emph{tries} to acquire the lock, but does not block if that goes wrong. It always returns, and its return value indicates whether the lock was acquired or not. If it failed, it returns [[false]]. So programs can use this to attempt to get a lock, but they have to check the return value and must not enter the critical section, if [[false]] was returned.

Regarding the placement of [[<<begin critical section in kernel>>]]
see exercises~\ref{ex:lock:as:critical:section} and \ref{ex:lock:as:critical:section2}.

<<function implementations>>=
void mutex_lock (lock lockvar) {
  if ( //lockvar != kstack_delete_list_lock &&     // REMOVE_DEBUGGING_CODE
       lockvar != paging_lock)                     // REMOVE_DEBUGGING_CODE
    debug_printf ("[%d]   LOCK(%s)\n",             // REMOVE_DEBUGGING_CODE
                  current_task,                    // REMOVE_DEBUGGING_CODE
                  lockvar->lockname);              // REMOVE_DEBUGGING_CODE
  if (current_task == 0) { return; }        // no process
  <<begin critical section in kernel>>
  // while ( tsl_test_and_set (lockvar) != 0 ) {   // REMOVE_DEBUGGING_CODE
  while ( lockvar->l == 1 ) {
    block (&(lockvar->bq), TSTATE_LOCKED);  // put process to sleep
    debug_printf ("LOCK going to call resign()\n");   // REMOVE_DEBUGGING_CODE
    <<resign>>
  }
  lockvar->l = 1;
  <<end critical section in kernel>>
}
@ %def mutex_lock


<<function implementations>>=
boolean mutex_try_lock (lock lockvar) {
  if ( // lockvar != kstack_delete_list_lock &&        // REMOVE_DEBUGGING_CODE
      lockvar != paging_lock)                          // REMOVE_DEBUGGING_CODE
    debug_printf ("[%d] TRLOCK(%s)\n",                 // REMOVE_DEBUGGING_CODE
                  current_task, lockvar->lockname);    // REMOVE_DEBUGGING_CODE
//  int res = tsl_test_and_set (lockvar);              // REMOVE_DEBUGGING_CODE
//  return (res == 0);                                 // REMOVE_DEBUGGING_CODE
  <<begin critical section in kernel>>
  int tmp = lockvar->l;  lockvar->l = 1;
  <<end critical section in kernel>>
  return (tmp == 0);
}
@ %def mutex_try_lock

For unlocking, we reset [[lockvar->l]] to [[0]] and then check whether we can wake up a waiting thread:

<<function implementations>>=
void mutex_unlock (lock lockvar) {
  if (current_task == 0) { return; }    // no process
  if (lockvar->l == 0) {
    debug_printf ("NOTICE: unlocking unlocked LOCK: %s\n", lockvar->lockname);
  }
//  tsl_reset (lockvar);                              // REMOVE_DEBUGGING_CODE
  <<begin critical section in kernel>>
  lockvar->l = 0;
  // wake a process
  blocked_queue *bq = &(lockvar->bq);
  thread_id head = bq->next;
  if (head != 0) {            // If one thread is waiting, deblock and resign_
    deblock (head, bq);
    debug_printf ("UNLOCK going to call resign()\n");    // REMOVE_DEBUGGING_CODE
  } 
  <<end critical section in kernel>>
}
@ %def mutex_unlock

If you compare the [[mutex_lock]] and [[mutex_unlock]] functions with [[wait_semaphore]] and [[signal_semaphore]] you will notice a big similarity. The main difference is that semaphores are more general, thus allowing $k$-mutual exclusion, whereas locks can only be used for single-mutual exclusion. However, in none of the \UlixI{} code we came across a situation where a semaphore with $k>1$ would have been useful. \felix So now, if we want to achieve mutual exclusion between kernel level threads, we can simply acquire a kernel lock. This strategy is more elegant than using hardware mechanisms directly and also more efficient on multi-processor systems where we can avoid effort spent spinning in spin locks. \black

\subsubsection{Lock Administration}

Finally, we need to provide functions that allow to create a new lock and release it when it is no longer needed. They have these prototypes:

%nouse
<<function prototypes>>=
lock get_new_lock (char *name);
void release_lock (lock l);
@

The [[get_new_lock]] function has an argument via which we can give the lock a name. If you enable the kernel mode shell, you can type [[locks]] to see a list of all the locks, with their names and the threads on their blocked queues.

%BREAK BEFORE DEFINES
<<function implementations>>=
lock get_new_lock (char *name) {
  mutex_lock (kernel_locks);  // lock the list of kernel locks, we use kernel_locks[0]
    for (int i = 1;  i < MAX_LOCKS;  i++) {
      if (!kernel_locks[i].used) {
        kernel_locks[i].used = true;
        initialize_blocked_queue (&kernel_locks[i].bq); // initialize blocked queue
        strncpy (kernel_locks[i].lockname, name, 20);
        mutex_unlock (kernel_locks);                    // unlock access to  list
        return &kernel_locks[i];
      }
    }
  mutex_unlock (kernel_locks);
  return NULL;
}
@ %def get_new_lock

For freeing a lock we set the [[used]] entry to [[false]] and unlock all threads on the blocked list (if there are any):

<<function implementations>>=
void release_lock (lock l) {
  mutex_lock (kernel_locks);  // lock the list of kernel locks
    l->used = false;
    blocked_queue *bq = &(l->bq);
    thread_id head = bq->next;
    while (head != 0) {
      thread_id next = thread_table[head].next;
      deblock (head, bq);
      head = next;
    }
  mutex_unlock (kernel_locks);
}
@ %def release_lock


\section{Pthread Mutexes for Threads}
\label{sec:sync:pthread-mutex}%
\index{synchronization!threads}%
\index{POSIX thread!synchronization}%
\index{POSIX pthread mutex}%

In order to provide user space programs with mutexes, it is not 
necessary to interface the kernel---the code that we used for the
implementation of kernel locks would also work in user mode since
it requires no privileged instructions. However, we want to
queue threads which try to acquire a mutex, and that is a task
for the kernel. So instead of duplicating parts of the already
existing locking code, we provide a user mode interface to the
kernel functions [[get_new_lock]], [[mutex_lock]], [[mutex_unlock]] and
[[release_lock]].

If you search for POSIX mutex functions on a Linux\index{Linux!POSIX mutexes} machine, you will
find several functions, including the following ones:

\begin{verbatim}
pthread_mutex_init(3)    - create a mutex
pthread_mutex_lock(3)    - lock a mutex
pthread_mutex_trylock(3) - attempt to lock a mutex without blocking
pthread_mutex_unlock(3)  - unlock a mutex
pthread_mutex_destroy(3) - free resources allocated for a mutex
\end{verbatim}


Our implementation only supports the essential features, so for example, you cannot use mutex attributes. We only include the corresponding argument in the function call so that the functions have a similar look and feel as the regular POSIX functions. You've already seen the same comment when you looked at the implementation of POSIX threads.

Also note that our kernel locks are valid globally and can be used across process borders. That means that in a \UlixI{} program a process can create a mutex and then fork; afterwards both processes can be synchronized via the mutex. POSIX mutexes forbid this.


\subsection{Creating a New Mutex}

Before we start, we define two types that simplify attempts to port programs to \UlixI{}:

%nouse
<<public type definitions>>=
typedef int pthread_mutex_t;
typedef int pthread_mutexattr_t;
@ %def pthread_mutex_t pthread_mutexattr_t

For mutex creation we implement the function

%nouse
<<function prototypes>>=
int u_pthread_mutex_init (pthread_mutex_t *restrict mutex,
         const pthread_mutexattr_t *restrict attr);
@ %
that reserves a fresh kernel lock via [[get_new_lock]] and returns the 
memory address of the lock data structure. This serves as a unique identifier 
for the lock when used in user space. (Since that address is in the kernel's
private memory range, it will also be valid across process borders; see our
earlier comment about cross-process use of mutexes.)

Since kernel locks have names, the function generates a name that consists of
the string \verb#"lock, pid="# and the thread ID. Note that this is not unique
if the same thread creates several mutexes.

\index{kernel lock!for kernel POSIX mutexes}%
<<function implementations>>=
int u_pthread_mutex_init (pthread_mutex_t *restrict mutex,
         const pthread_mutexattr_t *restrict attr) {
  char s[20];
  sprintf ((char*)s, "lock, pid=%d", thread_table[current_task].pid);
  lock tmp = get_new_lock (s);
  // printf ("LOCKNAME = '%s', address = %08x\n", s, tmp);  // REMOVE_DEBUGGING_CODE
  if (tmp != NULL) {
    *mutex = (pthread_mutex_t)tmp;
    return 0;        // success
  } else {
    thread_table[current_task].error = EAGAIN;
    return -1;       // error
  }
}
@ %def u_pthread_mutex_init

If [[get_new_lock]] was unsuccessful, we set the [[error]] field in the TCB to 
[[EAGAIN]] (it can be queried via the [[errno]] macro in the process).

<<error constants>>=
#define EAGAIN 35
@ %def EAGAIN

We add a system call:

<<ulix system calls>>=
#define __NR_pthread_mutex_init 517
@ %def __NR_pthread_mutex_init

\index{pthread\_mutex\_init system call@\texttt{pthread\_mutex\_init} system call}%
\index{system call!pthread\_mutex\_init@\texttt{pthread\_mutex\_init}}%
%nouse
<<syscall prototypes>>=
void syscall_pthread_mutex_init (context_t *r);
@

<<syscall functions>>=
void syscall_pthread_mutex_init (context_t *r) {
  // ebx: mutex id
  // ecx: attributes, not implemented
  eax_return ( u_pthread_mutex_init ( (pthread_mutex_t*)r->ebx,
                                      (pthread_mutexattr_t*)r->ecx ) );
}
@ %def syscall_pthread_mutex_init
and enter it in the syscall table:

<<initialize syscalls>>=
install_syscall_handler (__NR_pthread_mutex_init, syscall_pthread_mutex_init);
@


\subsection{Locking and Unlocking a Mutex}

We define the three locking and unlocking functions

%nouse
<<function prototypes>>=
int u_pthread_mutex_lock    (pthread_mutex_t *mutex);
int u_pthread_mutex_trylock (pthread_mutex_t *mutex);
int u_pthread_mutex_unlock  (pthread_mutex_t *mutex);
@ which ``convert'' POSIX-compliant mutexes into kernel mutexes and call the [[mutex_lock]], [[mutex_try_lock]] and [[mutex_unlock]] functions. If [[u_pthread_mutex_trylock]] cannot acquire the mutex via [[mutex_try_lock]], it will set the [[error]] field of the TCB to [[EBUSY]] (as expected by the POSIX standard) and return $-1$. The other two functions cannot fail, they simply return.

\pagebreak

<<function implementations>>=
int u_pthread_mutex_lock (pthread_mutex_t *mutex) {
  lock l = (lock)*mutex;
  mutex_lock (l);
  return 0;
}

int u_pthread_mutex_trylock (pthread_mutex_t *mutex) {
  lock l = (lock)*mutex;
  if (mutex_try_lock (l))
    return 0;    // success
  else {
    thread_table[current_task].error = EBUSY;
    return -1;   // error
  }
}

int u_pthread_mutex_unlock (pthread_mutex_t *mutex) {
  lock l = (lock)*mutex;
  mutex_unlock (l);
  return 0;
}
@ %def u_pthread_mutex_lock u_pthread_mutex_unlock u_pthread_mutex_trylock

<<error constants>>=
#define EBUSY           16          // device / resource busy
@ %def EBUSY


Again, we add system calls for the new functions:

<<ulix system calls>>=
#define __NR_pthread_mutex_lock    518
#define __NR_pthread_mutex_unlock  519
#define __NR_pthread_mutex_trylock 526
@ %def __NR_pthread_mutex_lock __NR_pthread_mutex_unlock __NR_pthread_mutex_trylock

\index{pthread\_mutex\_lock system call@\texttt{pthread\_mutex\_lock} system call}%
\index{system call!pthread\_mutex\_lock@\texttt{pthread\_mutex\_lock}}%
\index{pthread\_mutex\_trylock system call@\texttt{pthread\_mutex\_trylock} system call}%
\index{system call!pthread\_mutex\_trylock@\texttt{pthread\_mutex\_trylock}}%
\index{pthread\_mutex\_unlock system call@\texttt{pthread\_mutex\_unlock} system call}%
\index{system call!pthread\_mutex\_unlock@\texttt{pthread\_mutex\_unlock}}%
%nouse
<<syscall prototypes>>=
void syscall_pthread_mutex_lock    (context_t *r);
void syscall_pthread_mutex_trylock (context_t *r);
void syscall_pthread_mutex_unlock  (context_t *r);
@ %
They simply evaluate the mutex ID (found in the \register{EBX} register) and return the result by setting the \register{EAX} register:

<<syscall functions>>=
void syscall_pthread_mutex_lock (context_t *r) {
  // ebx: mutex id
  eax_return ( u_pthread_mutex_lock ((pthread_mutex_t*)r->ebx) );
}

void syscall_pthread_mutex_trylock (context_t *r) {
  // ebx: mutex id
  eax_return ( u_pthread_mutex_trylock ((pthread_mutex_t*)r->ebx) );
}

void syscall_pthread_mutex_unlock (context_t *r) {
  // ebx: mutex id
  eax_return ( u_pthread_mutex_unlock ((pthread_mutex_t*)r->ebx) );
}
@ %def syscall_pthread_mutex_lock syscall_pthread_mutex_unlock

<<initialize syscalls>>=
install_syscall_handler (__NR_pthread_mutex_lock,   syscall_pthread_mutex_lock);
install_syscall_handler (__NR_pthread_mutex_trylock,syscall_pthread_mutex_trylock);
install_syscall_handler (__NR_pthread_mutex_unlock, syscall_pthread_mutex_unlock);
@


\subsection{Destroying a Mutex}

Finally, we need to be able to destroy a mutex when it is no longer needed. 

\index{pthread\_mutex\_destroy system call@\texttt{pthread\_mutex\_destroy} system call}%
\index{system call!pthread\_mutex\_destroy@\texttt{pthread\_mutex\_destroy}}%
%nouse
<<syscall prototypes>>=
void syscall_pthread_mutex_destroy (context_t *r);
@

<<syscall functions>>=
void syscall_pthread_mutex_destroy (context_t *r) {
  // ebx: mutex id
  eax_return ( u_pthread_mutex_destroy ((pthread_mutex_t*)r->ebx) );
}
@ %def syscall_pthread_mutex_destroy

<<ulix system calls>>=
#define __NR_pthread_mutex_destroy 520
@ %def __NR_pthread_mutex_destroy

<<initialize syscalls>>=
install_syscall_handler (__NR_pthread_mutex_destroy, syscall_pthread_mutex_destroy);
@

Here is the implementation of the kernel function

%nouse
<<function prototypes>>=
int u_pthread_mutex_destroy (pthread_mutex_t *mutex);
@

<<function implementations>>=
int u_pthread_mutex_destroy (pthread_mutex_t *mutex) {
  lock l = (lock)*mutex;
  release_lock (l);
  return 0;
}
@ %def u_pthread_mutex_destroy


\subsection{The Library Functions}

As usual we provide a set of library functions that let user mode processes make these system calls:

%nouse
<<ulixlib function prototypes>>=
int pthread_mutex_init    (pthread_mutex_t *mutex,
                           const pthread_mutexattr_t *attr);
int pthread_mutex_lock    (pthread_mutex_t *mutex);
int pthread_mutex_unlock  (pthread_mutex_t *mutex);
int pthread_mutex_destroy (pthread_mutex_t *mutex);
@

<<ulixlib function implementations>>=
int pthread_mutex_init    (pthread_mutex_t *mutex,
                           const pthread_mutexattr_t *attr) {
  return syscall3 (__NR_pthread_mutex_init, (unsigned int)mutex, (unsigned int)attr);
}

int pthread_mutex_lock    (pthread_mutex_t *mutex) {
  return syscall2 (__NR_pthread_mutex_lock, (int)mutex);
}

int pthread_mutex_unlock  (pthread_mutex_t *mutex) {
  return syscall2 (__NR_pthread_mutex_unlock, (int)mutex);
}

int pthread_mutex_destroy (pthread_mutex_t *mutex) {
  return syscall2 (__NR_pthread_mutex_destroy, (int)mutex);
}
@ %def pthread_mutex_init pthread_mutex_lock pthread_mutex_unlock pthread_mutex_destroy


\subsection{Testing}

In order to test the synchronization of threads, you can run the \path!/bin/thread! program. It starts three threads, two of which add to or subtract from a shared variable. After 250 additions and 250 subtractions, the variable should have the initial value. The program accepts a parameter: If you start it as [[thread 0]] it will work without synchronization (and return random results due to the two threads concurrently entering their critical sections). If, however, you start it as [[thread 1]] it will use a [[pthread_mutex_t]] to protect those sections and consistently return the correct result.
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}


\section{Kernel Synchronization}
\label{sec:kernel-sync}%

\index{kernel-level semaphore}
\index{user-level semaphore}
\index{synchronization!disabling interrupts}%
\felix
Until now, we have dealt with a couple of synchronization mechanisms that are suitable for different levels of abstraction:
%
\begin{enumerate}
\item Hardware-based mechanisms, such as interrupt masking and spin
  locks, that can establish mutual exclusion on a monoprocessor or
  multiprocessor system.
\item Kernel-level semaphores that can be used to block and deblock
  kernel level threads. Kernel-level locks are a special instance of
  such semaphores.
\item User-level semaphores that can be used to block and deblock
  user-level threads.
\end{enumerate}
%
\black%
So far, our discussion of synchronization has focused on threads and with semaphores and locks we have provided nice abstractions to synchronize them. Whenever we need to prevent a thread from accessing some resource we simply block it; later when the resource becomes available again, we unblock such a thread so that it can continue execution. This works for both threads in user mode and in kernel mode. 

\index{kernel synchronization}
However, there is other code in the kernel which is not executed on behalf of some particular thread: Interrupt handlers are activated whenever an interrupt occurs, and while such a handler function runs in the context of the thread which was active when the interrupt was signaled, it is not related to that thread in any manner. \felix Getting this right is called \emph{kernel synchronization}. 

\index{critical section}
Kernel synchronization is a messy business because machine operations run in kernel mode and interrupts and context switches make code and execution sequences unintuitive. At its core, kernel synchronization deals with correctly implementing critical sections at the lowest level (the kernel). This section deals with kernel synchronization and discusses how this issue is solved in \Ulix{}.
\black


\subsection{Overview}

In general, synchronization may be needed on different levels of abstraction within an operating system. Figure \ref{fig:sync:hierarchy} (a modified version of Figure~\ref{fig:processor:hierarchy} on page~\pageref{fig:processor:hierarchy}) shows those levels; the dotted black lines represent situations where shared data may be used, thus requiring synchronization. Differing from Figure~\ref{fig:processor:hierarchy}, it also includes an interrupt handler which always runs in kernel mode.

\begin{figure}[b!]
  \raggedleft
  %\hspace{-0.20\textwidth}%
  \includegraphics[width=1.20\textwidth]{pics/sync-hierarchy.pdf}
  \centering
  \caption[Synchronization in user and kernel mode.]{Synchronization in user and kernel mode. Arrow colors (on one level) express the order of allocation of a virtual (top) or physical (bottom) processor; black dotted arrows show where synchronization can be supported between user-level threads (1), between kernel-level threads (2), between kernel-level threads and interrupt handlers (3), and between two CPUs (4).}
  \label{fig:sync:hierarchy}
\end{figure}

\felix
We now discuss the different synchronization issues in context from top (user-level threads) to bottom (CPUs).


\subsubsection{Synchronizing User-Level Threads}

\index{user-level thread}
\index{synchronization!user-level thread}
\index{virtual multiprocessor}
\index{virtual monoprocessor}
First we consider the following case: Two user-level threads which are mapped to one or multiple kernel-level threads  may use the same data and need to perform mutual exclusion. In Figure \ref{fig:sync:hierarchy}, for example, Process 1 runs on one kernel-level thread (virtual monoprocessor) and Process 2 runs on two kernel-level threads (virtual multiprocessor). In both cases, the user-level thread library has to take care of synchronization since the kernel does not recognize the two threads as separate entities. 

\pagebreak
\index{user-level semaphore}
\index{user-level interrupt}
\index{signal}
The mechanism of choice to synchronize user-level threads are user-level semaphores. They can be used to block and deblock user-level threads for synchronization. And if the thread library runs on a single kernel-level thread and the library does not support a signal mechanism (a ``user-level interrupt'' mechanism, see Chapter~\ref{chap:ulix:signals}), only one concurrent activity will update the critical thread library data structures at any time. So while there might be critical sections in the thread (library) code, the entry and exit protocols may be empty.

\index{signal masking}
However, if user-level threads can be interrupted (using signals for example) or if user-level threads run on a virtual multiprocessor (multiple kernel-level threads), we have to ensure mutual exclusion of concurrent activities in the threads library again. For the case of ``interruptible'' user-level threads (via signals), we need to enusure that any invocation of a signal handler does not violate mutual exclusion. A valid method would be to ``mask'' signals (i.\,e., ensure that during certain times user-defined signal handlers are not executed). This situation is analogous to interrupt-masking at lower levels.

For the case of a virtual multiprocessor (multiple kernel-level threads), signal masking is not enough since signals target kernel-level threads and so if one kernel-level thread masks signals another can still receive them and invoke a signal handler, thus violating mutual exclusion. So how could mutual exclusion be achieved here?

\index{spin lock}
A naive approach would be to use a spin lock in addition to signal masking. Since the necessary machine instructions like Test-and-Set are not privileged, the user-level thread library can use them to achieve ``global'' mutual exclusion. However, spin locks imply busy waiting, so the question is: Can we do better?

\index{kernel-level semaphore}
Fortunately, the answer is yes: We can use a kernel-level semaphore, or more precisely a kernel lock as follows. During initialization of the thread library we allocate a kernel lock. Whenever a user-level thread wishes to run exclusively, if will lock the mutex and proceed. When it finishes its critical section, it releases the lock. To see why this works, consider again Figure \ref{fig:sync:hierarchy} and look at user-level thread 3 and user-level thread 4 in the top right. Both threads might be running on different virtual processors (kernel-level thread 2 and kernel-level thread 3, the green assignment). Now assume that user-level thread 3 enters a critical section and acquires the lock. If user-level thread 4 attempts to enter its own critical section, it will try to acquire the same lock, but because it is taken, then \emph{kernel-level} thread 3 is blocked. It is automatically deblocked when user-level thread 3 releases the lock. Busy waiting is completely avoided!

\index{virtual monoprocessor}
\index{virtual multiprocessor}
Remember however, that the above solution still needs to take care of user-level ``interrupts'' (signals). If signal handlers can be run at any time, also note that kernel locks are not useful for mutual exclusion if the thread library is running on a virtual monoprocessor. If one of the user-level threads acquires the lock, is interrupted by a signal handler and switches to another thread that also tries to acquire the lock, the kernel-level thread (i.\,e., the entire user-level thread library) would block and the situation could never be resolved. 

\black
\Ulix{} (like most other systems) does not implement the mapping of several user-level threads to one kernel-level thread, thus we need not consider this case---the user-mode functions [[pthread_mutex_lock]] and [[pthread_mutex_unlock]] use system calls to call the kernel functions [[u_pthread_mutex_lock]] and [[u_pthread_mutex_unlock]].


\felix
\subsubsection{Synchronizing Kernel-Level Threads}

\index{mutual exclusion}
\index{kernel-level semaphore}
\index{kernel lock}
Now we consider the case where two kernel-level threads wish to synchronize because they use the same data. This is case (2) in Figure \ref{fig:sync:hierarchy}. The method of choice here is obviously to use kernel-level semaphores, or more specifically (for mutual exclusion) kernel locks. If such locks can be acquired and released atomically, kernel locks can be used to achieve mutual exclusion between kernel-level threads, just as discussed previously for the virtual multiprocessor that runs a user-level thread library. 

The property we need to ensure, however, is in fact the atomicity of lock acquisition. Remember that kernel-level threads may be interrupted at any time and a context switch might schedule another kernel-level thread. So the problem of achieving mutual exclusion between kernel-level threads can be reduced to the problem of ensuring the atomicity of the locking procedure. Unfortunately, we cannot use kernel mutexes for this since this is the mechanism we are trying to implement.

\index{critical section}
We have handled exactly this case in the previous sections where we have discussed the implementation of [[u_pthread_mutex_lock]] and [[u_pthread_mutex_unlock]]. The trick to solve this problem was to declare the main parts of [[mutex_lock]], [[mutex_try_lock]] and [[mutex_unlock]] as critical sections in the kernel, but we have not yet discussed how to actually implement this. However, we have all necessary ingredients ready to deal with it now. This is what kernel synchronization is all about.

\black
Many operating systems also support synchronization across processes which is also possible in \Ulix{} if two processes share a [[pthread_mutex_t]] variable; note however that the POSIX standard forbids this (see Section~\ref{sec:sync:pthread-mutex}). Instead Unix systems use \index{named semaphore}\index{semaphore!named}\marginnote{named\\ semaphore}\emph{named sema- phores} for cross-process synchronization which are not implemented in \Ulix{}.

To summarize synchronization issues up to now---and as partially shown in Figure~\ref{fig:sync:functions},

\begin{itemize}
\item in user mode, threads can call the user-mode library functions [[pthread_mutex_lock]] and [[pthread_mutex_unlock]] to acquire kernel level mutexes that can be used for inter-thread synchronization.
\item in kernel mode, threads can also use the kernel functions [[u_pthread_mutex_lock]] and [[u_pthread_mutex_unlock]] for the same purposes,
\item and these are (again) wrappers for the general kernel"=internal synchronization functions [[mutex_lock]] and [[mutex_unlock]].
\item Besides [[mutex_lock]] and [[mutex_unlock]] the \Ulix{} kernel also supports synchronization with semaphores via the [[wait_semaphore]] and [[signal_semaphore]] functions which are not accessible from user mode applications.
\end{itemize}

\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\black
\begin{figure}[h!]
  \raggedleft
  \includegraphics[width=1.0\textwidth]{pics/sync-functions.pdf}
  \centering
  \caption[Synchronization functions for user and kernel mode.]{Mutex functionality is available in user mode and kernel mode; the kernel can also use semaphores.}
  \label{fig:sync:functions}
\end{figure}


\felix
\subsubsection{Sychronizing the Kernel}

Kernel synchronization deals with cases (3) and (4) in Figure \ref{fig:sync:hierarchy}. The main task of kernel synchronization is to achieve mutual exclusion of concurrent activities in the kernel. This is a challenge because concurrent activities are natural in operating systems, let they be introduced through interrupts or through multiple CPUs.

The case of interrupts, case (3) in Figure \ref{fig:sync:hierarchy}, is probably the toughest issue to solve because it happens in all operating systems: 

\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\special{color pop}
\black
An interrupt handler may share data with a process which has made a system call. As we will show on the following pages, we cannot use the same mutex/locking approach as for inter-thread synchronization, 
\felix
instead we will need to revert to hardware-based mechanisms discussed in Section \ref{sec:hardware:based:synchronization}. 
In fact, \Ulix{} uses the simplest approach to synchronize the kernel: It realizes a non-interruptible kernel. What this means will be discussed shortly.

The case of multiprocessing, case (4) in Figure \ref{fig:sync:hierarchy}, is equally tough.
\black
When more than one CPU (or CPU core) is used, the situation becomes more complicated because code will be executed truly simultaneously on those CPUs or cores. 
\felix
But as we will see, if case (3) has been solved conceptually, it is not too hard to extend this solution to case (4). 
Furthermore, since \Ulix{} does not support more than one CPU or core, we do not need to work out this case in code anyway.

\black

\subsection[Minimizing the Size of Critical Sections: Interruptible Kernels]{Minimizing the Size of Critical Sections:\\ Interruptible Kernels}

We now turn to the central problem of implementing critical sections in the kernel, i.\,e., achieving mutual exclusion at the lowest layer. Until now, we declared critical sections \linebreak using the markers [[<<begin critical section in kernel>>]] and [[<<end critical section in kernel>>]]. 
A kernel built in this way is called an 
\marginnote{interruptible\\ kernel}%
\index{interruptible kernel}%
\index{kernel!interruptible}%
\emph{interruptible kernel}. Such kernels allow concurrent activities within the kernel, but only in \emph{some} parts. For a monoprocessor system this means that interrupts may be enabled during the execution of \emph{some} kernel code. (It does not mean that interrupts are always on.) For multiprocessor systems, spin locks are needed in addition to disabling the interrupts (see Section \ref{sec:hardware:based:synchronization}).

Building correct interruptible kernels boils down to finding all critical sections and ensuring that the entry and exit protocols to these sections are implemented correctly. Both problems are non-trivial and have caused much misery in the history of operating systems:
%
\begin{itemize}
\item It is easy to spot some critical sections, but it is hard to overlook no critical section. Overlooking a critcal section (i.\,e., failing to mark it correctly) usually causes hard to diagnose system faults because bugs are usually the result of non-reproducible race conditions (so called \emph{Heisenbugs}).\index{Heisenbug}
\item It is easy to ``play safe'' and mark all possible candidates for critical sections as such, following the strategy: if in doubt, then it's a critcal section. But this results in rather large critical sections, and large critical sections cause their own problems (inefficiency being one). So the challenge is to declare ``minimal'' critical sections.
\end{itemize}
%
A typical approach is to let system call handlers be interruptible while disabling (all or some) interrupts during the execution of interrupt handlers.

These challenges have been debated by operating system designers for many decades. They effectively ask the question of the size of critical sections. The more code allows interrupts, the better the performance and responsiveness of the system can become, but at the same time complexity of synchronization increases.

Interestingly, there is a very simple synchronization strategy that works in most cases and allows you to start off with a system which is inefficient yet correctly synchronized: The most simple approach is to generally forbid interrupts while executing kernel code, thereby ``maximizing'' the size of critical sections in the kernel. We call such an implementation a 
\marginnote{non-interrupt-\\ ible kernel}%
\index{non-interruptible kernel}%
\index{kernel!non-interruptible}%
\emph{non-interruptible kernel}. For a single-CPU, single-core machine this means that all kernel code can expect to remain in control and keep the CPU until it either finishes or blocks (in a system call handler).

Only when the system runs in user mode (i.\,e., executes the application code of some thread), interrupts can occur. Note that this means that whenever a thread makes a system call (and thus transitions to kernel mode via the system call interface), interrupts will be disabled until the system call function completes its work and returns to user mode. In such systems, there will be no need to synchronize interrupt handlers and system call handlers.

\enlargethispage{1cm}%
Note however that system call handlers still have to consider synchronization because a thread executing such a system call handler may decide to block (for example, in order to wait for a disk operation to complete). In that case control will transfer to a different thread which might call some other or the same system call handler, thus possibly accessing the same kernel data structures. Therefore, the begin of a critical section might happen in thread $A$ while the end of a critical section might happen in thread $B$ (after a context switch). This needs to be considered.
\pagebreak

Fortunately, the Intel CPU lets developers decide whether interrupts are automatically disabled upon entering some handler by providing both \emph{interrupt gates} (which auto"=disable interrupts) and \emph{trap gates} (which do not), see also Section~\ref{sec:system-calls-in-ulix}.


\subsection{\Ulix{} as a Non-Interruptible Kernel}
\label{chap:ulix-as-non-interruptible-kernel}%

We have decided to make the \Ulix{} kernel non"=interruptible which greatly reduces the demand for synchronization. For completeness, Section~\ref{sec:problems-of-interruptible-kernels} will describe the issues arising with interruptible kernels and illustrate them with examples from the \Ulix{} code.

As mentioned above, the Intel CPU lets developers decide whether interrupts are automatically disabled upon entering some handler by providing both \emph{interrupt gates} and \emph{trap gates}. We have used an interrupt gate in our system call implementation in Section~\ref{sec:system-calls-in-ulix}. So we can safely assume that interrupts are off whenever we execute code in kernel mode. Since \Ulix{} does not support multiple CPUs, there is nothing more to do.

Now, finally, we can show the entry and exit protocols for the critical sections in the kernel. Recall that we marked them using the code chunks [[<<begin critical section in kernel>>]] and [[<<end critical section in kernel>>]]. Since we have a non-interruptible kernel and switch off interrupts using an interrupt gate, there is no further necessity for additional synchronization. Therefore, their implementations are empty.

%% 
% for the following two chunks I need to redefine \nwusesondefline to include
% a linebreak because the list of references is too long and overflows the 
% column.
%%
\let\BACKUP\nwusesondefline
\renewcommand\nwusesondefline[1]{\linebreak ${}^{}$\nwstartdeflinemarkup\BACKUP{#1}}
\def\nwtagstyle{\fontsize{7.3pt}{7.3pt}\Rm}
<<begin critical section in kernel>>=
// do nothing
@

<<end critical section in kernel>>=
// do nothing
@

% restore \@nwusesondefline
\let\nwusesondefline\BACKUP
\def\nwtagstyle{\footnotesize\Rm}

The interested reader might ask: Why didn't we omit these markers from the beginning if they are empty anyway? There are two answers to this question:
%
\begin{enumerate}
\item Omitting these markers would have avoided the discussion (and identification) of critical sections, which would have avoided some nice intellectual challenges.
\item Keeping these markers allows for a future evolution of \Ulix{} into an interruptible kernel.
\end{enumerate}
%
In such a future \Ulix{} version with an interruptible kernel these chunks would be implemented using [[<<disable interrupts>>]] and [[<<enable interrupts>>]], or with the nestable versions.


\subsection{Illustrating Problems of Interruptible Kernels}
\label{sec:problems-of-interruptible-kernels}%

In this section we describe some relevant problems that arise and discuss the additional care that needs to be taken when the kernel is interruptible. Note that the situation would become even more complex if several CPUs (or cores) were supported. Wherever possible, we use code of \Ulix{} to illustrate the problems.


\subsubsection{Example: Accessing a Keyboard Buffer}

We begin with an introductory example for the synchronization problems that arise from using an interruptible kernel.
Consider the way that reading from the keyboard works for a thread:

\begin{itemize}
\item A thread calls the [[read()]] function (using file descriptor [[STDIN_FILENO]] = 0) which in turn makes a system call. This enters kernel mode and leads to the execution of [[syscall_read()]] which in turn will make an other system call that activates the system call handler [[syscall_readchar()]].
\item [[syscall_readchar()]] determines the current terminal [[term]], reads a character from its associated buffer [[term->kbd[]]] and updates the current position and number of characters in the buffer ([[term->kbd_lastread]] and [[term->kbd_count]]). Note that those two changes modify a global data structure.
\item On the other hand, the keyboard interrupt handler, [[keyboard_handler()]], updates the same data structure: it determines the active terminal (the one currently displayed on the screen), enters the character's ASCII code in the corresponding buffer and also modifies the buffer's current position and number of contained characters.
\end{itemize}

\noindent
If both accesses originated from threads, we could simply use a list of mutexes (one for each terminal) to lock these structures, but we cannot use the locking mechanism in the interrupt handler since that might put it to sleep if a thread had just acquired the lock right before the keyboard interrupt occurred. Thus, the obvious attempt of using a lock list [[keyboard_buffer_lock[]]] and implementing mutual exclusion via

%nouse
<<first attempt for locking the keyboard buffer (in [[syscall_readchar]])>>=
void syscall_readchar (context_t *r) {
  char c;
  int t = thread_table[current_task].terminal;
  terminal_t *term = &terminals[t];
  
  // get character, return 0 if there is no new character in the buffer
  mutex_lock (keyboard_buffer_lock[t]);
    if (term->kbd_count > 0) {
      term->kbd_count--;
      term->kbd_lastread = (term->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
      c = term->kbd[term->kbd_lastread];
    }
  mutex_unlock (keyboard_buffer_lock[t]);
  // ...  
@

\noindent
and

%nouse
<<first attempt for locking the keyboard buffer (in keyboard handler implementation)>>=
terminal_t *term = &terminals[cur_vt];
mutex_lock (keyboard_buffer_lock[cur_vt]);
  if (term->kbd_count < SYSTEM_KBD_BUFLEN) {
    if (ctrl_pressed && c >= 'a' && c <= 'z') c -= 96;  // Ctrl
    term->kbd[term->kbd_pos] = c;
    term->kbd_pos = (term->kbd_pos + 1) % SYSTEM_KBD_BUFLEN;
    term->kbd_count++;
    if (scheduler_is_active) { <<keyboard handler: wake sleeping process>> }
  }
mutex_unlock (keyboard_buffer_lock[cur_vt]);
@

\noindent
cannot work. However, note that the situation is not symmetrical: Whereas two threads will run alternately, this is not true for an interrupt handler which will interrupt the flow of control in a thread, but not vice versa. Thus it will be sufficient to prevent the interrupt handler from running at all while we access the data structures in a system call handler---we can simply disable interrupts before the critical section and re-enable them afterwards. 

This implements a synchronization model that is called \marginnote{one-sided\\ synchronization}\emph{one-sided synchronization}\index{one-sided synchronization}\index{synchronization!one-sided}. Since disabling interrupts disturbs the overall functioning of the operating system (e.\,g., by delaying the next scheduling decision) we should limit this to very short time spans. Figure~\ref{fig:kernel-sync} shows the difference between \emph{two-sided}\marginnote{two-sided\\ synchronization}\index{two-sided synchronization}\index{synchronization!two-sided} inter-thread synchronization and the synchronization of system call and interrupt handlers.

\begin{figure}[ht!]
\centering
\includegraphics[width=14.1cm]{pics/kernel-sync.pdf}
\caption[One-sided vs.{} two-sided synchronization.]{Mutex-based synchronization of threads (top) is an example of \emph{two-sided synchronization}; data which is shared between system call and interrupt handlers is handled via a \emph{one-sided synchronization} method (bottom; i.\,e., disabling interrupts in the system call handler).}
\label{fig:kernel-sync}
\end{figure}

A working implementation of [[syscall_readchar()]] thus looks as follows:

%nouse
<<second attempt for locking the keyboard buffer (in [[syscall_readchar]])>>=
void syscall_readchar (context_t *r) {
  char c;
  int t = thread_table[current_task].terminal;
  terminal_t *term = &terminals[t];
  
  // get character, return 0 if there is no new character in the buffer
  <<disable interrupts>>    // critical section starts here
    if (term->kbd_count > 0) {
      term->kbd_count--;
      term->kbd_lastread = (term->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
      c = term->kbd[term->kbd_lastread];
    }
  <<enable interrupts>>    // critical section ends here
  // ...  
@

\noindent
and that is also the way it could be implemented in \Ulix{} (see page~\pageref{sycall:readchar}). The corresponding critical section in the interrupt handler would need no protection because there it would be impossible for the system call handler's code to interfere with the running interrupt handler.


\subsubsection{Restoring Old Interrupt States}
\label{sec:restoring-old-int-states}%

As discussed in Section \ref{sec:nested:critical:sections}, marking critical sections needs to be done with care since nested critical sections can cause premature enabling of interrupts. This can be avoided by using ``nestable'' entry and exit protocols for critical sections, as discussed. 
However, sometimes interrupts might have been turned off by other means (e.\,g., the interrupt gate) and so we might not even know whether interrupts were enabled before we wish to disable them. For example, [[deblock]] calls [[remove_from_blocked_queue]] and [[add_to_ready_queue]], and [[deblock]] itself is both called from the interrupt handler [[keyboard_handler]] and from the syscall handler [[syscall_kill]] via [[u_kill]] and a further helper function (see Figure~\ref{fig:entering deblock}). 

% trim: left bottom right top
\begin{figure}[h!]
  \centering
  \includegraphics[trim=0 2mm 0 2mm,width=0.9\textwidth]{pics/keyb-handler-vs-u-kill.pdf}
  \caption{Two ways to enter the \texttt{deblock} functions with interrupts off or on.}
  \label{fig:entering deblock}
\end{figure}

Thus, for a \Ulix{} version with an interruptible kernel, we might enter [[deblock]] with interrupts on or off, depending on which function calls it.

In those situations we want to restore the original state afterwards. Thus, we need to save the current state of the interrupt flag (\register{IF}) which is bit 9 of the \register{EFLAGS} register before we disable interrupts. We can use a global variable 

<<global variables>>=
boolean if_state;   // state of the interrupt flag (IF)
@ %def if_state
for storing the state because interrupts will always be off after reading the state and until it is restored.

The following two new code chunks save and disable interrupts and restore them, respectively:

\pagebreak

<<save and disable interrupts>>=
{  // create scope for scope-local variable eflags
  int eflags;
  asm volatile (
    "pushf                 \n"     // push EFLAGS
    "cli                   \n"     // disable interrupts
    "movl   (%%esp), %0    \n"     // copy to eflags variable
    "addl   $4,      %%esp \n"     // restore stack pointer
  : "=r"(eflags) );
  if_state = (eflags >> 9) & 1;    // bit 9 of EFLAGS is IF
}
@

<<restore interrupts>>=
if (if_state == 1) {
  <<enable interrupts>>
}
@

The functions [[add_to_blocked_queue]] and [[remove_from_blocked_queue]] as well as \linebreak[[add_to_ready_queue]] and [[remove_from_ready_queue]] which handle the blocked queues and the ready queue could use this feature. 


\subsubsection{Finding Critical Sections}

As mentioned above, identifying critical sections is one of the major problems in interruptible kernels. It needs much experience to do this correctly, and doing it minimally is more an art than a science. A best-practice approach is to invest much discipline during development and for every new data structure investigate thoroughly whether this data structure is critical and, if yes, who accesses it. These accesses must be declared as critical sections. 

We will now discuss these points using \Ulix{} code. For example,
look at all the interrupt handlers of \Ulix{} and search for data structures which are accessed elsewhere. For an interruptible kernel we would have to make sure that interrupts are disabled whenever such an access (outside interrupt handlers) occurs. Luckily, the number of handlers is small---there are only five interrupt handlers:

\begin{itemize}
\item [[keyboard_handler]] served as our initial example and has already been dealt with.

\item [[timer_handler]] periodically activates the scheduler---we will discuss it below.
\end{itemize}

\noindent
The next three handlers deal with filesystem activity; you will only fully understand the following discussion after reading Chapters~\ref{chap:ulix:fs} (Filesystems) and \ref{chap:ulix:disk-i-o} (Disk I/O).

\begin{itemize}
\item [[ide_handler]] modifies the global [[hd_buf]] buffer and the [[hd_direction]] variable and deblocks a thread that has been waiting for the completion of a hard disk action. Other than from the IDE handler, any access to these data will originate from a system call handler initiated by a thread trying to read from or write to disk.

Since the implementation of the filesystem code does not allow multiple parallel accesses to the disk (once a transfer has been initiated, all other threads block on a mutex [[hd_lock]]), no thread will access the data before a current transaction has completed. Similarly, the IDE controller will only generate an interrupt after a (single) thread has made a system call that accesses the disk.

\item [[floppy_handler]] calls [[fdc_wakeup]] which manipulates an entry in the thread list (like [[ide_handler]], it deblocks a thread that has been waiting for the floppy drive's action to complete).

Floppy access is also serialized for threads using an [[fdc_lock]] variable (similar to [[hd_lock]]). 
[[fdc_timer]] (which is called by the timer handler) checks the lock state of [[fdc_lock]] but does not change it.

\item [[serial_hard_disk_handler]] also deblocks a thread which caused the recently finished action of the serial hard disk. Again, there is a [[serial_disk_lock]] variable which is used to serialize parallel accesses to the serial disk device.
\end{itemize}

For all hard disk, floppy disk and serial disk accesses the following order of execution is enforced:

\begin{enumerate}
\item A thread initiates disk access which leads to acquisition of one of the locks [[hd_lock]], [[fdc_lock]] or [[serial_disk_lock]]. Eventually the thread will block (and wait for the disk operation to complete).
\item One or more interrupts are generated by the controller, thus the corresponding interrupt handler will be executed. When \Ulix{} detects that the requested operation has completed, it will wake up the thread.
\item When the scheduler selects the thread, it will unlock the lock. Only then can the system start the next disk access (if other threads are waiting).
\end{enumerate}

Thus, we do not need one-sided synchronization in the disk I/O code.
Access to different devices (e.\,g., a hard disk and a floppy disk) can happen in parallel.

Note that the ready and blocked queues are manipulated by these interrupt handlers. These are critical regions because those queues are also modified via system calls (when a new process or thread is created or exits or when a process asks to wait for termination of a child process). Thus the functions

\begin{itemize}
\item [[u_fork]] (forks a process; called by [[syscall_fork]])
\item [[syscall_exit]] (exits a process)
\item [[u_pthread_create]] (creates a new thread in the current process)
\item [[syscall_waitpid]] (makes a process wait for termination of a child)
\end{itemize}
%
(in an interruptible kernel) would have to disable interrupts while accessing the thread table in order to ensure that they cannot be interrupted by one of the interrupt handlers. ([[syscall_pthread_exit]] uses [[syscall_exit]] to make the thread terminate.)

The timer handler calls the scheduler which also modifies the thread list. Since it runs with deactivated interrupts it cannot conflict with the other functions that modify this list.

An earlier version of the \Ulix{} code (up to release 0.12) used a [[thread_list_lock]] mutex for controlling access to the thread list (e.\,g., when creating a new thread or removing one from the list). However, the scheduler (which is sometimes started from a thread when it exits or yields, but typically runs on behalf of the timer interrupt handler) must not block and thus cannot use the mutex.


\subsubsection{Dealing With Complex Handlers}

In more complex operating systems handling an interrupt can become time"=intensive. Since disabling interrupts should be limited to short time spans (see above), in those cases the approach of splitting the handler code into a ``first-level interrupt handler'' and a ``second-level interrupt handler'' can help.

\begin{itemize}
\item The first-level\marginnote{1\textsuperscript{st}-level handler\\(top half)} interrupt handler (sometimes called \index{top half}\index{interrupt handler!top half}top half) is registered as the regular handler and runs with other interrupts disabled. It performs only the most important tasks (e.\,g., it acknowledges the interrupt and saves volatile data from a device's internal buffer). As a last step it creates the lower half of the handler, re-enables interrupts and terminates.

\item The second-level\marginnote{2\textsuperscript{nd}-level handler\\(bottom half)} interrupt handler (sometimes: \index{bottom half}\index{interrupt handler!bottom half}bottom half) is not part of the interrupt handler and runs while interrupts are enabled. It is somewhat similar to a kernel thread but without an address space of its own (it only uses the kernel's memory). The bottom half could be activated by the scheduler (in that case bottom halves would need to have a higher priority than regular threads) or some other mechanism could be used for making sure that the bottom halves run as early as possible---as long as no other top half has to be executed because new interrupts occurred.
\end{itemize}

The Linux kernel uses this concept and uses the terms \emph{top half} (for the first-level handler) and \emph{bottom half} or \emph{tasklet}\marginnote{tasklet}\index{tasklet}\index{Linux!tasklet}\index{interrupt handler!tasklet (Linux)} (for the second-level handler) \cite[pp.~81--106]{Love:2003:Linux-Kernel}. Tasklets in the Linux 2.6 kernel can have one of two priorities where the higher"=priority tasklets are always executed before the lower"=priority ones and both run before the next thread is scheduled. The top half of the interrupt handler registers a \emph{tasklet handler}. Those tasklet handlers must not block (just like the top halves, they cannot be scheduled, so it is not possible for them to use locks or semaphores), and they must be able to cope with being interrupted.


\subsubsection{Spurious Interrupts}

A \emph{spurious interrupt}\index{spurious interrupt}\index{interrupt!spurious} is an interrupt whose occurrence is faulty and unexpected. Yet, on physical hardware it is a problem that needs to be dealt with. 
For example, the Intel 8259 PIC\index{Intel 8259 PIC} which \Ulix{} uses allows the discovery of a spurious interrupt:

\begin{quotation}
\noindent
``In both the edge and level triggered modes the IR inputs must remain high until after the falling edge of the first $\overline{\textrm{INTA}}$. If the IR input goes low before this time a DEFAULT IR7 will occur when the CPU acknowledges the interrupt. This can be a useful safeguard for detecting interrupts caused by spurious noise glitches on the IR inputs. To implement this feature the IR7 routine is used for `clean up' simply executing a return instruction, thus ignoring the interrupt. If IR7 is needed for other purposes a default IR7 can still be detected by reading the ISR. A normal IR7 interrupt will set the corresponding ISR bit, a default IR7 won't.'' \cite[p. 18]{pic-8259a}
\end{quotation}

\noindent
(\register{ISR} is the In-Service Register.) Thus it is sufficient to modify handlers for interrupt numbers 7 (coming from the first PIC) and 15 (from the second PIC). In case of an interrupt from the first PIC, no action is required; especially it is not necessary to acknowledge the interrupt. However, if the interrupt comes from the second PIC, the first PIC (and only the first PIC) needs to be sent the acknowledgement.

Certain spurious interrupts can be detected by the system because interrupts usually provide services with prior demands. So if there is an interrupt which has no obvious demand, then it probably is spurious. Other types of spurious interrupts are harder to detect. 
Since \Ulix{} uses neither interrupt 7 (first parallel port) nor 15 (secondary IDE controller), we fortunately need not deal with this situation.


\subsubsection{Lost Wakeup}
\label{sec:lost:wakeup}

Blocking processes until an interrupt occurs introduces a problem that is called \emph{lost wakeup}\index{lost wakeup}\index{interrupt!lost wakeup}. Lost wakeups can be caused by bad programming or unfortunate circumstances. 

For example, if the interrupt that should deblock a thread is received before the thread is actually blocked, the deblock operation is not triggered and the thread might never get deblocked. 

Lost wakeup situations are hard to deal with in practice since it is difficult to distinguish the case where a wakeup is lost or merely very slow.  Lost wakeups usually result in deadlocks or threads being blocked forever. So in principle, techniques to discover deadlocks or timeouts on the waiting times of threads can help resolve this issue.

The same problem can occur with signals (see Chapter~\ref{chap:ulix:signals}) which might be sent to a process which is not yet waiting for them.

Lost wakeups could occur in a \Ulix{} version with an interruptible kernel whenever a process or thread is blocked and the reason for blocking can disappear before the block operation completes. There are several such potential situations in the interruptible version's \Ulix{} code, but they cannot occur in our non"=interruptible version. We have, however, marked the critical sections in some places so that these cases are already dealt with (preparing again for the transition to an interruptible kernel).

As before, some of the following explanations will only make sense once you have read later chapters, so we suggest you return here after (for example) reading Chapter~\ref{sec:hard-disk-controller} which discusses the hard disk controller.

\begin{itemize}
\item [[syscall_waitpid]] blocks a process so that it can wait for a child process to terminate. In the interruptible version of \Ulix{}, running this function with interrupts disabled would solve the possible situation of the child exiting after the parent entered [[syscall_waitpid]] but before it blocked.

\item hard disk access (see Chapter \ref{sec:hard-disk-controller}):
  before sending a request to the disk controller, 
  in the interruptible version of \Ulix{},
  the code would disable
  the interrupts. It would then check whether the request has already
  been completed and potentially block, re"=enabling the interrupts
  after the thread has been moved to the blocked queue. This 
  concerns the functions [[writesector_hd]] and [[readsector_hd]].

\item floppy disk access (see Chapter \ref{sec:floppy}):
  this is analogous to the hard disk case, but disabling and
  enabling interrupts would occur in different functions. 
  
  The functions 
  [[fdc_read_sector]] and [[fdc_write_sector]] call [[fdc_command]] 
  which would disable interrupts and send a control sequence to the
  floppy controller. 
  
  Then  
  [[fdc_command]] calls [[wait_fdc_interrupt]] (in [[<<fdc transfer>>]])
  which in turn calls [[fdc_sleep]] where interrupts would be re"=enabled
  after blocking the thread.
  
\item serial disk access (see Chapter \ref{sec:serial hard disk}):
  only read access can block, and this situation would be handled in the 
  same way as hard disk access: before sending a read request to
  the serial disk, interrupts would be disabled.

\item [[syscall_readchar]] (as discussed above) reads from a keyboard buffer and blocks if that is empty. Here, interrupts would be turned off between checking the buffer and calling [[block]].

\item [[mutex_lock]] blocks when the mutex is already held elsewhere.
  Since this function could be called in situations where interrupts
  may already be disabled, it saves the current state (interrupts
  on or off) and restores it before returning (when the lock has
  been acquired; see Section~\ref{sec:restoring-old-int-states}).
\end{itemize}

\noindent
In all these cases, when a thread blocks, interrupts would be re"=enabled
after moving a thread to a blocked queue via [[block]].


\section{Further Reading}

An excellent collection of synchronization problems (and solutions) is ``The Little Book of Semaphores'' by Allen B.~Downey \cite{Downey:2008:Semaphores} which is freely available on the publisher's website. It presents both classical and less well-known problems, and solutions are not simply given, but developed step by step---passing through several failed attempts and explaining why they failed.

For details on the POSIX synchronization functions, take a look at ``Programming with POSIX Threads'' by David R.\ Butenhof \cite{Butenhof:1997:Posix-Threads}. Its chapter 3 (which deals with synchronization) is freely available online\footnote{\url{http://ptgmedia.pearsoncmg.com/images/9780201633924/samplepages/0201633922.pdf}}.

``The Art of Multiprocessor Programming'' by Maurice Herlihy and Nir Shavit \cite{Herlihy:2012:AMP} is a very thorough introduction to the synchronization problems, especially those that occur on multiprocessor machines. As we mentioned earlier in Chapter~\ref{sec:multiprocessor:scheduling}, things get much more complicated when more than one CPU is used. It contains a lot of code that exemplifies the presented theory. That code is also available online.

A detailed discussion of top and bottom halves (tasklets) in the Linux kernel can be found in chapter~6 of Robert Love's kernel development book \cite{Love:2003:Linux-Kernel}.


\section{Exercises}

\begin{enumerate}
% start with ex. 30 
\setcounter{enumi}{29}

\item \label{ex:kernel:sync} \textbf{Multiprocessor Kernel Synchronization}

This exercise deals with the implementation of critical sections on multiprocessor systems, i.\,e., systems with multiple CPUs or CPUs with multiple cores. Assume you have a kernel in which critical sections are correctly labelled with [[ENTER_MUTEX]] and [[EXIT_MUTEX]]. For simplicity, assume that this holds for all interrupt handlers and all system calls. Assume further that two kernel level threads $A$ and $B$ are running on the system and that at least two CPUs execute these threads.

For each of the following cases discuss whether one of the following two situations can arise:
%
\begin{enumerate}
\item violation of mutual exclusion, i.\,e., threads $A$ and $B$ concurrently execute critical sections.
\item deadlock, i.\,e., at least one thread will never be scheduled again.
\end{enumerate}
%
If one of these conditions can occur, construct a schedule of the system that ends in the condition being true. If the conditions can never occur, argue why it is impossible.

\begin{itemize}
\item Case 1: single CPU, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are empty.
\item Case 2: single CPU, [[ENTER_MUTEX]] disables the interrupts on that CPU, [[ENTER_MUTEX]] enables the interrupts again.
\item Case 3: single CPU, [[ENTER_MUTEX]] contains a spin lock on a global bit called [[busy]] and assigns 1 when the lock is taken. [[EXIT_MUTEX]] assigns 0 to [[busy]].
\item Case 4: single CPU, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as follows, using the definition of [[Lock]] from Section~\ref{code:lock:instruction} (page~\pageref{code:lock:instruction}):

<<synchronization exercises, case 4>>=
Byte busy = false;

ENTER_MUTEX {
  <<disable interrupts>>
  while (Lock() == true);
}
EXIT_MUTEX {
  busy = false;
  <<enable interrupts>>
}
@
\end{itemize}

\begin{itemize}
\item Case 5: single CPU, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as follows:

<<synchronization exercises, case 5>>=
Byte busy = false;

ENTER_MUTEX {
  <<disable interrupts>>
  while (Lock() == true);
  <<enable interrupts>>
}
EXIT_MUTEX {
  <<disable interrupts>>
  busy = false;
  <<enable interrupts>>
}
@
\end{itemize}
\begin{itemize}
\item Case 6: two CPUs, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as in case 1.
\item Case 7: two CPUs, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as in case 2.
\item Case 8: two CPUs, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as in case 3.
\item Case 9: two CPUs, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as in case 4.
\item Case 10: two CPUs, [[ENTER_MUTEX]] and [[EXIT_MUTEX]] are implemented as in case 5.
\end{itemize}


\item \label{ex:nestable:cs:multiprocessor} \textbf{Nestable Critical Sections on Multiprocessor Systems}

Does the implementation of nestable critical sections presented in chunks [[<<nestable begin critical section>>]] and [[<<nestable end critical section>>]] work on multiprocessor systems?

% Answer: no. Since interrupts are turned off only for a single CPU, another CPU can enter and exit critical sections and mess up the global variable cs_nesting_level.

Does it work if disabling the interrupts is accompanied by a spin lock? 

% Answer: yes. The global mutual exclusion property of disable interrupts and spin locks allows only one CPU to enter its critical section. The global variable cs_nesting_level counts the nesting for that CPU.

\item 
\label{ex:semaphore:critical:section}%
\textbf{Kernel Level Semaphores as Critical Sections}

  Consider the implementation of [[wait_semaphore]] and [[signal_semaphore]] in Section~\ref{sec:implementing:p:and:v} and assume it were not declared as a critical section (i.\,e., interrupts remain on during execution of the code apart from within dispatcher operations). Is the implementation then still correct? Try to construct an example where two threads use a single semaphore, a context switch occurs and semaphore semantics are violated.

% Answer: interrupt has to occur between counter manipulation and counter checking. Problems occur if the counter is changed twice through unlucky scheduling and the condition of the counter check is not met.

\vspace{3mm}
\item \textbf{Implementing Kernel Level Semaphores}

Consider the following implementation of [[wait_semaphore]] and [[signal_semaphore]] that use atomic counter manipulations instead of non-atomic ones as in the actual implementation:

\index{wait (semaphore)}%
\index{signal (semaphore)}%

<<function implementations (inactive)>>=
void wait_semaphore (kl_semaphore_id sid) {
  kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  <<begin critical section in kernel>>
  int count = __sync_sub_and_fetch (&sem.counter, 1);  // atomic "--sem.counter"
  if (count < 0) {
    block (&sem.bq, TSTATE_LOCKED);
    debug_printf ("sem_LOCK going to call resign()\n");  // REMOVE_DEBUGGING_CODE
    <<resign>>
  }
  <<end critical section in kernel>>
}

void signal_semaphore (kl_semaphore_id sid) {
  kl_semaphore sem = <<semaphore structure with identifier [[sid]]>>;
  <<begin critical section in kernel>>
  int count = __sync_add_and_fetch (&sem.counter, 1);  // atomic "++sem.counter"
  if (count < 1) {
    blocked_queue *bq = &(sem.bq);
    thread_id head = bq->next;
    if (head != 0) {
      deblock (head, bq);
    } 
  }
  <<end critical section in kernel>>
}
@ %
The atomic counter manipulation is done using the [[gcc]] compiler's built-in functions [[__sync_sub_and_fetch]] and [[__sync_add_and_fetch]] \cite[section~7.4.1, p.~59]{intel-itanium-abi} that require that we add the option [[-march=i586]] to the compiler flags ([[CFLAGS]]). The implementation of those functions is semantically equivalent to

<<compiler-internal functions>>=
int __sync_sub_and_fetch (int *variable, int value) {
  *variable -= value;
  return *variable;
}

int __sync_add_and_fetch (int *variable, int value) {
  *variable += value;
  return *variable;
} 
@ %def __sync_sub_and_fetch __sync_add_and_fetch
but performs all steps atomically\index{atomic}.

The question is whether this implementation is in any aspect better than the one given in Section~\ref{sec:implementing:p:and:v}. Would it change anything if the body of the function were not protected as a critical section? (The latter question is an extension of exercise~\ref{ex:semaphore:critical:section}.)

% Answer: no, it does not help, apart from making the code potentially more efficient. The insight of exercise \ref{ex:semaphore:critical:section} remain valid: you need to protect P and V as a critical section, even if the counter manipulation is atomic.

\enlargethispage{1cm}
\vspace{2mm}
\item 
\label{ex:lock:as:critical:section}
\textbf{Locks as Critical Sections}

Consider the following variation of the implementation of [[mutex_lock]]. The only difference is that the [[<<begin critical section in kernel>>]] is moved to within the loop.

%nouse
<<function implementations (inactive)>>=
void mutex_lock (lock lockvar) {
  if (current_task == 0) { return; }        // no process
  while ( lockvar->l == 1 ) {
    <<begin critical section in kernel>>
    block (&(lockvar->bq), TSTATE_LOCKED);  // put process to sleep
    <<resign>>
  }
  lockvar->l = 1;
  <<end critical section in kernel>>
}
@ 

\end{enumerate}

\begin{enumerate}
\vspace{-6mm}
\item[] Is this implementation correct? Does it matter if the kernel were interruptible? 

\vspace{2mm}
% start with ex. 35 
\setcounter{enumi}{34}
\item 
\label{ex:lock:as:critical:section2}
\textbf{Locks as Critical Sections (Variation)}

Here is another variation of the [[mutex_lock]] implementation. It uses the
[[gcc]]"=internal function [[__sync_lock_test_and_set]] discussed in Section~\ref{sec:sync:test-and-set} to guarantee that testing and setting are performed atomically.

%nouse
<<function implementations (inactive)>>=
void mutex_lock (lock lockvar) {
  if (current_task == 0) { return; }        // no process
  while ( __sync_lock_test_and_set (&(lockvar->l), 1) != 0 ) {
    <<begin critical section in kernel>>
    block (&(lockvar->bq), TSTATE_LOCKED);  // put process to sleep
    debug_printf ("LOCK going to call resign()\n");   // REMOVE_DEBUGGING_CODE
    <<resign>>
  }
  <<end critical section in kernel>>
}
@ 
%
\end{enumerate}

\begin{enumerate}
\vspace{-6mm}
\item[] Does this improve the correctness?

\end{enumerate}



%---------------------------------------------------------------------------------------



\chapter{Filesystems}
\label{chap:ulix:fs}%
\index{filesystem}

In this chapter we describe how operating systems store files on
hard disks and floppy disks. The central concept for organizing directories
and files is the filesystem: it is an abstract description of the required
data structures.

In Chapter~\ref{chap:ulix:disk-i-o} we will look at what is needed to actually 
talk to a physical drive, but for now let's just assume that there is some
mechanism which enables us to read and write ``blocks'': these are small
chunks of disk storage into which we partition a disk---quite similar to
the way that we've split memory into page frames. 

We start with an overview of filesystem concepts in Section~\ref{sec:fs:intro}
that briefly discusses CP/M, FAT, NTFS and Unix filesystems. 
Section~\ref{sec:fs:mounting} explains the concept of mounting devices to
mount points which is used on Unix operating systems. After this short
theory block we jump right
into the implementation details: First, Section~\ref{sec:fs-implementation}
shows how the virtual filesystem (VFS) is organized in \UlixI{}. It
provides some abstractions which allow the OS to locate and use files on media
which are formatted with various filesystems. In Section~\ref{sec:fs:syscalls}
we present the new system calls that can be used by user mode programs.

Then, in Sections~\ref{sec:fs:minix-overview} and
\ref{sec:minix-implementation} we introduce the Minix filesystem and show
its implementation in \Ulix{}. 

Section~\ref{sec:dev-filesystem} presents a second
filesystem (for accessing device files in [[/dev]]), so you will see
that the virtual filesystem layer is actually put to good use.

Finally, Section~\ref{sec:fs:default-contents} gives a very short overview
of the directory hierarchy that \UlixI{} uses (which is modeled after
other Unix systems).


\section{Introduction to Filesystems}
\label{sec:fs:intro}%

Every operating system needs to support one or more filesystems---at least
one is required so that the OS can store and retrieve data, load programs
from the disk and enable them to access files. Support for more than one
filesystem makes sense when the OS wants to read media from other systems,
e.\,g.\ FAT-formatted media which can be used on most of today's systems.

Why is there no single filesystem which all operating systems could agree
on? Surely, this would make the cooperation of diverse systems much simpler.

If we want to understand why every OS has its own idea of how to store
files (and possibly directories) on disk we have to look back to the 
beginnings of external storage.

\begin{description}
\item [Card Readers] \index{card reader}Early computers used punch cards 
(see Figure~\ref{img:punchcard}) to store jobs and
the associated data: a card reader would be filled with a stack of such
cards, the first set of cards contained the binary program to be run, and
the following cards held the data. The system would read all these cards
into memory and then run the job. After completion, the results of the
computation would be punched on empty cards or sent to a connected printer.
Data organization in such a card stack was strictly serial, so there was
no concept of a filesystem: the first card(s) would describe how many
program and data cards would follow and where to store their contents in
RAM.

\begin{figure}[ht!]
\centering
\includegraphics[width=12cm]{pics/Blue-punch-card-front-horiz.jpg}
\caption{Punch cards were used to store program code and data.}
\label{img:punchcard}
\end{figure}

\item[Tape] \index{tape drive}\index{magnetic tape drive}\index{hardware!magnetic tape drive}The next step was the introduction of magnetic tape drives.
These live on until today (as backup media, or third-level storage),
and they are also strictly serial: Typically tape drives can be sent a
\emph{rewind} command to move to the beginning of the tape and \emph{read}
and \emph{write} commands to read or write the tape sequentially.
While it is possible to store more than one file on a tape, accessing the
third file requires skipping the first two ones---which can only be 
achieved by reading them first. Thus, tapes have no filesystem, either.
Today, when people use a tape drive for backup, they typically generate
an archive file (which may or may not contain a central listing of the
files) and write this single archive file onto the tape. The Unix
[[tar]]\marginnote{[[tar]]} program ([[tar]]: tape archive) writes a file header for each
contained file and then the file's data; then the next file header and
data follow. The created archive file is written raw to the tape.

\item[Disk] \index{hardware!hard disk}The seriality of storage was changed with the introduction
of disks: it does not matter whether you think of floppy or hard disks,
all of them allow \index{random access (hard disk)}\emph{random access}\marginnote{random access}, that means you can store several files
on one disk and read any file (or part of a file) without looking at
other data as long as you know where to find the file on the disk. Thus,
disks need some kind of \index{directory}\emph{directory}\marginnote{directory} information so that the machine can
look up files on a previously unseen disk. The question of how and where 
to store this directory information on the disk defines (most of) a 
filesystem, and many OS developers have had their own ideas about the
organization of files on a disk. Early machines were not meant to be
compatible with machines of other manufacturers, and this led to
various incompatible filesystems. 
We'll look at some examples in the next section.
\end{description}


\subsection{Simple Filesystems}

We assume throughout the rest of this chapter that a disk is divided
into \emph{blocks}\marginnote{physical block} of some fixed size (typically 512 or 1024 bytes),
and these blocks can be read and written using some kind of
\verb#readblock# and \verb#writeblock# commands which the disk drive controller
supports. We're not going to delve into the details of how a hard disk
is organized into platters, cylinders, sectors and tracks; instead we will 
assume that there is a logical ordering of blocks and that the controller 
allows to access these \emph{logical blocks}\marginnote{logical block} directly via some mechanism that
the OS can use.


\subsubsection{Contiguous Filesystems}

\index{filesystem!contiguous}%
\index{contiguous filesystem}%
As long as you want to write files to a disk only \emph{once} (and then
continue using it in read-only-mode), organizing files is rather simple:
Assume you want to store 150 files on the disk. You can then reserve
one or more blocks at the beginning of the disk for a central directory---just
enough space to store filename, starting block and file length for each
file (see Table~\ref{table:files:contiguous}). Then write each file to 
the disk, starting at the first unused block, and update the directory afterwards. 

All files are stored
\emph{contiguously}, which means that you can later read them sequentially
as long as you know where to start reading (see Figure \ref{fig:contiguous filesystem}). 
Opening and reading files
then means just looking up the filename in the directory and starting to
read at the start block number which is stored next to the filename.

\begin{table}[t!]
\centering
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Filename} & \textbf{Size} & \textbf{First Block} & \textbf{Block Count} \\
\hline
\hline
{\tt somefile.txt}  &  3301 &  2 &  4 \\
\hline
{\tt otherfile.txt} & 49152 &  6 & 48 \\
\hline
{\tt test.txt}      & 11147 & 54 & 11 \\
\hline
\end{tabular}
\caption[Directory of a contiguous filesystem.]{This is a simple directory of a contiguous filesystem. It stores both
the number of blocks as well as the actual file size which might be less than a
multiple of the block size (1024). The number of blocks could also be calculated
from the file size.}
\label{table:files:contiguous}
\end{table}

\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=7mm]{16}
\bitbox{1}{\textbf{T}}\bitbox{1}{\textbf{T}}
\bitbox{1}{A}\bitbox{1}{A}\bitbox{1}{A}\bitbox{1}{A}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B} \,\, {\footnotesize 00..15} \\

\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B} \,\, {\footnotesize 16..31} \\

\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B} \,\, {\footnotesize 32..47} \\

\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}
\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}
\bitbox{1}{C}\bitbox{1}{C} \,\, {\footnotesize 48..63} \\

\bitbox{1}{C}\bitbox{15}{(free)}  \,\, {\footnotesize 64..79} \\

\bitbox{16}{(free)} \,\, {\footnotesize 80..95} \\[-5mm]
\end{bytefield}
\caption[Organization of disk blocks in a contiguous filesystem.]{Organization of disk blocks in a contiguous filesystem: The \textbf{T} blocks hold the table of contents, and A, B and C represent the three sample files.}
\label{fig:contiguous filesystem}
\end{centering}
\end{figure}

\index{ISO-9660 filesystem}\index{filesystem!ISO-9660, CD-ROM}\index{CD-ROM filesystem ISO-9660}The ISO-9660\marginnote{ISO-9660 (CD)} filesystem \cite{ECMA-119} which is used for compact discs works in a similar
way, so this concept is still in use today. When we first implemented a
disk driver for \UlixI{} we used this approach as a quick hack to create
a read-only filesystem.

Why is there a problem with this kind of organization? Imagine you want to
enable write-support for such a filesystem. As long as you only modify
blocks inside a file, everything is fine: In the same fashion used for
reading a file, you can calculate the block number from the first block
and the file offset and then change the right data block on the disk to
update the file's contents. But what about appending to a file? Here's where
we run into problems. Once you reach the end of the last block of a file,
you cannot go on, since the next block on the disk belongs to a different
file. You would first have to move all blocks of the following file to
an unused region on the disk (and update the directory) before you can
continue to write new blocks for the first file. But such a procedure will
leave \emph{holes} in the disk: unused regions which may be used for new
files but more often than not will be too small to store a complete file
inside. This is called \marginnote{external\\ fragmentation}\emph{external fragmentation}.

The solution to this problem is to not store just a starting block and
the file length, but a collection of block numbers: with such a method
any free block may be used to store file contents, and the order of the
blocks is irrelevant. Also, files can then be spread all over the disk
instead of being contiguous.


\subsubsection{Non-contiguous Filesystems}

\index{filesystem!non-contiguous}%
\index{non-contiguous filesystem}%
Giving up the contiguousness makes file storage more flexible, but reading
and writing become harder: once you start reading or writing to a file,
you can only read/write until the end of the current block; to continue
you need to first look up the block number of the next data block (which
can be found in some kind of directory, see 
Table~\ref{table:files:non-contiguous} and Figure~\ref{fig:non-contiguous filesystem}). 
And again, this information is only good until the end of that block, when 
you need to look up the next block number.

\begin{table}[h!]
\centering
\begin{tabular}{|l|r|l|}
\hline
\textbf{Filename} & \textbf{Size} & \textbf{Block List} \\
\hline
\hline
{\tt somefile.txt}  &  3301 &  2, 3, 16, 44  \\
\hline
{\tt otherfile.txt} & 49152 &  4, 5, \dots, 15, 17, 18, \dots, 43, 55, 56, \dots, 63 \\
\hline
{\tt test.txt}      & 11147 &  45, 46, \dots, 54, 64 \\
\hline
\end{tabular}
\caption[Directory of a non-contiguous filesystem.]{This is the directory of a non-contiguous filesystem. Instead of start block and block count it stores a block list for each entry.}
\label{table:files:non-contiguous}
\end{table}

\begin{figure}[th]
\begin{centering}
%\settowidth{\bitwidth}{Ok~}
\begin{bytefield}[bitwidth=7mm]{16}
\bitbox{1}{\textbf{T}}\bitbox{1}{\textbf{T}}
\bitbox{1}{A}\bitbox{1}{A}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B} \,\, {\footnotesize 00..15} \\

\bitbox{1}{A}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B} 
\,\, {\footnotesize 16..31} \\

\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{A}\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C} 
\,\, {\footnotesize 32..47} \\

\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}
\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{C}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}
\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B}\bitbox{1}{B} 
\,\, {\footnotesize 48..63} \\

\bitbox{1}{C}\bitbox{15}{(free)}  \,\, {\footnotesize 64..79} \\

\bitbox{16}{(free)} \,\, {\footnotesize 80..95} \\[-5mm]
\end{bytefield}
\caption[Organization of disk blocks in a non-contiguous filesystem.]{Organization of disk blocks in a non-contiguous filesystem: Files can use any set of available blocks.}
\label{fig:non-contiguous filesystem}
\end{centering}
\end{figure}

\pagebreak

Most modern filesystems work in this way, so the question remains where
to store the block numbers.

The new flexibility comes at a cost: reading a disk sequentially is
cheap because the read/write heads are always positioned properly for
reading the next block. When you allow a file to spread over the disk,
the disk must seek to the next block which costs time: it slows down
reading. A disk that holds lots of files which are spread over the disk
blocks in this fashion is called \emph{fragmented}\marginnote{fragmented disk}, and many operating
systems provide defragmenting tools which reorganize the files so that
all blocks of a file occur in-order on the disk. However, a freshly
defragmented disk becomes fragmented again once you start deleting files
and writing new ones.


\subsubsection{CP/M}

\index{CP/M operating system}\index{filesystem!CP/M}%
An early example for non-contiguous filesystems is that of CP/M, an
operating system which was popular in the 70s and early 80s. Actually,
there was a variety of non-compatible CP/M filesystems, but they were
at least all similar.

CP/M's filesystem was flat, i.\,e., it did not implement the concept of
subdirectories. There was one central directory that held the information
about all files on the disk. For bringing some order into a big list of
files, CP/M introduced the concept of a user number: each file's metadata
contained a number between 0 and 15 (standard: 0) and by changing the
current user number to $n$ the internal [[DIR]] command would only show
files with that user number $n$. That did not protect a user's files from
access by another user, but it allowed cooperative and trusted users to
share a disk.

\pagebreak
Block numbers for each file were stored in the directory entry (which was
32 bytes long, with 16 bytes reserved for block numbers). If a file used 
more data blocks than one directory entry
could address, another directory entry for the same file was created
(and called an \emph{extent})\marginnote{extent (CP/M)}. One directory entry could hold either
16 or eight block numbers, depending on the total size of the disk:
early floppy disks stored $\approx 180$ KByte, and the blocksize was 1 KByte,
thus on those floppies one byte was enough to reference a block
\cite[pp.{} 19 ff.]{Johnson-Laird:1983}.

CP/M files have three attributes which may be set or unset: `read-only',
`system' and `file changed'. These are stored in the highest bits of
three of the filename bytes---filenames must be made of ASCII characters
which use only seven bits of each byte. CP/M\index{CP/M operating system!filename convention} filenames follow the ``8.3''
convention which was later picked up by MS-DOS\index{MS-DOS operating system!filename convention}: the first eight characters
named the file, the other three characters were used for the file extension
which defined the filetype (e.\,g.\ [[COM]], [[C]], [[PAS]]). Lower-case
letters were forbidden. The dot in a filename such as [[TEST.COM]] was
not stored in the directory entry, and you could not create names like
[[X.ENDING]], since the filename and extension were treated separately
(with their eight characters / three characters limits).


\subsubsection{MS-DOS FAT}

\index{FAT filesystem}\index{filesystem!FAT}\index{MS-DOS operating system!FAT filesystem}\index{Windows operating system!FAT filesystem}\index{file allocation table}%
The \emph{FAT} filesystem (\emph{File Allocation Table}) of MS-DOS and Windows 
uses a 
different approach for storing the block numbers.  Instead of blocks,
disks are divided into \index{cluster}\emph{clusters}\marginnote{cluster (FAT)}, and the size of a cluster depends on
the filesystem size. For example, with FAT16 the cluster size is 512 
bytes for filesystem sizes up to 32 MByte, it is 32 KByte for
filesystems with a size between 1 GByte and 2 GByte \cite{Microsoft:2000:FAT}.

There are three variants of FAT named FAT12, FAT16 and FAT32. For example,
a FAT16 directory entry maps a filename to the first data cluster of the
file. Further clusters can be found via traversing a linked list, the
file allocation table: it contains one 16-bit entry for each cluster, 
and such an entry has one of the following values:

\begin{itemize}
\item \hex{0000}: Free cluster.
\item \hex{0002}--\hex{FFEF}: points to the next cluster in the linked list.
\item \hex{FFF0}--\hex{FFF6}: Reserved.
\item \hex{FFF7}: Bad cluster (cannot be used).
\item \hex{FFF8}--\hex{FFFF}: This is the last cluster of the file. (Microsoft operating systems only use the \hex{FFFF} value.)
\end{itemize}

\noindent
(The size of the cluster number (16 bit) is what gives FAT16 its name. For FAT12 and FAT32 there are similar conventions, e.\,g.\ \hex{0FFFFFFF} (28 1-bits) marks the end of the list on FAT32, and \hex{FFF} (twelve 1-bits) on FAT12 media. As Microsoft's specification \cite{Microsoft:2000:FAT} notes, FAT32 is actually ``FAT28'' since only the lower 28 bits of a cluster number are interpreted.)

This means that it is impossible to quickly access the end of a large file, for example a file with FAT16's maximum size (which uses 65522 clusters) requires reading 65522 FAT entries
in order to determine the last cluster number.


\subsection{Advanced Filesystems}

Leaving FAT and other classical filesystems behind, we now look at two more advanced specimens: the NTFS filesystem which was introduced with Microsoft Windows\index{Windows operating system} NT and the Unix way of storing files.


\subsubsection{NTFS}

\index{filesystem!NTFS}\index{NTFS filesystem}\index{new technology filesystem}\index{Windows operating system!NTFS filesystem}\index{OS/2 operating system}\index{HPFS filesystem}\index{filesystem!HPFS}%
The \emph{New Technology Filesystem} (\emph{NTFS}) is a successor to both FAT and the \emph{High Performance Filesystem} (\emph{HPFS})\marginnote{HPFS, OS/2} that was developed for \emph{OS/2} by Microsoft and IBM. When the two companies ended the cooperation on OS/2, IBM kept on using HPFS, and Microsoft developed Windows NT which introduced NTFS. The central data structure of an NTFS volume is the \emph{Master File Table}\index{master file table (MFT)} (\emph{MFT})\marginnote{MFT} which contains entries for each file and each directory, including itself (since the MFT is also a file). Filename and data are attributes of a file. The filename is always part of the MFT entry, and the file data may also be if they are small enough. Otherwise, the data are external to the MFT entry. In that case, NTFS stores information about one or more \index{cluster}\index{cluster run (NTFS)}\emph{cluster runs}\marginnote{cluster run}: A cluster run is a contiguous set of clusters, identified by a starting cluster and the number of clusters. Each such cluster run description is encoded so that is uses as few bytes as possible, it starts with a header byte in which the high half-byte gives the size (in bytes) of the following start cluster number, and the low half-byte tells how many bytes are used to describe the number of clusters (they follow behind the first encoded number).

As an example, \verb#32 EF CD AB 02 01# (all numbers are hexadecimal) describes a cluster run with the following properties:

\begin{itemize}
\item \texttt{\textbf{3}2}: three bytes for the start cluster number
\item \texttt{3\textbf{2}}: two bytes for the cluster count number
\item \texttt{EF CD AB}: little-endian encoding of the start cluster number, \hex{abcdef}
\item \texttt{02 01}: little-endian encoding of the cluster count number, \hex{0102}
\end{itemize}

This means that the cluster starts at cluster \hex{abcdef} and ends at cluster \hex{0xabcef0} (= \hex{abcdef} $+$ \hex{0102} $-$ 1).

If this is the only cluster (i.\,e., the file is contiguous or non-fragmented), a further 0 byte ends the description, otherwise the encoded form of the next cluster run follows; in any case the last cluster run description is followed by a 0 byte, ending the entry. This may degenerate into a classical list of used clusters where the cluster count number is always 1, but that is not normally the case.

In comparison to FAT, access to an arbitrary cluster is much faster because all the information that is needed to find the $n$th cluster of a file is stored directly in the MFT entry, whereas on a FAT volume half the cluster chain must be inspected (on average).

NTFS allows a file to have several names; it can store more than one filename attribute in an MFT entry. For example, besides the regular name (as seen on Windows\index{Windows operating system}) files can also have a short filename for compatibility with old MS-DOS\index{MS-DOS operating system} applications.

Directories on NTFS are also files (again with an MFT entry) and their file entries are organized as  B-trees. Directory entries map a name to the MFT entry of the associated file, but also (redundantly) store the file size and time stamps that are also available via each file's MFT entry \cite[p.~28]{Custer:NTFS:1994}.

The organization into directories that map filenames to MFT entries somewhat resembles the Unix filesystem structure where directories map filenames to inodes (see below).

NTFS provides several interesting features, for example it performs journaling and allows more than one standard \emph{data stream}\index{data stream (NTFS)}\index{stream (NTFS)}\marginnote{data stream}: The file contents are considered the default data stream, but there can be further, named data streams which can be accessed via a [[filename:streamname]] syntax. These extra streams could be used to implement versioning of files (keeping several old version of a file).


\subsubsection{Unix Filesystems}

Where CP/M and MS-DOS link all data to a filename as the significant identifier in a directory entry, \index{filesystem!Unix}Unix filesystems work differently: They assign numbers to files, not names. These numbers are called \emph{inode numbers} and they point to entries in an inode table. Each \emph{inode}\index{inode}\marginnote{inode} (index node) stores metadata about a file, such as ownership, access permissions, file creation and modification dates and some kind of pointers to the file's data blocks.

Files get a name by writing that name and an inode number into a special directory file. As an inode may occur several times in such directory files, any file can have more than one name. Thus, filenames are not unique.

Like a CP/M directory entry, a Unix inode has a few fields which contain block numbers and lead to the first data blocks of a file. However, in order to support large files, a different mechanism is needed because the inode has a fixed (and small) size.
We have already discussed in Section~\ref{sect:memory:fs:indirection} (p.~\pageref{sect:memory:fs:indirection}) that Unix filesystems work with several layers of \emph{indirection}\marginnote{indirection}---how many depends on the concrete filesystem. With single indirection\index{single indirection} one or more of the inode fields point to blocks which do not contain data but other block numbers. Double indirection\index{indirection}\index{double indirection} introduces an extra layer of indirection, and triple indirection\index{triple indirection} goes yet one step further (Figure~\ref{img:disk-indirection-general}).

\begin{figure}[ht!]
\centering
\includegraphics[width=12cm]{pics/indirection-general-clipped.pdf}
\caption[Unix inodes store direct and indirect block addresses.]{In Unix filesystems inodes store direct and single or mulitiple indirection block addresses.}
\label{img:disk-indirection-general}
\end{figure}

We will not discuss the general Unix filesystem characteristics in this overview since you will see all the details in the upcoming sections which implement one of its variants (the Minix filesystem).


\section[Mounting: the Unix Way to Access Many Volumes]{Mounting: the Unix Way to Access\\ Many Volumes}
\label{sec:fs:mounting}

Some operating systems dedicate a ``drive identifier'' to each volume
that is in use. CP/M\index{CP/M operating system} was one of the earlier systems with a huge user
base, and they used \emph{drive letters}\marginnote{drive letter}\index{drive letter} (A, B) to access more than one
floppy drive. The idea was copied by MS-DOS\index{MS-DOS operating system} and has been kept alive to
this day, with Windows\index{Windows operating system} drive letters always starting at C (A and B
are still reserved for floppy drives). Figure~\ref{fig:fs-windows} shows
how Windows accesses three volumes via three drive letters.

\begin{figure}[p!]
\centering
\includegraphics[width=11cm]{pics/fs-windows.png}
\caption{Windows uses separate drive letters for each volume.}
\vspace{4mm}
\label{fig:fs-windows}
\end{figure}

In the Unix world drive letters are unknown. Instead, Unix combines
all volumes into one huge Unix directory tree (Figure~\ref{fig:fs-unix}). 
This means that
parts of the tree can represent the contents of several volumes.
The process of adding a new volume (and thus enlarging the tree) is
called \emph{mounting}\marginnote{mounting}\index{mount}. The root of the newly included filesystem will
not appear as the root of the overall tree, but as some node in the
middle of the new tree. That node is called the \emph{mount point}\index{mount point}\marginnote{mount point}.

\begin{figure}[p!]
\centering
\includegraphics[width=14cm]{pics/fs-unix.png}
\caption[Unix systems integrate all volumes in one tree.]{Unix systems integrate all volumes in one tree. In this example, [[/]], [[/mnt/dvd/]] and [[/mnt/disk2/]] are mount points.}
\label{fig:fs-unix}
\end{figure}

Originally, Unix used regular files as mount points. The idea was to
look at the current directory tree (before the mount operation), then
pick a leaf in this tree (regular files cannot have children in the
tree) and attach the root of the new volume to this leaf
\cite{Ritchie:1974:UTS:361011.361061}.

Modern Unix-type systems use directories as mount points which can have
the effect of hiding files if the directory chosen as a mount point is
not empty (i.\,e., it is not a leaf of the tree).

A mount operation can be undone: the system can \emph{unmount}\marginnote{unmount}\index{unmount}
a volume which removes the volume's sub-tree from the directory tree.
This is only possible when there are no open files on the volume.
Unix systems support mounting and unmounting via [[mount]] and [[unmount]]
system calls (and library functions of the same names), whereas the
corresponding command line tools are called [[mount]] and [[umount]]
(without the ``n'' letter of [[unmount]]).

When mounting a volume, it is also possible to provide \emph{mount options}\index{mount option}\marginnote{mount option}
which are specific to this volume, and special mount options may be 
available which depend on the filesystem. A classical mount option is
\emph{read only} which completely forbids write operations to the volume.
This is sometimes required by the device type (e.\,g.{} in case of a DVD),
and at other times it is just so desired by the user; for example,
computer forensic examiners need to mount media in read-only mode so
that all data will remain in their original state.


\section{The \UlixI{} Virtual Filesystem}
\label{sec:fs-implementation}
\index{filesystem!implementation in Ulix}%
\index{Ulix!implementation of the virtual filesystem}%

\UlixI{} shall use a \emph{virtual filesystem}\index{virtual filesystem}\index{filesystem!virtual filesystem}\index{VFS (virtual filesystem)} (\emph{VFS})\marginnote{VFS}. That means that several real
filesystems might be used, and the VFS provides an abstraction so that
generic functions such as [[open]], [[read]] and [[write]] may be used
for accessing these.

\index{filesystem!layered design}%
There are several layers, as you can see in Figure~\ref{fig:vfs}:

\begin{figure}[h!]
\centering
\includegraphics[width=10cm]{pics/vfs.pdf}
\caption[Layered design of the Virtual Filesystem.]{The Virtual Filesystem has a layered design. For accessing files, the kernel and processes use functions at the virtual filesystem level, and they will be translated through the layers until they are finally turned into floppy or hard disk access function calls.}
\label{fig:vfs}
\end{figure}

\begin{itemize}

\item Starting at the lowest level, we need code that can interact with the controllers to which floppy or hard disk drives are connected. They will work with blocks of data, i.\,e., they read or write a whole block (and not single bytes) each time. Chapter \ref{chap:ulix:disk-i-o} will present the code necessary to talk to the devices and perform the data transfers between memory and disk.

\item One level above, we provide generic block read/write functions that will work with any supported device. They take a device ID as a parameter but otherwise let the next level ignore specifics of the device in use.

\item Yet higher in the driver hierarchy are the \emph{logical filesystem drivers}\marginnote{logical\\ filesystem}\index{logical filesystem}\index{filesystem!logical filesystem}. \UlixI{} only provides one implementation of such a driver (we support the Minix filesystem), but we write the code in such a way that we (or you) could easily add additional drivers. The logical level is concerned with the organization of files, directories and \emph{metadata}\marginnote{metadata} of a volume: this is what this chapter is mainly about. We will give an introduction to all the details of the \emph{Minix}\marginnote{Minix}\index{Minix!filesystem}\index{filesystem!Minix} filesystem design.

\item On the highest level there are the virtual file system functions. They work with pathnames for accessing files or directories, and such pathnames will be translated into (device, local pathname) pairs. If you split the mount point from an absolute path, the remainder is the local (absolute) path on the volume which is mounted on that mount point. This is also the code for which we provide a user mode interface via system calls.
\end{itemize}

\noindent
Whenever a file is being accessed, we want \UlixI{} to take the following
steps:

\begin{enumerate}
\item Calculate the \emph{absolute path}\marginnote{absolute path} of the file. Note that a filename may
already be given as an absolute path (\eg\ \verb#/usr/bin/ps#), but it
may also be given as a relative path (\eg\ \verb#../ps#). In the latter
case we construct the absolute path from the current working directory
and the \emph{relative path}\marginnote{relative path}.
\item Scan the mount table to find out on which filesystem the file is
located. This will return two values: a pointer to the filesystem and
a path which is local to this filesystem. 
In case of \verb#/mnt/tmp/file.txt# this may lead to the number 1 (standing
for filesystem number 1 which is mounted on \verb#/mnt#) and the path
(\verb#/tmp/file.txt#) within that filesystem.
\item Depending on the service function which was called (\eg\ \verb#open#),
find a registered function that can talk to this kind of filesystem
(\eg\ \verb#mx_open# for a Minix filesystem or \verb#fat_open# for a 
DOS/FAT filesystem) and call it.
\end{enumerate}

\noindent
The filesystem-specific functions should assume that they can access
the filesystem as a large, consecutive block of data. As already mentioned, \UlixI{} will
provide generic functions [[readblock]] and [[writeblock]] which
can be used to access the raw data, be they on a disk partition, a
floppy disk or inside RAM.

\pagebreak
We will restrict the number of mounts to 16. A \emph{mount table entry}\marginnote{mount table}\index{mount table} looks like this:

%nouse
<<type definitions>>=
typedef struct {
  char mountpoint[256];
  short fstype;            // filesystem type, e. g. Minix, device filesystem
  short device;            // e. g. DEV_FD0, DEV_HDA
  short mount_flags;       // always 0; we will not use mount flags
} mount_table_entry;
@ %def mount_table_entry

\noindent
We do not provide [[mount]] and [[umount]] functions in the kernel, but
instead work with a fixed table. This could easily be remedied since those
functions would just add or remove an entry to the following array and
perform some checks:

<<global variables>>=
mount_table_entry mount_table[16] = { 
  { "/",     FS_MINIX, DEV_HDA,  0 },
  { "/mnt/", FS_MINIX, DEV_FD1,  0 },
  { "/tmp/", FS_MINIX, DEV_HDB,  0 },
  { "/dev/", FS_DEV,   DEV_NONE, 0 },  
  { { 0 } }
};
short current_mounts = 4;   // how many FSs are mounted?
@ %def mount_table current_mounts
(The constants [[DEV_HDA]], [[DEV_HDB]] and [[DEV_FD1]] identify the first two hard disks and the second floppy disk; we will define them in the next chapter.) 
The information in such an entry corresponds roughly to the data
you can observe in \verb#/etc/mtab# on a Linux\index{Linux!/etc/mtab file@\texttt{/etc/mtab} file} system:

%nouse
<<Linux mtab entry>>=
/dev/sda2 / ext3 rw,errors=remount-ro 0 0
@

\noindent
(This line shows the device filename, the mount point, the
filesystem type, the mount options (in this case: read-write, remount as read-only in case of errors) and dump and filesystem check
options which we will not deal with in \UlixI{}.)

A mount table entry is unused if its [[fstype]] element is [[0]]. The mount flag value [[0]] calls for standard mount options. (In our case that means readable and writeable, though we do not provide alternatives such as read-only.) The following helper function

%nouse
<<function prototypes>>=
void print_mount_table ();
@ will be called during system startup and show the mount table:

\pagebreak

<<function implementations>>=
void print_mount_table () {
  int i, dev;
  for (i=0; i<current_mounts; i++) {
    dev = mount_table[i].device;
    if (dev != 0) {
      char *devname;
      switch (dev) {
        case DEV_HDA: devname = "hda"; break;
        case DEV_HDB: devname = "hdb"; break;
        case DEV_FD0: devname = "fd0"; break;
        case DEV_FD1: devname = "fd1"; break;
      }
      printf ("mount: dev[%02x:%02x] = /dev/%s on %-5s type %-5s (options %d)\n",
              devmajor (dev), devminor (dev), devname, mount_table[i].mountpoint, 
              fs_names[mount_table[i].fstype], mount_table[i].mount_flags);
    } else
      printf ("mount: none                  on %-5s type %-5s (options %d)\n",
              mount_table[i].mountpoint, 
              fs_names[mount_table[i].fstype], mount_table[i].mount_flags);
  }
}
@ %def print_mount_table

\noindent
The [[fs_names[]]] array contains strings describing the filesystems; its definition
follows on page \pageref{definition of fs names}.

We will provide two concrete implementations of filesystems:

\begin{itemize}
\item a \emph{Minix filesystem}\marginnote{Minix} implementation which describes how to (logically)
read and write Minix-formatted media
%\item a [[/proc]] filesystem similar to Linux which will hold process
%and system information,
\item and a [[/dev]]\marginnote{\texttt{/dev} filesystem} filesystem, similar to Linux\index{Linux!/dev filesystem@\texttt{/dev} filesystem}, which provides
information about known devices (such as [[/dev/fd0]] for the first
floppy drive).
\end{itemize}

\noindent
The architecture will be such that it is possible to add support for other
filesystems, for example FAT (from MS-DOS\index{MS-DOS operating system}/Windows\index{Windows operating system}). Since \UlixI{} belongs
to the Unix family, we will provide abstract Unix filesystem features
(such as symbolic and hard links, user and group information, classical Unix
access permissions and timestamps) and have to map them to the data which are
available in a concrete filesystem (on a disk).

The other layer is the hardware: It shall be possible to use all supported
filesystems on any kind of device for which there are [[blockread]] and
[[blockwrite]] functions. Thus, when \UlixI{} tries to \verb#open# 
a file and \verb#read# from it, the system will start with executing the
virtual [[u_open]] or [[u_read]] function, then call (for example) Minix-related
[[mx_open]] or [[mx_read]] functions and finally end in calls to the
hardware-specific [[readblock]] functions. The overall process of executing
[[fd = open("/mnt/tmp/test");]] with the second floppy drive mounted on
[[/mnt/]] is shown in Figure \ref{fig:calling-open}.

\pagebreak

\begin{figure}[h!]
\centering
\includegraphics[width=1.0\textwidth]{pics/vfs-open.pdf}
\caption{Opening a file via the user mode library function \texttt{open()}.}
\label{fig:calling-open}
\end{figure}

On the hardware side, \UlixI{} will provide drivers for floppy disks and
hard disks. Thus, there will be support for Minix-formatted floppy disks
and hard disks.

\enlargethispage{4mm}


\subsection{Finding the Device and Local Path}

Let's look at a possible scenario: Assume we have two floppy disks ([[fda]], [[fdb]]) and two
RAM disks\index{RAM disk} ([[ram0]], [[ram1]]) mounted like this:
\vspace{-1mm}

\begin{Verbatim}
/dev/fda  on  /             (minix)
/def/fdb  on  /home         (minix)
/dev/ram0 on  /mnt          (minix)
/dev/ram1 on  /home/ramtest (minix)
\end{Verbatim}

Since the path \path!/home/ramtest! does not exist before [[fdb]] has been mounted
on \path!/home/!, the second RAM disk\footnote{This version of \UlixI{} does not implement RAM disks; if you want to see \UlixI{} RAM disk support, you can read Liviu Beraru's bachelor thesis \cite{Beraru:2013:Bachelor}.}
must have been mounted \emph{after} the second floppy
disk. Thus, if we assume that we store the mount information in the order in which it
was created by [[mount]], we can search the mount table backwards, starting with the
last entry, and compare each mount point to the leading chraracters of the absolute
path name:

<<function implementations>>=
<<find device and local path>>
@

%nouse
<<function prototypes>>=
int get_dev_and_path (char *path, short *dev, short *fs, char *localpath);
@

<<find device and local path>>=
int get_dev_and_path (char *path, short *dev, short *fs, char *localpath) {
  int i, mount_entry;
  for (i = current_mounts-1;  i >= 0;  i--) {
    // standard case: file; mount point (e.g. "/mnt/" is head of path)
    if (string_starts_with (path, mount_table[i].mountpoint)) {
      mount_entry = i;  break;
    }
    // second case: directory, path is mount point without /, e.g. "/mnt"
    if ( strlen (path) == strlen (mount_table[i].mountpoint)-1 &&
       string_starts_with (mount_table[i].mountpoint, path) ) {
      mount_entry = i;  break;
    }
  }
@ %def get_dev_and_path

Note that this loop cannot fail since the first mount entry always has
the mount point \path!/!, and every syntactically correct absolute path
begins with \path!/!. This only works because we search backwards: if we
were searching forwards, we would always find the root filesystem and
ignore all further mounts.

Once we have found the relevant entry we can split off the leading mount point
and also know the device and filesystem type:

<<find device and local path>>=
  split_mountpoint (mount_table[mount_entry].mountpoint, path, localpath);
  if (strlen (localpath) == 0) {
    // empty string
    localpath[0] = '/';  localpath[1] = 0;
  }
  *dev = mount_table[mount_entry].device;
  *fs  = mount_table[mount_entry].fstype;
  return 0;
}
@

\pagebreak

That is really all there is to do. Every call of this function (with a
syntactically correct absolute path) must be successful, however that does
not mean that the path truly exists: Other functions must check whether
the local part of the path ([[localpath]]) is available on the device---but
we know where to look now.

We need to implement the two helper functions [[string_starts_with]] 
(which is similar to [[strcmp]]) and
[[split_mountpoint]]:

%nouse
<<function prototypes>>=
int string_starts_with (char *str, char *start);
void split_mountpoint (char *mountpoint, char *path, char *localpath);
@

<<function implementations>>=
int string_starts_with (char *str, char *prefix) {
  if (strlen (prefix) > strlen (str)) { return false; }  // cannot be a sub-string
  while (*prefix != '\0') {
    if (*prefix++ != *str++) { return false; }     // found different character
  };
  return true;                                     // parsed all of prefix; match!
}
@ %def string_starts_with

The function [[split_mountpoint]] expects that the [[path]] string does in fact start with [[mountpoint]]. It does not check this property but only removes as many characters as necessary:

<<function implementations>>=
void split_mountpoint (char *mountpoint, char *path, char *localpath) {
  // input:  mountpoint, e.g. /home/
  //         path,       e.g. /home/user/file.txt
  // output: localpath,  e.g. /user/file.txt
  int len = strlen (mountpoint);
  strncpy (localpath, path+len-1, 256);
}
@ %def split_mountpoint


\subsection{Constants for Filesystems}

We declare some constants for the filesystems which are (or might be) supported by \UlixI{}: In most cases we will work with [[FS_MINIX]] since we provide a full implementation of the Minix filesystem. The device filesystem [[FS_DEV]] is also available, but [[FS_ERROR]] and als [[FS_FAT]] will only cause errors if they occur anywhere. We have included an [[FS_FAT]] constant because we use it occasionally for explaining how FAT support \emph{could} be added to \UlixI{}.

\pagebreak

<<constants>>=
#define FS_ERROR  0
#define FS_MINIX  1
#define FS_FAT    2
#define FS_DEV    3
@ %def FS_ERROR FS_MINIX FS_FAT FS_DEV

\label{definition of fs names}
<<global variables>>=
char *fs_names[] = { "ERROR", "minix", "fat", "dev" };
@ %def fs_names

A definition of devices will follow in Chapter \ref{chap:ulix:disk-i-o} on disk I/O.


\subsection{Global File Descriptors}
\label{sec:fs:global-file-descriptors}%
\index{global file descriptor}%
\index{file descriptor!global}%

We will allow all filesystem drivers to manage their own sets of file 
descriptors since they may use them as an index into a private table. Thus,
when we open several files on Minix-formatted media, file descriptors
0, 1, 2, 3, etc. will be in use. If another filesystem driver (e.\,g.\
one for FAT) exists, it may use the same numbers.

Obviously just passing those file descriptor numbers to the calling
process (or kernel function) would create chaos with some numbers 
being used twice or more often. We avoid this problem by granting each
filesystem a range of 256 numbers. For each filesystem [[filesys]] and a
filesystem-\emph{local file descriptor} [[localfd]] we calculate the \emph{global
file descriptor} via [[fd = (filesys @<< 8) + localfd]].

Open Minix files will have file descriptors in the range 256--511,
and FAT files would have descriptors in the range 512--767. When one of
the functions [[u_read]], [[u_write]] etc.\ is called, it expects a
global file descriptor as argument. By reversing the above calculation
via [[filesys = fd @>> 8; localfd = fd & 0xff;]] we can easily find out
which filesystem function we need to call and which local file descriptor
we have to provide it.

So, in order to clear the terminology, here is an overview of the three
types of file descriptors we will use:

\begin{description}
\item[Global File Descriptor:] A global file descriptor is used by the
kernel to identify a unique open file---across all processes (and the
kernel itself).
\item[Local File Descriptor:] \index{local file descriptor}\index{file descriptor!local}Each subsystem (such as the Minix or
[[/dev]] subsystem) uses its own set of file descriptors. These are also
global in that they are not associated with any specific process, but
no generic filesystem function is meant to use them.
\item[Process File Descriptor:] \index{process file descriptor}\index{file descriptor!inside a process}Each process keeps a list of its own file
descriptors (in its thread table entry). Those descriptors are mapped
to global file descriptors via those entries. They only make sense
when seen from a process' point of view.
\end{description}


\subsection{Opening a File}

\index{file!open}\index{opening a file}%
We start with an implementation of the [[u_open]] function which---in case of
a file on a Minix filesystem---will call [[mx_open]]. All filesystem related
functions on the virtual filesystem layer will have a [[u_]] prefix\marginnote{[[u_]] prefix} so that 
we can distinguish them from the user mode library functions with the same 
names (e.\,g.\ [[u_open]] and [[u_read]] inside the kernel, [[open]] and 
[[read]] in the user mode library).

The prototype for [[u_open]] almost follows the Unix standards. We do not allow 
the optional third argument of the POSIX standard, 

%nouse
<<POSIX prototypes>>=
int open (const char *pathname, int flags);
int open (const char *pathname, int flags, mode_t mode);
@ but instead expect a third parameter [[open_link]] that we will use 
to decide whether [[u_open]] shall follow symbolic links or just open 
the link file itself. This option will not be available to the 
corresponding system call since we do not want processes to manually 
handle symbolic links. 

When creating a file, \UlixI{} always sets the standard access permissions
\oct{644}; they can later be modified with [[u_chmod]]. Thus the [[u_open]]
prototype is:

%nouse
<<function prototypes>>=
int u_open (char *path, int oflag, int open_link);
@

<<constants>>=
// u_open parameter  int open_link:
#define DONT_FOLLOW_LINK 1
#define FOLLOW_LINK 0
@

Before we start with the function implementation we note that there will be
a recurring pattern in many of the following functions: Many of them start 
with converting a path argument into an absolute path via [[relpath_to_abspath]],
and then they look up the device, the filesystem type and the local path
via [[get_dev_and_path]]. They will always use variables named [[localpath]],
[[abspath]], [[device]] and [[fs]]. Thus, we create two code chunks for the
variable declarations and the function calls:

<<VFS functions: declare default variables>>=
char  localpath[256], abspath[256];
short device, fs;
@

<<VFS functions: make absolute path, get device, fs and local path>>=
if (*path != '/') 
  relpath_to_abspath (path, abspath);
else
  strncpy (abspath, path, 256);
get_dev_and_path (abspath, &device, &fs, (char*)&localpath);
@

\pagebreak

%nouse
<<function prototypes>>=
void relpath_to_abspath (const char *relpath, char *abspath);
@

<<function implementations>>=
void relpath_to_abspath (const char *relpath, char *abspath) {
  if (strlen (thread_table[current_task].cwd) > 1) {
    // combine cwd and relpath, add "/" in the middle
    strncpy (abspath, thread_table[current_task].cwd, 256);
  } else {
    strncpy (abspath, "", 256);
  }
  strncpy (abspath + strlen (abspath) + 1, relpath, 256 - strlen (abspath) - 1);
  abspath[strlen (abspath)] = '/';
  debug_printf ("absolute path: %s\n", abspath);    // REMOVE_DEBUGGING_CODE
}
@ %def relpath_to_abspath

The implementation of [[u_open]] is rather short because the VFS layer
forwards all the real work the the corresponding functions in some
subsystem (for the Minix or device filesystem):

<<function implementations>>=
int u_open (char *path, int oflag, int open_link) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>
  <<[[u_open]]: handle symlink>>
  if (scheduler_is_active) {
    <<[[u_open]]: check permissions>>              // see user/group chapter
  }
  
  int fd;
  switch (fs) {
    case FS_MINIX: 
      fd = mx_open (device, localpath, oflag);
      if (fd == -1) return -1;                 // error (opening failed)
      else          return (fs @<< 8) + fd;
    case FS_FAT:    return -1;                 // not implemented
    case FS_DEV: 
      fd = dev_open (localpath, oflag);
      if (fd == -1) return -1;                 // error (opening failed)
      else          return (fs @<< 8) + fd;
    case FS_ERROR:  return -1;                 // error (wrong FS)
    default:        return -1;                 // error (wrong FS)
  }
}
@ %def u_open

This is all there is to do: the function first looks into the mount table
in order to determine on which device the file resides and what filesystem that
device is formatted with. Since [[get_dev_and_path]] also calculates the
local absolute path within the filesystem, [[u_open]] can immediately call
[[mx_open]] or [[dev_open]] which do the real work. If we were to add support
for the Linux\index{Linux!Ext3 filesystem} Ext3\index{Ext3 filesystem}\index{filesystem!Ext3} filesystem, we would modify this code by adding a case for [[fs == FS_EXT3]]:

%nouse
<<adding Ext3 support>>=
    case FS_EXT3:   
      fd = ext3_open (device, localpath, oflag);
      if (fd == -1) return -1;                 // error (opening failed)
      else          return (fs @<< 8) + fd;
@

Note that we need not deal with special cases such as non-existing files or
files which do not have the necessary access permissions in this code: This
will be handled in the filesystem-specific functions, such as [[mx_open]].
If these return an error code (instead of a file descriptor), the result
is just forwarded to the caller of [[u_open]].

In case that the file to open is a \emph{symbolic link}\marginnote{symbolic link}, we need to follow the
link. We do this by reading the link file and using the path found there: 

<<[[u_open]]: handle symlink>>=
struct stat st;
char link[256];
u_stat (abspath, &st);
if (((st.st_mode & S_IFLNK) == S_IFLNK) && (open_link == FOLLOW_LINK)) {
  // open_ (how?), read_, then u_open (symlink)
  int link_fd = u_open (abspath, O_RDONLY, DONT_FOLLOW_LINK);  // open_ link file
  u_read (link_fd, link, 256);
  u_close (link_fd);
  return u_open (link, oflag, FOLLOW_LINK);                    // recursion
}
@

This calls [[u_open]] recursively, and our simple function does not check the recursion level. Thus a simple sequence of [[ln -s xyz xyz]] and [[cat xyz]] in some directory will force [[u_open]] into an infinite recursion (and crash the system when the kernel stack exceeds its boundary).

\enlargethispage{3mm}
To see this mechanism in operation, consider that there is a file \verb#file# and we have two symbolic links, \verb#a# and \verb#b#, where \verb#a# points to \verb#b# and \verb#b# points to \verb#file#. Trying to open \verb#a# will cause the following recursion:

%nouse
<<example for recursive [[u_open]] calls>>=
u_open ("/a", oflag, FOLLOW_LINK)              // open "a", called from somewhere
  st.st_mode == S_IFLNK                        // "a" is a symlink
  u_open ("/a", O_RDONLY, DONT_FOLLOW_LINK)    // open it read-only and...
  u_read () -> "/b"                            // read the contents: it's "b"
  u_close ("/a)                                // close "a"
  u_open ("/b", oflag, FOLLOW_LINK)            // open "b" (return its retval)
    st.st_mode == S_IFLNK                      // "b" is also a symlink
    u_open ("/b", O_RDONLY, DONT_FOLLOW_LINK)  // open it RO and...
    u_read () -> "/file"                       // read the contents: it's "file"
    u_close ("/b)                              // close b
    u_open ("/file", oflag, FOLLOW_LINK)       // open "file" (return its retval)
      st.st_mode != S_IFLNK                    // no link; return file descriptor
@


\subsection{Reading, Writing and Other Operations}

The operations on open files are even simpler because we don't have to
find out what filesystem to use: we get that information via the global
file descriptor. For example, the [[u_read]] function extracts the filesystem
type and the local file descriptor from the global file descriptor (just like
we have already described earlier); then it branches and calls one of the
[[*_read]] functions.

%nouse
<<function prototypes>>=
int u_read      (int fd, void *buf, int nbyte);
int u_write     (int fd, void *buf, int nbyte);
int u_close     (int fd);
int u_lseek     (int fd, int offset, int whence);
int u_unlink    (const char *path);
int u_link      (const char *path, const char *path2);
int u_symlink   (const char *path, const char *path2);
int u_truncate  (const char *path, int length);
int u_ftruncate (int fd, int length);
int u_readlink  (char *path, char *restrict buf, size_t bufsize);
@ [[u_read]] simply requires the following code:

\index{file!read}\index{reading from a file}%
<<function implementations>>=
int u_read (int fd, void *buf, int nbyte) {
  if (fd < -100) { <<read: standard I/O and pipes>> }
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>  
  switch (fs) {
    case FS_MINIX: return mx_read  (localfd, buf, nbyte);
    case FS_FAT:   return -1;                               // not implemented
    case FS_DEV:   return dev_read (localfd, buf, nbyte);
    case FS_ERROR: return -1;                               // error
    default:       return -1;
  }
}
@ %def u_read
with
%nouse
<<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>=
if (fd < 0) return -1;   // file not open
int fs      = fd @>> 8;
int localfd = fd & 0xff;
@ (Again we create a separate code chunk for this check and the calculation which turns a global file descriptor into a (filesystem, local file descriptor) pair since we will reuse it several times.)

Negative file descriptors with [[fd < -100]] deal with the special cases of \marginnote{standard I/O}\emph{standard input/output} and \emph{pipes}\index{pipe}\marginnote{pipe} (though pipes have not been implemented in this version); we will describe that case soon.
The code for writing is almost identical to that of [[u_read]]:

\index{file!write}\index{writing to a file}%
<<function implementations>>=
int u_write (int fd, void *buf, int nbyte) {
  if (fd < -100) { <<write: standard I/O and pipes>>  }
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>  
  switch (fs) {
    case FS_MINIX: return mx_write  (localfd, buf, nbyte);
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return dev_write (localfd, buf, nbyte);
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_write

\index{standard input}\index{standard output}\index{standard error}%
We define the file descriptors for\marginnote{[[stdin]], [[stdout]],\\ [[stderr]]} [[stdin]], [[stdout]] and [[stderr]] (as
they are valid inside processes) and kernel-internal negative values for 
the three standard I/O streams:

<<public constants>>=
#define STDIN_FILENO  0
#define STDOUT_FILENO 1
#define STDERR_FILENO 2
@ %def STDIN_FILENO STDOUT_FILENO STDERR_FILENO
<<constants>>=
#define DEV_STDIN     (-101)
#define DEV_STDOUT    (-102)
#define DEV_STDERR    (-103)
@ %def DEV_STDIN DEV_STDOUT DEV_STDERR

In order to read from standard input, we make a system call which in turn will execute [[syscall_readchar]], our function for reading from the keyboard:

<<ulix system calls>>=
#define __NR_readchar  525
@ %def __NR_readchar

\pagebreak
\index{readchar system call@\texttt{readchar} system call}%
\index{system call!readchar@\texttt{readchar}}%
<<syscall prototypes>>=
void syscall_readchar (context_t *r);
@

The implementation lets the current process block if no new character is available in the keyboard buffer:
\label{sycall:readchar}%

<<syscall functions>>=
void syscall_readchar (context_t *r) {
  char c;
  int t = thread_table[current_task].terminal;
  terminal_t *term = &terminals[t];
  
  // get character, return 0 if there is no new character in the buffer
  <<begin critical section in kernel>>  // access the thread table
  if (term->kbd_count > 0) {
    term->kbd_count--;
    term->kbd_lastread = (term->kbd_lastread+1) % SYSTEM_KBD_BUFLEN;
    c = term->kbd[term->kbd_lastread];
  } else {
    c = 0;
    if ((current_task > 1) && scheduler_is_active) {
      block (&keyboard_queue, TSTATE_WAITKEY);
      <<end critical section in kernel>>
      <<resign>>
    }
  };
  r->ebx = c;     // return value in ebx
  <<end critical section in kernel>>
};
@ %def syscall_readchar

As usual, we need to add the new system call handler to the table:

<<initialize syscalls>>=
install_syscall_handler (__NR_readchar, syscall_readchar);
@

Reading from standard output or standard error is not allowed and causes an error. Also there are no pipes in this \UlixI{} version, but the idea is to let the kernel create an internal buffer for each pipe and associate two negative file descriptors with it.

<<read: standard I/O and pipes>>=
byte c = 0;
unsigned int u;
switch (fd) {
  case DEV_STDIN: 
    for (int i = 0;  i < nbyte;  i++) {
      // read_ one character from the keyboard
      __asm__ ("\
        .intel_syntax noprefix; \
        mov eax, 525; \
        int 0x80; \
        mov %0, ebx; \
        .att_syntax"
        :
        "=r"(u)
      );
      c = (byte) u;
      ((byte*) buf)[i] = c;
    };
    break;

  case DEV_STDOUT:
  case DEV_STDERR:
    printf ("(ERROR: reading from stdout or stderr)\n");
    return (-1);         // error, cannot read_ from output

  default: return (-1);  // pipes not implemented yet
}
@

Simlilarly, writing to standard output or standard error dumps data on the terminal using the [[kputch]] function, whereas writing to standard input (or pipes) is forbidden:

<<write: standard I/O and pipes>>=
byte c;
switch (fd) {
  case DEV_STDIN: 
    printf ("(ERROR: writing to stdin)\n");
    return (-1);  // error, cannot write_ to input

  case DEV_STDOUT:
  case DEV_STDERR:
    for (int i = 0;  i < nbyte;  i++) {
      c = ((char*)buf)[i];
      if (c > 31 || c == '\n' || c == 0x08) {
        kputch (c);                    // regular characters: 32..255, \n, \b
      } else {
        kputch ('^'); kputch (c+64);   // control characters: <32
      }
    }
    
  default: return (-1);                // pipes not implemented yet
}
@

Closing an open file or performing a seek operation work like reading, in that [[u_close]] and [[u_lseek]] simply call the corresponding [[mx_*]] or [[dev_*]] functions:

\pagebreak

\index{file!close}\index{closing a file}%
\index{file!seek}\index{seeking in a file}%
<<function implementations>>=
int u_close (int fd) {
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>  
  switch (fs) {
    case FS_MINIX: return mx_close (localfd);
    case FS_FAT:   return -1;                                  // not implemented
    case FS_DEV:   return dev_close (localfd);
    case FS_ERROR: return -1;                                  // error
    default:       return -1;
  }
}

int u_lseek (int fd, int offset, int whence) {
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>  
  switch (fs) {
    case FS_MINIX: return mx_lseek (localfd, offset, whence);
    case FS_FAT:   return -1;                                  // not implemented
    case FS_DEV:   return dev_lseek (localfd, offset, whence);
    case FS_ERROR: return -1;                                  // error
    default:       return -1;
  }
}
@ %def u_close u_lseek

The implementation of [[u_unlink]] is similar to that of [[u_open]]
since in both cases we get a pathname as argument:

<<function implementations>>=
int u_unlink (const char *path) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>  
  switch (fs) {
    case FS_MINIX: return mx_unlink (device, localpath);
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return -1;  // no unlink_ support in device FS
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_unlink

On the other hand, creating a new \emph{hard link}\marginnote{hard link} with [[u_link]] requires some extra work: The function takes two pathnames, one of which is for a name that does not yet exist. It must check that both reside on the same volume because hard links cannot cross volumes. The rest is similar, but we work without the [[switch]] statement since hard links only exist on Unix filesystems (of which \UlixI{} only supports Minix):

\index{file!hard link}\index{hard link}\index{link!hard link}%
<<function implementations>>=
int u_link (const char *path, const char *path2) {
  char localpath[256],  abspath[256];  short device,  fs;
  char localpath2[256], abspath2[256]; short device2, fs2;
  char dir2[256], base2[256], localdir2[256];
  
  if (*path != '/')  relpath_to_abspath (path, abspath);       // source
  else               strncpy (abspath, path, 256);
  get_dev_and_path (abspath, &device, &fs, (char*)&localpath);
  
  if (*path2 != '/') relpath_to_abspath (path2, abspath2);     // target
  else               strncpy (abspath2, path2, 256);
  splitpath (abspath2, dir2, base2);            // get dirname
  get_dev_and_path (dir2, &device2, &fs2, (char*)&localdir2);

  if (device != device2) return -1;             // error: link across volumes
  if (fs != FS_MINIX)    return -1;             // error: not Minix

  strncpy (localpath2, localdir2, 256);         // localpath2 = localdir2
  int len = strlen(localpath2); 
  if (len == 1) len = 0;  // special case "/"
  localpath2[len] = '/';                        // localpath2 += "/"
  strncpy (localpath2 + len + 1, base2, 256);   // localpath2 += base2
  // printf ("DEBUG: u_link, fs = %d, fs2 = %d, dev = %d, "    // REMOVE_DEBUGGING_CODE
  //         "dev2 = %d,\nlocalpath = %s, localpath2 = %s\n",  // REMOVE_DEBUGGING_CODE
  //         fs, fs2, device, device2, localpath, localpath2); // REMOVE_DEBUGGING_CODE
  return mx_link (device, localpath, localpath2);
}
@ %def u_link

The [[u_symlink]] function only checks the target since it is allowed to write invalid paths (and paths to different volumes) into a symbolic link:

\index{file!soft link}\index{soft link}\index{link!soft link}%
\index{symbolic link|see {soft link}}%
<<function implementations>>=
int u_symlink (const char *path, const char *path2) {
  char localpath2[256], abspath2[256]; short device2, fs2;
  if (*path2 != '/') relpath_to_abspath (path2, abspath2);     // target
  else               strncpy (abspath2, path2, 256);
  get_dev_and_path (abspath2, &device2, &fs2, (char*)&localpath2);
  if (fs2 != FS_MINIX)  return -1;              // error: not Minix
  return mx_symlink (device2, (char*)path, localpath2);
}
@ %def u_symlink

\enlargethispage{2mm}

For truncating a file we only need to think about the the [[u_ftruncate]] variant which works on an open file; the other function can just open the file and call [[u_ftruncate]]:

\pagebreak

\index{file!truncate}\index{truncating a file}%
<<function implementations>>=
int u_truncate  (const char *path, int length) {
  printf ("DEBUG: u_truncate entered\n");  // REMOVE_DEBUGGING_CODE
  int fd = u_open ((char*)path, O_WRONLY, FOLLOW_LINK);
  int retval = u_ftruncate (fd, length);
  u_close (fd);
  return retval;
}
@ %def u_truncate

The [[u_ftruncate]] function looks like all the other [[u_*]] functions that have a file descriptor as their first argument, but we only allow the Minix filesystem:

<<function implementations>>=
int u_ftruncate (int fd, int length) {
  printf ("DEBUG: u_ftruncate (%d,%d) entered\n", fd, length);  // REMOVE_DEBUGGING_CODE
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>  
  switch (fs) {
    case FS_MINIX: return mx_ftruncate (localfd, length);
    case FS_FAT:   return -1;                                  // not implemented
    case FS_DEV:   return -1;                                  // forbidden
    case FS_ERROR: return -1;                                  // error
    default:       return -1;
  }
}
@ %def u_ftruncate

The function [[u_readlink]] reads a link file and retrieves the link target:

<<minix filesystem implementation>>=
int u_readlink (char *path, char *restrict buf, size_t bufsize) {
  struct stat st;
  u_stat (path, &st);
  if ((st.st_mode & S_IFLNK) != S_IFLNK) {
    return -1;  // error: no symlink_
  }
  int link_fd = u_open (path, O_RDONLY, DONT_FOLLOW_LINK);  // open_ the link file
  u_read (link_fd, buf, bufsize);
  u_close (link_fd);
  return 0;     // success
}
@ %def u_readlink


\subsection{Detect Terminals}

\index{terminal}%
Sometimes a process needs to find out whether it is reading from or writing to a file or one of the standard I/O streams. For that purpose it can call the user mode function [[isatty]] which returns [[true]] if the file descriptor is connected to a terminal. In case of files or pipes it returns [[false]]. In order to implement the kernel function

%nodef
<<function prototypes>>=
boolean u_isatty (int fd);
@ we simply check whether the 
% global file descriptor that is associated with the 
file descriptor is [[DEV_STDIN]], [[DEV_STDOUT]] or
[[DEV_STDERR]]:

<<function implementations>>=
boolean u_isatty (int fd) {
  return ((fd == DEV_STDIN) || (fd == DEV_STDOUT) || (fd == DEV_STDERR));
}
@


\subsection{Status}

The [[u_stat]] function fills a [[struct stat]] entry with the status information about a file which can be queried with [[mx_stat]] or [[dev_stat]]:

%nouse
<<function prototypes>>=
int u_stat (const char *path, struct stat *buf);
@

<<function implementations>>=
int u_stat (const char *path, struct stat *buf) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>
  switch (fs) {
    case FS_MINIX: return mx_stat (device, localpath, buf);
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return dev_stat (localpath, buf);
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_stat


\subsection{Directories}

We also need to handle directories: it is possible to create and remove them via the
\index{directory}%

%nouse
<<function prototypes>>=
int u_mkdir (const char *path, int mode);
int u_rmdir (const char *path);
@ functions and to read their entries via [[u_getdent]]. The [[u_mkdir]] and [[u_rmdir]] implementations are just rewrites of [[u_open]] and [[u_unlink]]:

\pagebreak

\index{directory!make}\index{directory!remove}%
<<function implementations>>=
int u_mkdir (const char *path, int mode) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>
  switch (fs) {
    case FS_MINIX: return mx_mkdir (device, localpath, mode);
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return -1;  // not allowed
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}

int u_rmdir (const char *path) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>
  switch (fs) {
    case FS_MINIX: return mx_rmdir (device, abspath, localpath);  // two path args
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return -1;  // no rmdir_ support in device FS
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_mkdir u_rmdir

For reading a directory we provide the

\index{directory!get entries}%
\index{list directory entries}%
%nouse
<<function prototypes>>=
int u_getdent (const char *path, int index, struct dir_entry *buf);
@ function which reads single entries and writes them into a [[struct dir_entry]] buffer:


<<function implementations>>=
int u_getdent (const char *path, int index, struct dir_entry *buf) {
  <<VFS functions: declare default variables>>
  <<VFS functions: make absolute path, get device, fs and local path>>
  switch (fs) {
    case FS_MINIX: return mx_getdent (device, localpath, index, buf);
    case FS_FAT:   return -1;  // not implemented
    case FS_DEV:   return dev_getdent (localpath, index, buf);
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@

\pagebreak


\section{System Calls for File Access}
\label{sec:fs:syscalls}%
\index{filesystem!system calls}%
\index{system call!filesystem access}%

We have already discussed the three types of file descriptors which are used in \UlixI{}. All the functions of the virtual filesystem layer which you have seen so far use global file descriptors which uniquely identify an open file across all processes. But this information should be hidden from individual processes---after all, operating systems are all about abstraction, and from a process' point of view only its own open files are relevant, thus a process can expect that its internal file descriptor numbers do not depend on the activities of other processes (or the kernel). Also, we want to support the Unix tradition of reserving file descriptor numbers 0, 1 and 2 for the standard I/O streams.

\begin{figure}[ht!]
%\centering
\hspace{-1mm}%
\includegraphics[width=1.22\textwidth]{pics/gfd-lfd.pdf}
\caption[Relationship of global, local and process file descriptors.]{Relationship between the various file descriptors.}
\label{fig:gfd-lfd-fd}
\end{figure}

The [[u_*]] functions in the kernel use global file descriptors
which do not recognize process affiliation. Since we do not want to
export these numbers to the processes, we must convert them
to process file descriptors.\index{process file descriptor}\index{file descriptor!inside a process}

\index{file descriptor!conversion process $\leftrightarrow$ global descriptors}%
We provide the following two functions [[gfd2pfd]] and [[pfd2gfd]]
which convert global to process and process to global file descriptors.
Figure~\ref{fig:gfd-lfd-fd} shows the relationship between process, 
local and global file descriptors.

%nouse
<<function prototypes>>=
int gfd2pfd (int gfd);
int pfd2gfd (int pfd);
@

Processes may open up to 16 files; we add a new field to the TCB which stores that many file descriptors.

<<public constants>>=
#define MAX_PFD 16   // up to 16 open_ files per process
@ %def MAX_PFD

\index{process!file descriptors}%
\tcbindex{file descriptors}%
<<more TCB entries>>=
int files[MAX_PFD];
@

If we start with a process file descriptor, the translation is simpler: we
just look it up in the process' file descriptor table.

<<function implementations>>=
int pfd2gfd (int pfd) {
  if (pfd == -1) return -1;  
  thread_id pid = thread_table[current_task].pid;
  if (pfd >= 0 && pfd < MAX_PFD)
    return thread_table[pid].files[pfd];
  else return -1;
}
@ (Note that [[thread_table[current_task].files[pfd]]] may also be [[-1]]
which is the standard value for an unused local file descriptor.)

Turning a global file descriptor into a process one is a bit more complicated: if there is no mapping (yet), we need to find a free place in the process' descriptor list [[files]]. But we start with searching for a mapping:

<<function implementations>>=
int gfd2pfd (int gfd) {
  int pfd;
  if (gfd == -1) return -1;
  thread_id pid = thread_table[current_task].pid;
  for (pfd = 0;  pfd < MAX_PFD;  pfd++) {
    if (thread_table[pid].files[pfd] == gfd)
      return pfd;
  }
  // found none, create it
  for (pfd = 0;  pfd < MAX_PFD;  pfd++) {
    if (thread_table[pid].files[pfd] == -1) {
      thread_table[pid].files[pfd] = gfd;
      return pfd;
    }
  }
  // no free entry
  return -1;  // error
}
@

We need to copy file descriptors when we create a new process: The following chunk completes the TCB initialization in the [[u_fork]] function.
\index{fork operation!duplicate file descriptors}%

<<[[u_fork]]: copy the file descriptors>>=
if (t_new->pid != t_old->pid) {
  for (int pfd = 0;  pfd < MAX_PFD;  pfd++) {
    int gfd = t_old->files[pfd];
    if (gfd >= 0)
      t_new->files[pfd] = u_reopen (gfd);  // get new gfd
      // printf ("old proc: files[%d]=%d, "          // REMOVE_DEBUGGING_CODE
      //         "new proc: files[%d]=%d\n",         // REMOVE_DEBUGGING_CODE
      //         pfd, gfd, pfd, t_new->files[pfd]);  // REMOVE_DEBUGGING_CODE
    else
      t_new->files[pfd] = gfd;             // use old gfd (stdio)
  }
}
@

The function [[u_reopen]] creates a copy of a file descriptor. We cannot simply give the newly forked process access to the same (globally visible) file descriptor because the current read/write position in the file is associated with that descriptor. If one of the two processes changes that position, the modification must not be visible in the other process. 

%nouse
<<function prototypes>>=
int u_reopen (int fd);
@

<<function implementations>>=
int u_reopen (int fd) {
  <<VFS functions: turn [[fd]] into [[(fs, localfd)]] pair or fail>>
  switch (fs) {
    case FS_MINIX: return (fs << 8) + mx_reopen (localfd);
    case FS_FAT:   return -1;                   // not implemented
    case FS_DEV:   return -1;
    case FS_ERROR: return -1;                   // error
    default:       return -1;
  }
}
@

As usual, the real work is done my [[mx_reopen]]. (There is no such function for the device filesystem.)

We can now implement the system calls:

\syscallindex{open}\syscallindex{stat}\syscallindex{close}\syscallindex{read}\syscallindex{write}\syscallindex{lseek}\syscallindex{isatty}\syscallindex{mkdir}\syscallindex{rmdir}\syscallindex{getdent}\syscallindex{truncate}\syscallindex{ftruncate}\syscallindex{link}\syscallindex{unlink}\syscallindex{symlink}\syscallindex{readlink}%
%nouse
<<syscall prototypes>>=
void syscall_open      (context_t *r);
void syscall_stat      (context_t *r);
void syscall_close     (context_t *r);
void syscall_read      (context_t *r);
void syscall_write     (context_t *r);
void syscall_lseek     (context_t *r);
void syscall_isatty    (context_t *r);
void syscall_mkdir     (context_t *r);
void syscall_rmdir     (context_t *r);
void syscall_getdent   (context_t *r);
void syscall_truncate  (context_t *r);
void syscall_ftruncate (context_t *r);
void syscall_link      (context_t *r);
void syscall_unlink    (context_t *r);
void syscall_symlink   (context_t *r);
void syscall_readlink  (context_t *r);
@

For [[syscall_getdent]] we will use the [[__NR_readdir]] syscall number but it
should be noted that [[readdir]] accesses directory entries differently (and
\UlixI{} does not implement [[readdir]]).

<<syscall functions>>=
void syscall_open (context_t *r) {
  eax_return ( gfd2pfd (u_open ((char*) r->ebx, r->ecx, 0) ) ); };

void syscall_stat (context_t *r) {
  eax_return ( u_stat ((char*) r->ebx, (struct stat*) r->ecx) ); };

void syscall_getdent (context_t *r) {
  // ebx: path, ecx: index, edx: dir_entry buffer
  eax_return ( u_getdent ((char*) r->ebx, r->ecx, (struct dir_entry*) r->edx) ); };

void syscall_close (context_t *r) {
  // ebx: fd
  int pfd = r->ebx;
  thread_id pid = thread_table[current_task].pid;
  r->eax = u_close (pfd2gfd (pfd));        // close_ (globally)  
  if (pfd >= 0 && pfd < MAX_PFD)
    thread_table[pid].files[pfd] = -1; };  // close_ (locally) 

void syscall_read (context_t *r) {
  // ebx: fd, ecx: *buf, edx: nbytes
  eax_return ( u_read (pfd2gfd (r->ebx), (byte*) r->ecx, r->edx) ); };

void syscall_write (context_t *r) {
  // ebx: fd, ecx: *buf, edx: nbytes
  eax_return ( u_write (pfd2gfd (r->ebx), (byte*) r->ecx, r->edx) ); };
void syscall_lseek (context_t *r) {
  // ebx: fd, ecx: offset, edx: whence
  eax_return ( u_lseek (pfd2gfd (r->ebx), r->ecx, r->edx) ); };
  
void syscall_isatty (context_t *r) {
  // ebx: file descriptor
  eax_return ( pfd2gfd (u_isatty (r->ebx)) ); }

void syscall_mkdir (context_t *r) {
  // ebx: name of new directory, ecx: mode
  eax_return ( u_mkdir ((char*)r->ebx, r->ecx) ); }

void syscall_rmdir (context_t *r) {
  // ebx: name of directory that we want to delete
  eax_return ( u_rmdir ((char*)r->ebx) ); }
  
void syscall_truncate  (context_t *r) {
  // ebx: filename, ecx: length
  eax_return ( u_truncate ((char*)r->ebx, r->ecx) ); }

void syscall_ftruncate (context_t *r) {
  // ebx: file descriptor, ecx: length
  eax_return ( u_ftruncate ( pfd2gfd (r->ebx), r->ecx) ); }

void syscall_link (context_t *r) {
  // ebx: original name, ecx: new name
  // eax_return ( mx_link (ROOT_DISK, (char*)r->ebx, (char*)r->ecx) );  // REMOVE_DEBUGGING_CODE 
  eax_return ( u_link ((char*)r->ebx, (char*)r->ecx) ); }

void syscall_unlink (context_t *r) {
  // ebx: pathname
  eax_return ( u_unlink ((char*)r->ebx) );
}

void syscall_symlink (context_t *r) {
  // ebx: target file name, ecx: symbolic link name
  // eax_return ( mx_symlink (ROOT_DISK, (char*)r->ebx, (char*)r->ecx) ); // REMOVE_DEBUGGING_CODE
  eax_return ( u_symlink ((char*)r->ebx, (char*)r->ecx) ); }

void syscall_readlink (context_t *r) {
  // ebx: file name
  // ecx: buffer for link target
  // edx: buffer length
  eax_return ( u_readlink ((char*)r->ebx, (char*)r->ecx, r->edx) );
}
@ %def syscall_read_sector syscall_write_sector syscall_open syscall_close syscall_read syscall_write syscall_lseek syscall_isatty syscall_mkdir syscall_rmdir syscall_truncate syscall_ftruncate syscall_link syscall_unlink syscall_symlink syscall_readlink

As a last step we create syscall table entries for the new system call handlers:

<<initialize syscalls>>=
install_syscall_handler (__NR_open,      syscall_open);
install_syscall_handler (__NR_stat,      syscall_stat);
install_syscall_handler (__NR_close,     syscall_close);
install_syscall_handler (__NR_read,      syscall_read);
install_syscall_handler (__NR_write,     syscall_write);
install_syscall_handler (__NR_lseek,     syscall_lseek);
install_syscall_handler (__NR_isatty,    syscall_isatty);
install_syscall_handler (__NR_mkdir,     syscall_mkdir);
install_syscall_handler (__NR_rmdir,     syscall_rmdir);
install_syscall_handler (__NR_readdir,   syscall_getdent);
install_syscall_handler (__NR_truncate,  syscall_truncate);
install_syscall_handler (__NR_ftruncate, syscall_ftruncate);
install_syscall_handler (__NR_link,      syscall_link);
install_syscall_handler (__NR_unlink,    syscall_unlink);
install_syscall_handler (__NR_symlink,   syscall_symlink);
install_syscall_handler (__NR_readlink,  syscall_readlink);
@

We need a system call number for [[syscall_isatty]]:

<<ulix system calls>>=
#define __NR_isatty  521
@ %def __NR_isatty

\pagebreak


\subsection{Library Functions}
\index{filesystem!library functions}%
\index{user mode library!filesystem functions}%

Here we define the user mode library functions for our collection of new system calls:

%nouse
<<ulixlib function prototypes>>=
int open       (const char *path, int oflag, ...);
int stat       (const char *path, struct stat *buf);
int close      (int fildes);
int read       (int fildes, void *buf, size_t nbyte);
int write      (int fildes, const void *buf, size_t nbyte);
int lseek      (int fildes, int offset, int whence);
boolean isatty (int fd);
int mkdir      (const char *path, int mode);
int rmdir      (const char *path);
int getdent    (const char *path, int index, struct dir_entry *buf);
int ftruncate  (int fd, int length);
int truncate   (const char *path, int length);
int link       (const char *path1, const char *path2);
int unlink     (const char *path);
int symlink    (const char *path1, const char *path2);
int readlink   (char *path, char *buf, int bufsize);
@

<<ulixlib function implementations>>=
int open (const char *path, int oflag, ...) {
  return syscall3 (__NR_open, (uint)path, oflag); }

int stat (const char *path, struct stat *buf) {
  return syscall3 (__NR_stat, (uint)path, (uint)buf); }

int close (int fildes) { return syscall2 (__NR_close, fildes); }

int read (int fd, void *buf, size_t nbyte) { 
  return syscall4 (__NR_read, fd, (uint)buf, nbyte); }

int write (int fd, const void *buf, size_t nbyte) {
  return syscall4 (__NR_write, fd, (uint)buf, nbyte); }

int lseek (int fildes, int offset, int whence) {
  return syscall4 (__NR_lseek, fildes, offset, whence); }

boolean isatty (int fd) { return syscall2 (__NR_isatty, fd); }

int mkdir (const char *path, int mode) { 
  return syscall3 (__NR_mkdir, (uint)path, mode); }

int rmdir (const char *path) {
  return syscall2 (__NR_rmdir, (uint)path); }

int getdent (const char *path, int index, struct dir_entry *buf) {
  return syscall4 (__NR_readdir, (uint)path, index, (uint)buf); }
int ftruncate (int fd, int length) { 
  return syscall3 (__NR_ftruncate, fd, length); }

int truncate (const char *path, int length) { 
  return syscall3 (__NR_truncate, (uint)path, length); }

int link (const char *path1, const char *path2) {
  return syscall3 (__NR_link, (uint) path1, (uint) path2); }

int unlink (const char *path) {
  return syscall2 (__NR_unlink, (unsigned int) path); }

int symlink (const char *path1, const char *path2) {
  return syscall3 (__NR_symlink, (uint) path1, (uint) path2); }

int readlink (char *path, char *buf, int bufsize) {
  return syscall4 (__NR_readlink, (uint)path, (uint)buf, bufsize); }
@ %def open close read write lseek getdent stat isatty mkdir rmdir ftruncate truncate link unlink symlink readlink


\subsection{Reading from Standard Input}

\index{standard input}%
The functions
%nouse
<<ulixlib function prototypes>>=
int  ureadline (char *s, int maxlength, boolean echo);
byte ureadchar ();
@ use [[read]] with the standard input file descriptor [[STDIN_FILENO]] to read one or more characters. Writing to standard output will be handled by [[ulixlib_printchar]] which just [[write]]s to the standard output (via file descriptor [[STDOUT_FILENO]]) and is implemented where we discuss the [[printf]] function.

[[ureadline]] takes three arguments: a buffer, a maximum length and an \verb#echo# flag. If the length parameter is negative then pressing [Enter] to complete the input will not cause the newline character to be displayed. If [[echo]] is not set, output will be disabled completely which is useful for password queries: The \path!/bin/login! and \path!/bin/su! programs use that feature.

\pagebreak

<<ulixlib function implementations>>=
int ureadline (char *s, int maxlength, boolean echo) {
  // if maxlength is negative, dont print \n at the end
  char print_newline = 1;
  if (maxlength < 0) {
    print_newline = 0;
    maxlength = -maxlength;
  }
  int pos=0;
  for (;;) {
    startlabel:
    if (pos < 0) { printf ("ERROR: pos < 0\n"); return; }
    byte c = 0;
    int nbytes = read (STDIN_FILENO, &c, 1);         // read one char. from stdin
    if (nbytes == 0) return -1;

    if (c == 0 || c == 27 || c > 190)                // Esc, cursor and other keys
      goto startlabel;

    if (c == 3) {                                    // Strg-C, kill command
      pos = 0; s[0] = 0;
      if (echo) printf ("\n");
      return 0;
    }

    if (c == 4 && pos == 0) {                        // Strg-D in first column
      strncpy (s, "ex" "it", 5);
      if (echo) printf ("ex" "it\n");
      return 0;
    }

    if ((c == 0x08) && (pos>0)) {                    // backspace
      pos--;
      if (echo) write (STDOUT_FILENO, "\010 \010", 3);
    } else if ( c == '\n' ) {                        // newline, end of input
      if ((print_newline == 1) && echo) write (STDOUT_FILENO, "\n", 1);
      s[pos] = '\0';
      return 0;
    } else if ( (c != 0x08) && (pos < maxlength) ) { // other character
      if (echo) write (STDOUT_FILENO, &c, 1);
      s[pos++] = c;
    };
  };
};
@ %def ureadline

\pagebreak

Since [[gets]]\marginnote{\texttt{gets}} is a traditional Unix function for reading from standard input, we provide it as a macro that uses [[ureadline]] with a maximum string length of 9999 characters. Note that using [[gets]] is deprecated since an application cannot control the length of the input which is likely to cause problems when the reserved buffer overflows due too overly long input.

<<ulixlib macro definitions>>=
#define gets(s) ((ureadline(s,9999,true)), s)
@ %def gets

The [[ureadchar]] function reads just one single character. It is used by the \path!/bin/vi!, \path!/bin/keys! and \path!/bin/hexdump! programs:

<<ulixlib function implementations>>=
byte ureadchar () {
  byte b;
  read (STDIN_FILENO, &b, 1);
  return b;
};
@ %def ureadchar


\subsection{Working Directory, Relative Paths}

\index{working directory}%
\index{filesystem!working directory}%
\index{process!working directory}%
\tcbindex{working directory}%
We want processes to have a ``current working directory'', so we add an 
entry to the thread control block structure:

%nouse
<<more TCB entries>>=
char cwd[256];
@

To query and set this value, we will need two functions [[u_getcwd]] and [[u_chdir]] which can also be accessed by user mode functions [[getcwd]] and [[chdir]] via system calls.

Now [[u_getcwd]] just copies a string, while [[chdir]] needs to check
whether the argument is a valid directory:

<<function prototypes>>=
char *u_getcwd (char *buf, int size);
int u_chdir (const char *path);
@

<<function implementations>>=
char *u_getcwd (char *buf, int size) {
  strncpy (buf, thread_table[current_task].cwd, size);
  return buf;
}

int u_chdir (const char *path) {
  char abspath[256], dir[256], base[256], localpath[256];
  if (strequal (path, "..")) {        // special case ".."
    if (strequal (thread_table[current_task].cwd, "/"))
      return 0;  // already at root directory
    // change to ..
    strncpy (abspath, thread_table[current_task].cwd, 256);
    splitpath (abspath, dir, base);
    strncpy (thread_table[current_task].cwd, dir, 256);
    return 0;
  }

  // check relative/absolute path
  if (*path != '/')  relpath_to_abspath (path, abspath);
  else               strncpy (abspath, path, 256);
  // printf ("chdir: abspath   = '%s'\n", abspath);    // REMOVE_DEBUGGING_CODE
  // get_dev_and_path (abspath, &device, &fs, (char*)&localpath);  // OLD!!    // REMOVE_DEBUGGING_CODE

  // check if abspath is directory
  struct stat st;
  u_stat (abspath, &st);
  // if (mx_file_is_directory (device, localpath)) {   // REMOVE_DEBUGGING_CODE
  if ((st.st_mode & S_IFDIR) == S_IFDIR) {
    strncpy (thread_table[current_task].cwd, abspath, 256);
    return 0;
  } else {
    return -1;  // error
  }
}
@ %def u_getcwd u_chdir

As usual, we define and register system call functions \dots

\syscallindex{getcwd}\syscallindex{chdir}%
%nouse
<<syscall prototypes>>=
void syscall_getcwd (context_t *r);
void syscall_chdir (context_t *r);
@

<<syscall functions>>=
void syscall_getcwd (context_t *r) {
  // ebx: buffer for directory
  // ecx: maximum length of path
  eax_return ( u_getcwd ((char*)r->ebx, r->ecx) );
}

void syscall_chdir (context_t *r) {
  // ebx: new directory
  eax_return ( u_chdir ((char*)r->ebx) );
}
@ %def syscall_getcwd syscall_chdir

<<initialize syscalls>>=
install_syscall_handler (__NR_getcwd, syscall_getcwd);
install_syscall_handler (__NR_chdir, syscall_chdir);
@ %
\dots and provide user mode library functions:

%nouse
<<ulixlib function prototypes>>=
char *getcwd (char *buf, int size);
int chdir (const char *path);
@

<<ulixlib function implementations>>=
char *getcwd (char *buf, int size) {
  syscall3 (__NR_getcwd, (unsigned int) buf, size);
}

int chdir (const char *path) {
  return syscall2 (__NR_chdir, (unsigned int) path);
}
@ %def getcwd chdir

\pagebreak


\section{The Minix Filesystem}
\label{sec:fs:minix-overview}%
\index{Minix!filesystem}\index{filesystem!Minix}%

We have chosen to use the Minix \cite{Tanenbaum:1987:OSD} filesystem as the native filesystem
for \UlixI{} for two reasons:

\begin{itemize}
\item While Minix has all the properties of a Unix filesystem, it is very simple.
That also means that explaining and implementing its function is fit for an
introductory book. There is no redundancy (for example, Minix does not create
backup copies of the superblock, like other Unix filesystems do), so the code
does not become complex.
\item Minix was the first filesystem that Linux\index{Linux!Minix filesystem} used, and it is still supported.
Thus, on a Linux\index{Linux!mkfs.minix@\texttt{mkfs.minix}} machine the commands \verb#mkfs.minix# and \verb#fsck.minix#\tindex{mkfs.minix}\index{fsck.minix}
are available for creating and checking Minix volumes. The last tool is
especially helpful because it allowed us to check the correctness of our
implementation: Whenever earlier revisions of the \UlixI{} code wrote wrong
data to the volume, \verb#fsck.minix# detected that.
\end{itemize}

\noindent
Conceptually, the Minix filesystem uses data structures which can also be found in all other Unix filesystems:
\vspace{-1mm}

\begin{description}
\item[Superblock:] A \emph{superblock} contains general information about the whole filesystem. For example it tells how large the volume is. In the Minix case it also lists the maximum numbers of data blocks and inodes as well as where the first data block starts (after the metadata).
\item[Inode:] For every file on the volume there is an \emph{inode} (index node) that describes the file. You can find the file size, owner and group IDs, access permissions, timestamps and some pointer to the data blocks in an inode. How these data are organized and how exactly the data blocks can be found after inspecting the inode depends on the specific filesystem.
\item[Directory:] In order to have a hierarchic filesystem, \emph{directories} are used. In all Unix filesystems a directory is a simple file that maps filenames to inode numbers. The version of the Minix filesystem that we will look at uses 32 bytes for each directory entry: 30 bytes for the file name and two bytes for a 16-bit inode number. Note again: Directories are files, too (if of a special kind), so when we create a new directory we also need a new inode that describes this directory (file). A freshly created filesystem already contains the root directory.
\item[Bitmaps:] Inodes are reserved on the volume when it is created. While it would be possible to scan the inode table for a free inode, this would take too long on larger filesystems. So there is also a \emph{bitmap} that holds a bit for each inode that indicates if it is free or not. Similarly there is a second bitmap which describes the free/used status of the data blocks.
\end{description}
\vspace{-1mm}

\enlargethispage{4mm}
We will first look at the Minix filesystem by creating one on a Linux\index{Linux!Minix filesystem}
machine and trying to understand some of its properties. For that purpose
we format a floppy image with the Minix filesystem. We create a 1440 KByte
image file with \verb#dd#:

\pagebreak

%nouse
<<create 1.4 MB disk file>>=
$ dd if=/dev/zero of=minixfs.img bs=1k count=1440
1440+0 records in
1440+0 records out
1474560 bytes (1,5 MB) copied, 0.219079 s, 6.7 MB/s
@

\noindent
and then format it with \verb#mkfs.minix#:

<<format the disk image with minix fs>>=
$ /sbin/mkfs.minix -2 minixfs.img 
480 inodes
1440 blocks
Firstdatazone=34 (34)
Zonesize=1024
Maxsize=2147483647
@

\noindent
The option \verb#-2# creates a version 2 filesystem with ``long'' filenames (up to 30 characters; the option \verb#-n 14# would enable ``short'' filenames that have only up to 14 characters). As a next step, \verb#hexdump# will show that there is not much data on a freshly formatted Minix filesystem. (We removed lines that displayed only \hex{00} bytes from the output.)

<<look at the image with hexdump>>=
$ hexdump -C minixfs.img
00000400  e0 01 00 00 01 00 01 00  22 00 00 00 ff ff ff 7f  |........".......|
00000410  78 24 01 00 a0 05 00 00  00 00 00 00 00 00 00 00  |x$..............|
00000800  03 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000830  00 00 00 00 00 00 00 00  00 00 00 00 fe ff ff ff  |................|
00000840  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00000c00  03 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000ca0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 80  |................|
00000cb0  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|
*
00001000  ed 41 02 00 e8 03 e8 03  40 00 00 00 66 89 eb 53  |.A......@...f..S|
00001010  66 89 eb 53 66 89 eb 53  22 00 00 00 00 00 00 00  |f..Sf..S".......|
00008800  01 00 2e 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00008820  01 00 2e 2e 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00008830  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00008840  00 00 2e 62 61 64 62 6c  6f 63 6b 73 00 00 00 00  |...badblocks....|
@

We cannot interpret the output without knowledge of the internal data structures; we will explain them in the next section where we present the implementation.

Next we ask \verb#fsck.minix# to display as much information as
it can. The \verb#file# command also recognizes the file type:

\begin{multicols}{2}
%nouse
<<fsck on an empty minix filesystem>>=
$ /sbin/fsck.minix -sfv minixfs.img 
Forcing filesystem check on minixfs.img
480 inodes
1440 blocks
Firstdatazone=34 (34)
Zonesize=1024
Maxsize=2147483647
Filesystem state=1
namelen=30

     1 inodes used (0%)
    35 zones used (2%)

     0 regular files
     1 directories
     0 character device files
     0 block device files
     0 links
     0 symbolic links
------
     1 files
     
$ file minixfs.img 
minixfs.img: Minix filesystem, V2, 
30 char names, 0 zones
@
\end{multicols}

Now we want to see what happens when we write a file onto that
filesystem. For that purpose we mount the image and then create
a file. We then print a new hexdump; the output only shows
the changed or new lines:

%nouse
<<write file to disk image>>=
$ sudo mount -o loop minixfs.img /mnt
$ sudo echo "Hello World" > /mnt/hello.txt
$ sudo umount /mnt
$ hexdump -C minixfs.img      # only changed lines are shown
00000800  07 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000c00  07 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00001000  ed 41 02 00 e8 03 e8 03  60 00 00 00 cf 8b eb 53  |.A......`......S|
00001010  d8 8b eb 53 d8 8b eb 53  22 00 00 00 00 00 00 00  |...S...S".......|
00001040  a4 81 01 00 e8 03 e8 03  0c 00 00 00 d8 8b eb 53  |...............S|
00001050  d8 8b eb 53 d8 8b eb 53  23 00 00 00 00 00 00 00  |...S...S#.......|
00008840  02 00 68 65 6c 6c 6f 2e  74 78 74 00 00 00 00 00  |..hello.txt.....|
00008c00  48 65 6c 6c 6f 20 57 6f  72 6c 64 0a 00 00 00 00  |Hello World.....|
$ /sbin/fsck.minix -sfv minixfs.img
[...]
     2 inodes used (0%)
    36 zones used (2%)

     1 regular files
     1 directories
[...]
@

So what happened here? First of all, [[fsck.minix]] tells us that one more inode and one more \emph{zone}\marginnote{zone} are used and that we have one regular file. Zones are blocks (of size 1~KByte); the original Minix filesystem implementation (on Minix) allows zones to have a larger size, but the Linux\index{Linux!mkfs.minix@\texttt{mkfs.minix}}\tindex{mkfs.minix} [[mkfs.minix]] tool cannot create such volumes. So from now on, whenever you read ``zone'', think ``block''.

As you can see, the filename \verb#hello.txt# and the file contents \verb#Hello World# show up in the new hexdump, and some of the other locations have new values, for example at addresses \hex{800} and \hex{c00} the bytes have changed from \hex{03} to \hex{07}. In binary these numbers are \bin{00000011} and \bin{00000111}: One bit was flipped from 0 to 1 in both locations. We will soon see that these newly set bits refer to a new inode and a new zone---which makes sense since we created a new file which is so small that it fits in one block.

We perform another test (with a freshly [[dd]]'ed and [[mkfs.minix]]-formatted filesystem) and populate it with more than one file:

\begin{itemize}
\item We copy the file [[testfile1.txt]] (6144 bytes, hex.: 0x1800, exactly six blocks) onto the filesystem. 
\item With [[sed -e 's/file1/file2' < testfile1.txt > testfile2.txt]] we create a slightly modified copy ([[testfile2.txt]]), 
\item and then use [[ln]] to create a hard link ([[Hardlink.txt]]) 
\item and [[ln -s]] to create a symbolic link [[Symlink.txt]] (of [[testfile1.txt]]).
\end{itemize}

\noindent
When listing the filesystem's root directory with [[ls]], we get:

\begin{Verbatim}
$ ls -il
2 -rw-r--r-- 2 root root 6144 2014-06-04 23:32 Hardlink.txt
4 lrwxrwxrwx 1 root root   14 2014-06-04 23:33 Symlink.txt -> testfile1.txt
2 -rw-r--r-- 2 root root 6144 2014-06-04 23:32 testfile1.txt
3 -rw-r--r-- 1 root root 6144 2014-06-04 23:32 testfile2.txt
$ ls -ild /mnt
1 drwxr-xr-x 2 root root  192 2012-06-04 23:33 /mnt
\end{Verbatim}

Every inode has an internal number.
The output shows that the inodes with numbers 1--4 are in use (see first column of the [[ls]] output). Looking at the image again with [[hexdump]] would reveal the root directory's table of contents and the contents of the two files.

The following blocks are in use:

\begin{itemize}
\item The root directory [[/]] uses block 34.
\item The file [[testfile1.txt]] uses blocks 35--40.
\item The file [[testfile2.txt]] uses blocks 41--46.
\item The symbolic link [[Symlink.txt]] uses block 47. (Symbolic links need data blocks as well!)
\item No further blocks are in use, the hard link is just a further entry in the root directory.
\end{itemize}

The \emph{inode bitmap}\marginnote{inode bitmap} starts at position \hex{800} in the image file and has the following contents which we display with our [[bindump]] tool (see p.~\pageref{tools:bindump}) that works like \verb#hexdump# but displays bytes as binary numbers:

{\small
\begin{Verbatim}
# bindump -r < minixfs.img
[...]
00000800  11111000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000808  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000810  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{Verbatim}
}

Those five ones represent inode numbers 0--4---however, there is no inode 0. This is what the \emph{zone bitmap}\marginnote{zone bitmap} (that starts at offset \hex{c00} in the image) looks like:

\pagebreak

{\small
\begin{Verbatim}
# bindump -r < minixfs.img
[...]
00000c00  11111111 11111110 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c08  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c10  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{Verbatim}
}

The 15 set bits refer to block numbers 33--47. Block 33 is used by the inodes and is not a data block! So this represents 14 used data blocks (which fits what we told you above: The 14 blocks 34--46 are in use.)

In comparison, when looking at a freshly created (empty) Minix filesystem (with no files and an empty root directory) the inode and zone bitmaps look like this:

{\small
\begin{Verbatim}
# bindump -r < minix-empty.img
[...]
00000800  11000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000808  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
00000c00  11000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
00000c08  00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000  ........
[...]
\end{Verbatim}
}

Two inodes (with numbers 0, 1) and two blocks (numbers 33, 34) are marked as used.
Inode 0 does not exit, and inode 1 stores information about the root directory.
A directory is never empty, since it always contains [[.]] and [[..]] entries.

It is now time to properly introduce the data structures that Minix filesystems use; they will shed light on the hexdump we've shown earlier.


\section[The \UlixI{} Implementation of the Minix Filesystem]{The \UlixI{} Implementation of the\\ Minix Filesystem}
\label{sec:minix-implementation}
\index{Ulix!implementation of the Minix filesystem}%
\index{Minix!filesystem!implementation in Ulix}%
\index{filesystem!Minix!implementation in Ulix}%

There are five variants of the Minix filesystem which differ in the sizes of inodes and block numbers (leading to different maximum file sizes) and the maximum length of filenames (14, 30 or 60). For any Minix filesystem image you can find out its version. Our implementation allows access to version 2 of the filesystem with a filename length of up to 30 characters. The Linux\index{Linux!mkfs.minix@\texttt{mkfs.minix}}\tindex{mkfs.minix} tool [[mkfs.minix]] will create a Minix version 1 filesystem (with 30-character filenames and a theoretical maximum file size of 256 MByte) by default, but this can be changed by supplying the options [[-v]] or [[-2]] (for version 2 with an approximate maximum filesize of 2~GByte) or [[-3]] (for version 3). For version 1 and 2, the filename length can be set to 14 with the [[-n 14]] option which reduces the size of a directory entry from 32 bytes to 16 bytes, whereas version 3 only supports a filename length of 60 characters. This leads to the characteristics shown in Table~\ref{table:minix-versions}.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Minix version} & \textbf{inode number} & \textbf{directory} & \textbf{entries} \\
& \textbf{size} & \textbf{entry size} & \textbf{per block}\\
\hline
Version 1 (filenames: 14) & 2 bytes & 16 bytes & 64 \\
Version 1 (filenames: 30) & 2 bytes & 32 bytes & 32 \\
Version 2 (filenames: 14) & 2 bytes & 16 bytes & 64 \\
Version 2 (filenames: 30) & 2 bytes & 32 bytes & 32 \\
Version 3 (filenames: 60) & 4 bytes & 64 bytes & 16 \\
\hline
\end{tabular}
\caption{Characteristics of the Minix filesystem versions.}
\label{table:minix-versions}
\end{table}

The standard zone size of a Minix filesystem is 1 KByte (1024 bytes). It is possible to increase this size to $1024 \times 2^n$ bytes (for some $n$), but not with the Linux\index{Linux!mkfs.minix@\texttt{mkfs.minix}}\tindex{mkfs.minix} tool [[mkfs.minix]]. The first block in the filesystem contains the boot sector (which we will ignore), the second block is the \emph{superblock}\marginnote{superblock} which contains the setup information of a specific filesystem, including two magic bytes which tell the filesystem version number.

Since the Minix filesystem is the standard filesystem for \UlixI{}, we will always work with KByte-sized blocks---even in functions that work on a lower level. We define:

<<constants>>=
#define BLOCK_SIZE 1024
@ %def BLOCK_SIZE


\subsection{The Minix Superblock}

\index{superblock}%
Every Unix filesystem has a superblock: that is a block which stores global information about a specific volume, and it must always be visited upon first interaction with a volume. It is created when the volume is formatted. In the case of Minix its contents are immutable; they remain the same over the lifetime of that volume.

We start our Minix filesystem implementation with a look at the superblock. All functions will appear inside the [[<<minix filesystem implementation>>]] code chunk:

<<function implementations>>=
<<minix filesystem implementation>>
@

The superblock (i.\,e., the absolute bytes 1024--2047 of the image file) contains only the following few entries, with the rest of the block being ignored:

<<type definitions>>=
struct minix_superblock { 
  uint16_t s_ninodes;        uint16_t s_nzones; 
  uint16_t s_imap_blocks;    uint16_t s_zmap_blocks; 
  uint16_t s_firstdatazone;  uint16_t s_log_zone_size; 
  uint32_t s_max_size;       uint16_t s_magic; 
  uint16_t s_state;          uint32_t s_zones;
};
@ %def minix_superblock

The [[uint16_t]] and [[uint32_t]] types are defined in \path!/usr/include/stdint.h! (on a Linux system). They are 16 bit and 32 bit wide unsigned integers, respectively. Thus, the superblock only uses 24 bytes.

When you copy the superblock into a [[struct minix_superblock]] variable, you can check (or print) the values; an analysis of these values is a first step towards properly accessing the filesystem. The [[s_magic]] field tells what version of the Minix filesystem was used when the medium was formatted. There are five possible cases:

\begin{itemize}
  \item Minix v1 (14 characters per filename): 0x137F
  \item Minix v1 (30 characters per filename): 0x138F
  \item Minix v2 (14 characters per filename): 0x2468
  \item Minix v2 (30 characters per filename): 0x2478
  \item Minix v3 (60 characters per filename): 0x4D5A (but stored elsewhere since the v3 superblock has a different layout)
\end{itemize}

Without checking the version it is impossible to access the filesystem since the versions differ in size and content of the inodes and the directory entries. A version 1 superblock stores the number of blocks in the [[s_nzones]] entry, whereas a version 2 superblock uses the [[s_zones]] entry. The unused value is set to 0.

\begin{figure}[t!]
%\centering
\hspace{-1mm}% for right page placement
%\hspace{-0.235\textwidth}\hspace{2mm}% for left page placement
% trim: left bottom right top
\includegraphics[width=1.22\textwidth,trim=0 0 60mm 0,clip]{pics/minix-fs-structure.pdf}
\caption[\hgepolylot{Layout of a Minix-formatted volume.}]{A Minix filesystem consists of boot block, superblock, inode and zone bitmaps, an inode table and the data blocks.}
\label{fig:minix-fs-structure}
\end{figure}

As mentioned before, instead of blocks, Minix uses ``zones''\marginnote{zone}\index{zone} as the smallest allocatable unit. Typically a zone contains just one block, but theoretically a zone may consist of a collection of blocks if [[s_log_zone_size]] is non-zero; the following formula expresses the relationship between zone size and block size:

\[
\text{zone size} = \text{block size} \times 2^{\text{\large[[s_log_zone_size]]}}
\]
(With a default setting of [[s_log_zone_size = 0]] that formula reads: zone size = block size, since $2^0=1$.) In our implementation we only support the case where block size = zone size = 1024, and so we will often use the terms \emph{zone} and \emph{block} interchangeably. Some filesystems use the name \emph{cluster}\marginnote{cluster} to discuss smallest allocatable units, thus a zone is also a cluster.

The [[s_imap_blocks]] and [[s_zmap_blocks]] fields note how many blocks are reserved for the inode bitmap and the zone bitmap. Those bitmaps store a single bit for each inode or data block, respectively, and the bits show whether an inode/a data block is free (0) or occupied (1). [[s_ninodes]] is the number of inodes from which we can calculate the size of the inode table.

The inode bitmap\index{bitmap!inode bitmap}\index{inode bitmap} and the zone bitmap\index{bitmap!zone bitmap}\index{zone bitmap} follow directly after the superblock (see Figure~\ref{fig:minix-fs-structure}). After that the filesystem contains the inode table\index{inode table} and finally the data blocks\index{data block}.

The zone bitmap starts with a [[1]] bit (which does not represent any zone); the second bit (bit 1) refers to the first data zone that contains (the start of) the filesystem's root directory. Blocks before the data blocks area are not available for data storage, thus they are not represented in the zone bitmap.

An inode of a Minix (version 2) filesystem has the following form:

<<type definitions>>=
struct minix2_inode { <<external minix2 inode>> };
@ %def minix2_inode

<<external minix2 inode>>=
  uint16_t i_mode;           uint16_t i_nlinks;
  uint16_t i_uid;            uint16_t i_gid;
  uint32_t i_size;           uint32_t i_atime;
  uint32_t i_mtime;          uint32_t i_ctime;
  uint32_t i_zone[10];
@

We're placing the [[minix2_inode]] entries in a separate code chunk since we will later define another inode data structure for the in-memory management of open files; there we will also need these fields.

Thus, we can calculate the size of an inode: it uses [[sizeof(struct minix2_inode)]] $= 24 + 4 \times 10 = 64$ bytes, which lets $1024/64 = 16$ inodes fit inside one inode table block. When we look at a 1.44 MByte floppy disk that was formatted with the Minix version 2 filesystem (using [[mkfs.minix -v]]), we find that the superblock contains the following values:

<<example minix super block>>=
s_ninodes:       480
s_nzones:        0
s_imap_blocks:   1
s_zmap_blocks:   1
s_firstdatazone: 34
s_log_zone_size: 0
s_max_size:      2147483647
s_magic:         9336
s_state:         1
s_zones:         1440
@ That tells us:
\begin{itemize}
\item There are 480 inodes. With 16 inodes per block the inode table requires $480/16 = 30$ blocks.
\item The inode bitmap consists of only 480 bits ($= 60$ bytes) and fits in one block, with the rest of the block remaining unused. During filesystem creation the unused bits are filled with [[1]]s.
\item 1440 blocks require 1440 bits ($= 180$ bytes) for the zone bitmap which (again) fit in one block. This bitmap also fills the unused bits with [[1]]s.
\end{itemize}
This leads to the layout shown in Table~\ref{table:minix-floppy}.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Blocks} & \textbf{Usage} & \textbf{Absolute Bytes} & \textbf{Absolute Bytes (hex)} \\
\hline
0 & unused (boot sector) & 0--1023 & \hexrange{0000}{03ff} \\
\hline
1 & superblock & 1024--2047 & \hexrange{0400}{07ff}\\
\hline
2 & inode bitmap & 2048--3071 & \hexrange{0800}{0bff} \\
\hline
3 & zone bitmap & 3072--4095 & \hexrange{0c00}{0fff} \\
\hline
4--33 & inode table (30 blocks) & 4096--34815 & \hexrange{1000}{87ff} \\
\hline
34--1439 & data blocks (zones) & 34816--\dots & \hex{8800}\,--\dots\\
\hline
\end{tabular}
\caption[Layout of a Minix-formatted 1.44 MB floppy disk.]{The layout of a Minix version 2 floppy disk formatted with [[mkfs.minix -v]].}
\label{table:minix-floppy}
\end{table}

From calculating the sizes of the bitmaps and the inode table we know that the first data block is block 34, but this information is also stored (redundantly) in the superblock's [[s_firstdatazone]] field.

We provide a function which extracts specific values from
the superblock, e.\,g, the number of inodes. Since we do not want
to write several similar functions we combine this in one function called
[[mx_query_superblock]] that expects a device identifier and a constant
which refers to some specific property:

%nouse
<<function prototypes>>=
int mx_query_superblock (int device, char index);
@

<<minix filesystem implementation>>=
int mx_query_superblock (int device, char index) {
  byte block[1024];
  struct minix_superblock *sblock;
  readblock (device, 1, (byte*)block);                    // superblock = block 1
  sblock = (struct minix_superblock*) &block;
  switch (index) {
    case MX_SB_NINODES:       return sblock->s_ninodes;
    case MX_SB_NZONES:        return sblock->s_nzones;
    case MX_SB_IMAP_BLOCKS:   return sblock->s_imap_blocks;
    case MX_SB_ZMAP_BLOCKS:   return sblock->s_zmap_blocks;
    case MX_SB_FIRSTDATAZONE: return sblock->s_firstdatazone;
    case MX_SB_LOG_ZONE_SIZE: return sblock->s_log_zone_size;
    case MX_SB_MAX_SIZE:      return sblock->s_max_size;
    case MX_SB_MAGIC:         return sblock->s_magic;
    case MX_SB_STATE:         return sblock->s_state;
    case MX_SB_ZONES:         return sblock->s_zones;
    default:                  return -1;  // error
  }
}
@ %def mx_query_superblock

These constants can be declared as follows:

<<constants>>=
enum { MX_SB_NINODES, MX_SB_NZONES, MX_SB_IMAP_BLOCKS, MX_SB_ZMAP_BLOCKS,
       MX_SB_FIRSTDATAZONE, MX_SB_LOG_ZONE_SIZE, MX_SB_MAX_SIZE, 
       MX_SB_MAGIC, MX_SB_STATE, MX_SB_ZONES };
@


\subsection{Zone and Inode Bitmaps}

\begin{goingwhere}%
Now that we know how to access the superblock, our next task is to deal with the zone and inode bitmaps properly. This requires some fiddling to extract or modify single bits of a byte.
\end{goingwhere}

\noindent
We need ways to access single bits in the inode and zone bitmaps\index{inode bitmap}\index{zone bitmap}\index{bitmap!inode bitmap}\index{bitmap!zone bitmap}. Reading is simple, because we only need to find the right byte and then perform a bit-shift operation, followed by a modulo operation to isolate a specific bit.

Let's start with the inode bitmap: One block stores 1024 bytes = 8192 bits, and the inode bitmap begins in block 2. Thus if [[i]] is the number of the bit we want to read, we must read in block [[2 + i/8192]]. Inside that block we need to read byte number [[(i%8192) / 8]].

<<minix filesystem implementation>>=
byte mx_get_imap_bit (int device, int i) {
  byte block[1024];
  byte thebyte;
  readblock (device, 2 + i/8192, (byte*)&block);
  thebyte = block[(i%8192)/8];
  return (thebyte >> (i%8)) % 2;
};
@ %def mx_get_imap_bit

For the zone map, we need to consider that the inode map (which is
located just before it) may be larger than one block (if we have
more than 8192 inodes). We can query the superblock to find out
how many blocks are used.

Again, the zone map may be larger than one block, so we have to
find out which block we need to read via a similar calculation.

\pagebreak

<<minix filesystem implementation>>=
byte mx_get_zmap_bit (int device, int i) {
  byte block[1024];
  byte thebyte;
  unsigned int zmap_start = 2 + mx_query_superblock (device, MX_SB_IMAP_BLOCKS);
  readblock (device, zmap_start + i/8192, (byte*)&block);
  thebyte = block[(i%8192)/8];
  return (thebyte >> (i%8)) % 2;
};
@ %def mx_get_zmap_bit
In order to fetch the bit number $i$ of an integer number $n$ we use the formula [[(n >> i) % 2]]
which performs a right shift (by $i$ positions) and then cuts out the lowest bit with [[% 2]].

We also need to set and clear individual bits. Since the code for
accessing and changing a bit is almost identical for setting and
clearing, we write two functions [[mx_set_clear_*]] which can both set
and clear; they are called by the four [[mx_set_*]] and [[mx_clear_*]] functions
with appropriate arguments:

<<minix filesystem implementation>>=
void mx_set_clear_imap_bit (int device, int i, int value) {
  byte block[1024];
  byte thebyte;
  readblock (device, 2 + i/8192, (byte*)&block);
  <<set bit [[i]] from block [[block]] to [[value]]>>
  writeblock (device, 2 + i/8192, (byte*)&block);  
};

void mx_set_clear_zmap_bit (int device, int i, int value) {
  byte block[1024];
  byte thebyte;
  unsigned int zmap_start = 2 + mx_query_superblock (device, MX_SB_IMAP_BLOCKS);
  readblock (device, zmap_start + i/8192, (byte*)&block);
  <<set bit [[i]] from block [[block]] to [[value]]>>
  writeblock (device, zmap_start + i/8192, (byte*)&block);  
};
@ %def mx_set_clear_imap_bit mx_set_clear_zmap_bit
where setting the bit from a block looks like this in both cases:

<<set bit [[i]] from block [[block]] to [[value]]>>=
  thebyte = block[(i%8192)/8];
  if (value==0) {
    thebyte = thebyte & ~(1<<(i%8));            // Clear bit
  } else {
    thebyte = thebyte | 1<<(i%8);               // Set bit
  }; 
  block[(i%8192)/8] = thebyte;
@

\noindent
If the shift ([[<<]]), modulo ([[%]]), bitwise ``and'' ([[&]]), bitwise ``or'' ([[|]]) and bitwise negation ([[~]]) operations seem like magic to you, consider the following example calculations:

\begin{itemize}
\item For clearing bit 3 of \bin{00101100}:
\begin{Verbatim}
byte                = 00101100
1@<<3                = 00001000
~(1@<<3)             = 11110111
00101100 & 11110111 = 00100100
\end{Verbatim}
\item For setting bit 3 of \bin{00100100}:
\begin{Verbatim}
byte                = 00100100
1@<<3                = 00001000
00100100 | 00001000 = 00101100
\end{Verbatim}
\end{itemize}

\noindent
This should explain setting and clearing a bit in a single byte well enough. The extra code which reads and writes [[block[(i%8192)/8]]] is necessary because we do not deal with a single byte but an array of such bytes.

Now the [[mx_set_*]] and [[mx_clear_*]] functions simply provide the right value (0 or 1) to the more general [[mx_set_clear_*]] function:

<<minix filesystem implementation>>=
void mx_set_imap_bit (int device, int i)   { mx_set_clear_imap_bit (device, i, 1); };
void mx_clear_imap_bit (int device, int i) { mx_set_clear_imap_bit (device, i, 0); };
void mx_set_zmap_bit (int device, int i)   { mx_set_clear_zmap_bit (device, i, 1); };
void mx_clear_zmap_bit (int device, int i) { mx_set_clear_zmap_bit (device, i, 0); };
@ %def mx_set_imap_bit mx_clear_imap_bit mx_set_zmap_bit mx_clear_zmap_bit

Note: An optimized implementation will not do this calculation every single time, instead when mounting the filesystem, we should copy the superblock to memory and also memorize where the zone bitmap starts. Early versions of \UlixI{} suffered from very slow disk access because reading blocks was not buffered---this led to actually reading the superblock from disk whenever we wanted to query the zone bitmap. With buffered read operations this is no longer a problem but still highly inefficient. It is, however, the simplest implementation and thus easy to grasp. Yet, you will see on the next pages that we did not stick with it because a slightly optimized version improved performance a lot.

Requesting a free inode or a free block means searching the corresponding bitmap for a zero bit. We start with the simple implementation of two [[mx_request_inode()]] and [[mx_request_block()]] functions which just loop over the whole bitmaps and check the bits with [[mx_get_*_bit]]. If all inodes or blocks are in use, these functions return [[-1]].

Note that (as described above) the zone bitmap does not start with an entry for block 0, but with a fixed [[1]] entry, followed by the bit that describes the first data zone. In order to query the state of data zone [[n]] we need to call \verb#mx_get_zmap_bit (device, n-s_firstdatazone# \verb#+1)#. If this is unclear, go back to the example filesystem where [[s_firstdatazone]] is 34, then evaluate the expression for [[n=34]].

%nouse
<<old minix filesystem implementation>>=
int mx_request_inode (int device) {
  int no_inodes = mx_query_superblock (device, MX_SB_NINODES);  // floppy: 480  
  for (int i = 0;  i < no_inodes;  i++) {
    if (mx_get_imap_bit (device, i) == 0) {
      // found a free inode
      mx_set_imap_bit (device, i);   // mark as used
      return i;
    }
  }
  return -1;                         // found nothing
};

int mx_request_block (int device) {
  int no_zones   = mx_query_superblock (device, MX_SB_ZONES);   // floppy: 1440
  int first_data = mx_query_superblock (device, MX_SB_FIRSTDATAZONE);
  for (int i = 0;  i < no_zones - first_data - 2;  i++) {
    if (mx_get_zmap_bit (device, i) == 0) {
      mx_set_zmap_bit (device, i);   // mark as used
      return i + first_data - 1;     // floppy example: i+33
    }
  }
  return -1;                         // found nothing
};
@

While the above implementations of [[mx_request_inode]] and [[mx_request_block]] are correct, they are also highly inefficient. Thus, we will provide a second implementation which has a better performance. Normally, we do not focus on performance issues, but these functions are very slow which makes writing a new file unbearable.

We start with a helper function

%nouse
<<function prototypes>>=
int findZeroBitAndSet (byte *block, int maxindex);
@ which finds the first [[0]] bit in a block, changes it to [[1]] and returns its (bit) position

<<minix filesystem implementation>>=
int findZeroBitAndSet (byte *block, int maxindex) {
  int i, j;
  byte b;
  for (i = 0;  i < 1024;  i++) {
    b = block[i];
    if (b != 0xFF) {
      // at least one bit in this byte is 0, find the first one
      for (j = 0;  j < 8;  j++) {
        if ( ((b >> j) % 2 == 0)       // bit is 0
             && (i*8 + j < maxindex) ) // bit position is ok
        {
          block[i] = b | (1 << j);     // set bit
          return i*8 + j;
        }
      }
    }
  }
  return -1;   // not found
}
@ %def findZeroBitAndSet
We need to provide a [[maxindex]] argument since the last block of the bitmap may not always be fully used. In the floppy example from above, only 480 bits of the inode bitmap and only less than 1440 bits of the inode bitmap have to be considered.

The implementations of [[mx_request_inode]] and [[mx_request_block]] that we actually use start with manually reading the superblock (since they need to access several of its entries). The optimization is reached via checking a whole block for a [[0]] bit with the helper function:

<<minix filesystem implementation>>=
int mx_request_inode (int device) {
  byte block[1024];
  struct minix_superblock *sblock;
  readblock (device, 1, (byte*)block);               // superblock = block 1
  sblock = (struct minix_superblock*) &block;

  int no_inodes  = sblock->s_ninodes;                // floppy: 480  
  int imap_start = 2;

  int i, index;
  for (i = 0;  i < sblock->s_imap_blocks;  i++) {    // all IMAP blocks
    readblock (device, imap_start + i, (byte*)&block);
    index = findZeroBitAndSet ((byte*)&block, no_inodes);
    if (index != -1) {                               // found one!
      writeblock (device, imap_start + i, (byte*)&block);
      return i*8192 + index;
    }
  }
  return -1;                                         // found nothing
};

int mx_request_block (int device) {
  byte block[1024];
  struct minix_superblock *sblock;
  readblock (device, 1, (byte*)block);               // superblock = block 1
  sblock = (struct minix_superblock*) &block;

  int no_zones    = sblock->s_zones;                 // floppy: 1440
  int zmap_start  = 2 + sblock->s_imap_blocks;
  int zmap_blocks = sblock->s_zmap_blocks;
  int data_start  = sblock->s_firstdatazone;
  int i, index;
  for (i = 0;  i < zmap_blocks;  i++) {              // all ZMAP blocks
    readblock (device, zmap_start + i, (byte*)&block);
    index = findZeroBitAndSet ((byte*)&block, no_zones);
    if (index != -1) {                               // found one!
      writeblock (device, zmap_start + i, (byte*)&block);
      return i*8192 + index + data_start - 1;        // convert to zone number
    }
  }
  return -1;                                         // found nothing
};
@ %def mx_request_inode mx_request_block
Note that [[mx_request_inode]] simply returns the bit position of a free entry. On the other hand, [[mx_request_block]] returns a block number which is \emph{not} identical to the bit position since the zone bitmap holds no bits for the early blocks in the filesystem.


\subsection{Reading and Writing Inodes}

\begin{goingwhere}%
We're now able to query the superblock and read and write the two bitmaps. Our next goal is to create (empty) files. Since empty files use no data blocks, this requires being able to read and write inodes.
\end{goingwhere}

\noindent
Creating a new (empty) file consists of the following steps:

\begin{enumerate}
\item Reserve an inode with [[mx_request_inode]].
\item Write the inode.
\item Create an entry in the file's directory, i.\,e., create the (filename $\rightarrow$ inode number) mapping.
\end{enumerate}

\noindent
Before we start, remember how \emph{pointer arithmetic}\marginnote{pointer\\ arithmetic} works; we will sometimes use [[memcpy]] to move data from a block around. If that block is declared as [[char block[1024];]] and you want to write a 32 byte chunk to position 512, then the code

%nouse
<<pointer arithmetic test 1>>=
offset = 512; size = 32;
memcpy (&block + offset, &data, size);
@ will fail. On the other hand, if the block was declared via [[char *block;]] then the similar code

\enlargethispage{5mm}
%nouse
<<pointer arithmetic test 2>>=
offset = 512; size = 32;
memcpy (block + offset, &data, size);
@ works as expected. The following example program [[offset-test.c]] shows the difference:

\pagebreak

%nouse
<<offset-test.c>>=
#include <stdio.h>
int main () {
  char block[1024]; char *block2=(char*)&block; char data[]="Test";
  int size = sizeof (data); int offset = 512; long diff;

  printf ("&block:          %p \n", &block);
  printf ("&block + offset: %p \n", &block + offset);
  diff = (long)(&block+offset)-(long)&block;
  printf ("difference:      %ld \n", diff);
  
  printf ("block2:          %p \n", block2);
  printf ("block2 + offset: %p \n", block2 + offset);
  diff = (long)(block2+offset)-(long)block2;
  printf ("difference:      %ld \n", diff);
};
@ generates the following output:

\begin{Verbatim}
$ ./offset-test 
&block:          0x7ffff31802b0 
&block + offset: 0x7ffff32002b0 
difference:      524288                  // that is 512 x 1024 !
block2:          0x7ffff31802b0 
block2 + offset: 0x7ffff31804b0 
difference:      512                     // that's what we want
\end{Verbatim}

In the first attempt, [[&block]] creates a pointer to [[block]] that ``knows'' the size of [[block]] (which is a whole kilobyte). When adding the offset (512) the program actually adds that offset multiplied with the size (resulting in a 512~KByte offset). So in order to perform correct pointer arithmetic, it is necessary to first perform a cast to a [[(char*)]] pointer; otherwise you would access wrong memory areas (see also Appendix~\ref{appendix:c:pointerarithmetic}).

We continue the implementation with two functions
%nouse
<<function prototypes>>=
int mx_read_inode  (int device, int i, struct minix2_inode *inodeptr);
int mx_write_inode (int device, int i, struct minix2_inode *inodeptr);
@ which copy an inode from disk to memory or vice versa. They shall return 0 when an error occurs and the inode number [[i]] otherwise---this lets us write code of the form
[[if (!mx_read_inode(...) { /* error */ }]]. Trying to read an unused inode shall also generate an error.

\enlargethispage{5mm}
Since reading and writing an inode are similar tasks we write a combined function
%nouse
<<function prototypes>>=
int mx_read_write_inode (int device, int i, struct minix2_inode *inodeptr, 
                         int wr_flag);
@ which can do both; the flag [[wr_flag]] decides about the direction.

\pagebreak

<<minix filesystem implementation>>=
int mx_read_write_inode (int device, int i, struct minix2_inode *inodeptr, 
                         int wr_flag) {
  debug_printf ("mx_read_write_inode: entered\n"); // REMOVE_DEBUGGING_CODE
                                                   // REMOVE_DEBUGGING_CODE
  i--;         // first inode is No. 1, but has position 0 in table
  if ((i < 0) || (i >= mx_query_superblock (device, MX_SB_NINODES))) {
    return 0;  // illegal inode number
  }
  if (mx_get_imap_bit (device, i+1) == 0) {
    debug_printf ("DEBUG: mx_get_imap_bit(%d) = %d "  // REMOVE_DEBUGGING_CODE
                  "in mx_read_inode\n", i+1,          // REMOVE_DEBUGGING_CODE
                  mx_get_imap_bit (device, i));       // REMOVE_DEBUGGING_CODE
    return 0;  // attempt to read_ unused inode; forbidden
  }
  debug_printf ("mx_read_write_inode: after "      // REMOVE_DEBUGGING_CODE
                "mx_get_imap_bit()\n");            // REMOVE_DEBUGGING_CODE  
  const int inodesize      = sizeof (struct minix2_inode);
  const int inodesperblock = BLOCK_SIZE / inodesize;  
  int       blockno        = i / inodesperblock + 2 
                             + mx_query_superblock (device, MX_SB_IMAP_BLOCKS)
                             + mx_query_superblock (device, MX_SB_ZMAP_BLOCKS);
  int       blockoffset    = i % inodesperblock;  
  // we need to read_ the block, even if this is a write_ operation
  byte block[1024];
  readblock (device, blockno, (byte*)&block);
  byte *addr = (byte*)&block;      // add offset, beware of pointer arithmetic
  addr += blockoffset * inodesize;
  if (!wr_flag) {                  // read_ or write_?
    memcpy (inodeptr, addr, inodesize);
  } else {
    memcpy (addr, inodeptr, inodesize);
    writeblock (device, blockno, (byte*)&block);  // write_ whole block to disk
  };
  return (i+1);                    // return original number
};
@ %def mx_read_write_inode
The only statement that needs some explanation is the calculation of [[blockno]] which queries the superblock twice to find out about the layout of the filesystem; the first block of the inode table is placed behind the zone bitmap. Block 2 is where the inode bitmap starts, and adding [[mx_query_superblock (device, MX_SB_IMAP_BLOCKS)]] and [[mx_query_superblock (device, MX_SB_ZMAP_BLOCKS)]] brings us right behind the zone bitmap. We need to add [[i / inodesperblock]] in order to pick the right block within the inode table.

As explained above, [[mx_read_inode]] and [[mx_write_inode]] simply call the function [[mx_read_write_inode]] with [[wr_flag]] set to [[0]] or [[1]]:

<<minix filesystem implementation>>=
int mx_read_inode (int device, int i, struct minix2_inode *inodeptr) {
  return mx_read_write_inode (device, i, inodeptr, 0);  // 0 = false
}
@ %def mx_read_inode

\pagebreak

<<minix filesystem implementation>>=
int mx_write_inode (int device, int i, struct minix2_inode *inodeptr) {
  return mx_read_write_inode (device, i, inodeptr, 1);  // 1 = true
}
@ %def mx_write_inode


\subsection{Directory Entries}

\index{directory}%
\begin{goingwhere}%
Reserving and writing inodes is only the first half of creating a new file; we also need to create directory entries (in the directory where we want to place a file). Our goal is to write a function [[mx_write_link]] that takes an inode number and a pathname and creates the link between them.
\end{goingwhere}

\noindent
That task consists of several smaller tasks: We need to be able to read and write single entries in the directory (file), find a free entry in the directory, split a pathname (such as \path!/home/user/dir/file!) into its \emph{base name}\marginnote{base name,\\directory name} (\path!file!) and its \emph{directory name} (\path!/home/user/dir!). The directory name will lead us to the directory where we need to place the link.

Let's look at the task step by step. In order to read the root directory of a volume, we need to know that Minix always uses inode number 1 for it, and it also starts counting inodes with 1. Thus, inode 1 is the first (not the second) inode, stored at position 0 of the inode table, \emph{but} the corresponding bitmap entry is bit 1 (not 0), see further below.

Looking at the root directory's inode brings up a special case of file access (before reading the first regular file): Directories are a special kind of file which map filenames to inode numbers. We can read a directory block by block, and the first zone number is stored in [[i_zone[0]]]. We just need to know how to interpret the data: A directory file is an array of structures of type [[minix_dir_entry]]:

<<type definitions>>=
struct minix_dir_entry {
  uint16_t inode;
  char name[30];
};
@ %def minix_dir_entry

Each such entry has a size of $2+30 = 32$ bytes und starts with the 16-bit inode number, followed by the filename. Such filenames are normally null-terminated (as is standard for all strings on Unix systems), but when a filename uses the maximum allowed size of 30 characters, there is no space for the terminating [[\0]] character. Thus, simply copying an entry with [[strncpy]] will fail on filenames with maximum length. When dealing with Minix filenames internally, they should be stored in a [[char[31]]] string whose last byte is manually set to [[\0]].

A block can hold $1024 / 32 = 32$ such directory entries. If there are more than 32 entries in a directory, an additional block is used (whose block number can be found in the next entry, [[i_zone[1]]]. The total size of the directory is found by inspecting the inode entry [[i_size]].

Now we start the work on the function [[mx_write_link()]] that can add a (filename $\mapsto$ inode number) mapping to a directory. As already mentioned, directories are special files and the root directory has the inode number 1. Each of the associated data blocks contains 32 directory entries of type [[struct minix_dir_entry]] (since $32 \cdot 32 = 1024$). An unused entry has the [[inode]] field set to 0. We provide two functions

%nouse
<<function prototypes>>=
int mx_read_dir_entry  (int device, int inodenr, int entrynr, 
                        struct minix_dir_entry *entry);
int mx_write_dir_entry (int device, int inodenr, int entrynr, 
                        struct minix_dir_entry *entry);
@ for reading or writing individual entries of a directory.

We will use the same trick that we applied to reading and writing inodes by providing a common function [[mx_read_write_dir_entry]] that can do both and decides via an extra flag [[wr_flag]] whether it shall read or write. The other arguments are the device, the inode number of the directory (file) and a pointer to a [[struct minix_dir_entry]] variable.

Since only 32 entries fit in one block, we might have to reserve a new block and enter its location in the directory's inode; then we can go on writing entries in the new block. Similarly, when we later delete entries, we might want to remove additional blocks that are no longer needed. 

In each inode's [[i_zone]] array only the first seven entries refer directly to data blocks, so using these we can work with up to $7 \cdot 32 = 224$ directory entries. After that an indirection block must be used, but we will restrict our Minix implementation to a maximum of 224 entries for a directory.

<<minix filesystem implementation>>=
int mx_read_write_dir_entry (int device, int inodenr, int entrynr, 
                             struct minix_dir_entry *entry, int wr_flag) {
  debug_printf ("mx_read_write_dir_entry: entered\n");    // REMOVE_DEBUGGING_CODE
                                                          // REMOVE_DEBUGGING_CODE
  if (entrynr >= 32 * 7) {  // 7 direct blocks, 32 entries per block
    debug_printf ("directory too big!\n");             // REMOVE_DEBUGGING_CODE
    return false;
  }
  
  struct minix2_inode inode;
  debug_printf ("mx_read_write_dir_entry: before mx_read_inode()\n"); // REMOVE_DEBUGGING_CODE
  mx_read_inode (device, inodenr, &inode);            // read_ directory inode
  debug_printf ("mx_read_write_dir_entry: after mx_read_inode()\n");  // REMOVE_DEBUGGING_CODE
  int blockno;
  blockno = inode.i_zone[entrynr/32];    // number of block that holds the entry
  if (blockno == 0) {
    if (wr_flag) { <<reserve a block and map it in the directory inode>> } 
    else         return false;
  }
  
  char block[1024];
  readblock (device, blockno, (byte*)&block);
  
  int offset = (32*entrynr) % BLOCK_SIZE;
  if (!wr_flag) {
    memcpy (entry, ((char*)&block)+offset, 32);       // reading
    return (entry->inode != 0);                       // true if entry non-empty
  } else {
    memcpy (((byte*)&block)+offset, entry, 32);       // writing
    writeblock (device, blockno, (byte*)&block);
    return true;
  };
};

int mx_read_dir_entry (int device, int inodenr, int entrynr, 
                       struct minix_dir_entry *entry) {
  return mx_read_write_dir_entry (device, inodenr, entrynr, entry, false);
};

int mx_write_dir_entry (int device, int inodenr, int entrynr, 
                        struct minix_dir_entry *entry) {
  return mx_read_write_dir_entry (device, inodenr, entrynr, entry, true);
};
@ %def mx_read_write_dir_entry mx_read_dir_entry mx_write_dir_entry

If the block which should hold the directory entry does not yet exist (and we're trying to write to it), we create it and enter it in the directory inode:

<<reserve a block and map it in the directory inode>>=
blockno = mx_request_block (device);
char empty_block[1024] = { 0 };
writeblock (device, blockno, (byte*)&empty_block);
inode.i_zone[entrynr/32] = blockno;
// printf ("DEBUG: entrynr = %d, entrynr/32 = %d, "          // REMOVE_DEBUGGING_CODE
//         "blockno = %d\n", entrynr, entrynr/32, blockno);  // REMOVE_DEBUGGING_CODE
// printf ("DEBUG: i_zone[] = [");                           // REMOVE_DEBUGGING_CODE
// for (int i = 0; i < 7; i++)                               // REMOVE_DEBUGGING_CODE
//   printf ("%d, ", inode.i_zone[i]);  printf ("]\n");      // REMOVE_DEBUGGING_CODE
// int ret =                                                 // REMOVE_DEBUGGING_CODE
mx_write_inode (device, inodenr, &inode);        // update directory inode
// printf ("DEBUG: updating inode %d, mx_write_inode() "     // REMOVE_DEBUGGING_CODE
//   "returns %d\n", inodenr, ret);                          // REMOVE_DEBUGGING_CODE
@

For dealing with pathnames we will sometimes need two helper functions:
[[dirname]] and [[basename]] can be used to split a path into a directory (path)
\index{basename (of a path)}\index{directory name (of a path)}
and a file or directory name, for example
\verb#dirname ("/usr/bin/vi") = "/usr/bin"# and \verb#basename ("/usr/bin/vi")# \verb#= "vi"#.
This works similarly for relative paths, and the special case of a pathname
[[x]] without any slashes is handled by 
\verb#dirname ("x") = "."# and \verb#basename ("x") = "x"#.

We will also recycle these functions in the user mode library, since it does not
matter whether the kernel or a program wants to split a pathname.
Instead of parsing the path in two separate functions, we write a combined function
[[splitpath]] and call that one from [[basename]] and [[dirname]].

%nouse
<<public function prototypes>>=
void splitpath (const char *path, char *dirname, char *basename);
char *basename (char *path);
char *dirname  (char *path);
@

<<public function implementations>>=
void splitpath (const char *path, char *dirname, char *basename) {
  if (strlen (path) == 1 && path[0] == '/') { // special case "/"
    strncpy (dirname, "/", 1);  strncpy (basename, "/", 1);  return;
  }
  char p[256]; strncpy (p, path, 256);        // work on copy
  int pos = strlen (p) - 1;
  if (p[pos] == '/') { p[pos] = 0; pos--; }   // strip trailing '/'
  
  for (;;) {                                  // search for / (from back to front)
    pos--;
    if (pos == -1) {                          // no single slash found
      strncpy (dirname, ".", 2);  strncpy (basename, p, 256);  return;
    }
    if (p[pos] == '/') {                      // slash found
      if (pos==0)
        strncpy (dirname, "/", 2);            // special case /
      else {
        memcpy (dirname, p, pos);
        dirname[pos] = 0;                     // remove trailing '/'
      }
      strncpy (basename, p + pos + 1, 30);
      return;
    }
  }
}
@ %def splitpath

In the implementations of [[basename]] and [[dirname]] we declare \verb#bname# and \verb#dname# as [[static]] so that they are not stored on the stack; that way we can return a pointer.

<<public function implementations>>=
char *basename (char *path) {
  static char bname[30];  static char dname[256];
  splitpath (path, dname, bname);  return (char *)bname;
}

char *dirname (char *path) {
  static char bname[30];  static char dname[256];
  splitpath (path, dname, bname);  return (char *)dname;
}
@ %def basename dirname

The implementation of the
%nouse
<<function prototypes>>=
void mx_write_link (int device, int inodenr, const char *filename);
@ function is complex:

\begin{itemize}
\item First, we check whether the directory already contains an entry for the filename---it is not possible to have the same filename twice in a directory.
\item Then we split the path into the directory name and the base filemame.
\item We locate the inode that belongs to the directory file using [[mx_pathname_to_ino]] (a function  that we still have to implement; this follows a few pages later).
\item Then we read all the directory entries (using [[mx_read_dir_entry]] from above) until we find a free entry. If we don't, we have to abort because the directory is full.
\item Once we've found a free entry, we prepare a directory entry and write it to the free location.
\item As a last thought, we must not forget to increase the link count of the inode: It counts how many links to the inode exist. For a freshly created file we could always set that value to 1, but we will also use this function when we create a hard link.
\item Finally we update the size of the directory (it may have grown by 32 bytes unless we've found a free entry between other, used entries) and write back the modified directory inode.
\end{itemize}

<<minix filesystem implementation>>=
void mx_write_link (int device, int inodenr, const char *path) {
  if (mx_file_exists (device, path)) {   // check if filename already exists
      printf ("ERROR: filename %s exists!\n", path);  return;
  };
  struct minix_dir_entry dentry;  struct minix2_inode inode;
  char dirname[256];  char filename[30];
  splitpath (path, dirname, filename);
  int dir_inode_no = mx_pathname_to_ino (device, dirname);
  debug_printf ("DEBUG: dirname='%s' (ino: %d), "    // REMOVE_DEBUGGING_CODE
                "filename='%s'\n", dirname,          // REMOVE_DEBUGGING_CODE
                dir_inode_no, filename);             // REMOVE_DEBUGGING_CODE
                                                     // REMOVE_DEBUGGING_CODE
  // find free location and enter it
  mx_read_inode (device, dir_inode_no, &inode);   // read_ directory inode
  for (int i = 0;  i < 32 * 7;  i++) {
    mx_read_dir_entry (device, dir_inode_no, i, &dentry);
    if (dentry.inode==0 || i * 32 >= inode.i_size) {
      dentry.inode = inodenr;                     // found an empty entry
      memcpy ((char*)dentry.name, filename, 30);
      mx_write_dir_entry (device, dir_inode_no, i, &dentry);
      mx_increase_link_count (device, inodenr);   // link count for file
      if (inode.i_size < 32*(i+1)) {              // modify dir. inode size
        mx_read_inode (device, dir_inode_no, &inode);   // must read again
        inode.i_size = 32*(i+1);
        mx_write_inode (device, dir_inode_no, &inode);
      };
      return;                                     // success
    };
  };
  printf ("ERROR: no free entry in directory\n"); // search failed
};
@ %def mx_write_link

In the last few lines we need to read the directory inode from disk again (even though we did so just nine lines ago, but calling [[mx_write_dir_entry]] may have modified it if a new block was added to the directory---we must not overwrite this change.

This function uses [[mx_increase_link_count()]] which adds 1 to the
number of links for a given inode:\index{link count}

%nouse
<<function prototypes>>=
int mx_increase_link_count (int device, int inodenr);
@ It simply reads an inode, increments the [[i_nlinks]] entry and writes it back:

<<minix filesystem implementation>>=
int mx_increase_link_count (int device, int inodenr) {
  struct minix2_inode inode;
  mx_read_inode (device, inodenr, &inode);
  inode.i_nlinks++;
  mx_write_inode (device, inodenr, &inode);
  return inode.i_nlinks;
};
@ %def mx_increase_link_count


\subsection{The \texttt{i\_mode} Entry of the Inode}

Each inode contains an [[i_mode]] entry that describes the file type and the access permissions\index{access permissions (files)}. Since we will need to query this information in some of the following functions, we provide a few standard constants that make it easier to check for a specific property. 

<<public constants>>=
#define S_IRWXU  0000700    // RWX mask for owner
#define S_IRUSR  0000400    // R for owner
#define S_IWUSR  0000200    // W for owner
#define S_IXUSR  0000100    // X for owner

#define S_IRWXG  0000070    // RWX mask for group
#define S_IRGRP  0000040    // R for group
#define S_IWGRP  0000020    // W for group
#define S_IXGRP  0000010    // X for group

#define S_IRWXO  0000007    // RWX mask for other
#define S_IROTH  0000004    // R for other
#define S_IWOTH  0000002    // W for other
#define S_IXOTH  0000001    // X for other

#define S_ISUID  0004000    // suid bit (set user ID)
#define S_ISGID  0002000    // sgid bit (set group ID)
#define S_ISVTX  0001000    // save swapped text even after use

#define S_IFMT   0170000    // mask the file type part
#define S_IFIFO  0010000    // named pipe (fifo)
#define S_IFCHR  0020000    // character special
#define S_IFDIR  0040000    // directory
#define S_IFBLK  0060000    // block special
#define S_IFREG  0100000    // regular
#define S_IFLNK  0120000    // symbolic link
#define S_IFSOCK 0140000    // socket
@ %def S_IRWXU S_IRUSR S_IWUSR S_IXUSR S_IRWXG S_IRGRP S_IWGRP S_IXGRP S_IRWXO S_IROTH S_IWOTH S_IXOTH S_ISUID S_ISGID S_ISVTX S_IFMT S_IFIFO S_IFCHR S_IFDIR S_IFBLK S_IFREG S_IFLNK S_IFSOCK

Some of these constants can be used for direct comparisons, for example, in order to check whether a file has the read access bit for the file owner set, you could check whether [[(i_mode & S_IRUSR) != 0]]. We assume that you're aware of the standard access permissions on Unix systems---if not, here's a brief summary:

\looseness=-1
The standard \emph{access permissions}\marginnote{access\\ permissions} encompass nine bits grouped in three groups of three bits each. The first group describes the permissions granted to the file owner who may or may not read, write or execute the file. In the output of the [[ls -l]] command, these are represented by the characters in the second to fourth column and shown as [[rwx]]\marginnote{[[rwx]] (owner)} (or some of those letters replaced with [[-]] if a permission is not set. For example, [[rw-]] in that place says: owner can read and write, but not execute (those are the standard settings for a document file). The next group\marginnote{[[rwx]] (group,\\ other users)} describes the corresponding permissions for the members of the group that the file belongs to, and the third group shows permissions for all other users.

There are two further interesting bits which can be set: The \emph{Set User ID bit}\marginnote{Set User ID bit}\index{set used ID bit}\index{SUID} ([[suid]]), when set on an executable file, changes the effective user ID of a program to the file owner, regardless of who started it. Similarly the \emph{Set Group ID bit}\marginnote{Set Group\\ ID bit}\index{set group ID bit}\index{SGID} ([[sgid]]) sets the effective group ID to the file's group. Owner and group are also stored in the inode (in the [[i_uid]] and [[i_gid]] fields).

The last block of constants can be used for identifying the type of a file. This does not refer to properties like ``Word document'' and ``C source file'', but to whether a file is a ``classical'' file or something else, like a directory, a block or character device file (only the block variety is implemented in \UlixI{}, see Section~\ref{sec:dev-filesystem}), a symbolic link or a socket (not available, either). Since a file cannot be in more than one of these categories, you can check for a specific file type with an expression like [[(i_mode & S_IFMT) == S_IFDIR]]. This is an example for using a \emph{mask}\marginnote{mask} (to mask out the irrelevant bits of the [[i_mode]] field): We used [[S_IFMT]] to remove the access permissions. Similarly, [[S_IRWXU]], [[S_IRWXG]] and [[S_IRWXO]] are masks for the \emph{owner}, \emph{group} and \emph{others} parts of the permissions.

We will explain this in more detail in Chapter~\ref{chap:ulix:usersgroups} where we discuss users and groups and also add permission checking code to the filesystem functions from this chapter.

\pagebreak


\subsection{Opening and Closing Files}

\begin{goingwhere}%
We're getting closer to actually opening files. First, we need to introduce some new data structures, including an internal inode representation and a file status structure. Next up is a function that gets the inode number when given a path. Then we can start work on the implementation of the [[mx_open]] function.
\end{goingwhere}

% weiter mit Uebung 9, Aufgabe 14

\noindent
The goal is to provide the kernel functions which will be called when a process uses the standard filesystem functions [[open]], [[read]], [[write]] [[lseek]] and [[close]]. In the Minix subsystem we need the functions [[mx_open]], [[mx_read]], [[mx_write]], [[mx_lseek]] and [[mx_close]] (and they are called by the corresponding [[u_*]] functions).

We have to introduce some new data structures that will help the kernel stay aware of the states of open files:

\begin{description}
\item[Internal Inode:] \index{inode!internal}\index{internal inode}This will be an enhanced copy of the inode (as it is stored on the filesystem), but with extra elements, e.\,g.\ a reference counter [[refcount]] that takes notice of how often the associated file is opened. Whenever we open a file we reserve such an internal inode. All changes to the inode will first be made in the internal copy only; when closing the file we will write the information back to disk. (For immediate writing there will be an [[mx_sync]] function.) One of the new fields is [[clean]]: It is set to 1 as long as no changes were made to the internal inode. A change resets it, and calling [[my_sync]] will set it again (after saving the changes to disk).

<<type definitions>>=
struct int_minix2_inode {
  <<external minix2 inode>>  // fields from the external inode
  int ino;                    // inode number
  unsigned int    refcount;   // how many users?
  unsigned short  clean;      // 0: changed; 1: unchanged (as on disk)
  short           device;     // file resides on which device?
};
@ %def int_minix2_inode

\indent
\hspace{10mm}We create an internal inode table that can store up to 256 records on open files:

<<constants>>=
#define MAX_INT_INODES 256
@

<<global variables>>=
struct int_minix2_inode mx_inodes[MAX_INT_INODES] = {{ 0 }};
@ %def  MAX_INT_INODES mx_inodes

\end{description}
\begin{description}
\item[Local File Descriptor:] \index{local file descriptor}\index{file descriptor!local}The LFD is a non-negative integer returned by [[mx_open]] which the other [[mx_*]] functions use for accessing an open file. It has the same function as the process file descriptor in user mode programs, however the local file descriptor is valid in the whole Minix subsystem, whereas each process counts file descriptors separately. When we later allow processes to work with files (via system calls), we will map process-local file descriptors to global file descriptors which are more general than the local ones. For a reminder of how global, local and process file descriptors are connected, go back to Section~\ref{sec:fs:global-file-descriptors} (p.~\pageref{sec:fs:global-file-descriptors}).

\item[File Status:] \index{file!status}This is a structure that points to an internal inode. (If there's a null pointer, then this specific file status structure is not in use.) Additionally, it stores the current read/write position and the access mode (see below).

<<type definitions>>=
struct mx_filestat { 
  struct int_minix2_inode *int_inode; 
  int pos; 
  short mode;
};
@ %def mx_filestat
\end{description}
\vspace{-4mm}
\begin{description}
\item[]\hspace{7.8mm}Thus, if a file is opened twice, there will be \emph{one} internal inode, referenced by the (Minix-subsystem-)local file descriptor, and \emph{two} [[mx_filestat]] structures, since access mode and read/write position may be different.

We support the following modes for opening:

%nouse
<<public constants>>=
#define O_RDONLY        0x0000     // read only
#define O_WRONLY        0x0001     // write only
#define O_RDWR          0x0002     // read and write
#define O_APPEND        0x0008     // append mode
#define O_CREAT         0x0200     // create file
@ %def O_RDONLY O_WRONLY O_RDWR O_APPEND O_CREAT
\begin{itemize}
\item [[O_RDONLY]] and [[O_WRONLY]] are used when the file shall be used exclusively for reading or writing, respectively.
\item Using the [[O_RDWR]] mode allows read and write access.
\item The mode [[O_APPEND]] can be supplied in addition to [[O_WRONLY]] (by calculating the mode as [[O_WRONLY | O_APPEND]]). In that case all write operations append to the file, and [[lseek]] calls are ignored.
\item [[O_CREAT]] allows the creation of new files. Trying to open a non-existing file without [[O_CREAT]] will fail. On the other hand, using [[O_CREAT]] with an already existing file does not change anything (specifically: it does not truncate the file).
\end{itemize}

\item[Status List:] \index{file!status list}This is an array that holds 256 file status entries, so we allow the Minix subsystem to open up to 256 files simultaneously---the same limit holds for all subsystems since we defined the global file descriptors in a way that allows the local component of the number to lie between 0 and 255.

<<constants>>=
#define MX_MAX_FILES 256
@ %def MX_MAX_FILES

<<global variables>>=
struct mx_filestat mx_status[MX_MAX_FILES] = { { 0 } };
@ %def mx_status

\end{description}

\noindent
We need a function that looks up a filename in the directory and returns the inode number.
Assume we want to look up the path \path!/etc/passwd!: We can assume that this
is an absolute path (because the virtual filesystem layer already took care of that). 
Then we scan the path until we reach the next \path!/! (or the string terminator [[\0]])
which gives us a directory to search for. We can then look up its inode and continue
the search with the next directory element. Eventually we reach the last part of the
pathname and return its inode number.

The search begins in the volume's root directory that always has inode number 1 on a
Minix filesystem.

%nouse
<<function prototypes>>=
int mx_pathname_to_ino (int device, const char *path);
@

<<minix filesystem implementation>>=
int mx_pathname_to_ino (int device, const char *path) {
  debug_printf ("mx_pathname_to_ino: entered\n");    // REMOVE_DEBUGGING_CODE
  struct minix2_inode dirinode, inode;
  struct minix_dir_entry dentry;
  char subpath[31];                         // maximum name length: 30
  char searchbuf[256];
  char *search = (char*)searchbuf;
  strncpy (search, path, 256);              // do not modify original path
  int dirinode_no = 1;                      // inode number of / directory
  int next_dirinode_no;
  short final = 0;                          // final = 1 if looking at final part
  
  search++;
  if (*search == '\0') { return 1; }        // searching for / : inode 1
  while (*search != '\0') {                 // work until end of path reached
    <<[[mx_pathname_to_ino]]: search loop>>
  } 
  debug_printf ("DEBUG: returning inode no %d\n",   // REMOVE_DEBUGGING_CODE
                next_dirinode_no);                  // REMOVE_DEBUGGING_CODE
  return next_dirinode_no;
};
@ %def mx_pathname_to_ino

\pagebreak

Inside the loop we pick the next sub-path and perform the inode lookup. We know that we're done when [[search]] points to the [['\0']] character (the end of the pathname):

<<[[mx_pathname_to_ino]]: search loop>>=
int i = 0;
while (*search != '\0' && *search != '/') {
  subpath[i] = *search;
  search++; i++;
}
subpath[i] = '\0';                      // terminate subpath string

if (*search == '\0') final = 1;         // looking at final part of path

debug_printf ("DEBUG: searching for subpath "    // REMOVE_DEBUGGING_CODE
              "%s in inode %d\n", subpath,       // REMOVE_DEBUGGING_CODE
              dirinode_no);                      // REMOVE_DEBUGGING_CODE
next_dirinode_no = -1;                  // look up subpath
for (i = 0;  i < 32*7;  i++) {          // max. 32 * 7 entries
  if (dirinode_no == -1)                         // REMOVE_DEBUGGING_CODE
    printf ("FAIL: calling mx_read_dir_entry"    // REMOVE_DEBUGGING_CODE
            " (%d); i = %d, subpath = %s\n",     // REMOVE_DEBUGGING_CODE
            dirinode_no, i, subpath);            // REMOVE_DEBUGGING_CODE
                                                 // REMOVE_DEBUGGING_CODE
  mx_read_dir_entry (device, dirinode_no, i, &dentry);
  debug_printf ("mx_pathname_to_ino: "           // REMOVE_DEBUGGING_CODE
                "after mx_read_dir_entry()\n");  // REMOVE_DEBUGGING_CODE
  if (dentry.inode != 0) {
    if (strequal (dentry.name, subpath)) {
      next_dirinode_no = dentry.inode;  // found it!
      break;                            // leave for loop
    }
  }
}
    
// now next_dirinode_no is either -1 (not found) or points to next step
if (next_dirinode_no == -1) { return -1; }   // not found!
    
dirinode_no = next_dirinode_no;
debug_printf ("DEBUG: subpath = %s, "           // REMOVE_DEBUGGING_CODE
              "inode = %d\n",                   // REMOVE_DEBUGGING_CODE
              subpath, dirinode_no);            // REMOVE_DEBUGGING_CODE
if (*search != '\0')  search++;
else                  break;            // finished, leave while loop
@

We also need two helper functions that give us the index of a free [[mx_inodes[]]] and a free [[mx_status[]]] entry. The code is similar: We loop over the respective array and check whether an entry is free. [[mx_inodes[i]]] is free if its [[refcount]] element is 0; the file status entry [[mx_status[i]]] is free if its [[int_inode]] element is a [[NULL]] pointer.

\enlargethispage{3mm}
%nouse
<<function prototypes>>=
int mx_get_free_inodes_entry ();
int mx_get_free_status_entry ();
@

<<minix filesystem implementation>>=
int mx_get_free_inodes_entry () {
  for (int i = 0;  i < MAX_INT_INODES;  i++) {      // returns internal inode no.
    if (mx_inodes[i].refcount == 0)  return i;
  }
  return -1;
}
@ %def mx_get_free_inodes_entry

\pagebreak

<<minix filesystem implementation>>=
int mx_get_free_status_entry () {
  for (int i = 0;  i < MX_MAX_FILES;  i++) {        // returns an MFD
    if (mx_status[i].int_inode == NULL)  return i;
  }
  return -1;
}
@ %def mx_get_free_status_entry

We're about to show the implementation of the [[mx_open]] function

%nouse
<<function prototypes>>=
int mx_open (int device, const char *path, int oflag);
@ that will use many of the functions we've already discussed (and also some new ones). Figure~\ref{fig:mx-open-calls-who} shows the function call graph for [[mx_open]], so you can see that opening a file is a rather complex task.

\begin{figure}[ht!]
%\centering
\hspace{-1.5mm}% for right page placement
%\hspace{-0.235\textwidth}\hspace{2.5mm}% for left page placement
\includegraphics[width=1.22\textwidth]{pics/mx-who-calls-who.pdf}
\caption{Minix subsystem functions called my \texttt{mx\_open}.}
\label{fig:mx-open-calls-who}
\end{figure}

\pagebreak


\subsubsection{\texttt{mx\_open}}

\index{file!open}\index{opening a file}%
We define two variables 

<<global variables>>=
int count_open_files = 0;  // number of open_ files
int count_int_inodes = 0;  // number of internal inodes in use
@ %def count_open_files count_int_inodes
to keep track of the open files and the used internal inodes and we dedicate a
separate code chunk [[<<[[mx_open]]>>]] to the implementation:

<<minix filesystem implementation>>=
int mx_open (int device, const char *path, int oflag) {
  <<[[mx_open]]>>
}
@ %def mx_open

We start with checking whether the file exists---if it does not, but the [[O_CREAT]] flag was used, we will call [[mx_creat_empty_file]] to make a new file. In both cases [[ext_ino]] is set to the number of the external inode.

<<[[mx_open]]>>=  
debug_printf ("mx_open: entered\n");                     // REMOVE_DEBUGGING_CODE
int ext_ino = mx_pathname_to_ino (device, path);
debug_printf ("DEBUG: ext_ino = %d\n", ext_ino);         // REMOVE_DEBUGGING_CODE
debug_printf ("mx_open: after mx_pathname_to_ino()\n");  // REMOVE_DEBUGGING_CODE
if (ext_ino == -1) {
  // file not found
  if ((oflag & O_CREAT) != 0) {
    // REENABLE: printf ("DEBUG: mx_open calls mx_creat_empty_file\n");  // REMOVE_DEBUGGING_CODE
    ext_ino = mx_creat_empty_file (device, path, 0644);
  }
  else {
    return (-1);  // file not found and no O_CREAT
  }
}
@

In [[int_ino]] we will store the index into the internal inode table. The file may already be open, because another process (or even the same one) opened it earlier. In that case a valid internal inode is in place and can be recycled; otherwise we create a fresh one. We find out if the file is open by checking the [[ino]] and [[device]] fields of all our [[mx_inodes]] array entries.
  
<<[[mx_open]]>>=
short file_already_open = false;
int mfd = mx_get_free_status_entry ();

int int_ino = -1;   // number of internal inode for this file
int i;
if (count_open_files == 0) {
  int_ino = 0;      // first file to be opened
} else {
  for (i = 0; i < MAX_INT_INODES; i++) {
    if (mx_inodes[i].ino == ext_ino && mx_inodes[i].device == device) {
      // same inode number and same device: this is the same file!
      file_already_open = true;
      int_ino = i;
      break;
    }
  }
  // reached end of the loop: file is not open_
  if (int_ino == -1) int_ino = mx_get_free_inodes_entry ();
}

if (int_ino == -1) {
  return -1;      // error: no free internal inode available
}

struct int_minix2_inode *inode = &(mx_inodes[int_ino]);
@

Now [[int_ino]] is either set to 0 (we're just opening the first file), to an index of an already existing internal inode or to the index of a fresh internal inode (provided by [[mx_get_free_inodes_entry]]) and [[inode]] points to that entry.

[[mfd]] is the local file descriptor (an index into the [[mx_status]] file status table. We can start filling that entry:

<<[[mx_open]]>>=
mx_status[mfd].int_inode = inode;
mx_status[mfd].pos       = 0;
mx_status[mfd].mode      = oflag;

if (file_already_open) { <<[[mx_open]] case: file already open>> } 
else                   { <<[[mx_open]] case: file not open>> }

if ((oflag & O_APPEND) != 0)
  mx_status[mfd].pos = inode->i_size;   // append: set pos to end of file
@

[[mx_status[mfd].pos]] is set to the current read/write position---normally that is 0 when freshly opening a file, but if the [[O_APPEND]] flag was given, we set it to the the file size so that writing will begin at the end of the file. In [[mx_status[mfd].mode]] we remember the [[oflag]] argument of the [[mx_open]] call. This will later be used to determine whether it is acceptable to read from or write to the file. The current read/write position and the [[mode]] field are our reasons for having separate [[mx_status[]]] entries, since both can differ for several opening operations on the file. 

Now there are two cases that we need to treat differently. If the file is not yet open, we copy the inode from disk to memory. We can simply use the [[mx_read_inode]] function because we declared the two inode types (on-disk inode: [[struct minix2_inode]], internal inode: [[struct int_minix2_inode]]) so that they both start with the same fields---that lets us cast the pointer to the internal inode to a normal inode pointer; here are both types for a quick comparison:

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
\begin{Verbatim}
struct minix2_inode { 
  uint16_t i_mode;           
  uint16_t i_nlinks;
  uint16_t i_uid;            
  uint16_t i_gid;
  uint32_t i_size;           
  uint32_t i_atime;
  uint32_t i_mtime;          
  uint32_t i_ctime;
  uint32_t i_zone[10];
};
\end{Verbatim}
\columnbreak
\begin{Verbatim}
struct int_minix2_inode {
  uint16_t i_mode;           
  uint16_t i_nlinks;
  uint16_t i_uid;            
  uint16_t i_gid;
  uint32_t i_size;           
  uint32_t i_atime;
  uint32_t i_mtime;          
  uint32_t i_ctime;
  uint32_t i_zone[10];
  int      ino;
  uint32_t refcount;
  uint16_t clean;   
  short    device;  
};
\end{Verbatim}
\end{multicols}

<<[[mx_open]] case: file not open>>=
// copy diskinode[ext_ino] to mx_inodes[int_ino]
mx_read_inode (device, ext_ino, (struct minix2_inode*) inode);
inode->ino = ext_ino;    // number of external inode
inode->device = device;  // what device is the file on?
inode->refcount = 1;     // one user
inode->clean = true;     // inode is clean (just copied from disk)
@

If the file is already open, we have less work: We simply increase the inode's [[refcount]] field, because the inode is gaining an additional user:

<<[[mx_open]] case: file already open>>=
inode->refcount++;       // file is opened once more
@

We set [[clean]] to [[true]] and [[refcount]] to 1, and we take note of the external inode and the device. Note that it is important to remember what device the file resides on because the inode number alone is not enough to identify a file when more than one filesystem is mounted.

When opening fails we return $-1$ (earlier in the code). Otherwise we increment the counters for open files and (possibly) used inodes and return the new local file descriptor. (The variable [[mfd]] that we use in this function is short for ``Minix file descriptor''.)


<<[[mx_open]]>>=
count_open_files++;
if (!file_already_open) count_int_inodes++;
return mfd;
@

Note that we do not check access permissions---this is handled one layer further up in the virtual filesystem.


\subsubsection{\texttt{mx\_close}}

\index{file!close}\index{closing a file}%
Closing an open file with

%nouse
<<function prototypes>>=
int mx_close (int mfd);
@ is a comparatively simple task. We set the [[int_inode]] pointer in the file status entry to [[NULL]] and decrement [[count_open_files]]. We also check if this was the last user of the internal inode---if that is true and the internal inode is not clean, we write it back to disk. We don't have to explicitly mark the inode as unused---setting its [[refcount]] to 0 does the job since that property is what we use to find a free one.

<<minix filesystem implementation>>=
int mx_close (int mfd) {
  // REENABLE: printf ("DEBUG: mx_close(%d)\n", mfd);  // REMOVE_DEBUGGING_CODE
  if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;   // wrong mfd number
  struct mx_filestat      *st    = &mx_status[mfd];
  struct int_minix2_inode *inode = st->int_inode;
  // printf ("DEBUG: &inode = %x\n", inode);                            // REMOVE_DEBUGGING_CODE
  if (inode == NULL)  return -1;                   // no open file
    // REENABLE: printf ("DEBUG: mx_close(%d): file not open\n", mfd);  // REMOVE_DEBUGGING_CODE
  short device = inode->device;
  
  // close file
  inode->refcount--;
  // REENABLE: printf ("DEBUG: refcount(mfd=%d,%x) is now %d\n", mfd, inode, inode->refcount); // REMOVE_DEBUGGING_CODE
  st->int_inode = NULL;
  // REENABLE: printf ("DEBUG: I have set mx_status[%d].inode = NULL !\n", mfd);  // REMOVE_DEBUGGING_CODE
  
  if (inode->refcount == 0) {  // usage count down to 0? Then synchronize inode
    if (inode->clean == 0) {
      int ext_ino = inode->ino;
      mx_write_inode (device, ext_ino, (struct minix2_inode*) inode);
    }
    count_int_inodes--;
  }
  
  count_open_files--;
  return 0;
}
@ %def mx_close


\subsubsection{Helpers: \texttt{mx\_reopen} and \texttt{mx\_sync}}

We provide an [[mx_reopen]] function that is used when file descriptors are duplicated by [[fork]], it is then called by [[u_reopen]]:

\pagebreak

%nouse
<<function prototypes>>=
int mx_reopen (int mfd);
@ It makes a copy of the [[mx_status[]]] entry so that the original process and its child can work with different values for the read/write position---if we simply let the child process use the same [[mx_status[]]] entry, every read or write operation would also update the position for the other process. [[u_reopen]] also increments the usage counter of the file; when one of the two processes closes (its copy of) the file, the counter is reset to the original value.

<<minix filesystem implementation>>=
int mx_reopen (int mfd) {
  if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;   // wrong mfd number
  struct mx_filestat      *st    = &mx_status[mfd];
  struct int_minix2_inode *inode = st->int_inode;
  inode->refcount++;                               // increase reference count
 
  int new_mfd = mx_get_free_status_entry ();
  memcpy (&mx_status[new_mfd], &mx_status[mfd], sizeof (struct mx_filestat));

  // printf ("DEBUG: mx_reopen(%d) = %d\n", mfd, new_mfd);   // REMOVE_DEBUGGING_CODE
  // REENABLE: printf ("DEBUG: refcount(mfd=%d,mfd2=%d,%x) is now %d\n", mfd, new_mfd, inode, inode->refcount);   // REMOVE_DEBUGGING_CODE
  return new_mfd;
}
@ %def mx_reopen

The [[mx_sync]] function saves changes to the internal inode by writing it back to disk; after that it sets the [[clean]] flag.

\index{inode!synchronize internal and on-disk}%
\index{internal inode!synchronize with on-disk version}%
<<minix filesystem implementation>>=
int mx_sync (int device, int mfd) {
  if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;    // wrong mfd number
  struct mx_filestat      *st    = &mx_status[mfd];
  struct int_minix2_inode *inode = st->int_inode;
  if (inode == NULL)  return -1;                    // no open_ file
  
  if (inode->clean == 0) {
    int ext_ino = inode->ino;
    mx_write_inode (device, ext_ino, (struct minix2_inode*) inode);
    inode->clean = 1;   // now it is clean
  }
  return 0;
}
@ %def mx_sync


\subsubsection{\texttt{mx\_lseek}}

\index{file!seek}\index{seeking in a file}%
Seeking is a very simple operation: Since the file is open we know its size and the current read/write position; so 

%nouse
<<function prototypes>>=
int mx_lseek (int mfd, int offset, int whence);
@ will only check if the request makes sense and then update the internal inode. As usual, we support the following three [[SEEK_*]] constants for the [[whence]] parameter which decide how the offset is to be interpreted:

<<public constants>>=
#define SEEK_SET 0    // absolute offset
#define SEEK_CUR 1    // relative offset
#define SEEK_END 2    // EOF plus offset
@ %def SEEK_SET SEEK_CUR SEEK_END

When the file is opened in append mode, we must not change the position; otherwise we either set the position, add the offset to the current location or add it to the end of file position. For the last two cases negative values are OK.

<<minix filesystem implementation>>=
int mx_lseek (int mfd, int offset, int whence) {
  if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;      // wrong mfd number
  struct mx_filestat *st = &mx_status[mfd];
  struct int_minix2_inode *inode = st->int_inode;
  if (inode == NULL)              return -1;          // no open_ file
  if (whence < 0 || whence > 2)   return -1;          // wrong lseek_ option
  if ((st->mode & O_APPEND) != 0) return st->pos;     // append mode, ignore lseek_
  
  switch (whence) {
    case SEEK_SET: st->pos = offset;  break;          // set absolute
    case SEEK_CUR: st->pos += offset; break;          // relative to current loc.
    case SEEK_END: st->pos = inode->i_size + offset;  // relative to EOF
  };
  
  if (st->pos < 0)  st->pos = 0;                      // sanity check
  return st->pos;
}
@ %def mx_lseek


\subsection{Reading and Writing}

With all these preparations we can now approach the read and write operations which work on open files.

\pagebreak

\subsubsection{\texttt{mx\_read}}

\index{file!read}\index{reading from a file}%
We start with the function

%nouse
<<function prototypes>>=
int mx_read (int mfd, void *buf, int nbyte);
@ that reads [[nbyte]] bytes from an open file identified by [[mfd]] into a buffer [[buf]]. 

Since [[mx_read]] is a bit longer, we use a code chunk [[<<[[mx_read]]>>]] for displaying the code:

<<minix filesystem implementation>>=
int mx_read (int mfd, void *buf, int nbyte) {
  <<[[mx_read]]>>
}
@ %def mx_read

We start with the usual variable initialization so that we have access to both the internal inode and the file status entry. If [[mfd]] has an invalid value or we attempt to read a file in write-only or append mode, we return $-1$ at once.

<<[[mx_read]]>>=
debug_printf ("DEBUG: mx_read: %d bytes\n", nbyte);    // REMOVE_DEBUGGING_CODE
if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;    // wrong mfd number
  
struct mx_filestat *st = &mx_status[mfd];
struct int_minix2_inode *inode = st->int_inode;
short device = inode->device;

if (inode == NULL)  return -1;                    // no open_ file
if (st->mode == O_WRONLY || st->mode == O_APPEND)
  return -1;                                      // reading is forbbiden
@

Next we look at the current read/write position and determine which logical blocks of the file must be read---even if we want just a single byte from the file, we must read a whole block since that's the only way that we can access the hardware. (With ``logical block'' we mean the enumeration of the file's blocks. A file always starts with logical block 0 (unless it is empty).

Note that as a worst case, even reading two bytes can result in reading two blocks, if those bytes are placed precisely on a block boundary.

<<[[mx_read]]>>=
int startbyte = st->pos;
if (startbyte >= inode->i_size) { return 0; }   // nothing to read_
int endbyte = st->pos + nbyte - 1;
if (endbyte >= inode->i_size) {
  nbyte -= (endbyte - inode->i_size + 1);
  endbyte = inode->i_size - 1;
}
@

With [[startbyte]] and [[endbyte]] set, we can easily calculate the logical blocks:

\pagebreak

<<[[mx_read]]>>=
int startblock = startbyte / BLOCK_SIZE;
int endblock   = endbyte / BLOCK_SIZE;
int curblock = startblock;
@

We need to loop over all the logical blocks and read them. In order to read a logical block [[curblock]] from the file we must find out where it is located on the device (i.\,e., find the physical block where it is stored); we put the lookup of that block number into a separate function

%nouse
<<function prototypes>>=
int fileblocktozone (int device, int blockno, struct int_minix2_inode *inode);
@ that we will implement afterwards.

<<[[mx_read]]>>=
int read_bytes = 0;
while (nbyte > 0) {
  int zone = fileblocktozone (device, curblock, inode);  // where is the block?
  if (zone == -1) {
    printf ("ERROR, fileblocktozone() = -1\n");
    return -1;
  };

  byte block[BLOCK_SIZE];  readblock (device, zone, (byte*) block);
  int offset, length;
  if (curblock == startblock) {
    offset = startbyte % BLOCK_SIZE;
    length = MIN (nbyte, BLOCK_SIZE - offset);
  } else {
    offset = 0;
    length = MIN (nbyte, BLOCK_SIZE);
  }
  memcpy (buf, block+offset, length);
    
  nbyte -= length;        buf   += length;
  read_bytes += length;   curblock++;
  st->pos += length;       // update current location in inode
}

return read_bytes;         // return the read_ bytes, might be != nbyte
@

This code uses the [[MIN]] macro that we have not defined yet:

<<macro definitions>>=
#define MIN(a,b) ((a) <= (b) ? (a) : (b))
#define MAX(a,b) ((a) >= (b) ? (a) : (b))
@ %def MIN MAX


Now we need to show how to translate a logical block number to
a physical block number (or zone number). This may require looking at
single and double indirection\marginnote{indirection}\index{indirection} blocks.
The Minix V2 filesystem uses four byte long integers as zone addresses,
so one indirection block has space for
[[BLOCK_SIZE / 4]] = 256 such addresses. We'll define this number as
a constant:

<<constants>>=
#define BLOCKADDRESSES_PER_BLOCK (BLOCK_SIZE / 4)
@ %def BLOCKADDRESSES_PER_BLOCK

\begin{figure}[t!]
%\centering
%\hspace{-2mm}% for right page placement
\hspace{-0.22\textwidth}% for left page placement
\includegraphics[width=1.235\textwidth]{pics/indirection-minix-double.pdf}
\caption[Single and double indirection in Minix inodes.]{A Minix inode stores seven direct block numbers and two block numbers for single and double indirection blocks; \texttt{i\_zone[9]} is unused.}
\label{img:disk-indirection-repeat}
\end{figure}

Writing [[fileblocktozone]] is straightforward if we know how single and double indirection blocks are organized. Figure~\ref{img:disk-indirection-repeat} once more shows how Minix uses indirect blocks. You have already seen a bigger version of that figure on page~\pageref{img:disk-indirection}, here we only show the single and double indirection that we implement for \UlixI{}; triple indirection was not part of the original implementation in Minix either, but the inode entry [[i_zone[9]]] is reserved for triple indirection.

Thus, the physical block numbers of the first seven logical blocks (number 0--6) can be found directly in the inode. For the 256 blocks with numbers 7--262 we must load the indirection block (whose address is in [[i_zone[7]]], and any block number beyond 262 requires us to first load the double indirection block (via [[i_zone[8]]]) and then search for the address of the right single indirection block, so locating such a block always requires reading two indirection blocks which is one of the reasons why it is so helpful to use a caching\marginnote{caching} mechanism: When reading consecutive blocks beyond block number 262, the indirection blocks will remain in the cache once the first of those blocks has been accessed.

<<minix filesystem implementation>>=
int fileblocktozone (int device, int blockno, struct int_minix2_inode *inode) {
  int zone;  int *zone_ptr;  byte indirect_block[BLOCK_SIZE];
  if (blockno < 7) {
    // the first 7 zone numbers (0..6) are in the inode:
    zone = inode->i_zone[blockno];
    debug_printf ("\nDIRECT: zone(blockno=%d) "    // REMOVE_DEBUGGING_CODE
                  "= %d\n", blockno, zone);        // REMOVE_DEBUGGING_CODE
  } else if (blockno >= 7 && blockno < 7+BLOCKADDRESSES_PER_BLOCK) {
    // inode holds the address of an indirection block
    <<[[fileblocktozone]]: single indirect>>
  } else {
    // inode holds the address of a double indirection block
    <<[[fileblocktozone]]: double indirect>>
  }
  return zone;
}
@ %def fileblocktozone

For the two indirection cases (singly indirect, doubly indirect) we provide two code chunks which are increasingly complex. Single indirection works like this:

\index{single indirection}%
<<[[fileblocktozone]]: single indirect>>=
int indirect_zone = inode->i_zone[7];
if (indirect_zone == 0) {
  return -2;   // no indirection block found
}
debug_printf ("\nINDIRECTIONS IN: %d, ", indirect_zone);    // REMOVE_DEBUGGING_CODE
readblock (device, indirect_zone, (byte *) indirect_block);
zone_ptr = (int *) indirect_block;
zone_ptr += (blockno - 7);    
zone = *zone_ptr;
debug_printf ("INDIRECT: zone(blockno=%d) "    // REMOVE_DEBUGGING_CODE
              "= %d\n", blockno, zone);        // REMOVE_DEBUGGING_CODE
@ %
%
Here we set [[zone_ptr]] to the start address of the loaded indirection block. Then we need to add an offset to find the right block number inside that block. We don't add [[blockno]] but [[blockno - 7]] because the first seven block addresses are already found in the inode and not repeated in the indirection block which starts with the block number of block 7.

Resolving a double indirection works similarly, but consists of two steps.

\index{double indirection}%
\begin{itemize}
\item First, [[(blockno - 7 - BLOCKADDRESSES_PER_BLOCK) / BLOCKADDRESSES_PER_BLOCK]] 
is the index into the first indirection block---instead of [[blockno - 7]] (as in the single indirection case) we must also subtract [[BLOCKADDRESSES_PER_BLOCK]] since the first [[7 + BLOCKADDRESSES_PER_BLOCK]] blocks can be found via the direct addresses and the single indirection block. Then we also need to divide by [[BLOCKADDRESSES_PER_BLOCK]] as each address in the first indirection block points to a whole block of addresses.
\item In the second step, we take [[(blockno - 7) % BLOCKADDRESSES_PER_BLOCK]]
as an index into the second indirection block: Note that the equation
\begin{Verbatim}
  (blockno - 7 - BLOCKADDRESSES_PER_BLOCK) % BLOCKADDRESSES_PER_BLOCK
                                   == (blockno - 7) % BLOCKADDRESSES_PER_BLOCK
\end{Verbatim}                             
holds; the left side is the original formula, but [[n % n == 0]] for all [[n]].
\end{itemize}

<<[[fileblocktozone]]: double indirect>>=
int double_indirect_zone = inode->i_zone[8];
if (double_indirect_zone == 0) {
  return -2;  // no double indirection block found
}
debug_printf ("\nINDIRECTIONS IN: %d, ",       // REMOVE_DEBUGGING_CODE
              double_indirect_zone);           // REMOVE_DEBUGGING_CODE
readblock (device, double_indirect_zone, (byte *) indirect_block);
zone_ptr = (int *) indirect_block;
zone_ptr += (blockno - 7 - BLOCKADDRESSES_PER_BLOCK) / BLOCKADDRESSES_PER_BLOCK;
int indirect_zone = *zone_ptr;

readblock (device, indirect_zone, (byte *) indirect_block);
zone_ptr = (int *) indirect_block;
zone_ptr += (blockno - 7) % BLOCKADDRESSES_PER_BLOCK;    
zone = *zone_ptr;
debug_printf ("INDIRECT: zone(blockno=%d, "               // REMOVE_DEBUGGING_CODE
              "level1=%d, index=%d) = %d\n",              // REMOVE_DEBUGGING_CODE
              blockno, indirect_zone, (blockno - 7) %     // REMOVE_DEBUGGING_CODE
              BLOCKADDRESSES_PER_BLOCK, zone);            // REMOVE_DEBUGGING_CODE
@


\subsubsection{\texttt{mx\_write}}

\index{file!write}\index{writing to a file}%
The [[mx_write]] function works similar to [[mx_read]], but it must also read blocks which are only partly modified so that writing the block does not erase the parts which are not modified.

%nouse
<<function prototypes>>=
int mx_write (int mfd, void *buf, int nbyte);
@ The structure is the same as in [[mx_read]], and again we use a separate code chunk [[<<[[mx_write]]>>]]. 

<<minix filesystem implementation>>=
int mx_write (int mfd, void *buf, int nbyte) {
  <<[[mx_write]]>>
}
@ %def mx_write

We start with some checks:

<<[[mx_write]]>>=
if (mfd < 0 || mfd >= MX_MAX_FILES)   return -1;  // wrong mfd number
struct mx_filestat      *st    = &mx_status[mfd];
struct int_minix2_inode *inode = st->int_inode;
short device = inode->device;
if (inode == NULL)         return -1;            // no open file
if (st->mode == O_RDONLY)  return -1;            // cannot write to read-only file
@

The calculation of start and end positions (and blocks) is the same as well, but without the checks: writing does not require the data to be available.

<<[[mx_write]]>>=
int startbyte  = st->pos;
int endbyte    = st->pos + nbyte - 1;
int startblock = startbyte / BLOCK_SIZE;
int endblock   = endbyte / BLOCK_SIZE;
int curblock   = startblock;
@

The code for actually writing the blocks is just a little more complex than that
of the [[mx_read]] function:

<<[[mx_write]]>>=
byte block[BLOCK_SIZE];
int offset, length;
int written_bytes = 0;
while (nbyte > 0) {
  int zone = fileblocktozone (device, curblock, inode);
  // printf ("DEBUG: mx_write, fileblocktozone (%d) = %d\n", curblock, zone);  // REMOVE_DEBUGGING_CODE
  if (zone == -2 || zone == 0) {
    zone = mx_create_new_zone (device, curblock, inode); // block doesn't yet exist
  };
  if (zone == -1)  return -1;

  if (curblock == startblock) {
    offset = startbyte % BLOCK_SIZE;
    length = MIN (nbyte, BLOCK_SIZE - offset);
    // printf ("DEBUG: WRITE, FIRST BLOCK, curblock = %d, offset = %d, length = %d\n", curblock, offset, length);  // REMOVE_DEBUGGING_CODE
  } else {
    offset = 0;
    length = MIN (nbyte, BLOCK_SIZE);
  }

  if (offset != 0 || length != BLOCK_SIZE) {
    // writing a partial block -- read_ first!
    readblock (device, zone, (byte*) block);
  }
  memcpy (block+offset, buf, length);
  writeblock (device, zone, (byte*) block);
  nbyte -= length;          buf   += length;
  written_bytes += length;  curblock++;

  st->pos += length;
  if (st->pos > inode->i_size)  inode->i_size = st->pos;  // update size
}
  
inode->i_mtime = system_time;                             // update mtime
mx_write_inode (device, inode->ino, (struct minix2_inode*) inode);
return written_bytes;
@

The function uses 

%nouse
<<function prototypes>>=
int mx_create_new_zone (int device, int blockno, struct int_minix2_inode *inode);
@ which requests a new block and inserts it in the inode's block list: The argument [[blockno]] is the logical block number (as seen from the file). In the function, [[zone]] is the physical block (zone) number that is assigned to the logical block.

<<minix filesystem implementation>>=
int mx_create_new_zone (int device, int blockno, struct int_minix2_inode *inode) {
  int zone = mx_request_block (device);  // new data block
  if (zone == -1) {
    printf ("ERROR: cannot reserve data block; disk full\n");
    return -1;
  }
  int indirect_zone, double_indirect_zone;
  int *zone_ptr;
  byte indirect_block[BLOCK_SIZE] = { 0 };
  byte double_indirect_block[BLOCK_SIZE] = { 0 };
  if (blockno < 7) {
    <<create new zone: direct>>
  } else if (blockno >= 7 && blockno < 7+BLOCKADDRESSES_PER_BLOCK) {
    <<create new zone: single indirect>>
  } else {
    <<create new zone: double indirect>>
  }
  return zone;
}
@ %def mx_create_new_zone

\index{indirection}%
\noindent
with the following three cases for direct, indirect and double indirect blocks---they are similar to the three cases in the [[fileblocktozone]] function. If we deal with a direct zone, we can directly enter the zone number in the inode:

\pagebreak

<<create new zone: direct>>=
// the first 7 zone numbers (0..6) are in the inode:
inode->i_zone[blockno] = zone;
debug_printf ("\nADD DIRECT: %d\n", zone);    // REMOVE_DEBUGGING_CODE
@

In case of single indirection, we may have to create the indirection block which requires another call of [[mx_request_block]].

\index{single indirection}%
<<create new zone: single indirect>>=
indirect_zone = inode->i_zone[7];

// if there is no indirection block yet, create it
if (indirect_zone == 0) {
  // no indirection block found
  indirect_zone = mx_request_block (device);  // data block for indirections
  if (indirect_zone == -1) {
    debug_printf ("cannot reserve indirection "    // REMOVE_DEBUGGING_CODE
                  "block; disk full\n");           // REMOVE_DEBUGGING_CODE
    mx_clear_zmap_bit (device, zone);         // undo reservation of data block
    return -1;
  }
  inode->i_zone[7] = indirect_zone;
} else {
  // indirection block exists: read it
  readblock (device, indirect_zone, (byte *) indirect_block);
}
debug_printf ("\nINDIRECTIONS IN: %d, ", indirect_zone);    // REMOVE_DEBUGGING_CODE

zone_ptr = (int *) indirect_block;
zone_ptr += (blockno - 7);
*zone_ptr = zone;   // write_ information about new data block
// printf ("DEBUG: writeblock, indirect_zone = %d\n", indirect_zone);  // REMOVE_DEBUGGING_CODE
writeblock (device, indirect_zone, (byte *) indirect_block);
debug_printf ("ADD INDIRECT: %d\n", zone);    // REMOVE_DEBUGGING_CODE
@

\index{double indirection}%
Finally, in the case of double indirection, the worst that can happen is that we need to create both the first and the second indirection block. In both cases (single and double indirection) we use the same offset calculations as in [[fileblocktozone()]].

\enlargethispage{3mm}

<<create new zone: double indirect>>=
double_indirect_zone = inode->i_zone[8];

// if there is no double indirection block yet, create it
if (double_indirect_zone == 0) {
  // no double indirection block found
  double_indirect_zone = mx_request_block (device);  // data block for 2x indir.
  if (double_indirect_zone == -1) {
    debug_printf ("cannot reserve double "              // REMOVE_DEBUGGING_CODE
                  "indirection block; disk full\n");    // REMOVE_DEBUGGING_CODE
    mx_clear_zmap_bit (device, zone);    // undo reservation of data block
    return -1;
  }
  inode->i_zone[8] = double_indirect_zone;
} else {
  // indirection block exists: read_ it
  readblock (device, double_indirect_zone, (byte *) double_indirect_block);
}

zone_ptr = (int *) double_indirect_block;
zone_ptr += (blockno - 7 - BLOCKADDRESSES_PER_BLOCK) / BLOCKADDRESSES_PER_BLOCK;
indirect_zone = *zone_ptr;

// if there is no indirection block yet, create it
if (indirect_zone == 0) {
  // no indirection block found
  indirect_zone = mx_request_block (device);  // data block for indirections
  if (indirect_zone == -1) {
    debug_printf ("cannot reserve indirection "    // REMOVE_DEBUGGING_CODE
                  "block; disk full\n");           // REMOVE_DEBUGGING_CODE
    mx_clear_zmap_bit (device, zone);   // undo reservation of data block
    return -1;
  }
  
  // write_ to first level indirection block
  *zone_ptr = indirect_zone;
  writeblock (device, double_indirect_zone, (byte *) double_indirect_block);
} else {
  // indirection block exists: read_ it
  readblock (device, indirect_zone, (byte *) indirect_block);
}

zone_ptr = (int *) indirect_block;
zone_ptr += (blockno - 7) % BLOCKADDRESSES_PER_BLOCK;

*zone_ptr = zone;   // write_ information about new data block
// printf ("DEBUG: writeblock, indirect_zone = %d\n", indirect_zone);  // REMOVE_DEBUGGING_CODE
writeblock (device, indirect_zone, (byte *) indirect_block);
debug_printf ("ADD DOUBLE INDIRECT: %d\n", zone);    // REMOVE_DEBUGGING_CODE
@

What's still missing is a way to create a new (empty) file. The function

%nouse
<<function prototypes>>=
int mx_creat_empty_file (int device, const char *path, int mode);
@ requests a new inode, fills it with the appropriate data and writes it to disk. Then it writes a link into the directory that will hold the file.

\enlargethispage{5mm}
%BREAK BEFORE DEFINES
<<minix filesystem implementation>>=
int mx_creat_empty_file (int device, const char *path, int mode) {
  int inodenr = mx_request_inode (device);
  struct minix2_inode inode = { 0 };
  inode.i_size = 0;
  inode.i_atime = inode.i_ctime = inode.i_mtime = system_time;
  inode.i_uid = thread_table[current_task].uid;
  inode.i_gid = thread_table[current_task].gid;
  inode.i_nlinks = 0;
  inode.i_mode = S_IFREG | mode;
  mx_write_inode (device, inodenr, &inode);
  mx_write_link (device, inodenr, path);  // create directory entry
  return inodenr;
}
@ %def mx_creat_empty_file


\subsection{Linking and Unlinking}

Unix systems have no [[delete]]\marginnote{file deletion} or [[erase]] system calls for
files---instead there is an \verb#unlink# system call which removes
a directory entry (it deletes the link from a filename to an inode
in that directory). Only if the last name was deleted,
\verb#unlink# will also delete the file, which means freeing all data
blocks and the inode.

The opposite operation is creating a hardlink: This creates a new
name (a new link from a filename to an inode in some directory).

Both operations modify an inode's \emph{link count}\marginnote{link count}: That is where the
filesystem keeps track of how many names were given to a file.

We will start by showing two helper functions which can check whether a file exists and whether it is a directory, then we implement the [[link]] operation since it is the simpler one (of [[link]] and \verb#unlink#).

%nouse
<<function prototypes>>=
boolean mx_file_exists (int device, const char *path);
boolean mx_file_is_directory (int device, const char *path);
int mx_link (int device, const char *path1, const char *path2);
@

<<minix filesystem implementation>>=
boolean mx_file_exists (int device, const char *path) {
  if (mx_pathname_to_ino (device, path) == -1)  return false;
  return true;
}

boolean mx_file_is_directory (int device, const char *path) {
  int ino = mx_pathname_to_ino (device, path);
  if (ino == -1)  return false;                      // does not exist
  struct minix2_inode inode;
  mx_read_inode (device, ino, &inode);
  if ((inode.i_mode & S_IFDIR) == 0)  return false;  // no directory
  return true;
}
@ %def mx_file_exists mx_file_is_directory


\subsubsection{\texttt{mx\_link}}

\index{file!hard link}\index{hard link}\index{link!hard link}%
The [[mx_link]] function checks both paths and writes the link. Note that this implementation lets users create hard links of directories which is normally forbidden. We do check the condition but only print a warning because it is interesting to ``play'' with hard-linked directories.\index{link count}


<<minix filesystem implementation>>=
int mx_link (int device, const char *path1, const char *path2) {
  // check path1 exists
  if (!mx_file_exists (device, path1))  return -1;  // does not exist
  
  // check path1 is not a directory
  if (mx_file_is_directory (device, path1)) {
    printf ("ln: warning: %s is a directory. This option will be removed.\n");
  }
  
  // check path2 does NOT exist
  if (mx_file_exists (device, path2)) {
    return -1;   // path2 already exists; no forced linking
  }
  
  // everything ok now
  int ino = mx_pathname_to_ino (device, path1);
  mx_write_link (device, ino, path2);   // updates link count
  return 0;
}
@ %def mx_link


\subsubsection{\texttt{mx\_unlink}}

\index{file!unlink}\index{unlink}\index{link!unlink}%
\index{file!delete|see{file $\rightarrow$ unlink}}%
\index{deleting a file}%
Unlinking is similar as long as at least one filename (one link)
remains. If none remains, the data blocks of the file and the inode must be
freed.\index{link count}\index{inode!remove if link count is 0}

%nouse
<<function prototypes>>=
int mx_unlink (int device, const char *path);
@

<<minix filesystem implementation>>=
int mx_unlink (int device, const char *path) {
  char ind_block[BLOCK_SIZE], double_ind_block[BLOCK_SIZE];
  struct minix_dir_entry dentry;

  // check if path exists
  if (!mx_file_exists (device, path)) {
    printf ("rm: file does not exist\n");
    return -1;                             // error: path does not exist
  }
  
  // get inodes of file and directory
  int inodenr = mx_pathname_to_ino (device, path);
  struct minix2_inode inode;
  mx_read_inode (device, inodenr, &inode);
  char dir[256], base[30];
  splitpath (path, dir, base);            // split path into dir and base
  int dir_inodenr = mx_pathname_to_ino (device, dir);
  // printf ("dir_inodenr is %d\n", dir_inodenr);   // REMOVE_DEBUGGING_CODE

  // delete entry in directory
  boolean found = false;
  for (int i = 0;  i < 32*7;  i++) {
    mx_read_dir_entry (device, dir_inodenr, i, &dentry);
    if ( dentry.inode==inodenr && strequal (dentry.name, base) ) {
      dentry.inode = 0;
      memset (dentry.name, 0, 30);
      found = true;
      mx_write_dir_entry (device, dir_inodenr, i, &dentry);
      break;  // search finished
    }
  }
  if (found==false) { return -1; }  // error: not found in directory
  
  inode.i_nlinks--;   // one name less
  if (inode.i_nlinks == 0) { <<free this inode>> }
  mx_write_inode (device, inodenr, &inode);
  return 0;
}
@ %def mx_unlink

We must take care of the case when the last link has been
removed---then we have an inode with a reference count of 0, and
that means, the file is truly to be deleted: We need to mark its
data blocks as free (including an indirection block, if it exists)
and also mark the inode as free. We show this action in four 
separate steps:

\index{indirection}%
<<free this inode>>=
<<free this inode: (1) direct blocks>>
<<free this inode: (2) single indirect blocks>>
<<free this inode: (3) double indirect blocks>>
<<free this inode: (4) inode itself>>
@

<<free this inode: (1) direct blocks>>=
for (int i = 0;  i < 7;  i++) {
  if (inode.i_zone[i] != 0) {
    mx_clear_zmap_bit (device, inode.i_zone[i] - 33);  // mark data block as free
    inode.i_zone[i] = 0;
  }
}
@

\pagebreak

\index{single indirection}%
For single indirection, we clear both the zone map entries for the indirection block itself and all the blocks it points to.

<<free this inode: (2) single indirect blocks>>=
if (inode.i_zone[7] != 0) {
  readblock (device, inode.i_zone[7], ind_block);
  unsigned int *zoneno;
  zoneno = (unsigned int*)ind_block;      // cast to uint*
  int count = 0;
  while (*zoneno != 0 && count < 256) {
    mx_clear_zmap_bit (device, *zoneno - 33);        // mark data block as free
    zoneno++;
    count++;
  }
  mx_clear_zmap_bit (device, inode.i_zone[7] - 33);  // mark indir. block as free
  inode.i_zone[7] = 0;
}
@

And in case of double indirection, there are even more blocks to mark as free:

\index{double indirection}%
<<free this inode: (3) double indirect blocks>>=
if (inode.i_zone[8] != 0) {
  readblock (device, inode.i_zone[8], double_ind_block);

  unsigned int *ind_zoneno;
  ind_zoneno = (unsigned int*)double_ind_block;     // cast to uint*
  
  int count1 = 0;
  int count2;
  while (*ind_zoneno != 0 && count1 < 256) {
    // printf ("re" "ad block %d\n", *ind_zoneno);   // REMOVE_DEBUGGING_CODE
    readblock (device, *ind_zoneno, ind_block);
    unsigned int *zoneno;
    zoneno = (unsigned int*)ind_block;              // cast to uint*
    count2 = 0;
    while (*zoneno != 0 && count2 < 256) {
      mx_clear_zmap_bit (device, *zoneno - 33);     // mark data block as free
      zoneno++;
      count2++;
    }
    mx_clear_zmap_bit (device, *ind_zoneno - 33);   // mark indir. block as free
    ind_zoneno++;
    count1++;
  }

  mx_clear_zmap_bit (device, inode.i_zone[8] - 33); // mark double ind. block free
  inode.i_zone[8] = 0;
}
@

\pagebreak

Last, we free the inode:

<<free this inode: (4) inode itself>>=
// printf ("Freeing inode %d\n", inodenr);   // REMOVE_DEBUGGING_CODE
mx_clear_imap_bit (device, inodenr);
@


\subsubsection{\texttt{mx\_symlink}}

\index{file!soft link}\index{soft link}\index{link!soft link}%
Unix systems also know a second type of link, the \emph{symbolic}\marginnote{symbolic link} or \emph{soft link} (short: \emph{symlink}). While this name reminds of the (hard) links for which we have just
provided the implementation, and even the same Unix tool ([[ln]]) handles
both hard and soft links, these two link types have nothing in common.

A symbolic link is a special file which contains a path name as data.
When you disable the treatment of symbolic links on a Unix system
and try to read such a file, all you get is the stored path name: Figure
\ref{fig:symlink-as-file} shows how \UlixI{} displayed the content of a 
symbolic link before symlinks were implemented: [[ulix.symlink]] was
created by executing
\begin{Verbatim}
ln -s ulix.h ulix.symlink
\end{Verbatim}
\noindent
on a Linux system which had loop-mounted the Minix filesystem: As you can
see from the letter [[l]] at the start of the file entry, \UlixI{} already
recognized the file type but did not know better than to output the
contents of the file's first data block.
\vspace{2mm}

\begin{figure}[h]
\centering
\includegraphics[width=13cm]{pics/symlink-as-file-invert.png}
\caption[Displaying a symbolic link (in an old \UlixI{} version).]{\UlixI{} version 0.08 displays the contents of a symbolic link---in that version symbolic links were not yet implemented. (The image was inverted for better readability.)}
\label{fig:symlink-as-file}
\end{figure}


As you can see, creating a symlink is easy: We just write the link target
into a data block and mark the file as symlink:

%nouse
<<function prototypes>>=
int mx_symlink (int device, char *path1, char *path2);
@

<<minix filesystem implementation>>=
int mx_symlink (int device, char *path1, char *path2) {
  int fd = mx_open (device, path2, O_WRONLY | O_CREAT);
  if (fd == -1)  return -1;    // error: cannot create file
  mx_write (fd, path1, strlen (path1));
  mx_close (fd);
@ %def mx_symlink

(Note that we do \emph{not} write a terminating [[\0]] character: The
link target need not be terminated, the length of the filename is simply
the symlink's file size.)

We're not finished yet---now we have a regular file with the link target in
the first data block. We need to turn it into a symlink:

<<minix filesystem implementation>>=
  int inode_nr = mx_pathname_to_ino (device, path2);
  struct minix2_inode inode;
  mx_read_inode (device, inode_nr, &inode);
  inode.i_mode = S_IFLNK | 0777;
  mx_write_inode (device, inode_nr, &inode);
  return 0;  // OK.
}
@

We've set the symlink's access rights to 0777 ([[rwxrwxrwx]]) which is the default value on Linux\index{Linux} machines. The rights do not matter much anyway since reading, writing or executing the linked file requires the target to grant the needed access permissions.


\subsection{Truncating Files}

\index{file!truncate}\index{truncating a file}%
Sometimes is is necessary to truncate a file, i.\,e., to reduce its file size by cutting off everything after a given offset. A special case is deleting all the content (setting the file size to 0). For emptying the file, we could simply delete and recreate it, but that might give the new version a different inode number, and also that is impossible with an open file.

On other Unix systems, the truncate functions can also grow a file (by supplying a [[length]] argument that is larger than the current size); we do not support this feature.

%nouse
<<function prototypes>>=
int mx_ftruncate (int mfd, int length);
@

<<minix filesystem implementation>>=
int mx_ftruncate (int mfd, int length) {
  // printf ("DEBUG: mx_ftruncate entered\n");            // REMOVE_DEBUGGING_CODE
  if (mfd < 0 || mfd >= MX_MAX_FILES)  return -1;    // wrong mfd number
  struct mx_filestat      *st    = &mx_status[mfd];
  struct int_minix2_inode *inode = st->int_inode;
  if (inode == NULL)  return -1;                    // no open_ file
  short device = inode->device;
  
  if (inode->i_size <= length)  return -1;           // attempt to grow the file

  // calculate blocks to delete
  int last_kept_byte = length - 1;
  int firstblock;
  if (length == 0)  firstblock = 0;
  else              firstblock = last_kept_byte / BLOCK_SIZE + 1;
  int lastblock  = inode->i_size / BLOCK_SIZE - 1;
  
  if (lastblock >= firstblock) {    // any blocks to delete?
    for (int i = firstblock;  i <= lastblock; i++) {
      // delete block
      int zone = fileblocktozone (device, i, inode);
      printf ("DELETE ZONE %d\n", zone);               // REMOVE_DEBUGGING_CODE
      mx_clear_zmap_bit (device, zone);
    }
  }

  // check indirection blocks
  if (lastblock > 6   && inode->i_zone[7] != 0) { 
    <<[[mx_ftruncate]]: free single indirection block>> 
  }
  if (lastblock > 262 && inode->i_zone[8] != 0) {
    <<[[mx_ftruncate]]: free double indirection block>>
  }  
  
  // reset size and write_ changed inode
  inode->i_size = length;
  inode->clean  = false;    // inode was changed
  // mx_write_inode (device, inode->ino, (struct minix2_inode*)inode); // REMOVE_DEBUGGING_CODE
  // printf ("DEBUG: mx_ftruncate finished\n");                        // REMOVE_DEBUGGING_CODE
  return 0;
}
@ %def mx_ftruncate

We do not implement the [[<<[[mx_ftruncate]]: free single indirection block>>]] and [[<<[[mx_ftruncate]]: free double indirection block>>]] code chunks since they are basically a rewrite of corresponding chunks in [[fileblocktozone]]. Instead of looking up a zone number, it must be set to 0. Thus, when we truncate a file, single and double indirection blocks remain in use (and linked by the inode); they will however be destroyed when the file is finally deleted, and they will also be reused when the file grows again.

\pagebreak


\subsection{Making and Removing Directories}
\index{directory}

What's left is code for creating and deleting directories. Similar to
symlinks, directories are just a special type of file, and we already
know how to modify existing directories.

Deleting a directory means to free the data blocks that had been used
by it and to remove its entry in the super-directory (the directory 
which is one step closer to the filesystem root and contains it)---this
task is already handled by the [[mx_unlink]] function, so we need no
further code in the kernel. Actually, we could provide an [[mx_rmdir]]
function which is simpler than [[mx_unlink]] since directories must 
not be hard-linked: if we remove a directory, we always remove its
inode.

For making a directory, we could do this as the logical three-step-procedure
that is involded:

\begin{itemize}
\item create the (empty) directory,
\item within the new directory, create a hard link [[.]] to itself,
\item and also create a hard link [[..]]---either to the super-directory
or to [[/]] in case of the root directory [[/]]. But the kernel will
never create a root directory (that's handled by the user mode tool 
[[mkfs.minix]])
\end{itemize}

Also, all new directories look identical except for the two hard links 
[[.]] and [[..]], so we will keep our task simple by defining what the
contents of a new directory look like (data-bock-wise) and how to
update the inode numbers in the [[.]] and [[..]] entries.

The ``[[.]]'' character (dot) has the ASCII value 46, or 0x2E in hexadecimal
code. A hexdump of the data area of a Minix filesystem shows the following
contents for an empty directory:

\begin{Verbatim}
$ hexdump -C /tmp/minixdata.img
[...]
00013000  08 00 2e 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013020  01 00 2e 2e 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00013030  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
[...]
\end{Verbatim}

This shows a directory on the top level with inode number 8. The first two lines
contain the directory entry for [[.]] (pointing to itself: [[08 00]]) and the
last two lines hold the directory entry for [[..]] (pointing to the root directory 
which has inode number 1 ([[01 00]]).

The size of such an entry is 64:

\begin{Verbatim}
$ ls -ld /mnt/minix/empty
drwxr-xr-x 2 esser esser 64 Jul 17 16:13 /mnt/minix/empty
\end{Verbatim}

The code for creating a directory with
\index{directory!make}%

%nouse
<<function prototypes>>=
int mx_mkdir (int device, const char *path, int mode);
@ is as follows:

<<minix filesystem implementation>>=
int mx_mkdir (int device, const char *path, int mode) {
  struct minix_dir_entry entry = { 0 };
  char dir[256]; char base[256];
  int dir_inodenr, new_inodenr;
  struct minix2_inode inode;

  splitpath (path, dir, base);                     // split path into dir and base
  dir_inodenr = mx_pathname_to_ino (device, dir);

  // create new file
  int fd = mx_open (device, path, O_CREAT | O_WRONLY); mx_close (fd);
  new_inodenr = mx_pathname_to_ino (device, path);

  // enter "." and ".." inode numbers
  fd = mx_open (device, path, O_WRONLY);
  memset (&entry, 0, 32); memcpy (entry.name, ".", 2);  entry.inode = new_inodenr;
  mx_write (fd, &entry, 32);
  memset (&entry, 0, 32); memcpy (entry.name, "..", 3); entry.inode = dir_inodenr;
  mx_write (fd, &entry, 32);
  mx_close (fd);

  // fix inode (make it type directory, set nlinks to 2)
  mx_read_inode (device, new_inodenr, &inode);
  inode.i_mode = S_IFDIR | (mode & 0777);          // set mode
  inode.i_uid = thread_table[current_task].euid;   // set UID
  inode.i_gid = thread_table[current_task].egid;   // set GID
  inode.i_nlinks = 2;
  mx_write_inode (device, new_inodenr, &inode);
  
  // update link count of directory above
  mx_read_inode (device, dir_inodenr, &inode);
  inode.i_nlinks++;
  mx_write_inode (device, dir_inodenr, &inode);
  return 0;
}
@ %def mx_mkdir

Deleting a directory via
\index{directory!remove}%

%nouse
<<function prototypes>>=
int mx_rmdir (int device, const char *fullpath, const char *path);
@ % 
is only allowed if [[.]] and [[..]] are its only
entries. If so, we first unlink those two and then remove the
directory (file). Note that the function expects two path
arguments, the full (global) path and the device-local path.
Our implementation does not use the device"=local path, but
new implementations of similar [[*_rmdir]] functions for other
filesystems might do so.

<<minix filesystem implementation>>=
int mx_rmdir (int device, const char *fullpath, const char *path) {
  struct minix_dir_entry entry;
  char abspath[256]; char dir[256]; char base[256]; char cwd[256];
  int dir_inodenr, new_inodenr;
  struct minix2_inode inode;

  // check relative/absolute path
  if (*path != '/')  relpath_to_abspath (fullpath, abspath);
  else               strncpy (abspath, fullpath, 256);
  
  // check if directory exists
  int fd = u_open ((char*)fullpath, O_RDONLY, 0);
  if (fd == -1) { return -1; }
  u_close (fd);
  
  // split path into dir and base
  splitpath (abspath, dir, base);
  
  // save current working directory
  u_getcwd ((char*)cwd, 256);
  
  if (mx_directory_is_empty (device, path)) {
    if (u_chdir (dir) == -1) { return -1; }
    if (u_unlink (".")      == -1) { u_chdir (cwd); return -1; }
    if (u_unlink ("..")     == -1) { u_chdir (cwd); return -1; }
    if (u_unlink (fullpath) == -1) { u_chdir (cwd); return -1; }
    
    u_chdir (cwd);   // restore old current working directory
    return 0;
  }
  printf ("Directory not empty\n");
  return -1;   // not empty
}
@ %def mx_rmdir


We still need the function [[mx_directory_is_empty]] which could check
the file size of a directory: if it is 64 then the directory should contain
only the [[.]] and [[..]] entries. Our
%nouse
<<function prototypes>>=
boolean mx_directory_is_empty (int device, const char *path);
@ %

\pagebreak
\noindent
function expects that the provided [[path]] argument is already a
(device-local) absolute path, i.\,e., it starts with a slash. It does
not use the size check but queries individual directory entries instead
because we don't always update the directory size when we delete
files.

<<minix filesystem implementation>>=
boolean mx_directory_is_empty (int device, const char *path) {
  int count = 0;  // number of entries
  struct dir_entry d = { 0 };
  for (int i = 0;  i < 32 * 7;  i++) {
    if (mx_getdent (device, path, i, &d) == 0 && d.inode != 0) count++;
  }
  return (count == 2);
}
@ %def mx_directory_is_empty

The function uses [[mx_getdent()]] which we present in the following section.


\subsection{Listing a Directory}

In order to retrieve the information stored in the inode of a file,
all Unix systems offer a [[stat]] function which fills a status
structure with content. What that structure looks like depends on the
flavor of Unix; for \Ulix{} we use the [[struct stat]] definition as
it is shown in the Linux\index{Linux!stat structure@\texttt{stat} structure} man page \verb#stat(2)#, but without the
[[st_blksize]] and [[st_blocks]] entries:

\index{file!status}%
<<public type definitions>>=
struct stat {
  unsigned int   st_dev;     // ID of device containing file
  unsigned short st_ino;     // inode number
  unsigned short st_mode;    // protection
  unsigned short st_nlink;   // number of hard links
  unsigned short st_uid;     // user ID of owner
  unsigned short st_gid;     // group ID of owner
  unsigned short st_rdev;    // device ID (if special file)
  unsigned int   st_size;    // total size, in bytes
  unsigned int   st_atime;   // time of last access
  unsigned int   st_mtime;   // time of last modification
  unsigned int   st_ctime;   // time of last status change
};
@ %def stat

We have not prefixed the type name with [[mx_]] because we
use it for all supported filesystems. However, there are several
[[*_stat]] functions that retrieve the data---one for each
supported filesystem. As part of the Minix filesystem implementation,
we provide the

\enlargethispage{5mm}
%nouse
<<function prototypes>>=
int mx_stat (int device, const char *path, struct stat *buf);
@ %

\noindent
function which simply locates the inode and copies the data
into a [[struct stat]] variable:

\pagebreak

<<minix filesystem implementation>>=
int mx_stat (int device, const char *path, struct stat *buf) {
  struct minix2_inode inode;
  int ino = mx_pathname_to_ino (device, path);
  if (ino == -1) return -1;                              // error
  buf->st_dev   = device;            buf->st_rdev  = 0;
  buf->st_ino   = ino;
  mx_read_inode (device, ino, &inode);                   // read the inode
  buf->st_mode  = inode.i_mode;      buf->st_nlink = inode.i_nlinks;
  buf->st_uid   = inode.i_uid;       buf->st_gid   = inode.i_gid;
  buf->st_size  = inode.i_size;      buf->st_atime = inode.i_atime;
  buf->st_ctime = inode.i_ctime;     buf->st_mtime = inode.i_mtime;
  return 0;  
}
@ %def mx_stat

We define the generic directory entry structure [[struct dir_entry]] that is
similar to the Minix structure [[struct minix_dir_entry]] but allows longer
filenames.

<<public type definitions>>=
struct dir_entry {
  word inode;              // inode number
  byte filename[64];       // filename
};
@ %def dir_entry

The function
\index{directory!get entries}%
\index{list directory entries}%

%nouse
<<function prototypes>>=
int mx_getdent (int device, const char *path, int index, struct dir_entry *buf);
@ %
fills a [[struct dir_entry]] buffer with the data found in the Minix inode on
disk via the \linebreak [[mx_read_dir_entry]] function.

<<minix filesystem implementation>>=
int mx_getdent (int device, const char *path, int index, struct dir_entry *buf) {
  struct minix_dir_entry d;
  struct stat s;

  int ret = mx_stat (device, path, &s);
  if (ret == -1) return -1;             // error does not exist

  if (index*32 >= s.st_size) return -1; //  index out of bounds

  int ino = mx_pathname_to_ino (device, path);
  if (ino == -1) return -1;             // error: not a directory

  ret = mx_read_dir_entry (device, ino, index, &d);
  if (ret == -1) return -1;             // error: no such entry in directory
  buf->inode = d.inode;
  strncpy ((char*)(buf->filename), d.name, 30);
  d.name[30] = 0;                       // terminate string
  return 0;                             // success
}
@ %def mx_getdent


\subsection{Filesystem Information: \texttt{df}}

\index{df program@\texttt{df} program}%
In order to implement a [[df]] (disk free) application we need a method
to query the number of free blocks on a filesystem. As we will only support
this for the Minix filesystem, we do not provide a generic layer (as part
of the virtual filesystem) but directly write a Minix"=specific function.
It will fill [[struct diskfree_query]] structures:

%nouse
<<public type definitions>>=
struct diskfree_query {
  int device;         // device ID (is set before calling mx_diskfree)
  int size;           // size of filesystem, in blocks
  int used;           // number of used blocks
  int free;           // number of free blocks (redundant; == size-used)
  char name[10];      // name (such as "/dev/hda")
  char mount[256];    // mount point
  char fstype[10];    // filesystem name, e.g. "minix"
};
@ %def diskfree_query

The goal is to implement 

<<function prototypes>>=
void mx_diskfree (struct diskfree_query *query);
@

\noindent
which will use the helper function

%BREAK BEFORE DEFINES
<<minix filesystem implementation>>=
int count_zeros (byte *block, int maxcount) {
  int count = 0; 
  for (int i = 0;  i < (maxcount+7)/8;  i++) {
    if (block[i] == 0) { count += 8; } 
    else {
      for (int j = 0;  j < 8;  j++) {
        if (i*8 + j < maxcount && (block[i] >> j) % 2 == 0) count++;
      }
    }
  }
  return count;
}
@ %def count_zeros
\noindent
which counts the number of zero bits in a given block, but only up to the bit position specified by the [[maxcount]] parameter. (We can slightly optimize the counting by checking whether a byte is 0, in that case we can add 8 to the counter; this assumes that [[maxcount]] is always a multiple of 8.)

[[mx_diskfree]] takes the [[device]] element of the structure as an argument, reads all zone map blocks of that device and counts the contained zeros. That gives us the number of free blocks. The other values are taken from the mount table or the superblock (or we calculate them).

<<minix filesystem implementation>>=
void mx_diskfree (struct diskfree_query *query) {
  int device = query->device;
  struct minix_superblock sblock;
  char block[1024];
  query->size = mx_query_superblock (device, MX_SB_ZONES);
  unsigned int nblocks = mx_query_superblock (device, MX_SB_ZONES);
  unsigned int zmap_start = 2 + mx_query_superblock (device, MX_SB_IMAP_BLOCKS);
  unsigned int free_blocks = 0;
  for (int i = 0; i < mx_query_superblock (device, MX_SB_ZMAP_BLOCKS); i++) {
    readblock (device, zmap_start + i, (byte*)&block);
    if ((i+1)*8192 < query->size)
      free_blocks += count_zeros ((byte*)&block, 8192);
    else
      free_blocks += count_zeros ((byte*)&block, query->size - i*8192);
  }
  query->free = free_blocks;
  query->used = query->size - free_blocks;

  // find device name  
  switch (device) {
    case DEV_HDA: strncpy (query->name, "/dev/hda", 10); break;
    case DEV_HDB: strncpy (query->name, "/dev/hdb", 10); break;
    case DEV_FD0: strncpy (query->name, "/dev/fd0", 10); break;
    case DEV_FD1: strncpy (query->name, "/dev/fd1", 10); break;
    default:      strncpy (query->name, "unknown",  10); break;
  }
  
  // find mount point
  boolean mounted = false;
  for (int i=0; i<current_mounts; i++) {
    if (mount_table[i].device == device) {
      strncpy (query->fstype, fs_names[mount_table[i].fstype], 10);
      strncpy (query->mount,  mount_table[i].mountpoint, 255);
      mounted = true;
      break;
    }
  }
  if (!mounted) {
    strncpy (query->fstype, "none", 10);
    strncpy (query->mount,  "none", 10);
  }
}
@ %def mx_diskfree

We provide a system call handler

\syscallindex{diskfree}%
%nouse
<<syscall prototypes>>=
void syscall_diskfree (context_t *r);
@

<<syscall functions>>=
void syscall_diskfree (context_t *r) {
  // ebx: address of diskfree query structure
  mx_diskfree ((struct diskfree_query*)r->ebx);
}
@ %def syscall_diskfree
and register it: 

<<ulix system calls>>=
#define __NR_diskfree  522
@ %def __NR_diskfree

<<initialize syscalls>>=
install_syscall_handler (__NR_diskfree, syscall_diskfree);
@

User mode applications can then ask for the information by writing a value into the [[device]] field of a [[diskfree_query]] structure and calling

%nouse
<<ulixlib function prototypes>>=
void diskfree (struct diskfree_query *query);
@ which fills the other fields.

<<ulixlib function implementations>>=
void diskfree (struct diskfree_query *query) {
  syscall2 (__NR_diskfree, (unsigned int)query);
}
@ %def diskfree


\section{The \texttt{/dev} Filesystem}
\label{sec:dev-filesystem}
\index{filesystem!device filesystem}%
\index{device filesystem}%

This section provides an interface to block devices (via [[/dev/fd0]],
[[/dev/fd1]], [[/dev/hda]] and [[/dev/hdb]]) and the physical memory
(via [[/dev/kmem]]). We have not designed the code in a way that
would easily allow extensions to other device classes (however, a third
or fourth hard disk would be easy to add).

The [[/dev]] filesystem must be mounted on [[/dev/]], so the filesystem
itself has only the root directory and the following five files which 
reside inside:

\begin{multicols}{2}
<<constants>>=
#define DEV_HDA_NAME   "hda"
#define DEV_HDB_NAME   "hdb"
#define DEV_FD0_NAME   "fd0"
#define DEV_FD1_NAME   "fd1"
#define DEV_KMEM_NAME  "kmem"
#define DEV_FD0_INODE  3
#define DEV_FD1_INODE  4
#define DEV_HDA_INODE  5
#define DEV_HDB_INODE  6
#define DEV_KMEM_INODE 7
@ %def DEV_HDA_NAME DEV_HDB_NAME DEV_FD0_NAME DEV_FD1_NAME DEV_KMEM_NAME DEV_HDA_INODE DEV_HDB_INODE DEV_FD0_INODE DEV_FD1_INODE DEV_KMEM_INODE
\vspace{5mm}
\end{multicols}

We will simulate behavior of the Minix filesystem for our [[/dev]]
filesystem so that the function which inspects a directory works
with the [[/dev/]] directory as well.

\index{directory}%
<<global variables>>=
struct minix_dir_entry dev_directory[7] = {
  { 1, "." },          { 2, ".." },         { 3, DEV_FD0_NAME }, 
  { 4, DEV_FD1_NAME }, { 5, DEV_HDA_NAME }, { 6, DEV_HDB_NAME },
  { 7, DEV_KMEM_NAME } };  
@ %def dev_directory

Opening a file works similar to the way we have implemented it for the
Minix filesystem, it is just a bit simpler:

%nouse
<<function prototypes>>=
int dev_open (const char *path, int oflag);
@ Note that, different from [[mx_open]], it does not take a [[device]]
argument.

We will keep a list of open file descriptors:

\index{file!status}%
<<type definitions>>=
struct dev_filestat { 
  short dev;
  int pos;
  short mode;
};
@ %def dev_filestat

\pagebreak

\noindent
and allow up to 32 simultaneously open files:

<<constants>>=
#define MAX_DEV_FILES 32
@ %def MAX_DEV_FILES

So, similar to the [[mx_status]] array, we declare a [[dev_status]] array that holds the same kind of information:

<<global variables>>=
struct dev_filestat dev_status[MAX_DEV_FILES] = { { 0 } };
@ %def dev_status

The [[dev_open]] function is much simpler than [[mx_open]] because we know exactly which files can be opened. We identify the inode number with the index into the table [[dev_directory]] (plus 1, as we start counting inodes at number 1).

\index{file!open}\index{opening a file}%
<<function implementations>>=
int dev_open (const char *path, int oflag) {
  if ((oflag & O_CREAT) != 0)  return -1;   // cannot create
  int i, dev_inode = -1;
  
  // get the inode number
  for (i = 0;  i < 7;  i++) {
    if (strequal (path+1, dev_directory[i].name)) {
      // found!
      dev_inode = dev_directory[i].inode;  // which is always i...
      break;
    }
  }
  if (dev_inode == -1) return -1;   // not found
  
  // find free file descriptor
  int fd = -1;
  for (i = 0;  i < MAX_DEV_FILES;  i++) {
    if (dev_status[i].dev == 0) { fd = i; break; }
  }
  if (fd == -1) return -1;          // no free file descriptor  

  switch (dev_inode) {
    case DEV_FD0_INODE : dev_status[fd].dev = DEV_FD0;  break;
    case DEV_FD1_INODE : dev_status[fd].dev = DEV_FD1;  break;
    case DEV_HDA_INODE : dev_status[fd].dev = DEV_HDA;  break;
    case DEV_HDB_INODE : dev_status[fd].dev = DEV_HDB;  break;
    case DEV_KMEM_INODE: dev_status[fd].dev = DEV_KMEM; break; 
    default: dev_status[fd].dev = -1;
  }
  dev_status[fd].pos  = 0;
  dev_status[fd].mode = oflag;     
  // REENABLE: printf ("DEBUG: dev_open, dev_inode = %d, device = %d\n", dev_inode, dev_status[fd].dev);    // REMOVE_DEBUGGING_CODE
  return fd;
}
@ %def dev_open
 
Closing a device file via
\index{file!close}\index{closing a file}%

%nouse
<<function prototypes>>=
int dev_close (int fd);
@ is much simpler:

<<function implementations>>=
int dev_close (int fd) {
  if (fd >= 0 && fd < MAX_DEV_FILES && dev_status[fd].dev != 0) {
    dev_status[fd].dev = 0;
    return 0;  // success
  } else {
    return -1; // fail
  }
}
@ %def dev_close

Finally we need [[dev_read]], [[dev_write]] and [[dev_lseek]] functions:
%nouse
<<function prototypes>>=
int dev_read (int fd, char *buf, int nbyte);
int dev_write (int fd, char *buf, int nbyte);
int dev_lseek (int fd, int offset, int whence);
@

The implementation of [[dev_read]] and [[dev_write]] is similar to the
one of [[mx_read]] and [[mx_write]] (which you have seen earlier), but it
is simpler: the new functions need not access an inode in order to
retrieve block numbers.

There is a special case for reading from memory via [[/dev/kmem]] which
does not require any block read/write operations at all: For memory access
we can simple call [[memcpy]].

\index{file!read}\index{reading from a file}%
<<function implementations>>=
int dev_read (int fd, char *buf, int nbyte) {
  <<dev filesystem: check if [[fd]] is a proper file descriptor>>
  int startbyte = dev_status[fd].pos;
  int devsize = dev_size (dev_status[fd].dev);
  if (startbyte >= devsize) { return 0; }  // nothing to read_
  int endbyte = dev_status[fd].pos + nbyte - 1;
  if (endbyte >= devsize) {
    nbyte -= (endbyte - devsize + 1);  endbyte = devsize - 1;
  }

  // special case /dev/kmem: direct memcpy()
  if (dev_status[fd].dev == DEV_KMEM) {
    memcpy (buf, (char*)(PHYSICAL(startbyte)), nbyte);
    dev_status[fd].pos += nbyte;
    return nbyte;
  }

  int readbytes = 0;  int offset, length;
  int startblock = startbyte / BLOCK_SIZE;  int curblock = startblock;  
  while (nbyte > 0) {
    byte block[BLOCK_SIZE];
    readblock (dev_status[fd].dev, curblock, (byte*) block);
    if (curblock == startblock) {
      offset = startbyte % BLOCK_SIZE;  length = MIN (nbyte, BLOCK_SIZE - offset);
    } else {
      offset = 0;                       length = MIN (nbyte, BLOCK_SIZE);
    }
    memcpy (buf, block + offset, length);
    
    nbyte -= length;      buf   += length;
    readbytes += length;  curblock++;
    dev_status[fd].pos += length;
  }
  return readbytes;
}
@ %def dev_read


Writing is only slightly more complex because the first and last block
must be read before being written:

\index{file!write}\index{writing to a file}%
<<function implementations>>=
int dev_write (int fd, char *buf, int nbyte) {
  <<dev filesystem: check if [[fd]] is a proper file descriptor>>
  int startbyte = dev_status[fd].pos;
  int devsize = dev_size (dev_status[fd].dev);
  if (startbyte >= devsize) { return 0; }  // nothing to write_
  int endbyte = dev_status[fd].pos + nbyte - 1;
  if (endbyte >= devsize) {
    nbyte -= (endbyte - devsize + 1);  endbyte = devsize - 1;
  }

  // special case /dev/kmem: direct memcpy()
  if (dev_status[fd].dev == DEV_KMEM) {
    memcpy ((char*)(PHYSICAL(startbyte)), buf, nbyte);
    dev_status[fd].pos += nbyte;
    return nbyte;
  }

  int written_bytes = 0;  int offset, length;
  int startblock = startbyte / BLOCK_SIZE;  int curblock = startblock;  
  while (nbyte > 0) {
    byte block[BLOCK_SIZE];
    if (curblock == startblock) {
      offset = startbyte % BLOCK_SIZE;  length = MIN (nbyte, BLOCK_SIZE - offset);
    } else {
      offset = 0;                       length = MIN (nbyte, BLOCK_SIZE);
    }
    
    if (offset != 0 || length != BLOCK_SIZE) {
      // writing a partial block -- read_ it first!
      readblock (dev_status[fd].dev, curblock, (byte*) block);
    }
    memcpy (block + offset, buf, length);
    writeblock (dev_status[fd].dev, curblock, (byte*) block);
    
    nbyte -= length;          buf   += length;
    written_bytes += length;  curblock++;
    dev_status[fd].pos += length;
  }
  return written_bytes;
}
@ %def dev_write

Seeking is also simple:

\index{file!seek}\index{seeking in a file}%
<<function implementations>>=
int dev_lseek (int fd, int offset, int whence) {
  <<dev filesystem: check if [[fd]] is a proper file descriptor>>
  if (whence < 0 || whence > 2)
    return -1;                           // wrong lseek option
  if (whence == SEEK_END && offset > 0)
    return -1;                           // cannot seek beyond end of device
  switch (whence) {
    case SEEK_SET: dev_status[fd].pos = offset; break;
    case SEEK_CUR: dev_status[fd].pos += offset; break;
    case SEEK_END: dev_status[fd].pos = dev_size (dev_status[fd].dev) + offset;
  };
  return dev_status[fd].pos;
}
@ %def dev_lseek

We have used a function 

%nouse
<<function prototypes>>=
long dev_size (int dev);
@ which returns the size of the drive; here is its implementation:

<<function implementations>>=
long dev_size (int dev) {
  switch (dev) {
    case DEV_FD0  : return fdd_type[fdd[0].type].total_sectors * 512;  // fd0
    case DEV_FD1  : return fdd_type[fdd[1].type].total_sectors * 512;  // fd1
    case DEV_HDA  : return hd_size[0] * 512;                           // hda
    case DEV_HDB  : return hd_size[1] * 512;                           // hdb
    case DEV_KMEM : return MEM_SIZE;                                   // kmem
    default       : return -1;                                         // error
  }
}
@ %def dev_size

In both functions for reading and writing we check whether a valid
file descriptor was supplied and return [[-1]] if not:

<<dev filesystem: check if [[fd]] is a proper file descriptor>>=
if (fd < 0 || fd >= MAX_DEV_FILES)  return -1;  // bad file descriptor
if (dev_status[fd].dev == 0)       return -1;  // file not open_
@

Last, we supply functions for querying a file and reading a directory
entry which are called from [[u_stat]] and [[u_getdent]] in the
virtual filesystem layer.

%nouse
<<function prototypes>>=
int dev_stat (const char *path, struct stat *buf);
int dev_getdent (const char *path, int index, struct dir_entry *buf);
@ %

[[dev_stat]] compares the local path (which is expected to be \path!/fd0!, \path!/fd1!, \path!/hda!, \path!/hdb! or \path!/kmem!) against the list of known device names and fills the [[struct stat]] buffer:

\index{file!status}%
<<function implementations>>=
int dev_stat (const char *path, struct stat *buf) {
  int devices[] = { -1, 0, 0, DEV_FD0, DEV_FD1, DEV_HDA, DEV_HDB, DEV_KMEM };
  int dev_inode;

  for (int i = 0;  i < 7;  i++) {                      // get the inode number
    if (strequal (path+1, dev_directory[i].name)) {
      // found!
      dev_inode = dev_directory[i].inode;              // which is always i...
      break;
    }
  }
  if (dev_inode == -1) return -1;                      // not found

  // buf->st_dev   = 0;  // no device, /dev is a virtual FS
  buf->st_dev   = devices[dev_inode];
  buf->st_rdev  = 0;
  buf->st_ino   = dev_inode;
  if (dev_inode > 2)
    buf->st_mode  = S_IFBLK | 0600;   // block device; we have no char. devices
  else
    buf->st_mode  = S_IFDIR | 0600;   // directory
  buf->st_nlink = 1;    buf->st_uid   = 0;
  buf->st_gid   = 0;    buf->st_size  = dev_size (devices[dev_inode]);
  buf->st_atime = 0;    buf->st_ctime = 0;
  buf->st_mtime = 0;
  return 0;  
}
@ %def dev_stat

And [[dev_getdent]] copies an entry in the [[dev_directory]] table into the buffer (of type [[struct dir_entry]]).

<<function implementations>>=
int dev_getdent (const char *path, int index, struct dir_entry *buf) {
  if (index < 0 || index > 6) return -1;   // no such entry

  buf->inode = dev_directory[index].inode;
  strncpy (buf->filename, dev_directory[index].name, 5);
  return 0;  
}
@ %def dev_getdent


\section{Default Contents of the Filesystem}
\label{sec:fs:default-contents}%

\index{filesystem!contents of the Ulix root disk}%
\index{Ulix!contents of the root disk}%
In the last two sections we describe the directories and files that you can find on the \UlixI{} system disks and suggest two books which discuss other filesystems in depth.

Figure~\ref{fig:fs-content} shows the general tree structure of the virtual filesystem which is organized in a similar way as most Unix filesystems. The [[/bin]] directory contains executable programs, [[/etc]] is reserved for configuration files (currently the only one is \path!/etc/passwd!), [[/dev]] is the mount point for the device filesystem, and [[/home]] contains the \marginnote{home directory}\emph{home directories} of system users, it is already populated with two home directories that ``belong'' to us (the authors of this book). They correspond to identical user names in the \path!/etc/passwd! file (with the passwords set to ``xyz''). The administrator [[root]] has the home directory [[/root]]; it is standard practice to place it directly in the root directory ([[/]]) and not below [[/home]].

\begin{figure}[th]
\centering
\includegraphics[width=13cm]{pics/fs-content.pdf}
\caption[\hgepolylof{Default contents on a fresh \UlixI{} root disk.}]{These are the contents of the \UlixI{} disk.}
\label{fig:fs-content}
\end{figure}


\section{Further Reading}

If you are interested in further details about Unix filesystem implementations,
we suggest you take a look at the following books:

\begin{itemize}
\item Steve D. Pate: ``UNIX Filesystems: Evolution, Design, and Implementation'',
2003, ISBN: 978-0-471-16483-8 \cite{pate2003unix}
\item  William von Hagen: ``Linux Filesystems'', 2002, ISBN: 978-0672322723
\cite{vonhagen2002linux}
\end{itemize}


\section{Exercises}

\begin{enumerate}
% start with ex. 36 
\setcounter{enumi}{35}

\item \textbf{Sparse Files}

Sparse files\index{sparse file}\index{file!sparse} are ``files with holes'': They have large areas which only
contain \hex{00} bytes. Storing all those zeros on disk is a waste of disk
space (and also of time for initially writing them). Modern filesystems
support a special treatment of sparse files where information about these 
holes is stored in the inode or in a separate block that is linked from 
the inode. The Minix filesystem does not support this kind of treatment,
but you can modify it so that it does.

Modify the file access functions so that a block address of $-1$ 
(\hex{FFFF}) is interpreted as a reference to a sparse area, i.\,e., an 
area completely filled with zeros. No blocks need to be allocated for
such areas. If a direct block address is $-1$, the whole (logical) block 
is considered to consist of zeros. If an indirect block address is $-1$,
it means that there is no indirection block, but the space that 
could be addressed via the indirection block (up to 256 blocks =
256 KByte) are assumed to contain zeros.

\looseness=1
Every read access to a sparse area shall return a block of zeros,
but when writing to a sparse area you need to allocate a block and
change the block number from $-1$ to the new zone number. If data is
written in the middle of a sparse indirection block, you need to
allocate another block that then serves as indirection block with
one zone number pointing to the new non-zero data block (and all 
other zone numbers set to $-1$).

Change the [[mx_write]] function so that it recognizes whether a
whole sparse block is being written (or whether the result of the
current write operation is a block full of zeros)---if so, add a new
sparse area and release the block that is no longer needed.

You will need to make some changes to the system calls and user mode
library functions so that you can test the behavior.
\vspace{2mm}

\item \textbf{Completion of the \texttt{mx\_ftruncate} Function}

Our implementation of [[mx_ftruncate]] is incomplete: It does not provide
code for the [[<<[[mx_ftruncate]]: free single indirection block>>]] and 
[[<<[[mx_ftruncate]]: free double indirection block>>]] code chunks.
Add those chunks (or modify the function otherwise) and try to do that
in an optimized way that uses as few individual inode or block write 
operations as possible.

\end{enumerate}


%---------------------------------------------------------------------




\chapter{Disk I/O}
\label{chap:ulix:disk-i-o}%

In the last chapter you saw the implementations of both the Minix and the
FAT filesystem---but what we have not discussed so far is how to actually
talk to the hardware: we used functions [[readblock]] and [[writeblock]]
to read or write kilobyte-sized chunks of data from the disk, and in this
chapter you will see how to implement this.


\section{Block and Character Devices}

\index{block device}\index{character device}%
Classically, devices are split into two categories: \emph{block devices} and
\marginnote{block device\\character device}\emph{character devices}. The difference lies in the amounts of data which are
transferred with every single request. A typical character device is the
keyboard: each key-press generates an interrupt and the amount of data
transferred is (typically) two bytes. On the other hand, disks (both 
floppy and hard disks) transfer whole chunks of data (512 bytes or
larger quantities). The
controllers for floppy and hard disks do not provide the functionality
to read/write single bytes from/to the disk, but can only handle those
larger chunks. That has consequences for code which wants to change a
single byte in a disk file: The chunk containing this byte must first
be read into memory, then modifed and finally rewritten to disk.

Block devices can be accessed in two ways: in the classical approach
drivers used the processor's [[in]] and [[out]] instructions for every
single byte that was to be transferred. Reading a 512-byte-sized chunk
of data from the disk would basically look like this:

\enlargethispage{5mm}
%nouse
<<classical disk access example>>=
out ioport1, sector         ; request data from the disk
out ioport2, READ_CMD
mov reg1, memory            ; set up target address, length of data
mov reg2, ioport3
mov reg3, length            ; for "rep"
rep insl                    ; read data (loop)
@

\pagebreak

The [[rep]] prefix in the final statement uses the [[length]] argument
stored in some register to repeat the [[insl]] instruction [[length]]
times and auto-increment the memory address so that all the bytes
coming from the disk will be stored in consecutive memory positions.

This approach requires the CPU to do a lot of work since it has to deal
will every single byte that is to be transferred. It is better to use
\emph{direct memory access} (\emph{DMA})\index{DMA (direct memory access)}\marginnote{DMA} which 
allows the disk controller to store
the data in memory without bothering the CPU.

In this chapter we will provide implementations of three device drivers:

\begin{itemize}
\item We start with a driver for a device that doesn't exist but can easily
be simulated: the ``serial disk''. This driver assumes that a disk is
connected to the serial port of the machine. The drive accepts read/write
requests and sends or receives single bytes of such a request via the
serial port. Every byte sent by the disk will generate an interrupt
(and we need to provide an interrupt handler which will then read the
newly-arrived byte via an [[in]] instruction), every byte we want to send 
to the disk must be sent explicitly via an [[out]] instruction.
\item The second driver uses the classical (non-DMA)\index{DMA (direct memory access)} approach for accessing hard disks.
It is easy to implement; a request for a 512-bytes-chunk is sent to
the controller, the controller reads the data from the disk and then
generates \emph{one} interrupt. The interrupt handler must then read all
512 bytes from the controller. We use this to access the hard disks on
the machine.
\item The third driver uses DMA\index{DMA (direct memory access)} to talk to a floppy drive: Reading a 
512-bytes-chunk also starts with requesting it from the controller, but
the transfer happens in the background. When it's finished, the controller
generates an interrupt, and the interrupt handler only needs to acknowledge
it and tell the (suspended) process that its data have arrived.
\end{itemize}

This collection of drivers thus introduces three very different approaches
for talking to mass media controllers.


\section{Device Selection}

We will provide two generic functions

%nouse
<<function prototypes>>=
void readblock  (int device, int blockno, char *buffer);
void writeblock (int device, int blockno, char *buffer);
@ which read kilobyte-sized blocks from all the devices we support.
As a naming convention for devices we use the Unix concept of
\emph{major}\marginnote{major/minor\\ number} and \emph{minor device IDs}---this lets us break down device IDs
into a device class (the major device number\index{major device number}) and the specific
device of a class (the minor device number\index{minor device number}). We use the same
numbers as Linux\index{Linux!major and minor devices} (for floppies and hard disks):

\begin{itemize}
\item Floppy drives have the major number 2, we support two 
  drives [[/dev/fd0]] and [[/dev/fd1]] with minor numbers 0 and 1. 
\item Hard disks have the major number 3, we support two drives
  [[/dev/hda]] and [[/dev/hdb]] with minor numbers 0 and 64 
  (the numbers 1--63 and 65--127 are reserved for partitions of the
  first and second hard disk, respectively,
  but we do not implement partition support for hard disks).
\item The serial disk has major number 42. There is only one of
  this kind: [[/dev/sdisk]] has minor number 0.
\end{itemize}

\noindent
We combine major and minor numbers in one 16 bit wide device number 
via [[device = major @<< 8 + minor]]. That is: the upper eight bits
of a device number contain the major number, and the lower eight bits
contain the minor number.

With that formula we can also calculate major and minor numbers from
a given device number: [[major = device @>> 8]] and [[minor = device & 0xff]].

This leads to the major, minor and device numbers shown in
Table \ref{table:device numbers}. Note that we do not provide devices
for the serial ports or the keyboard even though they are also used by
\UlixI{}---they would be examples for the class of character devices.

\begin{table}[b!]
\begin{center}
\begin{tabular}{|l|r|r|l|}
\hline
\textbf{device file} & \textbf{major} & \textbf{minor} & \textbf{device} \\
\hline
%[[/dev/ram0]]  &  1 &  0 & \hex{0100} = 256 \\
%[[/dev/ram1]]  &  1 &  1 & \hex{0101} = 257 \\
%\vdots &&&\\
%[[/dev/ram9]]  &  1 &  9 & \hex{0109} = 265 \\
%\hline
[[/dev/fd0]]   &  2 &  0 & \hex{0200} = 512 \\
[[/dev/fd1]]   &  2 &  1 & \hex{0201} = 513 \\
\hline
[[/dev/hda]]   &  3 &  0 & \hex{0300} = 768 \\
[[/dev/hdb]]   &  3 & 64 & \hex{0340} = 832 \\
\hline
[[/dev/kmem]]  &  4 &  0 & \hex{0400} = 1024 \\
\hline
[[/dev/sdisk]] *) & 42 &  0 & \hex{2a00} = 10752 \\
\hline
\end{tabular}
\caption[List of block devices supported by \UlixI{}.]{\UlixI{} supports these devices.\,\, *) The device file \texttt{/dev/sdisk} is not
available.}
\label{table:device numbers}
\end{center}
\end{table}

We provide the following three functions to do the calculations:

%nouse
<<function prototypes>>=
word makedev  (byte major, byte minor);
byte devmajor (word device);
byte devminor (word device);
@ %
They just use the formulas which we have already described
above:

<<function implementations>>=
word makedev  (byte major, byte minor) { return ((major @<< 8) + minor); }
byte devmajor (word device)            { return (device >> 8); }
byte devminor (word device)            { return (device & 0xff); }
@ %def makedev devmajor devminor

Defining some constants makes our life easier in the following
implementations:

\pagebreak

% #define MAJOR_RAM     1
<<constants>>=
#define MAJOR_FD      2
#define MAJOR_HD      3
#define MAJOR_KMEM    4
#define MAJOR_SERIAL 42
@ %def MAJOR_FD MAJOR_HD MAJOR_KMEM MAJOR_SERIAL


The generic [[readblock]] and [[writeblock]] functions calculate the
major and minor numbers from the device number and then call the
appropriate reading or writing function for the correct device class:

%    case MAJOR_RAM:    return;   // not implemented
\index{block read/write!generic, with buffer cache}%
<<function implementations>>=
void readblock (int device, int blockno, char *buffer) {
  // check buffer
  if (buffer_read (device, blockno, buffer) == 0) { return; }

  // read_ from disk
  byte major = devmajor (device);
  byte minor = devminor (device);
  switch (major) {
    case MAJOR_HD:     readblock_hd (minor/64, blockno, buffer); break;
    case MAJOR_FD:     readblock_fd (minor,    blockno, buffer); break;
    case MAJOR_SERIAL: readblock_serial (      blockno, buffer); break;
    default: return;
  }
  
  // update buffer
  buffer_write (device, blockno, buffer, BUFFER_CLEAN);
}
@ %def readblock
The case selection is straightforward: depending on the [[major]] number,
[[readblock]] calls either [[readblock_hd]] (for hard disk access), 
[[readblock_fd]] (for the floppy disks), 
or [[readblock_serial]] (for the serial disk), and we will provide 
implementations of those functions in the following chapters.

The [[readblock]] function also calls [[buffer_read]] and [[buffer_write]]
which we have not discussed yet---these two functions provide access to a
system-wide disk cache which stores the contents of disk blocks so that
they need not be read again when they are requested a second time. We will
introduce the buffer mechanism in the next section. The short explanation
for the above code is this: [[readblock]] first checks whether the requested
block is already in the cache. If so, no disk access is necessary, and the
function can return immediately. Otherwise one of the [[readblock_*]]
functions takes care of the block transfer from disk to memory, and after
that the freshly-read block is stored in the cache. (The [[BUFFER_CLEAN]]
argument states that the buffer's copy of the block is identical to the
disk's version.) Note that the memory device ([[DEV_KMEM]]) is not supported
by [[readblock]] or [[writeblock]]: it is no block device; the [[u_read]] 
and [[u_write]] functions use [[memcpy]] to access the memory.

Writing a block comes in two variations: We first show the
[[writeblock_raw]] function which is the direct counterpart to
[[readblock]]: it has the same case selection and forwards the
writing task to the [[writeblock_hd]] (for hard disks),
[[writeblock_fd]] (for floppies) and [[writeblock_serial]]
(serial disk) functions. When that is done, it also updates
the buffer's copy of the block (if it is already cached).

<<constants>>=
#define UPDATE_BUF      1
#define DONT_UPDATE_BUF 0
@ %def UPDATE_BUF DONT_UPDATE_BUF

%    case MAJOR_RAM:    break;   // not implemented
\index{block read/write!generic, without buffer cache}%
<<function implementations>>=
void writeblock_raw (int device, int blockno, char *buffer, char flag) {
  byte major = devmajor (device);
  byte minor = devminor (device);
  switch (major) {
    case MAJOR_HD:     writeblock_hd (minor/64, blockno, buffer); break;
    case MAJOR_FD:     writeblock_fd (minor,    blockno, buffer); break;
    case MAJOR_SERIAL: writeblock_serial (      blockno, buffer); break;
    default: break;
  }
  
  // update buffer cache (if it is in the cache)
  if ( (flag == UPDATE_BUF) && (buffer_contains (device, blockno)) )
    buffer_write (device, blockno, buffer, BUFFER_CLEAN);
}
@ %def writeblock_raw
However, in order to increase the disk performance, \UlixI{} will not
write blocks to disk immediately. Instead, we will always call the
following function ([[writeblock]]) which simply copies the data
into the cache and marks it as dirty. At regular intervals the kernel
will check whether there are dirty blocks and write them to disk.

<<function implementations>>=
void writeblock (int device, int blockno, char *buffer) {
  buffer_write (device, blockno, buffer, BUFFER_DIRTY);
}
@ %def writeblock

Note that when calling [[readblock_hd]] or [[writeblock_hd]], we
pass [[minor/64]] as argument which turns the only supported values for
[[minor]] (0 and 64) into 0 and 1 for the two hard disks.

If you want to add a driver for a different kind of media (e.\,g.\
CD-ROM or DVD-ROM drives) all you need to do is develop 
[[readblock_XX]] and [[writeblock_XX]] functions for this new
category, define a new [[MAJOR_XX]] constant and add the new case
to the implementations of [[readblock]] and [[writeblock_raw]].

We define device constants for the five devices we plan to use
regularly and another one that is used for error checking:

<<constants>>=
#define DEV_HDA  0x300  //  disk   /dev/hda
#define DEV_HDB  0x340  //  disk   /dev/hdb
#define DEV_FD0  0x200  //  floppy /dev/fd0
#define DEV_FD1  0x201  //  floppy /dev/fd1
#define DEV_KMEM 0x400  //  memory /dev/kmem
#define DEV_NONE 0      //  no device
@ %def DEV_HDA DEV_HDB DEV_FD0 DEV_FD1 DEV_NONE DEV_KMEM


\section{A Simple Buffer Cache}
\label{sec:buffer cache}%

\index{buffer cache}%
In early versions of \UlixI{}, the [[readblock]] and [[writeblock]]
functions directly accessed the drive controllers which made even simple
things such as displaying the contents of the root directory very slow,
since many blocks were read over and over again.

Using a buffer cache can dramatically speed up disk access (to blocks which
have already been read) by buffering them in memory.
For our simple system it does not take much, we provide a buffer that
can store 512 blocks:

<<constants>>=
#define BUFFER_CACHE_SIZE 512
@ %def BUFFER_CACHE_SIZE

Buffer entries store the buffer and some additional information: the
device and block numbers (in order to identify which block is cached),
%in this entry), 
an access counter and a dirty flag:

%BREAK BEFORE DEFINES
<<type definitions>>=
struct buffer_entry {
  char buf[BLOCK_SIZE];
  int dev;      // from what device?              (-1 if free)
  int blockno;  // block number of buffered block (-1 if free)
  byte count;   // how often was it read_?
  byte dirty;   // true if not written to disk
};
@ %def buffer_entry
The cache is just an array of buffer entries:
<<global variables>>=
struct buffer_entry buffer_cache[BUFFER_CACHE_SIZE];
lock buffer_lock;
@ %def buffer_cache buffer_lock
and the kernel lock [[buffer_lock]] protects against parallel access attempts.

Here's how we initialize the buffer cache at system start:

\index{kernel lock!for the disk buffer}%
\index{buffer cache!kernel lock}%
<<initialize system>>=
memset (buffer_cache, 0, sizeof (buffer_cache));
debug_printf ("nulled buffer cache; size: %d\n",     // REMOVE_DEBUGGING_CODE
              sizeof (buffer_cache));                // REMOVE_DEBUGGING_CODE
for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
  buffer_cache[i].blockno = 
  buffer_cache[i].dev     = -1;
  buffer_cache[i].dirty   = 0;
}
buffer_lock = get_new_lock ("disk buffer");
@

Next we need code for entering data into and extracting it from the
buffer cache; we write three functions

\index{block read/write!buffer cache}%
\index{buffer cache!block read/write functions}%
%nouse
<<function prototypes>>=
int buffer_write (int dev, int blockno, char *block, char dirtyflag);
int buffer_read  (int dev, int blockno, char *block);
boolean buffer_contains (int dev, int blockno);
@ %
The functions for reading and writing buffer entries have the same
signatures as the \linebreak [[readblock]] and [[writeblock_raw]] functions.

Reading is the simpler task, so we start with that:

<<function implementations>>=
int buffer_read (int dev, int blockno, char *block) {
  // don't use the buffer before the scheduler_ is up
  if (!scheduler_is_active) { return -1; }  // -1 signals: must be read_ from disk
  mutex_lock (buffer_lock);
    debug_printf ("DEBUG: buffer_read (%d,%d,%x) entered\n",  // REMOVE_DEBUGGING_CODE
                  dev, blockno, block);                       // REMOVE_DEBUGGING_CODE

    // check if buffer cache holds the requested block
    int pos = -1;  // position in the cache
    for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
      if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
        // found it!
        pos = i;
        debug_printf ("DEBUG: in buffer_read, found "         // REMOVE_DEBUGGING_CODE
                      "entry pos = %d\n", pos);               // REMOVE_DEBUGGING_CODE
        break;
      }
    }
    if (pos == -1) { mutex_unlock (buffer_lock); return -1; }  // not found
    
    // we found it: copy the contents, update the counter
    memcpy (block, buffer_cache[pos].buf, BLOCK_SIZE);
    if ((int)buffer_cache[pos].count < 254) { buffer_cache[pos].count++; }
  mutex_unlock (buffer_lock); return 0;    // success
}
@ %def buffer_read

Writing to the buffer is a little more complicated---if there is no entry 
for the block we want to write. Otherwise it's pretty much the same:

<<constants>>=
#define BUFFER_CLEAN 0
#define BUFFER_DIRTY 1
@ %def BUFFER_CLEAN BUFFER_DIRTY

<<function implementations>>=
int buffer_write (int dev, int blockno, char *block, char dirtyflag) {
  // don't use the buffer before the scheduler_ is up
  if (!scheduler_is_active) { return 0; }
  mutex_lock (buffer_lock);
    debug_printf ("DEBUG: buffer_write (%d,%d,%x) "     // REMOVE_DEBUGGING_CODE
                  "entered\n", dev, blockno, block);    // REMOVE_DEBUGGING_CODE
    // check if buffer cache already holds the requested block
    int pos = -1;              // position in the cache
    for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
      if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
        pos = i; break;        // found it!
      }
    }
  
    // if not found, create it
    if (pos == -1) { <<buffer cache: find or create free entry; sets [[pos]]>> }
  
    // copy the contents, update the counter
    debug_printf ("DEBUG: in buffer_write, pos = %d, "  // REMOVE_DEBUGGING_CODE
                  "memcpy (%x,%x,%x)\n", pos,           // REMOVE_DEBUGGING_CODE
                  buffer_cache[pos].buf, block,         // REMOVE_DEBUGGING_CODE
                  BLOCK_SIZE);                          // REMOVE_DEBUGGING_CODE
    if ((pos >= 0) && (pos < BUFFER_CACHE_SIZE)) {
      memcpy (buffer_cache[pos].buf, block, BLOCK_SIZE);
      if ((int)buffer_cache[pos].count < 254)
        buffer_cache[pos].count++;
        buffer_cache[pos].dirty = dirtyflag;      
    } else {                                            // REMOVE_DEBUGGING_CODE
      debug_printf ("ERROR in buffer_write; index pos " // REMOVE_DEBUGGING_CODE
                    "= %d out of range\n", pos);        // REMOVE_DEBUGGING_CODE
    }
  mutex_unlock (buffer_lock);
  return 0;    // success
}
@ %def buffer_write

The obvious difference is that writing to the buffer cache always succeeds
because we either update an existing entry or create a new entry. Creating
a new one is not a problem as long as there remain free entries:

<<buffer cache: find or create free entry; sets [[pos]]>>=
pos = -1;  // new search
for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
  if (buffer_cache[i].dev == -1) {
    pos = i;  break;     // this one is free
  }
}

if (pos == -1) {         // we found no free entry
  <<buffer cache: free an entry; sets [[pos]]>>
}

// memset (0, buffer_cache[pos], sizeof (struct buffer_entry));  // REMOVE_DEBUGGING_CODE
buffer_cache[pos].dev = dev;
buffer_cache[pos].blockno = blockno;
buffer_cache[pos].count = 0;
@

This code prepares the buffer cache entry by setting its
[[dev]] and [[blockno]] members. The [[memset]] command above would
also zero out the buffer's contents, but this is not needed since
it will be overwritten immediately.

Finally we need to say how to find an entry when all entries are in
use. This asks for a replacement strategy and we'll implement a
simple ``least often used'' strategy.

<<buffer cache: free an entry; sets [[pos]]>>=
begin_buffer_search:              // find first clean entry
pos = -1;
for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
  if (buffer_cache[i].dirty == false) {
    pos = i;  break;              // end loop
  }
}
if (pos == -1) {
  buffer_sync (0);                // all buffers are dirty
  goto begin_buffer_search;
}

int least_used_val = buffer_cache[pos].count;

for (int i = pos+1;  i < BUFFER_CACHE_SIZE;  i++) {
  if (buffer_cache[i].count < least_used_val && buffer_cache[i].dirty == false) {
    // this entry is clean and was accessed less often
    least_used_val = buffer_cache[i].count;
    pos = i;  // update candidate
  }
}
@

\noindent
When we want to force a synchronization of the buffer (i.\,e., writing
dirty entries to disk and thereby making them clean), we call the
[[buffer_sync]] function
\index{block read/write!synchronize buffer cache}%
\index{buffer cache!synchonization}%
%nouse
<<function prototypes>>=
void buffer_sync (boolean lock_buffer);
@ which takes one argument indicating whether the [[buffer_lock]] needs to
be acquired:
<<function implementations>>=
void buffer_sync (boolean lock_buffer) {
  _set_statusline ("[B]", 34);
  if (lock_buffer) mutex_lock (buffer_lock);
    for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
      if (buffer_cache[i].dirty == true) {
        writeblock_raw (buffer_cache[i].dev, buffer_cache[i].blockno, 
                        (char*)buffer_cache[i].buf, DONT_UPDATE_BUF);
        buffer_cache[i].dirty = false;
      }
    }
  if (lock_buffer) mutex_unlock (buffer_lock);
  _set_statusline ("[ ]", 34);
}
@ %def buffer_sync

\noindent
We also add a function [[buffer_contains]] which lets us query whether
a specific block is currently buffered:

<<function implementations>>=
boolean buffer_contains (int dev, int blockno) {
  // don't use the buffer before the scheduler_ is up
  if (!scheduler_is_active) { return false; }
  
  // check if buffer cache holds this block
  for (int i = 0;  i < BUFFER_CACHE_SIZE;  i++) {
    if ((buffer_cache[i].dev == dev) && (buffer_cache[i].blockno == blockno)) {
      return true;  // found it!
    }
  }
  return false;
}
@ %def buffer_contains

\noindent
In order to let the user synchronize the buffer cache (before shutting
down the \UlixI{} machine), we provide a [[sync]] system call:

\syscallindex{sync}
%nouse
<<syscall prototypes>>=
void syscall_sync (context_t *r);
@

<<syscall functions>>=
void syscall_sync (context_t *r) {
  // this syscall takes no arguments
  buffer_sync (1);   // with lock_
}
@ %def syscall_sync

<<initialize syscalls>>=
install_syscall_handler (__NR_sync, syscall_sync);
@

\noindent
The system call will be available via the user mode library function 

%nouse
<<ulixlib function prototypes>>=
void sync ();
@ that we implement here: It provides no arguments, so we use [[syscall1]].

<<ulixlib function implementations>>=
void sync () { syscall1 (__NR_sync); }
@ %def sync

\noindent
Syncing will be done by the following swapper process which needs to be started during system initialization:

<<lib-build/tools/swapper.c>>=
#include "../ulixlib.h"
int main () {
  int pid = getpid ();
  if (pid != 2) { printf ("swapper: don't start_ me manually.\n"); exit (1); }
  setterm (9); setpsname ("[swapper]");
  int init_frames = get_free_frames ();
  int last_free_frames;
  int free_frames = init_frames;
  unsigned int counter = 0;
  #define THRESHOLD (init_frames - 500)
  for (;;) {
    last_free_frames = free_frames;
    free_frames = get_free_frames ();
    if (free_frames != last_free_frames) {
      printf ("[%d.%d] swapper: %d free frames. threshold = %d.", 
        pid, counter++, free_frames, THRESHOLD);
      if (free_frames < THRESHOLD) {
        printf ("calling free_a_frame (%d < %d)\n", free_frames, THRESHOLD);
        free_a_frame ();
      } else {
        printf ("\n");
      }
    }    
  }
}
@

\noindent
We launch that program from the \verb#init# process which guarantees that it will always have process ID 2; we also prevent that process against being killed.


\addtocontents{toc}{\protect\parttocpagebreak}
\section{Serial Hard Disk}
\label{sec:serial hard disk}%

\index{hardware!serial hard disk}\index{serial hard disk}%
Talking to device controllers requires knowledge of the protocols which those controllers understand. In later sections you will see how this is done for floppy and hard disk controllers, but we start with an example that is easier to understand, though it introduces a ``device'' that does not exist in real life: the serial hard disk. We provide support for a hypothetical disk which is connected to a serial port, and we can only make it work in an emulated machine (or with a second PC which takes the part of the serial disk).

Testing this code requires that you

\begin{itemize}
\item run \UlixI{} in a virtual machine which supports two serial ports and that you
\item add an external program which connects to the (virtual) second serial port, accepting commands and sending data back and forth.
\end{itemize}

It takes a little more than that, though, since we want to emulate
the ``normal'' behavior of a disk controller. In real life,
transfers use DMA\index{DMA (direct memory access)} (direct memory access). At the lowest level,
the disk driver creates a [[DMA_READ]] or [[DMA_WRITE]] message
and sends it to the controller. By itself, neither of these is a
blocking action, since the disk controller will handle the
transfer of data from the hard disk to memory (reading) or from
memory to the disk (writing) independently of the CPU which
continues executing. However, the process which initiated the
transfer must be blocked anyway, since reading from the disk will
take a while (and writing might not be safe if it continued and
possibly changed the data which are currently written). After
completion the disk controller creates an interrupt, the
corresponding interrupt handler starts and puts the process back
into the ready queue.

The actual DMA\index{DMA (direct memory access)} transfers work with physical memory addresses, so
code using DMA must always know where data is or will be stored in
physical memory.

Our serial hard disk works differently, it uses [[in]]\marginnote{[[in]], [[out]]} and [[out]]
commands to read or write single bytes through the serial port,
and it can use virtual memory.
In a simple implementation of this method the process would never
block, it would just take a while to send or receive the data,
and the scheduler would switch back and forth between this process
and others.

In order to emulate ``proper'' disk controller behavior we take
the following steps:

\begin{itemize}
\item Each time that a process starts a disk read/write operation,
we create a special buffer for this transfer (which knows what 
data to send in what direction) and put it in a disk queue; we
then block the process. We limit the queue size so that no more
than 100 processes may create an entry at the same time (the 101st
process would fail and exit).

\item Sending data via the serial port can happen
immediately, while receiving depends on the other side
(our external process). When the other side sends a byte, it
causes an interrupt for the serial port, and inside the \UlixI{}
interrupt handler we fill a different buffer with that byte.
So when ``reading'' in the timer handler, we don't actually
talk to the serial port, but instead just copy data from one
buffer to another.

\item We do not allow a read and a write operation at the same
time, since this would overcomplicate matters. Instead at each
moment, we either read a whole sector, write one or do not
access the serial disk at all.

\item We add extra functions for \emph{non-blocking}\marginnote{non-blocking I/O} data transfer,
because when we let the kernel (not processes) access the disk,
we have nothing that we can block. Since this is the easier
type of transfer, we start with it.
\end{itemize}


\subsection{Kernel Code for the Serial Disk}

We start with defining the buffer (which we create as a ring buffer):

<<type definitions>>=
struct serial_disk_buffer_entry {
  int pid;                 // process ID; -1 if kernel
  short status;            // New, Transfer, Finished, see BUF_STAT_*
  short direction;         // 100 = read_, 101 = write_
  unsigned int secno;      // sector number
  memaddress address;      // memory address (in process' address space)
  byte sector[BLOCK_SIZE]; // 1024 bytes
};
@ %def serial_disk_buffer_entry

<<constants>>=
#define BUF_STAT_NEW      0
#define BUF_STAT_TRANSFER 1
#define BUF_STAT_FINISHED 2
#define BUF_READ          100
#define BUF_WRITE         101
#define SER_BUF_SIZE      100
@ %def BUF_STAT_NEW BUF_STAT_TRANSFER BUF_STAT_FINISHED BUF_READ BUF_WRITE SER_BUF_SIZE

\noindent
The buffer is just an array with [[SER_BUF_SIZE]] buffer entries, and we mark its current use with two integers which remember its current start and end:

<<global variables>>=
struct serial_disk_buffer_entry serial_disk_buffer[SER_BUF_SIZE];
int serial_disk_buffer_start = 0;   // initialize start_ and end of buffer usage
int serial_disk_buffer_end   = 0;   // interval in use is [start_, end[, 
                                    // [0,0[ is empty
@ %def serial_disk_buffer serial_disk_buffer_start serial_disk_buffer_end

\noindent
This way we can always check whether the buffer is empty by testing if
the two variables [[serial_disk_buffer_start]] and [[serial_disk_buffer_end]] are equal.

The buffer shall be protected by a lock:

<<global variables>>=
lock serial_disk_lock;
@ %def serial_disk_lock

\index{kernel lock!for the serial disk}%
<<initialize kernel global variables>>=
serial_disk_lock = get_new_lock ("serial disk");
@

Next we provide a function with which we can enter a new entry in the buffer:

<<function implementations>>=
int serial_disk_enter (int pid, short direction, uint secno, uint address) {
  mutex_lock (serial_disk_lock);
    // check if buffer is full
    if ( (serial_disk_buffer_end+1) % SER_BUF_SIZE == serial_disk_buffer_start ) {
      mutex_unlock (serial_disk_lock);
      return -1;   // fail
    }
    struct serial_disk_buffer_entry *entry;
    entry = &serial_disk_buffer[serial_disk_buffer_end];
    entry->status = BUF_STAT_NEW;  entry->pid = pid;
    entry->direction = direction;  entry->secno = secno;
    entry->address = address;  
    short tmp = serial_disk_buffer_end;
    serial_disk_buffer_end = (serial_disk_buffer_end+1) % SER_BUF_SIZE;
  mutex_unlock (serial_disk_lock);
  return tmp;   // tell the caller what entry number we used
}
@ %def serial_disk_enter


\subsubsection{Non-Blocking Read/Write Operations}

Now it is time to provide the non-blocking functions for reading and writing.
We combine them in one function which does the appropriate thing, based on
the buffer entry's [[direction]] field. The function takes no arguments since
it finds all the necessary information in the buffer entry.

<<global variables>>=
volatile int serial_disk_reader = 0;   // are we currently reading?
@ %def serial_disk_reader

\noindent
When we want to send a sector number (as part of a request) we have to split it into bytes; a sector number is a 32 bit wide integer, so four bytes are needed:
<<function implementations>>=
void serial_disk_send_sector_number (uint secno) {
  /* send... */  uart2putc ((byte)(secno % 256));  // lowest byte
  secno /= 256;  uart2putc ((byte)(secno % 256));  // 2nd lowest byte
  secno /= 256;  uart2putc ((byte)(secno % 256));  // 3rd lowest byte
  secno /= 256;  uart2putc ((byte)(secno % 256));  // highest byte
}
@ %def serial_disk_send_sector_number

\noindent
The next function reads or writes a buffer.

<<function implementations>>=
int serial_disk_non_blocking_rw () {
  mutex_lock (serial_disk_lock);
    serial_hard_disk_blocks = false;                 // we don't block
    if (serial_disk_buffer_start == serial_disk_buffer_end) {
      mutex_unlock (serial_disk_lock);  return -1;   // buffer is empty
    }  
    struct serial_disk_buffer_entry *entry;
    entry = &serial_disk_buffer[serial_disk_buffer_start];
    switch (entry->direction) {
      case BUF_WRITE: <<serial disk: write a buffer>>; break;
      case BUF_READ:  <<serial disk: read a buffer>>;  break;
      default:        mutex_unlock (serial_disk_lock); return -1; 
    }
  mutex_unlock (serial_disk_lock);
  return 0;
}
@ %def serial_disk_non_blocking_rw

\enlargethispage{5mm}
\noindent
Writing is the simpler task: we only send the write command and the data via the serial port; we need not wait for a response since the serial port controller will not send one. 

\pagebreak

<<serial disk: write a buffer>>=
uart2putc (CMD_PUT);  serial_disk_send_sector_number (entry->secno);
byte *addressptr = (byte*)(entry->address);
for (int i = 0;  i < 1024;  i++) {
  uart2putc (*addressptr); addressptr++;
}
entry->status = BUF_STAT_FINISHED;
serial_disk_buffer_start++; 
serial_disk_buffer_start %= SER_BUF_SIZE;
@

\noindent
[[CMD_PUT]] will be defined soon; along with [[CMD_GET]] it is used to tell the serial disk whether we initiate a write or read operation.

Reading is more complicated and requires the help of an interrupt handler; in the non"=blocking implementation we  do not put processes to sleep while a read operation is active. Instead we simply wait for its completion by repeatedly using the CPU instruction [[hlt]].

<<serial disk: read a buffer>>=
uart2putc (CMD_GET);  serial_disk_send_sector_number (entry->secno);
serial_disk_reader = 1;                         // we're in read_ mode,
   // this value will be changed in the IRQ handler
while (serial_disk_reader == 1)  asm ("hlt");   // wait for data
entry->status = BUF_STAT_FINISHED;
serial_disk_buffer_start++;
serial_disk_buffer_start %= SER_BUF_SIZE;
// copy buffer to target memory location
memcpy ((char*)(entry->address), (char*)&(entry->sector), BLOCK_SIZE);
@

Next we combine our functions to provide non-blocking read and write
functions for the kernel ([[nb]] is short for ``non-blocking''):

%nouse
<<function prototypes>>=
void readblock_nb_serial  (int secno, char *buf);
void writeblock_nb_serial (int secno, char *buf);
@

\enlargethispage{5mm}
%BREAK BEFORE DEFINES
<<function implementations>>=
void readblock_nb_serial (int secno, char *buf) {
  int pid; if (scheduler_is_active) pid = current_task; else pid = -1;
  serial_disk_enter (pid, BUF_READ, secno, (uint)buf);
  serial_disk_non_blocking_rw ();
}

void writeblock_nb_serial (int secno, char *buf) {
  int pid; if (scheduler_is_active) pid = current_task; else pid = -1;
  serial_disk_enter (pid, BUF_WRITE, secno, (uint)buf);
  serial_disk_non_blocking_rw ();
}
@ %def readblock_nb_serial writeblock_nb_serial

\noindent
These are the commands which we can send to the external controller process:

<<serial-hd/serial-hd-controller.h>>=
#define CMD_STAT   1   // status query
#define CMD_GET    2   // GET a block (1024 bytes)
#define CMD_PUT    3   // PUT a block (1024 bytes)
#define CMD_TERM   99  // terminate controller
@ %def CMD_STAT CMD_GET CMD_PUT CMD_NUMSEC CMD_TERM
% REMOVED: # define CMD_NUMSEC 4   // query: how many blocks?
We use them both in the \UlixI{} code as well as in the controller program.

<<constants>>=
<<serial-hd/serial-hd-controller.h>>
@


\subsubsection{The Interrupt Handler}

The interrupt handler [[serial_hard_disk_handler]] copies a byte from the serial port into the buffer, and if the buffer is full, it resets the [[serial_disk_reader]] variable to indicate that a whole block (of 1024 bytes) has been transferred.

<<global variables>>=
char    serial_hard_disk_buffer[1024];
int     serial_hard_disk_pos    = 0;
boolean serial_hard_disk_blocks = false;
@ %def serial_hard_disk_buffer serial_hard_disk_pos serial_hard_disk_blocks

\index{interrupt handler!serial hard disk}%
\label{serial hard disk interrupt handler}%
We will also have to read from the second serial port, so we provide
a [[uart2getc]] function which reads a single character from that port.
There is no corresponding [[uartgetc]] function for the first port,
but it would look identical, except for using [[uart[0]]] and [[IO_COM1]] instead of
[[uart[1]]] and [[IO_COM2]]:

<<function implementations>>=
static int uart2getc () { 
  if (!uart[1]) { return -1; }
  if (!(inportb (IO_COM2+5) & 0x01)) { return -1; }
  return inportb (IO_COM2+0);
}

void serial_hard_disk_handler (context_t *r) {
  char c = uart2getc ();
  serial_hard_disk_buffer[serial_hard_disk_pos++] = c;
  if (serial_hard_disk_pos == 1024) {
    serial_hard_disk_pos = 0;
    // copy buffer to proper serial hard disk buffer
    memcpy ( &(serial_disk_buffer[serial_disk_buffer_start].sector), 
             &serial_hard_disk_buffer, 1024 );
    serial_disk_reader = 0;  // reading a sector is finished
    if (serial_hard_disk_blocks) { <<serial hard disk: wake process>> }
  }
}
@ %def serial_hard_disk_handler

Finally we enter this interrupt handler in the handler list and enable the interrupt.

<<setup serial hard disk>>=
install_interrupt_handler (IRQ_COM2, serial_hard_disk_handler);
enable_interrupt (IRQ_COM2);
@

Note that we're executing a code chunk [[<<serial hard disk: wake process>>]] if we're currently working on a request for which blocking was enabled. We explain this in the next subsection.


\subsubsection{Blocking Read/Write Operations}

For a multitasking system it is inacceptable to work with blocking
I/O operations, at least for processes. 
We will now implement the blocking read and write functions. For writing
there is no difference (because the transfer commands to the serial
port finish immediately), but for reading we will put the calling process
to sleep until a whole block of data has been read. The function

%nouse
<<function prototypes>>=
int serial_disk_blocking_rw ();
@ looks just like [[serial_disk_no_blocking_rw]] with two differences: 

\begin{itemize}
\item It sets [[serial_hard_disk_blocks]] to [[true]] (to indicate that we want to block), 
\item and in the [[switch]] expression it uses a fresh code chunk for reading.
\end{itemize}

<<function implementations>>=
int serial_disk_blocking_rw () {
  mutex_lock (serial_disk_lock);
    serial_hard_disk_blocks = true;                  // we block
    if (serial_disk_buffer_start == serial_disk_buffer_end) {
      mutex_unlock (serial_disk_lock);  return -1;   // buffer is empty
    }  
    struct serial_disk_buffer_entry *entry;
    entry = &serial_disk_buffer[serial_disk_buffer_start];
    switch (entry->direction) {
      case BUF_WRITE: <<serial disk: write a buffer>>; break;
      case BUF_READ:  <<serial disk: read a buffer and block>>;  break;
      default:        mutex_unlock (serial_disk_lock); return -1; 
    }
  mutex_unlock (serial_disk_lock);
  return 0;
}
@ %def serial_disk_blocking_rw

The difference between the [[<<serial disk: read a buffer>>]] and the following new code chunk is that we don't do busy waiting (as above) but the process to sleep. Only one line was changed (marked with [[[*]]]).

<<serial disk: read a buffer and block>>=
uart2putc (CMD_GET);
<<begin critical section in kernel>>
serial_disk_send_sector_number (entry->secno);
serial_disk_reader = 1;                         // we're in read_ mode,
   // this value will be changed in the IRQ handler
while (serial_disk_reader == 1)  { <<serial disk: put process to sleep>> }  // [*]
entry->status = BUF_STAT_FINISHED;
serial_disk_buffer_start++;
serial_disk_buffer_start %= SER_BUF_SIZE;
// copy buffer to target memory location
memcpy ((char*)(entry->address), (char*)&(entry->sector), BLOCK_SIZE);
@

In the non-blocking code we simply executed the assembler instruction [[hlt]] in the loop, we actively waited for the transfer to complete. Here we put the process to sleep:

<<serial disk: put process to sleep>>=
if (scheduler_is_active) {
  // we access thread table; interrupts are off
  block (&serial_disk_queue, TSTATE_WAITSD);
  <<end critical section in kernel>>
  <<resign>>
} else {
  <<end critical section in kernel>>
}
@

\index{blocked queue!serial disk}%
We define the new state [[TSTATE_WAITSD]] and the [[serial_disk_queue]] blocked queue:

<<constants>>=
#define TSTATE_WAITSD 12
@ %def TSTATE_WAITSD

<<global variables>>=
blocked_queue serial_disk_queue;
@ %def serial_disk_queue

The queue must also be initialized:

<<initialize system>>=
initialize_blocked_queue (&serial_disk_queue);
@

Since we need to wake the process up when the block was transmitted, we add the wake-up call to the interrupt handler. We've included the following code chunk in the [[serial_hard_disk_handler]] function:

<<serial hard disk: wake process>>=
if (scheduler_is_active) {
  int tid;
  if ((tid = serial_disk_queue.next) != 0)
    deblock (tid, &serial_disk_queue); 
}
@

\index{block read/write!serial disk}%

%nouse
<<function prototypes>>=
void readblock_serial  (int secno, char *buf);
void writeblock_serial (int secno, char *buf);
@

<<function implementations>>=
void readblock_serial (int secno, char *buf) {
  int pid; if (scheduler_is_active) pid = current_task; else pid = -1;
  serial_disk_enter (pid, BUF_READ, secno, (uint)buf);
  serial_disk_blocking_rw ();
}

void writeblock_serial (int secno, char *buf) {
  int pid; if (scheduler_is_active) pid = current_task; else pid = -1;
  serial_disk_enter (pid, BUF_WRITE, secno, (uint)buf);
  serial_disk_blocking_rw ();
}
@ %def readblock_serial writeblock_serial


\subsection{The External Controller Process}

The controller is a simple program that opens a TCP socket to talk to the serial port of the emulated PC that executes \UlixI{}. The functions [[readsect]] and [[writesect]] transfer individual blocks. The program only reacts to requests that come from the \UlixI{} machine. In that way it simulates the behavior of a disk controller.

%nouse
<<serial-hd/serial-hd-controller.c>>=
#include <fcntl.h>        // open()
#include <sys/types.h>    // socket()
#include <sys/socket.h>   // socket()
#include <netinet/in.h>   // socket()
#include <unistd.h>       // close()
#include <string.h>       // bzero()
#include <stdio.h> 
#include <unistd.h>       // lseek: SEEK_SET
#include "serial-hd-controller.h"

int socks;                // socket descriptor for ULIX connection
int fd = -1;              // file descriptor
int numsec = -1;          // number of sectors (1024 bytes) in disk image
byte sector[BLOCK_SIZE];

void readsocket (byte *buf, short len) {
  // We use this instead of recv(), since recv() does not always
  // read the expected number of bytes.
  int total = 0;
  while (total < len) {
    total += recv (socks, buf+total, len-total, 0);
  };
};

void openfile ()  { fd = open ("minix1.img", O_RDWR); numsec = 2880; };

void closefile () { close (fd); fd = -1; numsec = -1; }

void readsect (int i) {
  lseek (fd, i*BLOCK_SIZE, SEEK_SET);       // get sector from disk image
  int res = read (fd, &sector, BLOCK_SIZE);
  send (socks, &sector, BLOCK_SIZE, 0);     // send it to ULIX
};

void writesect (int i) {
  readsocket ((byte*) &sector, BLOCK_SIZE); // get sector from ULIX
  lseek (fd, i*BLOCK_SIZE, SEEK_SET);       // write it to disk image
  write (fd, &sector, BLOCK_SIZE);
};

int main () {
  openfile ();                              // open disk image
  socks = socket (AF_INET, SOCK_STREAM, 0); // connect to localhost:4444
  struct sockaddr_in serveraddr;
  bzero (&serveraddr, sizeof (serveraddr));
  inet_pton (AF_INET, "127.0.0.1", &(serveraddr.sin_addr));
  serveraddr.sin_family = AF_INET;
  serveraddr.sin_port = htons (4444);

  // Create connection
  connect (socks, (struct sockaddr*) &serveraddr, sizeof (serveraddr));

  byte cmd_type;
  int sectornumber;
  setbuf (stdout, 0);

  while (1) {
    readsocket (&cmd_type, 1);
    switch (cmd_type) {
      case CMD_STAT: printf ("ULIX asked for status\n"); break;
      case CMD_GET:  readsocket ((byte*)&sectornumber, 4);
                     printf ("ULIX asked get %d\n", sectornumber);
                     readsect (sectornumber); break;
      case CMD_PUT:  readsocket ((byte*)&sectornumber, 4);
                     printf ("ULIX asked put %d\n", sectornumber);
                     writesect (sectornumber); break;
      case CMD_TERM: printf ("ULIX terminated connection. Quitting.\n");
                     goto finished;
      default:       printf ("ERROR in Command from ULIX\n");
    };      
  }
  finished:                                 // Close connection
  close (socks); closefile ();
}
@

\noindent
In order to connect the external process to [[qemu]] (running \UlixI{}), we
start [[qemu]] as follows:

%nouse
<<qemu invocation>>=
qemu -m 64 -fda ulix-fd0.img -d cpu_reset -s -serial mon:stdio \
-serial tcp::4444,server
@

\noindent
Note that there are two [[-serial]] arguments; the first one connects
COM1 with the terminal from which [[qemu]] was started; the second one
connects COM2 with a TCP server on port 4444. That's the one our external
program is going to connect to.

The final release of \UlixI{} does not use the serial hard disk
any more because its dependency on the external controller program
made using the system uncomfortable. In the following two sections we
present our hard disk and floppy disk drivers.

\pagebreak


\section{The Hard Disk Controller}
\label{sec:hard-disk-controller}%

\index{hardware!hard disk}%
\index{hardware!IDE (hard disk) controller}%

As mentioned before, we will let our hard disk driver use non-DMA\index{DMA (direct memory access)}
data transfer, called \emph{PIO} (\emph{programmed input/output}).\index{PIO (programmed input/output), cf.\ DMA}\marginnote{PIO}
The code in this section is based on the IDE driver code of the
xv6 operating system \cite{xv6Draft}.\index{xv6 operating system}


\subsection{Sending Commands to the Controller}

Communication with a device always needs to follow strict protocols, this
holds for the hard disk controller, too.  The following description is
full of technical details about controller"=internal registers and the
ports used to access them, it also contains some assembler code. If you
want to skip this, here's a summary: in this subsection we'll define two
code chunks [[<<ide: read sector [[sector]] on device [[hd]]>>]] and 
[[<<ide: write sector [[sector]] on device [[hd]]>>]] which can be used 
for sending the controller the commands for \emph{initiating} the
transfer and for copying a sector from memory to the controller's
internal memory. The other direction (from the controller's memory to 
RAM) will be dealt with inside the interrupt handler which we'll discuss 
in one of the following subsections.

We'll define some constants which will be used in the following code:
The interrupt number for the (first) IDE controller is 14 ([[IRQ_IDE]]).
The controller accepts two commands for reading (\hex{20}; [[IDE_CMD_READ]])
and writing (\hex{30}; [[IDE_CMD_WRITE]]), and when we query the controller's 
status, there are four possible results which we'll be prepared to
handle (busy, data ready, device fault and error):

<<constants>>=
#define IDE_CMD_READ  0x20     // read from disk, with retries
#define IDE_CMD_WRITE 0x30     // write to disk, with retries
#define IDE_CMD_IDENT 0xec     // identify disk
#define IDE_BSY       0x80     // 0b10000000  (bit 7),  device busy
#define IDE_DRDY      0x40     // 0b01000000  (bit 6),  device ready
#define IDE_DF        0x20     // 0b00100000  (bit 5),  drive fault
#define IDE_ERR       0x01     // 0b00000001  (bit 0),  error
@ %def IRQ_IDE IDE_CMD_READ IDE_CMD_WRITE IDE_CMD_IDENT IDE_BSY IDE_DRDY IDE_DF IDE_ERR

In order to talk to the controller we use the ports \hexrange{1f0}{1f7} (the port numbers can 
be found in Seagate's ATA Interface Reference Manual
\cite[p. 13]{Seagate:ATA:1993}), we give them names to make things easier:

\enlargethispage{2mm}
\index{port!IDE (hard disk) controller}%
<<constants>>=
// IDE output
#define IO_IDE_SEC_COUNT  0x1f2  // sector count register (read_/write_)
#define IO_IDE_SECTOR     0x1f3  // (32 bits in 0x1f3..0x1f6)
#define IO_IDE_DISKSEL    0x1f6  // disk select and upper 4 bits of sector no.
#define IO_IDE_COMMAND    0x1f7  // command register
#define IO_IDE_DEVCTRL    0x3f6  // device control register
// IDE input
#define IO_IDE_DATA       0x1f0  // data (read_/write_)
#define IO_IDE_STATUS     0x1f7  // status register (identical to command reg.)
@ %def IO_IDE_SEC_COUNT IO_IDE_SECTOR IO_IDE_DISKSEL IO_IDE_COMMAND IO_IDE_DEVCTRL IO_IDE_DATA IO_IDE_STATUS
Note that [[IO_IDE_COMMAND]] and [[IO_IDE_STATUS]] are the same port number (\hex{1f7}),
but depending on the type of access, they refer to different registers: When
reading that port, we access the \emph{status register}\marginnote{status/com-\\ mand register}, and when writing, we access the
\emph{command register}.

The read and write commands are specified in the ``AT Attachment Interface for Disk Drives''
document \cite[p.~40]{ATA-1}; \hex{20} and \hex{30} are the read/write commands which trigger
data transfer with retries (in case of errors); there are also further commands
(\hex{21}, \hex{31}) which trigger corresponding reads or writes without retries. The kernel can
send a command by writing the required value into the controller's command register
via the [[IO_IDE_COMMAND]] port \hex{1f7} ([[outb IDE_CMD_READ, 0x1f7]]).

The status values represent the bit positions 7 (\hex{80} $= 128 = 2^7$),
6 (\hex{40} $= 64 = 2^6$), 5 (\hex{20} $= 32 = 2^5$) and 0 (\hex{01} $= 1 = 2^0$) 
of the status register \cite[p. 34]{ATA-1}, see Table~\ref{table:ide-status-register}.

\begin{table}[b!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
7 & 6 & 5 & 4 & 3 & 2 & 1 & 0 \\
BSY & DRDY & DWF & DSC & DRQ & CORR & IDX & ERR \\
\hline
\end{tabular}
\caption[\hgepolylot{\protect\enlargethispage{1cm}The status register of the IDE controller.}]{The status register of the IDE controller.}
\label{table:ide-status-register}
\end{center}
\end{table}

The read and write commands can make the disk read/write several
sectors with one command. To start such a read or write operation,
we need to tell the controller three things:

\begin{itemize}
\item How many sectors shall be read/written? This information must be stored
in the \emph{sector count register}\marginnote{sector count\\ register} which 
is accessible via the [[IO_IDE_SEC_COUNT]] port 
(\hex{1f2}). We will always read or write just a single sector:\vspace{1mm}

<<ide: read/write sector [[sector]] on device [[hd]]>>=
idewait (0);
outportb (IO_IDE_DISKSEL,   0xe0 | (hd<<4));   // select disk
outportb (IO_IDE_DEVCTRL,   0);                // generate interrupt
outportb (IO_IDE_SEC_COUNT, 1);                // one sector
@
\end{itemize}

\pagebreak

\begin{itemize}
\item Via the four ports \hexrange{1f3}{1f6}, we can specify the 28 bits of a
sector number (four bits are used for selecting the drive, making the
target register 32 bits wide):

<<ide: read/write sector [[sector]] on device [[hd]]>>=
outportb (IO_IDE_SECTOR,     sector        & 0xff);
outportb (IO_IDE_SECTOR+1,  (sector >> 8)  & 0xff);
outportb (IO_IDE_SECTOR+2,  (sector >> 16) & 0xff);
outportb (IO_IDE_SECTOR+3, ((sector >> 24) & 0x0f) | ((0xe + hd) @<< 4) );
@

\end{itemize}
\begin{itemize}
\item Finally, we send the [[IDE_CMD_READ]] or [[IDE_CMD_WRITE]] command
to the controller via the [[IO_IDE_COMMAND]] port \hex{1f7}:

<<ide: read sector [[sector]] on device [[hd]]>>=
<<ide: read/write sector [[sector]] on device [[hd]]>>
outportb (IO_IDE_COMMAND, IDE_CMD_READ);
@

<<ide: write sector [[sector]] on device [[hd]]>>=
<<ide: read/write sector [[sector]] on device [[hd]]>>
outportb (IO_IDE_COMMAND, IDE_CMD_WRITE);
@

\end{itemize}

Using 28 bits for the sector number allows us to access $2^{28} = 268\,435\,456$
sectors, thus the maximum disk size is $2^{28} \times 512 = 137\,438\,953\,472$
bytes (128 GByte) which should be enough for most \UlixI{} uses \dots\ 
This is called \emph{LBA28}\index{LBA28 (logical block addressing)}\index{IDE controller!LBA28}\index{logical block addressing (LBA)}\marginnote{LBA28} (\emph{Logical Block Addressing}, 28 bits). In 2002, 
ATA-6 \cite{ATA-6}, the sixth version of the ATA standard, introduced LBA48 
which uses 48 bits to specify sector numbers and allows for much larger disks.

Our IDE driver will not use DMA\index{DMA (direct memory access)}\index{direct memory access (DMA)|see {DMA}} transfer but instead copy the bytes
with [[in]] and [[out]] operations, directly talking to the controller.

Now we're able to send read/write commands to the hard disk controller,
and it will start servicing those requests immediately. But what happens
when the disk has read the sector contents and copied them into the
controller's internal memory? We need to fetch the data.

The controller is helpful in that it will tell us when it finished its
work: it will raise the [[IRQ_IDE]] interrupt (number 14), and our 
interrupt handler must then copy the data from the controller to RAM.

We do this by directly reading the data via the controller's data register
(i.\,e., by reading from [[IO_IDE_DATA]]). The CPU instruction [[insl]]\marginnote{[[insl]]}
can read four bytes (a 32 bit value) in one go. For reading the contents
of a whole sector we would need $512 / 4 = 128$ of these [[insl]]
instructions, but the processor has a way of repeating this command
automatically: if we add a [[rep]]\marginnote{[[rep insl]]} prefix to [[insl]], we get repeated
executions of [[insl]] witout manually writing a loop.

The logic of [[rep insl]] requires us to fill some registers with proper
values:

\begin{itemize}
\item The memory address (our buffer) goes into the \register{EDI} register (after
  each step, \register{EDI} will be incremented by 4),
\item the number of repetitions must be stored in the \register{ECX} register (after
  each step, \register{ECX} will be decremented; the loop continues while 
  \register{ECX} $\neq 0$),
\item and the port number must be stored in the (16 bit) \register{DX} register.
\end{itemize}

Thus, in C-like pseudo code, [[rep insl]] does the following:

%nouse
<<pseudo code for [[rep insl]]>>=
while (%ecx != 0) {
  *(%edi) = inportl (%ecx);  // read 4 bytes, write them to *(%edi) 
  %edi += 4;                 // update target memory
  %ecx--;                    // decrement counter
}
@

In the inline assembler language the registers \register{ECX}, \register{DX} and 
\register{EDI} can
be accessed using [["c"]], [["d"]] and [["D"]], respectively
(see Appendix \ref{chap:intro-to-asm} for an introduction to [[gcc]] inline assembler).
[[rep]] can either auto-increment or auto-decrement the target address
with each step; in order to make it increment (like we want), we need to
set the \emph{direction flag}\marginnote{direction flag} of the \register{EFLAGS} register to 0 using the machine 
instruction [[cld]]\marginnote{[[cld]]} (\emph{clear direction flag}).

The following function definition sets everything up properly and
executes [[rep insl]]:
\index{port!Assembler language}%
\index{Assembler language!ports}%
\tindex{rep in}\tindex{rep out}%

%nouse
<<function prototypes>>=
static inline void repeat_inportsl (int port, void *addr, int cnt);
@

<<function implementations>>=
static inline void repeat_inportsl (int port, void *addr, int cnt) {
  asm volatile ("cld \n"
                "rep insl" :
                "=D" (addr), "=c" (cnt) :
                "d" (port), "0" (addr), "1" (cnt) :
                "memory", "cc");
}
@ %def repeat_inportsl
With [["0"]] and [["1"]] we refer to the first two registers used,
that is, [["D"]] (\register{EDI}) and [["c"]] (\register{ECX}); see also
Appendix~\ref{sec:assembler:inline}.

For the other direction, we provide a [[repeat_outportsl]] function which looks
almost identical:

%nouse
<<function prototypes>>=
static inline void repeat_outportsl (int port, void *addr, int cnt);
@

<<function implementations>>=
static inline void repeat_outportsl (int port, void *addr, int cnt) {
  asm volatile ("cld \n"
                "rep outsl" :
                "=S" (addr), "=c" (cnt) :
                "d" (port), "0" (addr), "1" (cnt) :
                "cc");
}
@ %def repeat_outportsl

Instead of \register{EDI}, the [[outsl]] instruction expects the 
\register{ESI} register to contain the memory address, which is why we 
wrote \verb#"=S"(addr)# instead of \verb#"=D"(addr)#.

\subsection{The Blocked Queue}

\index{blocked queue!hard disk}%
We define a [[harddisk_queue]] which will contain processes waiting for a
hard disk access operation to finish:

<<global variables>>=
blocked_queue harddisk_queue;   // processes which wait for the hard disk
@ %def harddisk_queue
and we have to initialize this queue:

<<initialize system>>=
initialize_blocked_queue (&harddisk_queue);
@

Processes that access a hard disk drive will wait on this queue,
and the interrupt handler will wake up these processes when the
operation was completed.


\subsection{Reading and Writing}

Now we use the code presented so far to create two functions
\index{block read/write!hard disk}%

%nouse
<<function prototypes>>=
void readblock_hd  (int hd, int blockno, char *buffer);
void writeblock_hd (int hd, int blockno, char *buffer);
@ which read and write a complete
block (1024 bytes). They will use a buffer [[hd_buf]] which can 
contain one sector (512 bytes) and must be protected by a lock. We
also declare a global variable [[hd_direction]] which we set to
[[HD_OP_READ]] or [[HD_OP_WRITE]] when we initialize a read or 
write operation.

<<constants>>=
#define HD_OP_READ     0
#define HD_OP_WRITE    1
#define HD_OP_NONE    -1

#define HD_SECSIZE   512
@ %def HD_OP_READ HD_OP_WRITE HD_OP_NONE HD_SECSIZE

We also need some global variables: [[hd_buf]] is a buffer that can store one sector, [[hd_lock]] is used for locking disk access, and [[hd_direction]] will always be set to one of the [[HD_OP_*]] constants to indicate the current transfer direction.

\pagebreak

<<global variables>>=
char hd_buf[HD_SECSIZE];
lock hd_lock;
char hd_direction;
@ %def hd_buf hd_lock hd_direction
We initialize the lock at system start-up:

\index{kernel lock!for the hard disks}%
<<initialize system>>=
hd_lock = get_new_lock ("hard disk");
@

The functions [[readblock_hd]] and [[writeblock_hd]]
will transfer 1 KByte blocks of data. Since the hard disk controller
defaults to transferring 512-bytes-sized sectors, we first provide
functions for reading and writing such sectors.

<<function implementations>>=
void readsector_hd (int hd, int sector, char *buffer) {
  mutex_lock (hd_lock);
    hd_direction = HD_OP_READ;
    <<begin critical section in kernel>>
    <<ide: read sector [[sector]] on device [[hd]]>>
    while (hd_direction == HD_OP_READ) { <<ide: put process to sleep>> }
    <<ide: read data from the controller>>
    // idewait (0);  // wait for interrupt   // REMOVE_DEBUGGING_CODE
    memcpy (buffer, hd_buf, HD_SECSIZE);
    hd_direction = HD_OP_NONE;
  mutex_unlock (hd_lock);
}
@ %def readsector_hd

For writing, the sequence of events is slightly different; we first
transfer the data to the controller and then put the process to sleep,
letting it wait for the transfer to finish:

<<function implementations>>=
void writesector_hd (int hd, int sector, char *buffer) {
  mutex_lock (hd_lock);
    hd_direction = HD_OP_WRITE;
    memcpy (hd_buf, buffer, HD_SECSIZE);
    <<begin critical section in kernel>>
    <<ide: write sector [[sector]] on device [[hd]]>>
    <<ide: write data to the controller>>
    while (hd_direction == HD_OP_WRITE) { <<ide: put process to sleep>> }
    hd_direction = HD_OP_NONE;
  mutex_unlock (hd_lock);
}
@ %def writesector_hd

Why do we put the process to sleep anyway? While the PIO transfer
between system RAM and the controller's memory wastes some time
(and a DMA would save that waste), the actual transfer between
controller and disk takes a lot longer---this transfer is
what the process must wait for to complete.

\begin{itemize}
\item When the process reads from the disk, we cannot get around
waiting anyway: the data will not be available before the transfer
completes. Putting the process to sleep guarantees that execution
of the process only continues after the data have been read (and
stored in the buffer that this process has set up for reading).
\item In the case of writing, we could in principle let the process
continue immediately after sending the data off to the controller.
The process need not wait for the controller-to-disk transfer to
finish. But if it issued another write request immediately, that
would get in the way of the previous one. To make things simpler,
we block the process until the write operation is done.
\end{itemize}

\noindent
When we put the process to sleep we use the waiting state
[[TSTATE_WAITHD]] defined on page 
\pageref{definition of thread states}.

<<ide: put process to sleep>>=
if (scheduler_is_active) {
  // interrupts are off; we access the thread table
  block (&harddisk_queue, TSTATE_WAITHD);
  // debug_printf ("[%d.%d] hd_sleep going "       // REMOVE_DEBUGGING_CODE
  //               "to call resign()\n",           // REMOVE_DEBUGGING_CODE
  //               current_task, system_ticks);    // REMOVE_DEBUGGING_CODE
  <<end critical section in kernel>>
  <<resign>>
  // debug_printf ("[%d.%d] hd_sleep returned "    // REMOVE_DEBUGGING_CODE
  //               "from resign()\n",              // REMOVE_DEBUGGING_CODE
  //               current_task, system_ticks);    // REMOVE_DEBUGGING_CODE
} else {
  <<end critical section in kernel>>
}
@

The block read/write functions are now implemented as follows:

%nouse
<<function implementations>>=
void readblock_hd (int hd, int blockno, char *buffer) {
  readsector_hd (hd, blockno*2,   buffer);
  readsector_hd (hd, blockno*2+1, buffer + HD_SECSIZE);
}

void writeblock_hd (int hd, int blockno, char *buffer) {
  writesector_hd (hd, blockno*2,   buffer);
  writesector_hd (hd, blockno*2+1, buffer + HD_SECSIZE);
}
@ %def readblock_hd writeblock_hd

After a read operation has finished (and the controller has
generated an interrupt) we can copy the read data from the
controller's memory to the buffer. That transfer happens
in the interrupt handler, here we only let the process wait
for an interrupt.

\pagebreak

<<ide: read data from the controller>>=
idewait (0);
inportb (IO_IDE_STATUS);  // read_ status, ack irq
@

Writing is similar:

<<ide: write data to the controller>>=
inportb          (IO_IDE_STATUS);                         // read_ status, ack irq
repeat_outportsl (IO_IDE_DATA, hd_buf, HD_SECSIZE / 4);
inportb          (IO_IDE_STATUS);                         // read_ status, ack irq
@

Now the only missing bit is the interrupt handler which will
only acknowledge the interrupt and possibly wake up a waiting
process.


\subsection{Interrupt Handler}

The interrupt handler for the IDE controller 
\index{hard disk interrupt handler}%
\index{interrupt handler!hard disk}%

%nouse
<<function prototypes>>=
void ide_handler (context_t *r);
@ will be executed whenever
the controller finishes an operation and signals the CPU. What it has do
then depends on the transfer direction:

\begin{itemize}
\item In case of a write operation, [[writesector_hd]] had filled the buffer,
copied the data from there into the controller's memory and asked the 
controller to start the write operation onto the disk. So when that is
finished, the whole operation is completed, and the interrupt handler only 
has to wake up the waiting process.

\item The situation is different during a read operation: In that case
the [[readsector_hd]] function had only asked the controller to read the
data from disk and store them in the controller's memory. When the
controller signals completion, the sector is waiting there (in the 
controller memory) to be retrieved. Thus, the interrupt handler must
copy the data to system memory. Once it has finished that, it can also
wake up the waiting process.
\end{itemize}

<<function implementations>>=
void ide_handler (context_t *r) {
  switch (hd_direction) {
    case HD_OP_READ:  repeat_inportsl (IO_IDE_DATA, hd_buf, HD_SECSIZE / 4);
                      hd_direction = HD_OP_NONE;
                      break;

    case HD_OP_WRITE: hd_direction = HD_OP_NONE;
                      break;

    case HD_OP_NONE:  printf ("Funny IDE interrupt -- no request waiting\n");
                      return; 
  }

  if (scheduler_is_active) {
    int tid;
    if ((tid = harddisk_queue.next) != 0)
      deblock (tid, &harddisk_queue);     // wake up process
    else                                          // REMOVE_DEBUGGING_CODE
      debug_printf ("WARNING: IDE HANDLER, "      // REMOVE_DEBUGGING_CODE
                    "no thread waiting\n");       // REMOVE_DEBUGGING_CODE
  }
}
@ %def ide_handler

The last function we need to discuss in the context of reading form or writing to disk is

%nouse
<<function prototypes>>=
int idewait (int checkerr);
@ which waits if the IDE controller is not yet ready to receive the next command. It checks the [[IO_IDE_STATUS]] register's flags DRDY (device ready; bit 6) and BSY (busy; bit 7) and loops until the controller is ready and not busy.

<<function implementations>>=
int idewait (int checkerr) {
  <<enable interrupts>>
  int r;
  for (;;) {
    r = inportb (IO_IDE_STATUS);
    if ((r & (IDE_BSY | IDE_DRDY)) == IDE_DRDY)  break;  // ready, not busy
  }
  if (checkerr && (r & (IDE_DF|IDE_ERR)) != 0) {
    <<disable interrupts>>
    return -1;
  } else {
    if (current_task > 1) { <<disable interrupts>> }  // see comment
    return 0;
  }
// OLD CODE:                                                        // REMOVE_DEBUGGING_CODE
// while (((r = inportb (IO_IDE_STATUS)) & (IDE_BSY|IDE_DRDY)) != IDE_DRDY) // REMOVE_DEBUGGING_CODE
//   printf ("=");                                                  // REMOVE_DEBUGGING_CODE
}
@ %def idewait
%
([[idewait()]] must enable interrupts and disable them again after an IDE interrupt has occurred. With the check for [[current_task > 1]] we treat the special case of disk access before scheduling has started, i.\,e., when we load the init program.)


\subsection{Hard Disk Initialization}

When the system boots we check what hard disks (if any) are available. We support up to two IDE disks and store their disk sizes in the 

<<global variables>>=
ulonglong hd_size[2] = {-1, -1};
@ %def hd_size
record. If a disk is not available we keep the $-1$ value.

The [[ata_init]] function selects a disk by sending the encoded disk number to the [[IO_IDE_DISKSEL]] port and then asks for \emph{identification}\marginnote{disk iden-\\ tification} by sending the [[IDE_CMD_IDENT]] command to port [[IO_IDE_COMMAND]]. The answer is 512 bytes long and copied into a buffer using the [[repeat_inportsl]] function. The disk size is then assembled from four bytes and written to the right [[hd_size]] array entry (and displayed in the boot messages).

We also use this function to install the interrupt handler.

<<function implementations>>=
void ata_init () {
  // detect installed hard disks
  word buf[512]; short drivecount = 0;
  char *names[2] = { "hda", "hdb" };
  printf ("ATA: ");
  for (int disk = 0;  disk < 2;  disk++) {
    outportb (IO_IDE_DISKSEL, 0xe0 | (disk<<4));         // select disk
    for (int i = 0;  i < 1000;  i++) {
      if (inportb (IO_IDE_STATUS) != 0) {
        drivecount++;
        outportb (IO_IDE_COMMAND, IDE_CMD_IDENT);        // identify!
        repeat_inportsl (IO_IDE_DATA, buf, 256);         // 512 bytes = 256 words
        hd_size[disk] =   (ulonglong)buf[100]       + (((ulonglong)buf[101])<<16)
                      + (((ulonglong)buf[102])<<32) + (((ulonglong)buf[103])<<48);
        if (drivecount > 1) printf (", ");
        printf ("%s (%d KByte)", names[disk], 
                hd_size[disk]/2);                        // 512-byte sectors!
        break;
      }
    }
  }
  printf ("\n");
  outportb (IO_IDE_DISKSEL, 0xe0 | (0<<4));              // select disk 0
  
  // install the interrupt handler
  install_interrupt_handler (IRQ_IDE, ide_handler);
  enable_interrupt (IRQ_IDE);
}
@ %def ata_init


% nice documentation of IDE stuff: http://www.gaby.de/gide/IDE-TCJ.txt


\pagebreak

\section{The Floppy Controller}
\label{sec:floppy}
\index{hardware!floppy disk}%

In the previous sections you have already seen two ways to talk to a device controller:

\begin{itemize}
\item We accessed the ``serial hard disk'' by sending individual bytes
across the serial port. In one direction they contained controller commands
and data (sectors to be written on the disk), in the other direction only
data (sectors read from the disk). Every single received byte caused an
interrupt, and so the sector had to be assembled byte by byte.

\item For the IDE controller we used some kind of block transfer where we
copied a sector between the PC's memory and the controller's internal memory.
For that purpose we used a global buffer, though that was not strictly
necessary; we could have used the memory location that the read/write
functions use for storing the sector, i.\,e., memory that belongs to a 
process.

The transfer between controller memory and the actual disk was performed
by the controller itself, and we had to wait for that transfer to complete.
This type of data transfer is called PIO transfer (Parallel I/O).
\end{itemize}

\noindent
Now we show you a third way that uses \emph{DMA}\index{DMA (direct memory access)} transfer (\emph{Direct Memory Access}).\marginnote{DMA}
Here we need to work with a global buffer and we also need to know the
physical address of that buffer because the floppy controller will access
it directly---it cannot use the MMU to translate a virtual address. Once 
the controller has been told what to do, the data transfer
from or to that buffer happens automatically, no further activity by the
CPU is required. That is possible because the controller can access the
memory bus (just like the CPU does). This is most interesting in case of a
read operation: Our code only has to tell the controller that it shall read
a certain sector from the floppy, and the next time the controller generates
an interrupt, the data will already be stored in the buffer---we need not
call [[repeat_inportsl]] or an equivalent instruction, as in our hard disk
driver.

(Note that the IDE controller also supports DMA\index{DMA (direct memory access)} transfers. We have decided
to let it work in PIO mode so that you can see both approaches at work.
However, PIO transfers increase the load on the CPU, so if performance was
your goal, you would have to replace the PIO code with DMA code.)


\subsection{Talking to the Controller}

The floppy controller has several ports that can be used to communicate
with it; either for sending it a command or data or for reading data.
These ports are the following:

\enlargethispage{3mm}
\index{port!floppy controller}%
%nouse
<<constants>>=
#define IO_FLOPPY_OUTPUT      0x3f2   // digital output register (DOR)
#define IO_FLOPPY_STATUS      0x3f4   // main status register (MSR)
#define IO_FLOPPY_COMMAND     0x3f5   // command/data register
#define IO_FLOPPY_RATE        0x3f7   // configuration control register
@ %def IO_FLOPPY_OUTPUT IO_FLOPPY_STATUS IO_FLOPPY_COMMAND IO_FLOPPY_RATE

\pagebreak

In most cases we will use the function [[fdc_out]] to send a command
to the controller and read in the results with [[fdc_getresults]]. These
functions

%nouse
<<function prototypes>>=
void fdc_out (byte data);
int fdc_getresults ();
@ %
%
work as follows:

<<function implementations>>=
void fdc_out (byte data) {
  for (int i = 0;  i < 10000;  i++) {
    byte status = inb_delay (IO_FLOPPY_STATUS) & (FLOPPY_MASTER | FLOPPY_DIRECTION);
    if (status != FLOPPY_MASTER) continue;
    outb_delay (IO_FLOPPY_COMMAND, data);
    return;
  }
  fdc_need_reset = true;  printf ("FDC: can't send byte %w to controller\n", data);
}
@ %def fdc_out

Before we can write to the controller we need to check whether it is ready. We read the status from the status register via the [[IO_FLOPPY_STATUS]] port. We are only interested in the highest two bits of the status register that tell us whether it is ready (bit 7) and whether it is prepared for a write operation (bit 6). So we mask the returned status value with [[(FLOPPY_MASTER | FLOPPY_DIRECTION)]]:

<<constants>>=
#define FLOPPY_DIRECTION     0b01000000  // bit 6 of status reg.
#define FLOPPY_MASTER        0b10000000  // bit 7 of status reg.
@ %def FLOPPY_DIRECTION FLOPPY_MASTER

If only bit 7 is set in the resulting value, then we know that the controller is ready and expects a write operation. Then we can send the byte to the \emph{data/command register}\marginnote{data/command\\ register} via the [[IO_FLOPPY_COMMAND]] port; otherwise we loop until the status changes to what we need.

Sometimes a single byte (that was sent to the controller) constitutes a complete command, but often we need to send a sequence. The controller can tell from the first byte how many more bytes follow. When the command is complete, the controller executes it and generates a result that may consist of a sequence of bytes as well. 

If the loop completes without managing to send the byte, the controller needs to be reset. We store that information in the

<<global variables>>=
static volatile int fdc_need_reset = 0;
@ %def fdc_need_reset
%
variable and return.

We read the result in the following function:

<<function implementations>>=
int fdc_getresults () {
  int i, results = 0;
  if (fdc_need_reset) { printf ("exit_\n"); return 0; } ;

  for (i = 0; i < 30000; i++) {
    byte status = inb_delay (IO_FLOPPY_STATUS) & FLOPPY_NEW_BYTE;
    if (status == FLOPPY_MASTER)  return true;   // results are complete
    if (status != FLOPPY_NEW_BYTE) continue;
    if (results == MAX_FLOPPY_RESULTS) break;
    fdc_results[results++] = inb_delay (IO_FLOPPY_COMMAND);
  }

  fdc_need_reset = true;  printf ("FDC: reply error\n");
  return false;
}
@ %def fdc_getresults

If the last byte has been read, the status changes to [[FLOPPY_MASTER]] and our function can return. We check whether the status is [[FLOPPY_NEW_BYTE]] (i.\,e., the bits 4, 6 and 7 are set which indicates that the controller is busy, we're reading from the controller and it is ready to have us query it). If this is not yet the case, we repeat until the status changes to [[FLOPPY_NEW_BYTE]]: Then we can read the new byte via the [[IO_FLOPPY_COMMAND]] port.

If we exceed the maximum number of bytes that we expect the controller to send, we cancel the operation and set the [[fdc_need_reset]] flag.

<<constants>>=
#define FLOPPY_CONTROLLER_BUSY    0b00010000  // bit 4 of status reg., busy
#define FLOPPY_NEW_BYTE  (FLOPPY_MASTER | FLOPPY_DIRECTION | FLOPPY_CONTROLLER_BUSY)
@ %def FLOPPY_CONTROLLER_BUSY FLOPPY_NEW_BYTE

When we read the results, we store them in the [[fdc_results]] buffer:

<<constants>>=
#define MAX_FLOPPY_RESULTS              0x07
@ %def MAX_FLOPPY_RESULTS

<<global variables>>=
byte fdc_results[MAX_FLOPPY_RESULTS];
@ %def fdc_results 

The functions 

%nouse
<<function prototypes>>=
void outb_delay (word __port, byte __value);
byte inb_delay (word __port);
@

do the same as [[outportb()]] and
[[inportb()]], but they execute an extra [[outb]] to an unused port (\hex{E0}) in order to
create a short delay. It does not matter which value is sent to the port, so they just
send [[al]] (but could use any other value):

<<function implementations>>=
/**** FROM proc/i386.h *********/
void outb_delay (word __port, byte __value) {
  asm volatile ("outb %0,%1; \
                 outb %%al,$0xE0"      :
                /* no output */        :
                "a" (__value),
                "dN" (__port)           
                /* "eax","edx" */ );
}

byte inb_delay (word __port) {
  byte data;
  asm volatile ("inb %1,%0; \
                 outb %%al,$0xE0"      :
                "=a" (data)            :
                "dN" (__port)           
                /* "eax","edx" */ );
  return data;
}
@ %def outb_delay inb_delay


\subsection{Setting Up the DMA Transfer}

As we already mentioned, we will use a global buffer and declare its address here:
\index{DMA (direct memory access)!address of DMA buffer}%

<<global variables>>=
static char *fdc_buf = (char *)0x9a800;
@ %def fdc_buf
We have to pick the address manually because there are limitations on which memory areas can be used for DMA transfers.

The central function of the floppy driver which also handles the DMA setup is

%nouse
<<function prototypes>>=
int fdc_command (int cmd, int drive, int track, int sector);
@ It takes four parameters: [[cmd]] is set to either  [[FLOPPY_READ]] or [[FLOPPY_WRITE]] to indicate  the transfer direction, and the last three parameters describe the sector in terms of the physical layout of a floppy disk.

<<constants>>=
#define FLOPPY_READ                     0xe6
#define FLOPPY_WRITE                    0xc5
@ %def FLOPPY_READ FLOPPY_WRITE

[[fdc_command]] first sets the three variables

<<global variables>>=
static int fdc_drive, fdc_track, fdc_head;
@ %def fdc_drive fdc_track fdc_head
to the corresponding argument values; they will also be accessed by other functions of the floppy driver, so using global variables we can avoid passing these around as parameters.

Then the function resets the controller (if needed), starts the motor, lets the drive seek to the right track (we have to do that manually) and initiates the DMA transfer (see the [[<<fdc transfer>>]] chunk):

<<function implementations>>=
int fdc_command (int cmd, int drive, int track, int sector) {
  fdc_drive  = drive;
  fdc_track  = track;
  fdc_head   = sector / current_fdd_type->sectors;
  int fdc_sector = sector % current_fdd_type->sectors + 1;

  fdc_ticks_till_motor_stops = 3 * HZ;

  <<begin critical section in kernel>>  
  // will be re-enabled in fdc_read_/write_sector
  for (int err = 0;  err < MAX_FLOPPY_ERRORS;  err++) {
    if (fdc_need_reset)  fdc_reset ();
    <<fdc start motor>>
    if (!fdc_seek ())  continue;
    <<fdc transfer>>
    switch (transfer_status) {
      case -1: printf ("FDC: disk in drive %d is write protected\n", fdc_drive);
               return 0;
      case  0: continue;
      case  1: return 1;
    }
  }
  return 0;
}
@ %def fdc_command

<<constants>>=
#define HZ 100    // frequency of the timer
@ %def HZ

We allow up to eight floppy errors before we fail:

<<constants>>=
#define MAX_FLOPPY_ERRORS               0x08
@ %def MAX_FLOPPY_ERRORS

With all the information available we can initiate the transfer which means sending a longer sequence of bytes to the command/data register. We first tell the controller that we want to transfer in DMA mode (and not in PIO mode) which requires another command sequence shown in [[<<fdc dma init>>]]. 

<<fdc transfer>>=
int transfer_status = 0;  // will be set to 1 when successful
int sectors;              // number of transmitted sectors
<<begin critical section in kernel>>

if (!fdc_need_reset && current_fdd->motor && current_fdd->calibrated) {
  <<fdc dma init>>
  fdc_mode ();
  fdc_out (cmd);   fdc_out (fdc_head << 2 | fdc_drive);
  fdc_out (fdc_track); fdc_out (fdc_head); fdc_out (fdc_sector);
  fdc_out (current_fdd_type->sectorsize);      // 2: 512 bytes/sector
  fdc_out (current_fdd_type->sectors);         // end of track
  fdc_out (current_fdd_type->gap);             // gap length
  fdc_out (FLOPPY_DTL);                        // data length
@ We need not terminate the sequence because the controller knows when it has received a complete command. So we can immediately continue by waiting for the answer (via [[wait_fdc_interrupt]]) and call [[fdc_getresults]] to check whether the transfer was successful:

<<fdc transfer>>=
  if (!fdc_need_reset && !wait_fdc_interrupt () && fdc_getresults ()) { 
    if (cmd == FLOPPY_WRITE && fdc_results[1] & WRITE_PROTECTED) {
      fdc_out (FLOPPY_SENSE);
      fdc_getresults ();
      transfer_status = -1;
    } else if ((fdc_results[0] & TEST_BITS) != TRANSFER_OK ||
        fdc_results[1] || fdc_results[2]) {
      current_fdd->calibrated = 0;
      transfer_status = 0;
    } else {
      sectors = (fdc_results[3] - fdc_track) * current_fdd_type->sectors * 2
              + (fdc_results[4] - fdc_head)  * current_fdd_type->sectors
              +  fdc_results[5] - fdc_sector;
      // printf ("DEBUG: fdc_results = [%d,%d,%d], expr = [%d,%d,%d], sectors = %d\n", fdc_results[3], fdc_results[4], fdc_results[5], fdc_results[3] - fdc_track, fdc_results[4] - fdc_head, fdc_results[5] - fdc_sector, sectors);   // REMOVE_DEBUGGING_CODE
      if (sectors == 1)  transfer_status = 1;   // success
    }
  }
}
@

<<constants>>=
#define FLOPPY_DTL                      0xFF
#define TRANSFER_OK                     0x00
#define WRITE_PROTECTED                 0x02
@ %def FLOPPY_DTL TRANSFER_OK WRITE_PROTECTED

Both when sending the request and when checking whether the sector was successfully read we need the device information which declares the physical properties of the disk drive: In recent years only 3.5"\ drives with a formatted capacity of 1440 KByte have been built into PCs (if at all), but older machines used 5.25"\ drives with a 1200 KByte capacity. We store the information that we need to tell the controller in [[fdd_type]]:

<<type definitions>>=
typedef struct {
  int total_sectors, tracks, sectors, sectorsize, trackstep, rate, gap, spec1;
} struct_fdd_type;

typedef struct {
  int present, calibrated, motor, current_track, type;
} struct_fdd;
@ %def struct_fdd_type struct_fdd

<<global variables>>=
char *fdd_drive_name[6] = {
  "not installed", "360 KByte (not supported)",
  "1200 KByte",    "720 KByte (not supported)",
  "1440 KByte",    "2880 KByte (not supported)" };

struct_fdd_type fdd_type[2] = {
  { 80*15*2, 80, 15, 2, 0, 0, 0x1B, 0xDF },           /* 1.2M   */
  { 80*18*2, 80, 18, 2, 0, 0, 0x1B, 0xCF }      };    /* 1.44M  */
//  { 80*36*2, 80, 36, 2, 0, 3, 0x1B, 0xAF },           /* 2.88M  */  // REMOVE_DEBUGGING_CODE

struct_fdd_type *current_fdd_type;
struct_fdd fdd[2] = { { 0, 0, 0, INVALID_TRACK, 0 },  { 0, 0, 0, INVALID_TRACK, 0 } };
int fdds_in_use[2] = { 0, 0 };
struct_fdd *current_fdd;
@ %def fdd_drive_name fdd_type current_fdd_type fdd current_fdd fdds_in_use

<<constants>>=
#define INVALID_TRACK   -1
@ %def INVALID_TRACK

When we initialize the system, we will detect the available floppies and write the information into [[fdd]], see Section~\ref{sec:floppy:init}.

We have been using an [[fdc_mode]] function that tells the controller what kind of drive it has to access, but we have not shown its implementation yet. \marginnote{configuration\\ control register}It uses [[fdc_out]] but also writes to the \emph{configuration control register} via the [[IO_FLOPPY_RATE]] port:

%nouse
<<function prototypes>>=
void fdc_mode ();
@

<<function implementations>>=
void fdc_mode () {
  fdc_out (FLOPPY_SPECIFY);
  fdc_out (current_fdd_type->spec1);
  fdc_out (FLOPPY_SPEC2);
  outb_delay (IO_FLOPPY_RATE, current_fdd_type->rate & ~0x40);
}
@ %def fdc_mode


<<constants>>=
#define FLOPPY_SPECIFY      0x03
#define FLOPPY_SPEC2        0x06
@ %def FLOPPY_SPECIFY FLOPPY_SPEC2

\index{DMA (direct memory access)!set up the transfer}%
For setting up the DMA transfer we need to talk to the \emph{DMA controller}\marginnote{DMA controller} which uses its own ports for configuring:
\index{DMA (direct memory access)!DMA controller}%

\index{port!DMA controller}%
<<constants>>=
#define IO_DMA0_INIT        0x0A   // single channel mask register
#define IO_DMA0_MODE        0x0B   // mode register
#define IO_DMA0_FLIPFLOP    0x0C   // flip-flop reset register

#define IO_DMA_PAGE_2       0x81   // page    register for DMA channel 2
#define IO_DMA_ADDR_2       0x04   // address register for DMA channel 2
#define IO_DMA_COUNT_2      0x05   // count   register for DMA channel 2

#define DMA_READ_MODE       0x44
#define DMA_WRITE_MODE      0x48
@ %def IO_DMA0_INIT IO_DMA0_MODE IO_DMA0_FLIPFLOP DMA_READ_MODE DMA_WRITE_MODE IO_DMA_PAGE_2 IO_DMA_ADDR_2 IO_DMA_COUNT_2

The important bit about the following code chunk is that we tell the DMA controller which chunk of memory it shall use as buffer for the DMA data transfer. The controller only accepts 24 bit wide physical addresses. We tell it our buffer address [[fdc_buf]] by sending the lowest 16 bits to [[ID_DMA_ADDR_2]] and the highest eight bits to [[IO_DMA_PAGE_2]]. That stores the lower 16 bits in the controller's \emph{address register}\marginnote{address register} and the eight extra bits in the \emph{page register}\marginnote{page register}. The reason for this separate treatment is compatibility: Older DMA controllers only supported 16-bit addresses. The amount of bytes to read or write must be written to the \emph{count register}\marginnote{count register} via [[IO_DMA_COUNT_2]]. It takes a 16-bit value which requires two [[outb]] commands.

<<fdc dma init>>=
// old version used a larger buffer array with several entries // REMOVE_DEBUGGING_CODE
// replaced with fdc_buf                                       // REMOVE_DEBUGGING_CODE
// char *address = fdc_buf                                     // REMOVE_DEBUGGING_CODE 
//               + ((fdc_head * current_fdd_type->sectors      // REMOVE_DEBUGGING_CODE
//                  + fdc_sector - 1) << 9);                   // REMOVE_DEBUGGING_CODE        
int count = 1 << (current_fdd_type->sectorsize + 7);    // = 512
int mode;
if (cmd == FLOPPY_READ) 
  mode = DMA_READ_MODE;                                 // prepare read operation
else 
  mode = DMA_WRITE_MODE;                                // prepare write operation

outb_delay (IO_DMA0_INIT,     FLOPPY_CHANNEL | 4);      // disable DMA channel
outb_delay (IO_DMA0_FLIPFLOP, 0);                       // clear DMA ch. flipflop
outb_delay (IO_DMA0_MODE,     mode | FLOPPY_CHANNEL);   // set DMA ch. mode (r/w)
// set count, address and page registers
outb_delay (IO_DMA_COUNT_2,   (byte)(count-1));         // count
outb_delay (IO_DMA_COUNT_2,   (byte)((count-1) >> 8));
outb_delay (IO_DMA_ADDR_2,    (byte)(unsigned)fdc_buf); // address,    bits  0.. 7
outb_delay (IO_DMA_ADDR_2,    (byte)((unsigned)fdc_buf >> 8));      // bits  8..15
outb_delay (IO_DMA_PAGE_2,    (unsigned)fdc_buf >> 16); // page,       bits 16..23
outb_delay (IO_DMA0_INIT,     FLOPPY_CHANNEL);          // enable DMA channel
@

<<constants>>=
#define FLOPPY_CHANNEL                  0x02
@ %def FLOPPY_CHANNEL


\subsection{Starting and Stopping the Motor}

In comparison to the hard disk controller, the floppy controller needs a lot of help to get things right. For example, it is necessary to manually turn the floppy motor on and off. The code chunks [[<<fdc start motor>>]] and [[<<fdc stop motor>>]] send the right commands:

<<fdc start motor>>=
if (!current_fdd->motor) {
  outb_delay (IO_FLOPPY_OUTPUT, FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE |
                                fdc_drive | (16 << fdc_drive));
  current_fdd->motor = 1;
  fdd[!fdc_drive].motor = 0;
  for (int i = 0;  i < 500000;  i++);  // delay
}
@

<<fdc stop motor>>=
outb_delay (IO_FLOPPY_OUTPUT,
            FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE | fdc_drive);
fdd[0].motor = fdd[1].motor = 0;
@

<<constants>>=
#define FLOPPY_CONTROLLER_ENABLE        0x04
#define FLOPPY_DMAINT_ENABLE            0x08
@ %def FLOPPY_CONTROLLER_ENABLE FLOPPY_DMAINT_ENABLE


\subsection{Handling Floppy Interrupts}

We define a [[floppy_queue]] which will contain processes waiting for a floppy access operation to finish:
\index{blocked queue!floppy disk}%

<<global variables>>=
blocked_queue floppy_queue;   // processes which wait for the floppy
@ %def floppy_queue
and we have to initialize this queue:

<<initialize system>>=
initialize_blocked_queue (&floppy_queue);
@

Processes that access a floppy disk drive will wait on this queue,
and the interrupt handler will wake up these processes when the
operation was completed.

For example, when reading from an open file, we will call
[[fdc_read_sector]] which in turn calls [[fdc_command]]. 

The last function potentially calls [[fdc_reset]], and it will
call further functions all of which call [[wait_fdc_interrupt]].

[[wait_fdc_interrupt]] actually puts the process to sleep via [[fdc_sleep]] until an interrupt occurs.

Here is the implementation of the

%nouse
<<function prototypes>>=
void fdc_sleep ();
@ function:

<<function implementations>>=
void fdc_sleep () {
  if ((current_task > 1) && scheduler_is_active) {
    // block process
    fdc_is_busy = true;
    <<begin critical section in kernel>>  // access thread table
    block (&floppy_queue, TSTATE_WAITFLP);
    debug_printf ("fdc_sleep going to call resign()\n");    // REMOVE_DEBUGGING_CODE
    <<end critical section in kernel>>
    <<resign>>
  }
  fdc_is_busy = false;
};
@ %def fdc_sleep

It uses the global

<<global variables>>=
short int fdc_is_busy = false;
@ %def fdc_is_busy
variable to keep track of whether the floppy is currently working on a request.

When we need to wake up a process that has been waiting for the floppy drive, we use the

%nouse
<<function prototypes>>=
void fdc_wakeup ();
@ function. 
%We expect floppy operations to complete in the same order in which they were
%started, 
At any given time there can only be one active floppy operation, because (as you will see in the implementation of [[fdc_read_sector]] and [[fdc_write_sector]]), all read and write operations are critical sections, protected by the lock [[fdc_lock]]. So for [[fdc_wakeup]] we just wake the first process in the queue as there can only be one.

\pagebreak

<<function implementations>>=
void fdc_wakeup () {
  thread_id tid = floppy_queue.next;
  if (tid != 0)  deblock (tid, &floppy_queue);
}
@ %def fdc_wakeup

The actual interrupt handler for the floppy drives is rather simple: it first
checks whether interrupts were expected at all, and if so, it wakes the waiting
process.
\index{interrupt handler!floppy disk controller}%
\index{floppy disk interrupt handler}%

<<function implementations>>=
void floppy_handler (context_t *r) {
  fdc_timeout = false;
  debug_printf ("FDC: interrupt\n");              // REMOVE_DEBUGGING_CODE
  if (!fdc_waits_interrupt)
    fdc_need_reset = 1;  // unexpected floppy interrupt, reset controller
  fdc_waits_interrupt = false;
  fdc_wakeup ();
}
@ %def floppy_handler

We use two counters [[fdc_ticks]] and [[fdc_ticks_till_motor_stops]]: The first one starts counting when we have started a read or write operation. If it does not finish within two seconds (200 ticks) we abort the current operation (and fail). The second counter makes sure that the motor is stopped three seconds after the last operation completed. We don't turn the motor off immediately because further requests might follow. The flags [[fdc_timeout]] and [[fdc_waits_interrupt]] show whether our two seconds have run out and whether we're waiting for an interrupt.

<<global variables>>=
int     fdc_ticks                  = 0;
int     fdc_ticks_till_motor_stops = 0;
boolean fdc_timeout                = false;
boolean fdc_waits_interrupt        = false;
@ %def fdc_ticks fdc_timeout fdc_waits_interrupt fdc_ticks_till_motor_stops

The [[fdc_timer]] function will be called from the timer handler, so we need to 
declare it here:

%nouse
<<function prototypes>>=
void fdc_timer ();
@ We add it to the timer tasks which we have defined on page \pageref{chunk:timer-handler}:

<<timer tasks>>=
fdc_timer ();
@

The floppy timer has two objectives: It checks whether a timeout has occurred (and cancels the current operation) and it checks if the motor has been running too long:
\index{timer tasks!floppy driver}%

<<function implementations>>=
void fdc_timer () {
  if (fdc_waits_interrupt && ++fdc_ticks > HZ * 2) {
    fdc_waits_interrupt = false;
    fdc_timeout = true;
    fdc_wakeup ();
  } else if ((fdd[0].motor | fdd[1].motor) && 
             ~(fdc_lock->l) && !--fdc_ticks_till_motor_stops) {
    <<fdc stop motor>>
  }
}
@ %def fdc_timer

It only stops the motor if the lock [[fdc_lock]] is not held. We have not declared it yet, but already mentioned it twice:

<<global variables>>=
lock fdc_lock;
@ %def fdc_lock
We will initialize it in [[fdc_init ()]].

We also provide the function 

%nouse
<<function prototypes>>=
int wait_fdc_interrupt ();
@ that waits for an interrupt. It will return from the [[fdc_sleep]] call if either an interrupt has occurred or it has timed out:

<<function implementations>>=
int wait_fdc_interrupt () {
  fdc_ticks = 0;                  // reset the wait time
  fdc_waits_interrupt = true;     // yes, we wait
  fdc_sleep ();
  if (fdc_timeout) {              // a timeout occurred
    fdc_need_reset = 1;
    printf ("FDC: drive %d timeout\n", fdc_drive);
  }
  return fdc_timeout;
}
@ %def wait_fdc_interrupt


\subsection{Reading and Writing}

Reading and writing require that we first move the drive head to the right location. This is performed by the

%nouse
<<function prototypes>>=
int fdc_seek ();
@ function which calculates the physical parameters and sends them to the controller, using the [[FLOPPY_SEEK]] command.

<<function implementations>>=
int fdc_seek () {
  if (fdc_need_reset || 
      (!current_fdd->calibrated && !fdc_recalibrate ()))  return false;
  if (fdc_track == current_fdd->current_track)  return true;

  <<begin critical section in kernel>>
  if (!current_fdd->motor)  return false;

  fdc_out (FLOPPY_SEEK);
  fdc_out (fdc_head << 2 | fdc_drive);
  fdc_out (fdc_track);
  
  if (fdc_need_reset || wait_fdc_interrupt ())  return false;

  current_fdd->current_track = fdc_track;
  fdc_out (FLOPPY_SENSE);

  if (!fdc_getresults ())  return false;
  if ((fdc_results[0] & TEST_BITS) != SEEK_OK ||
      fdc_results[1] != fdc_track * (current_fdd_type->trackstep + 1))
    return false;
  return true;
}
@

Via [[fdc_getresults]] we check whether the seek operation was successful: In that case the highest five bits of [[fdc_results[0]]] will be \bin{00100}.

<<constants>>=
#define TEST_BITS     0b11111000   //   0xf8
#define SEEK_OK       0b00100000   //   0x20
@ %def TEST_BITS SEEK_OK

The commands [[FLOPPY_SEEK]] and [[FLOPPY_SENSE]] perform the seek operation and request status information from the floppy drive which is required after every command.

\pagebreak 

<<constants>>=
#define FLOPPY_SEEK                     0x0f
#define FLOPPY_SENSE                    0x08
@ %def FLOPPY_SEEK FLOPPY_SENSE

With seeking completed, we're ready to read or write.

%nouse
<<function prototypes>>=
int fdc_read_sector  (int device, int block, char *buffer);
int fdc_write_sector (int device, int block, char *buffer);
@

These functions read and write 512 byte sized sectors:

<<function implementations>>=
int fdc_read_sector (int device, int block, char *buffer) {
  // 1.4MB: 80 tracks, 18 sectors, sectorsize=2. 80x18x2=2880  // REMOVE_DEBUGGING_CODE
  <<fdc: prepare read/write sector>>
  result = fdc_command (FLOPPY_READ, device, ctrack, csector);  // will sleep
  if (result) {
    debug_printf ("DEBUG: fdc_read_sector: "    // REMOVE_DEBUGGING_CODE
                  "accessing FDC buffer\n");    // REMOVE_DEBUGGING_CODE
    // old version used a larger buffer array with several entries // REMOVE_DEBUGGING_CODE
    // memcpy ((void *)buffer, PHYSICAL(&fdc_buf[csector << 9]), FD_SECSIZE);  // REMOVE_DEBUGGING_CODE
    memcpy ((void *)buffer, PHYSICAL(fdc_buf), FD_SECSIZE);
  }
  <<fdc: finish read/write sector>>
}
@ %def fdc_read_sector
with
<<fdc: prepare read/write sector>>=
int spt;                            // sectors per track
int ctrack, csector;
int result;

mutex_lock (fdc_lock);
  current_fdd      = &fdd[device];
  current_fdd_type = &fdd_type[current_fdd->type];

  spt = current_fdd_type->sectors * 2;  // 36 ??
  ctrack   = block / spt;
  csector  = block % spt;
@ and
<<fdc: finish read/write sector>>=
mutex_unlock (fdc_lock);
if (result) return FD_SECSIZE;
else        return 0;
@

<<constants>>=
#define FD_SECSIZE                      512
@ %def FD_SECSIZE

Writing is similar, but the order of calling [[fdc_command]] and copying the buffer contents is reversed; also [[fdc_command]] supplies the argument [[FLOPPY_WRITE]] instead of [[FLOPPY_READ]], and the [[memcpy]] operation works the other way round:

<<function implementations>>=
int fdc_write_sector (int device, int block, char *buffer) {
  // 1.4MB: 80 tracks, 18 sectors, sectorsize=2. 80x18x2=2880   // REMOVE_DEBUGGING_CODE
  <<fdc: prepare read/write sector>>
  // memcpy (PHYSICAL(&fdc_buf[csector << 9]), (void *)buffer, FD_SECSIZE);  // REMOVE_DEBUGGING_CODE
  memcpy (PHYSICAL(fdc_buf), (void *)buffer, FD_SECSIZE);
  result = fdc_command (FLOPPY_WRITE, device, ctrack, csector);  // will sleep
  <<fdc: finish read/write sector>>
}
@ %def fdc_write_sector

\index{block read/write!floppy disk}%
Since we will always read or write whole blocks (1 KByte) we add
[[readblock_fd]] and [[writeblock_fd]] functions 

%nouse
<<function prototypes>>=
void readblock_fd  (int device, int blockno, char *buffer);
void writeblock_fd (int device, int blockno, char *buffer);
@ which simply call the sector functions twice:

<<function implementations>>=
void readblock_fd  (int device, int blockno, char *buffer) {
  fdc_read_sector  (device, blockno*2,     buffer);
  fdc_read_sector  (device, blockno*2 + 1, buffer + FD_SECSIZE);
};

void writeblock_fd (int device, int blockno, char *buffer) {
  fdc_write_sector (device, blockno*2,     buffer);
  fdc_write_sector (device, blockno*2 + 1, buffer + FD_SECSIZE);
};
@ %def readblock_fd writeblock_fd


\subsection{Resetting and Recalibrating}

Two further functions

%nouse
<<function prototypes>>=
void fdc_reset ();
int  fdc_recalibrate ();
@ are required for our floppy driver implementation. [[fdc_reset]] is called when too many errors have occurred; in that case it asks the controller to reset so that a new attempt can be started.

<<function implementations>>=
void fdc_reset () {
  // debug_printf ("DEBUG: cli, in fdc_reset\n");    // REMOVE_DEBUGGING_CODE
  <<begin critical section in kernel>>
  outb_delay (IO_FLOPPY_OUTPUT, FLOPPY_DMAINT_ENABLE);
  for (int i = 0;  i < 10000;  i++)  asm ("nop");   // wait a bit
  outb_delay (IO_FLOPPY_OUTPUT, FLOPPY_CONTROLLER_ENABLE | FLOPPY_DMAINT_ENABLE);

  fdc_need_reset = 0;
  fdd[0].calibrated = fdd[1].calibrated = 0;
  fdd[0].motor      = fdd[1].motor      = 0;

  if (wait_fdc_interrupt ())  printf ("FDC: can't reset controller (timeout)\n");
  fdc_out (FLOPPY_SENSE);
  if (!fdc_getresults ())  printf ("FDC: can't reset controller\n");
}
@ %def fdc_reset

The [[fdc_recalibrate]] function sends the [[FLOPPY_RECALIBRATE]] command to the controller which is necessary when the drive is not calibrated; this should happen only once (when the drive is accessed for the first time).

%BREAK BEFORE DEFINES
<<function implementations>>=
int fdc_recalibrate () {
  if (fdc_need_reset)  return 0;
  //! DEBUG(1, "FDC: recalibrating drive %d...\n", fdc_drive); // REMOVE_DEBUGGING_CODE
  <<begin critical section in kernel>>
  <<fdc start motor>>
  fdc_out (FLOPPY_RECALIBRATE);
  fdc_out (fdc_drive);
  if (fdc_need_reset || wait_fdc_interrupt ())  return 0;
  fdc_out (FLOPPY_SENSE);
  if (!fdc_getresults () || (fdc_results[0] & TEST_BITS) != SEEK_OK || fdc_results[1])
    goto bad_recalibration;

  current_fdd->current_track = INVALID_TRACK;
  return current_fdd->calibrated = 1;

  bad_recalibration:
  printf ("FDC: can't recalibrate\n");
  fdc_need_reset = 1;
  return 0;
}
@ %def fdc_recalibrate

<<constants>>=
#define FLOPPY_RECALIBRATE              0x07
@ %def FLOPPY_RECALIBRATE


\subsection{Floppy Driver Initialization}
\label{sec:floppy:init}%

As with the hard disk driver, we also need to initialize the floppy driver when the system boots. This happens in the

%nouse
<<function prototypes>>=
void fdc_init ();
@ function which initializes the locks, gathers the information about available floppy drives from the CMOS, enters them in the data structures (and displays them on the screen) and installs the interrupt handler for the floppy interrupt. It is comparable to the [[ata_init]] function.

\index{port!CMOS chip}%
\index{kernel lock!for the floppy disks}%
%BREAK BEFORE DEFINES
<<function implementations>>=
void fdc_init () {
  fdc_lock = get_new_lock ("fdc");                  // initialize lock

  outb_delay (IO_CMOS_CMD, 0x10);                   // read floppy status from CMOS
  int fdd_type_byte = inb_delay (IO_CMOS_DATA);

  int type; printf ("FDC: ");                       // enter and display data
  for (int i = 0;  i < 2;  i++) {
    // check floppy drive i
    if (i == 0) type = fdd_type_byte >> 4;    // upper 4 bits
    else        type = fdd_type_byte & 0x0F;  // lower 4 bits
    if ((fdd[i].present = (type == 2 || type == 4 || type == 5 )))
      fdd[i].type = fdc_map_type (type);
    printf ("fd%d (%s)%s", i, fdd_drive_name[type], (i==0) ? ", " : "\n");
  }

  if (fdd[0].present || fdd[1].present) {           // enable floppy handler
    install_interrupt_handler (IRQ_FDC, floppy_handler);
    enable_interrupt (IRQ_FDC);
    outportb (IO_FLOPPY_RATE,    0); // FDC Reset
    outportb (IO_FLOPPY_OUTPUT, 12); // enable DMA, disable Reset
  }
}
@ %def fdc_init

It uses the helper function

%nouse
<<function prototypes>>=
int fdc_map_type (int t);
@ that converts the floppy drive type (as seen in the CMOS) into an index into the [[fdd_type[]]] table which contains description of the drive characteristics.

<<function implementations>>=
int fdc_map_type (int t) {
  switch (t) {
    case 2:  return 0;   // 1.2  MByte drive
    case 4:  return 1;   // 1.44 MByte drive
    // case 5:  return 2;   // 2.88 MByte drive   // REMOVE_DEBUGGING_CODE
    default: return -1;
  }
}
@ %def fdc_map_type


\subsection*{Credits}

As a final note we want to give credit to Tudor Hulubei\index{Hulubei, Tudor} who wrote
the Thix Operating System\index{Thix operating system} \cite{Hulubei:1995:Thix} and published the
source code under the GPL 2 license. The whole floppy code in 
Section~\ref{sec:floppy} is based on his floppy driver implementation,
though we have removed a lot of the original code. For example, Thix
uses several disk buffers so that floppy requests can be queued.



%-----------------------------------------------------------------------




\chapter{Signals}
\label{chap:ulix:signals}%
\index{signal}%

Signals are a classical Unix mechanism which allows a simple kind of
messaging: processes can send signals to other processes which makes them
either terminate or call a registered \emph{signal handler}\index{signal!signal handler}\marginnote{signal handler}. In many ways these
signals are very similar to interrupts, but while an interrupt handler
can only be set up in kernel mode (and serves the whole operating system),
signal handlers can be set up in user mode and belong to just one process.

The similarity between signals and interrupts goes even further: Interrupts
exist in two varieties, \emph{synchronous} (e.\,g.\ interrupts caused by accessing
a bad memory address or trying to execute an unknown CPU instruction) and 
\emph{asynchronous} (e.\,g.\ raised by a device, such as the timer or a floppy or
hard disk controller), and the same holds for signals: a 
\marginnote{synchronous\\ signal}\emph{synchronous signal}
is caused by the process itself (again access to a bad memory address is an
example---in that case it causes an interrupt first and the interrupt handler
sends a corresponding signal to the process), but most signals are
\emph{asynchronous}\marginnote{asynchronous\\ signal} (sent by a different process).

Some functionality is available in both worlds (interrupts and signals),
take for example a timer: the computer's timer chip generates regular timer
interrupts which are asynchronous events and invoke the kernel's timer
interrupt handler. Besides other things, this handler checks whether one of
the processes has registered a (process-private) timer---and if so,
generates an alarm signal. When the process is scheduled the next time,
instead of continuing its normal execution it enters its alarm signal
handler and treats the asynchronous signal.

An example for synchronous events in both worlds is bad memory access.
When a process tries to access a virtual address which is not available
(because the page tables do not map it to some physical address), a
page fault is generated, so the CPU jumps into the page fault (interrupt)
handler. That one checks the reason (the only acceptable reason being
that the page was paged out to disk). If that is not the case, the 
process must be terminated. To achieve this goal, the page fault handler
sends the process a \marginnote{\texttt{SIGSEGV}}[[SIGSEGV]] (\emph{segmentation violation}) signal. 
When the process is scheduled again,
it will normally abort, though it may have registered a [[SIGSEGV]] signal
handler to deal with such a situation.

For the memory example, consider the following program [[segfault.c]]:

%nouse
<<segfault.c>>=
int main () {
  char *adr = (char *)0;
  char c = *adr;
  putchar (c);
}
@

\noindent
and its execution via the debugger [[gdb]]:

\begin{Verbatim}
$ gcc -g segfault.c 
$ gdb a.out 
GNU gdb (Ubuntu/Linaro 7.4-2012.04-0ubuntu2.1) 7.4-2012.04
(gdb) run
Starting program: /tmp/a.out 

Program received signal SIGSEGV, Segmentation fault.
0x0000000000400508 in main () at segfault.c:3
3	  char c = *adr;
\end{Verbatim}


\section{Use Cases for Signals}

What are signals good for? In this section we show you three examples which
demonstrate the range of application of signals.

\begin{description}

\item[Program Error:] In many cases programs may run into a problem when they try to perform an action that the CPU will not allow, for example when trying to access an invalid memory address. This is normally an indication that the program is faulty, and the best action will be to terminate the process. However, instead of checking every memory address in the program before it is accessed, a developer may decide to rely on an error handler that will be called if such behavior is detected. So a solution could be to write an error handler (and install it as the signal handler for the signal that will be generated) that resets the program to some initial state and starts over. Then, when an error occurs, the processor jumps into the fault handler\index{fault handler!signal|see {signal}}\index{signal!sent by the fault handler} which will send a signal to the process. When the process continues, it will execute the signal handler.

\item[Inter Process Communication:] \index{inter-process communication (IPC)}Processes that work together somehow, often need to communicate. Unix systems provide special mechanisms for sending complex messages, but if only some kind of ``ping'' is required to tell another process that a certain condition has been reached, then a signal can serve that purpose.

\item[Voluntary Abort:] A process may decide to terminate itself when it recognizes an error condition. Instead of calling [[exit]] with an error return value, it can use [[abort]] to send itself a \marginnote{\texttt{SIGABRT}}[[SIGABRT]] signal.\index{abort}\index{process!aborting}

\end{description}


\section{Signals in Classical Unix Systems}

\index{signal!classical Unix signals}%
\index{Unix!signals}%
In classical Unix systems, processes can use the \verb#kill# system call to
deliver a signal to an arbitrary process (as long as both have the same
owner or the signal-sending process belongs to [[root]]) or the \verb#raise#
system call to send a signal to themselves.

Every Unix system knows a few standard signals, with signal numbers 
typically ranging from 0 to 31. While some signals have standard signal
numbers (such as 9 and 15 for [[SIGKILL]] and [[SIGTERM]]), the POSIX
standard does not require signals to use standard values; it only asks
for signal names to be defined\footnote{see \url{http://pubs.opengroup.org/onlinepubs/009695399/basedefs/signal.h.html}}:

\newcommand{\signame}[1]{\textsf{\textbf{#1}}}

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
\begin{description}
\item[SIGABRT]\index{signal!SIGABRT (abort)}
(default action: abort)

Process abort signal. The signal could be sent by the process itself (see above), by a different process or by the kernel.

\item[SIGALRM]\index{signal!SIGALRM (alarm clock)}
(default action: abort)

Unix systems normally supply an alarm clock mechanism. By defining a timer, this signal will be sent when the requested timeout occurs.

\item[SIGBUS]\index{signal!SIGBUS (invalid address)}
(default action: abort)

The process tried to access an invalid address. This is similar to \signame{SIGSEGV}, but the latter deals with forbidden access to a valid address (an address that requires kernel privileges).

\item[SIGCHLD]\index{signal!SIGCHLD (child terminates, stops, continues)}
(default action: ignore)

When a child process terminates, stops (\textsf{\textbf{SIGSTOP}}) or continues (\textsf{\textbf{SIGCONT}}), its parent process is notified with this signal.

\item[SIGCONT]\index{signal!SIGCONT (continue)}
(default action: continue)

A process that was stopped (via \textsf{\textbf{SIGSTOP}}) continues execution.

\columnbreak
\item[SIGFPE]\index{signal!SIGFPE (floating point exception)}
(default action: abort)

Originally the acronym FPE stood for \emph{Floating Point Exception} and the signal was raised when the process caused the FPU (Floating Point Unit) to perform a faulting calculation, such as a division by zero. Today \textsf{\textbf{SIGFPU}} is used for all kinds of arithmetic errors.

\item[SIGHUP]\index{signal!SIGHUP (hang-up)}
(default action: abort)

The Hangup signal tells a process that its controlling terminal is gone. On a modern Unix system this often refers to a closed terminal window, traditionally it occurred when the connection of a dumb terminal device to the machine (via a serial line or a dial-in connection) was lost.

\item[SIGILL]\index{signal!SIGILL (illegal instruction)}
(default action: abort)

The process tried to execute an illegal instruction (e.\,g., one that requires a newer processor with an extended instruction set).

\item[SIGINT]\index{signal!SIGINT (Ctrl-C pressed)}
(default action: abort)

Pressing [Ctrl-C] generates this signal. It is possible to write a signal handler which may decide to ignore [Ctrl-C]. Note that \UlixI{} terminates processes when this key combination is pressed.

\item[SIGKILL]\index{signal!SIGKILL (kill at once)}
(default action: abort)

This is the aggressive KILL signal that cannot be intercepted by a signal handler. It terminates the process at once.

\item[SIGPIPE]\index{signal!SIGPIPE (writing to pipe with no reader)}
(default action: abort)

The process wrote to a pipe that has no reader.

\item[SIGQUIT]\index{signal!SIGQUIT}
(default action: abort)

This is similar to \textsf{\textbf{SIGINT}}. Some systems write a core dump, in addition to what is caused by \textsf{\textbf{SIGINT}}.

\item[SIGSEGV]\index{signal!SIG (forbidden address)}
(default action: abort)

The process tried to access a memory location for which it lacks the required privileges, see \textsf{\textbf{SIGBUS}}.

\item[SIGSTOP]\index{signal!SIGSTOP (stop)}
(default action: stop)

The signal stops a process. It will remain blocked until it receives \textsf{\textbf{SIGCONT}}. The signal cannot be intercepted by a handler.

\item[SIGTERM]\index{signal!SIGTERM (terminate)}
(default action: abort)

The process is asked to terminate. It can install a signal handler for this signal which allows it to write in-memory data to files or perform other final actions. The signal can also be ignored.

\item[SIGTSTP]\index{signal!SIGTSTP (stop)}
(default action: stop)

This is a variant of \textsf{\textbf{SIGSTOP}} and allows the installation of a signal handler.

\columnbreak
\item[SIGTTIN]\index{signal!SIGTTIN (no terminal)}
(default action: stop)

The process has no terminal but tried to read from a non-redirected standard input.

\item[SIGTTOU]\index{signal!SIGTTOU (no terminal)}
(default action: stop)

The process has no terminal but tried to write to a non-redirected standard output or standard error output.

\item[SIGUSR1, SIGUSR2]\index{signal!SIGUSR1 (user-defined)}\index{signal!SIGUSR2 (user-defined)}
(default: abort)

These signals can be used by application developers for their own purposes.

\item[SIGPOLL]\index{signal!SIGPOLL (new data)}
(default action: ignore)

When new data appear on a process' standard input, this signal is raised. Network sockets can also generate this signal.

\item[SIGPROF]\index{signal!SIGPROF (alarm)}
(default action: abort)

A special timer that counts CPU time which was spent in this process (or in the kernel, but for this process) generates this signal. It is similar to \textsf{\textbf{SIGALRM}} but that one uses real time. Also compare with \textsf{\textbf{SIGVTALRM}}.

\item[SIGSYS]\index{signal!SIGSYS (unknown system call)}\index{system call!SIGSYS signal}
(default action: abort)

The process tried to execute a system call with an unknown system call number.

\item[SIGTRAP]\index{signal!SIGTRAP (debugger breakpoint)}
(default action: abort)

This signal is raised when a process is run in a debugger and a breakpoint was reached.

\item[SIGURG]\index{signal!SIGURG (new data)}
(default action: ignore)

For systems that support networking, this signal indicates that data have arrived on a socket which require urgent treatment.

\item[SIGVTALRM]\index{signal!SIGVTALRM (alarm)}
(default action: abort)

A special timer that counts CPU time which was spent in this process (but not the kernel) generates this signal. It is similar to \textsf{\textbf{SIGALRM}} but that one uses real time. Also compare with \textsf{\textbf{SIGPROF}}.

\item[SIGXCPU]\index{signal!SIGXCPU (CPU usage exceeded)}
(default action: abort)

This can be used if a process is only granted a certain amount of CPU time before it is terminated. The signal is sent a bit earlier so that the process can finish its work.

\item[SIGXFSZ]\index{signal!SIGXFSZ (disk usage exceeded)}
(default action: abort)

The process has tried to create a file that is larger than allowed.

\end{description}
\end{multicols}


\renewcommand{\signame}[1]{\textsf{#1}}

Table \ref{tab:signals} shows how these signal names are mapped to signal numbers
on some standard systems.\index{Linux!signal numbers}\index{FreeBSD operating system!signal numbers}

The information in the table was gathered from the following sources: 
\begin{itemize}
\item \verb#kill -l# on Linux (kernel 3.0.0) and OS X
(Darwin kernel 10.8.0), 
\item Minix \path!signal.h! header file; ``n/a'' (not available) means: these
system calls have not been implemented in Minix, but the numbers were
assigned because the POSIX standard requires Unix implementations to define them;
\url{http://faculty.qu.edu.qa/rriley/cmpt507/minix/signal_8h-source.html}.
\item FreeBSD: \url{http://www.unix.com/man-page/FreeBSD/3/signal/}
\item OpenSolaris 2009.06, \url{http://www.unix.com/man-page/opensolaris/3head/signal.h/}
\end{itemize}

Over these five operating systems, only the signals \signame{SIGHUP} (1), \signame{SIGINT} (2), \signame{SIGQUIT} (3), \signame{SIGILL} (4), \signame{SIGTRAP} (5), \signame{SIGABRT} (6), \signame{SIGFPE} (8), \signame{SIGKILL} (9), \signame{SIGSEGV} (11), \signame{SIGPIPE} (13), \signame{SIGARLM} (14) and \signame{SIGTERM} (15) have common numbers.

You can find further details about signals in
section 2.4 (\emph{Signal Concepts}) of the \emph{System Interfaces} volume of the Single UNIX® Specification, Version 4, 2013 Edition \cite{IEEE:2013:SingleUNIXSpec2013}.


\section{Implementation of Signals in \UlixI{}}
\index{signal!implementation in Ulix}%
\index{Ulix!signal implementation}%

In order to implement signals the following two sets of functionalities are
normally required:

\begin{itemize}
\item Methods which let a process register \emph{signal handlers} (via a \verb#signal# 
system call) and decide which signals to block (by setting the
\emph{signal mask}\index{signal!signal mask}\marginnote{signal mask} via a [[sigprocmask]] system
call). (\UlixI{} does not support changing the signal mask.)
\item Methods to deliver signals to processes and have the process react
accordingly: for delivering, we need to implement the \verb#kill# system call,
and making the process execute (and return from) the signal handler requires
changes to the scheduling code.
\end{itemize}

We will allow each process to define signal handlers for 32 signals (0--31),
so we need space for 32 addresses, and we need to store $2 \times 32$ bits
in each process for pending signals and blocked signals: A signal handler
is stored as its address:

\pagebreak

\begin{table}[h!]
\centering
\begin{tabular}{l|r|r|r|r|r}
\textbf{Signal} & \textbf{Linux} & \textbf{OS X} & 
\textbf{Minix} & \textbf{FreeBSD} & \textbf{Solaris} \\
\hline
\signame{SIGABRT}   &  6 &  6 &  6 &  6 &  6 \\
\signame{SIGALRM}   & 14 & 14 & 14 & 14 & 14 \\
\signame{SIGBUS}    &  7 & 10 &  7 & 10 & 10 \\
\signame{SIGCHLD}   & 17 & 20 & 17 & 20 & 18 \\
\signame{SIGCONT}   & 18 & 19 & n/a, 18 & 19 & 25 \\
\signame{SIGFPE}    &  8 &  8 &  8 &  8 &  8 \\
\signame{SIGHUP}    &  1 &  1 &  1 &  1 &  1 \\
\signame{SIGILL}    &  4 &  4 &  4 &  4 &  4 \\
\signame{SIGINT}    &  2 &  2 &  2 &  2 &  2 \\
\signame{SIGKILL}   &  9 &  9 &  9 &  9 &  9 \\
\signame{SIGPIPE}   & 13 & 13 & 13 & 13 & 13 \\
\signame{SIGQUIT}   &  3 &  3 &  3 &  3 &  3 \\
\signame{SIGSEGV}   & 11 & 11 & 11 & 11 & 11 \\
\signame{SIGSTOP}   & 19 & 17 & n/a, 19 & 17 & 23 \\
\signame{SIGTERM}   & 15 & 15 & 15 & 15 & 15 \\
\signame{SIGTSTP}   & 20 & 18 & n/a, 20 & 18 & 24 \\
\signame{SIGTTIN}   & 21 & 21 & n/a, 22 & 21 & 26 \\
\signame{SIGTTOU}   & 22 & 22 & n/a, 23 & 22 & 27 \\
\signame{SIGUSR1}   & 10 & 30 & 10 & 30 & 16 \\
\signame{SIGUSR2}   & 12 & 31 & 12 & 31 & 17 \\
\signame{SIGPOLL} *)& 29 & 23 & -- & 23 & 22 \\
\signame{SIGPROF}   & 27 & 27 & 25 & 27 & 29 \\
\signame{SIGSYS}    & 31 & 12 & -- & 12 & 12 \\
\signame{SIGTRAP}   &  5 &  5 &  5 &  5 &  5 \\
\signame{SIGURG}    & 23 & 16 & -- & 16 & 21 \\
\signame{SIGVTALRM} & 26 & 26 & 24 & 26 & 28 \\
\signame{SIGXCPU}   & 24 & 24 & -- & 24 & 30 \\
\signame{SIGXFSZ}   & 25 & 25 & -- & 25 & 31 \\
%\hline
%SIGSTKFLT & 16 & -- & -- & -- & -- \\
%SIGWINCH  & 28 & 28 & 21 & 28 & 20 \\
%SIGPWR    & 30 & -- & -- & -- & 19 \\
%SIGEMT    & -- &  7 & 16 &  7 &  7 \\
%SIGINFO   & -- & 29 & -- & 29 & -- \\
%SIGKMESS  & -- & -- & 29 & -- & -- \\
%SIGKSIG   & -- & -- & 30 & -- & -- \\
%SIGNDELAY & -- & -- & 31 & -- & -- \\
%SIGTHR    & -- & -- & -- & 32 & -- \\
%SIGCANCEL & -- & -- & -- & -- & 36 \\
%SIGFREEZE & -- & -- & -- & -- & 34 \\
%SIGLOST   & -- & -- & -- & -- & 37 \\
%SIGLWP    & -- & -- & -- & -- & 33 \\
%SIGTHAW   & -- & -- & -- & -- & 35 \\
%SIGWAITING& -- & -- & -- & -- & 32 \\
%SIGXRES   & -- & -- & -- & -- & 38 \\
\end{tabular}
  \caption{Standard signals on five Unix systems.}
  \label{tab:signals}
  
\vspace{3mm}
{\small
*) Linux, Mac OS and FreeBSD call the SIGPOLL signal SIGIO.
}

\end{table}

\vspace{-2mm}\enlargethispage{3mm}
<<public elementary type definitions>>=
typedef void (*sighandler_t)(int);
@ %def sighandler_t

\noindent
and 32 bits fit precisely in an [[unsigned long]] integer, so we can add
two variables [[sig_pending]] and [[sig_blocked]] for storing those bits:

<<more TCB entries>>=
  sighandler_t sighandlers[32];
  unsigned long sig_pending;
  unsigned long sig_blocked;
@

\pagebreak

For every signal number [[i]] and each state of a process there are several
possibilities:
\index{signal!pending}\index{signal!blocked}\index{pending signal}\index{blocked signal}

\begin{itemize}
\item The signal is \emph{blocked}; in that case the [[i]]-th bit in [[sig_blocked]] 
is 1, and the value in [[sighandlers[i]]] is irrelevant, because the signal will
cause the [[i]]-th bit of [[sig_pending]] to be set.
\item The signal is not blocked and the default action shall take place;
in that case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[SIG_DFL]].
\item The signal is not blocked, but the process ignores this signal; in that 
case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[SIG_IGN]].
\item The signal is not blocked and a signal handler [[handler()]] has been
installed; in that case the corresponding bit in [[sig_blocked]] is 0 and
[[sighandlers[i]]] is [[handler]].
\end{itemize}

We use the [[SIG_DFL]] and [[SIG_IGN]] values from a Linux\index{Linux} system
(on a 32 bit Linux system their definitions can be found in
\path!/usr/include/asm-generic/signal-defs.h!):

<<public constants>>=
#define SIG_DFL ((sighandler_t)0)     // default signal handling
#define SIG_IGN ((sighandler_t)1)     // ignore signal
#define SIG_ERR ((sighandler_t)-1)    // error code
@ %def SIG_DFL SIG_IGN SIG_ERR

\index{signal!default action, \texttt{SIG\_DFL}}%
\index{signal!ignore, \texttt{SIG\_IGN}}%

This assumes that 0 and 1 can never be the addresses of a signal handler function. 

We will not implement queues for signals; if the same process receives
the same signal more than once before the scheduler activates it the next
time, then the extra signal(s) will be lost (which is also what other Unix
implementations do). Thus, our internal [[u_kill]] function is rather simple:

%nouse
<<function prototypes>>=
int u_kill (int pid, int signo);
@

\noindent
will set [[errno]] (more precisely: the TCB element [[error]]) to one of
the following error constants if something goes wrong:

<<error constants>>=
#define EPERM   1  // not permitted
#define ESRCH   3  // no such process
#define EINVAL 22  // invalid argument
@ %def EPERM ESRCH EINVAL

Now we present the implementation. We have taken the signal numbers from an
OS~X system (and renamed [[SIGIO]] to [[SIGPOLL]]):

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
<<public constants>>=
#define SIGHUP     1
#define SIGINT     2
#define SIGQUIT    3
#define SIGILL     4
#define SIGTRAP    5
#define SIGABRT    6
#define SIGFPE     8
#define SIGKILL    9
#define SIGBUS    10
#define SIGSEGV   11
#define SIGSYS    12
#define SIGPIPE   13
#define SIGALRM   14
#define SIGTERM   15
#define SIGURG    16
#define SIGSTOP   17
#define SIGTSTP   18
#define SIGCONT   19
#define SIGCHLD   20
#define SIGTTIN   21
#define SIGTTOU   22
#define SIGPOLL   23
#define SIGXCPU   24
#define SIGXFSZ   25
#define SIGVTALRM 26


#define SIGPROF   27
#define SIGUSR1   30
#define SIGUSR2   31
@ %def SIGHUP SIGINT SIGQUIT SIGILL SIGTRAP SIGABRT SIGFPE SIGKILL SIGBUS SIGSEGV SIGSYS SIGPIPE SIGALRM SIGTERM SIGURG SIGSTOP SIGTSTP SIGCONT SIGCHLD SIGTTIN SIGTTOU SIGPOLL SIGXCPU SIGXFSZ SIGVTALRM SIGPROF SIGUSR1 SIGUSR2
\end{multicols}

The [[u_kill]] function first tests a few error conditions and leaves immediately if it finds one of them: Signal numbers must be between 0 and 31, the target process must exist and must neither have PID 1 (\verb#init#/\verb#idle#) or 2 (\verb#swapper#) nor \verb#login# as command name.

Then it checks whether [[SIG_DFL]] is set as signal handler; depending on the signal it changes the signal number to [[SIGKILL]] (for killing the process) or [[SIGSTOP]] (for stopping it). After that it treats the three special cases of the [[SIGKILL]], [[SIGSTOP]] and [[SIGCONT]] signals which cannot be blocked or ignored.

Finally it checks whether the signal shall be ignored; if the signal is neither ignored nor blocked, it sets the pending bit in the target TCB's [[sig_pending]] field and returns.
\index{signal!kill() function@\texttt{kill()} function}%

<<function implementations>>=
int u_kill (int pid, int signo) {
  TCB *tcb = &thread_table[pid];
  if (signo < 0 || signo > 31) { set_errno (EINVAL); return -1; }
  if (!tcb->used)              { set_errno (ESRCH);  return -1; }
  if ( (pid < 3) || (strncmp (tcb->cmdline, "login", 5) == 0) ) 
                               { set_errno (EPERM);  return -1; }
  
  if (tcb->sighandlers[signo] == SIG_DFL) {           // default action
    if (signo == SIGABRT || signo == SIGALRM  || signo == SIGBUS  ||
        signo == SIGFPE  || signo == SIGHUP   || signo == SIGILL  ||
        signo == SIGINT  || signo == SIGPIPE  || signo == SIGTERM ||
        signo == SIGUSR1 || signo == SIGUSR2  || signo == SIGPROF ||
        signo == SIGSYS  || signo == SIGTRAP  || signo == SIGVTALRM ||
        signo == SIGXCPU || signo == SIGXFSZ) {
      // default: abort, send SIGKILL
      printf ("Replacing signal %d with kill signal (9)\n", signo);
      signo = SIGKILL;    // no handler? kill it
    } else if (signo == SIGTTIN || signo == SIGTTOU || signo == SIGTSTP) {
      // default: stop, send SIGSTOP
      printf ("Replacing signal %d with kill signal (9)\n", signo);
      signo = SIGSTOP;    // no handler? kill it
    }
  }
  
  switch (signo) {  <<[[u_kill]]: special cases>>  };     // cannot ignore/block
  
  if (tcb->sighandlers[signo] == SIG_IGN) return 0;   // ignore signal
  int blocked = tcb->sig_blocked & (1<<signo);
  if (!blocked && signo >= 0 && signo < 32) {
    tcb->sig_pending |= (1<<signo);                   // set the pending bit
  }
  return 0;
}
@ %def u_kill

We treat three special cases directly in the [[u_kill]] function:
\index{signal!special treatment for KILL, STOP, CONT}%

\begin{itemize}

\item The [[SIGSTOP]] signal:

<<[[u_kill]]: special cases>>=
case SIGSTOP:   <<[[u_kill]]: remove thread from queue>>
                tcb->state = TSTATE_STOPPED;
                if (pid == current_task) {
                  <<resign>>  // enter scheduler_
                }
                return 0;
@

\end{itemize}
\begin{itemize}
                
\item The [[SIGCONT]] signal:

<<[[u_kill]]: special cases>>=
case SIGCONT:   if (tcb->state == TSTATE_STOPPED) {
                  add_to_ready_queue (pid);  // sets TSTATE_READY
                }  // else ignore
                return 0;
@
                
\end{itemize}
\begin{itemize}

\item The [[SIGKILL]] signal:

<<[[u_kill]]: special cases>>=
case SIGKILL:   <<[[u_kill]]: remove thread from queue>>
                tcb->used = false;
                tcb->state = TSTATE_EXIT;
                <<[[u_kill]]: write kill message>>
                wake_waiting_parent_process (pid);
                <<enable scheduler>>
                if (pid == current_task) {
                  <<resign>>  // enter scheduler_
                }
                return 0;
@

\end{itemize}

We want to notify the user that the process was killed, so we write a ``Killed'' message onto the terminal that the task uses. For that purpose we need to temporarily change the value of [[thread_table[current_task].terminal]] (since [[printf()]] uses that value to find its target) and restore it after writing:

<<[[u_kill]]: write kill message>>=
int tmp_term = thread_table[current_task].terminal;
thread_table[current_task].terminal = thread_table[pid].terminal;
printf ("\nKilled\n");
thread_table[current_task].terminal = tmp_term;
@

In order to remove the thread from a queue we can only guess what queue it might be on since we do not have a list of all available queues; for example, every lock has its separate queue, and locks can be generated on the fly. We check the standard blocked queues (waiting for a child process, a keyboard, floppy or hard disk event) and the ready queue:

<<[[u_kill]]: remove thread from queue>>=
switch (tcb->state) {
  case TSTATE_READY:   remove_from_ready_queue (pid);                       break;
  case TSTATE_WAITFOR: remove_from_blocked_queue (pid, &waitpid_queue);     break;
  case TSTATE_WAITKEY: remove_from_blocked_queue (pid, &keyboard_queue);    break;
  case TSTATE_WAITFLP: remove_from_blocked_queue (pid, &floppy_queue);      break;
  case TSTATE_WAITHD:  remove_from_blocked_queue (pid, &harddisk_queue);    break;
  case TSTATE_WAITSD:  remove_from_blocked_queue (pid, &serial_disk_queue); break;
  default:             printf ("cannot remove process %d (state: %d) from blocked"
                               " queue, probably failure!\n", pid, tcb->state);
}
@

\pagebreak

Note that we need not (and do not) perform any checks in this function: [[u_kill]] 
can be called by the kernel itself (which may send any signal to any process), 
but it cannot be called directly by a process. Sending by a process requires using
a system call, and the system call handler will check whether the process
is allowed to send the signal to the target process before calling [[u_kill]].

It is also classical for a process to send a signal to itself; that is
what the [[raise]] function does. We will not implement it specifically
inside the kernel, but in the user mode library: [[raise(sig)]] is the
same as [[kill(getpid(),sig)]].

Here's the code for the system call handler:

<<initialize syscalls>>=
install_syscall_handler (__NR_kill, syscall_kill);
@

\syscallindex{kill}
%nouse
<<syscall prototypes>>=
void syscall_kill (context_t *r);
@

<<syscall functions>>=
void syscall_kill (context_t *r) {
  // ebx: pid of child to send a s signal,  ecx: signal number
  int retval; int target_pid = r->ebx; int signo = r->ecx;

  if (!thread_table[target_pid].used) {      // check if target process exists
    // target process does not exist
    set_errno (ESRCH);
    retval = -1; goto end;
  }
  
  if (signo < 0 || signo > 31) {             // check if signal is in range 0..31
    set_errno (EINVAL);
    retval = -1; goto end;
  }
  
  // check if current process may send a signal
  if ((thread_table[current_task].euid == 0) ||
      (thread_table[target_pid].euid == thread_table[current_task].euid)) {
    retval = u_kill (target_pid, signo);
  } else {
    set_errno (EPERM);
    retval = -1;
  }
  end: r->eax = retval;

  // run scheduler_ if this was a raise operation
  if (current_task == target_pid) {  <<resign>>  }
};
@ %def syscall_kill

We only allow sending a signal if either the sender's owner has user ID 0 or 
if sender and recipient have the same owner.

If sender and receiver are the same process, we have a [[raise]] operation,
and in that case we will jump into the scheduler: we do not want the current
process to continue execution since it might have sent a [[SIGKILL]] signal
to itself.

(Note that we cannot use the [[eax_return]] macro in this function because
we may or may not call [[<<resign>>]].)

How can a process declare a signal handler? It just defines a function
[[void *handler (int)]] (of type [[sighandler_t]]) and makes a [[signal]] 
syscall. The internal function for entering a system call is the following:
\index{signal!install signal handler (\texttt{signal()} function)}%

%nouse
<<function prototypes>>=
sighandler_t u_signal (int sig, sighandler_t func);
@

<<function implementations>>=
sighandler_t u_signal (int sig, sighandler_t func) {
  sighandler_t old_func;
  if (sig >= 0 && sig < 32 && 
      sig != SIGKILL && sig != SIGSTOP && sig != SIGCONT) {
    old_func = thread_table[current_task].sighandlers[sig];
    thread_table[current_task].sighandlers[sig] = func;
  } else {
    old_func = SIG_ERR;   // wrong signal number
  }
  return old_func;
}
@ %def u_signal

The function sets the new signal handler and returns the address of
the old handler (or 0 if there was none); that way the process can
keep a copy of the old handler address in order to restore it at a
later point.

As usual, we need to provide a system call so that a process can access
this function.

\syscallindex{signal}%
%BREAK BEFORE DEFINES
%nouse
<<syscall prototypes>>=
void syscall_signal (context_t *r);
@ It performs the already well-known transfers of register values
to arguments and of the return value to the \register{EAX} register:

<<syscall functions>>=
void syscall_signal (context_t *r) {
  // ebx: signal_ number
  // ecx: address of signal_ handler
  int signo         = r->ebx;
  sighandler_t func = (sighandler_t)r->ecx;
  func = u_signal (signo, func);
  eax_return (func);
};
@ %def syscall_signal

<<initialize syscalls>>=
install_syscall_handler (__NR_signal, syscall_signal);
@

Finally, we need to add code to the scheduler: it needs to check for
pending signals and---if there are any---launch the registered handler
function or execute the standard action. Running a handler can be
achieved by modifying the process' stack. We loop over the set of
possible signal numbers (0--31) and check the bits in [[sig_pending]].
(Remember that [[t_new]] points to the newly chosen process' TCB.)

Note that we only modify the stack (and the \register{EIP}\index{register!EIP}\index{EIP register} value) if the process
is currently running in user mode (i.\,e., [[t_new->regs.eip < 0xc0000000]]),
because otherwise we would change the kernel stack (making the signal
handler run with kernel privileges).

<<scheduler: check pending signals>>=
for (int signo = 0;  signo < 32;  signo++) {
  if ((t_new->sig_pending & (1<<signo)) != 0    // signal_ is pending
      && t_new->regs.eip < 0xc0000000) {        // and thread is in user mode
    if (t_new->sighandlers[signo] == SIG_DFL) {
      ;    // nop                               // default action, cannot happen
    } else if (t_new->sighandlers[signo] == SIG_IGN) {
      ;    // nop                               // ignored, should not happen
    } else {
      // handler exists
      <<modify process to execute signal handler>>
    }
    t_new->sig_pending &= ~(1<<signo);          // remove bit
    break;                                      // only one handler at a time
  }
}
@

When a handler exists, we modify both the (user mode) stack and the \register{EIP}\index{register!EIP}\index{EIP register} register.

<<modify process to execute signal handler>>=
// Note: t_new->regs has already been copied to r
memaddress oldeip = r->eip;
r->eip = (memaddress)t_new->sighandlers[signo];
// push signal_ number and oldeip on user mode stack
// int xx = PEEK_UINT (r->useresp);                      // REMOVE_DEBUGGING_CODE
// printf ("\nDEBUG: OLD STACK CONTENT: 0x%x\n", xx);    // REMOVE_DEBUGGING_CODE
POKE_UINT (r->useresp, signo);   // overwrites old RET address
r->useresp -= 4;
POKE_UINT (r->useresp, oldeip);  // writes new RET address
@


\subsection{Library Functions}

Now we can provide the user mode library functions for the two new system calls; we also define a [[raise]] function which sends a signal to the own process:

%nouse
<<ulixlib function prototypes>>=
int kill (int pid, int signo);
int raise (int signo);
sighandler_t signal (int sig, sighandler_t func);
@

<<ulixlib function implementations>>=
int kill (int pid, int signo) {
  return syscall3 (__NR_kill, pid, signo);
}

int raise (signo) {
  return kill (getpid (), signo);
}

sighandler_t signal (int sig, sighandler_t func) {
  return (sighandler_t)syscall3 (__NR_signal, sig, (memaddress)func);
}
@ %def kill signal raise


\subsection{Example Program}

We end this chapter with an example program that you can also find on the \UlixI{} disk image: \path!/bin/sigtest! forks, registers two signal handlers in the child and sends two signals twice from the parent process. Both processes otherwise print sequences of ``p''s or ``c''s to show that they are active. The expected behavior is that the output is interrupted with four messages from the two signal handlers.

%nouse
<<example for signal handlers>>=
#include "../ulixlib.h"

void handler1 (int sig);
void handler2 (int sig);
void waste_time ();

int main (int argc, char *argv[]) {
  int i; int pid = fork ();
  if (pid == 0) {                                    // child
    signal (5, handler1);   // register handler 1
    signal (6, handler2);   // register handler 2
    for (i = 0; i < 40; i++) { printf ("c"); waste_time (); }
    exit (0);
  } else {                                          // parent
    for (i = 0; i < 20; i++) { printf ("p"); waste_time (); }    
    kill (pid, 5);
    kill (pid, 6);
    for (i = 0; i < 22; i++) { printf ("p"); waste_time (); }    
    printf ("--done\n");
    exit (0);
  }
}

void handler1 (int sig) { printf ("\nHandler 1\n"); } 
void handler2 (int sig) { printf ("\nHandler 2\n"); } 

void waste_time () {
  long int i, z;
  for (i=0L; i<1000000L; i++)  z = i*i - (i+1)*(i+1);
}
@




%------------------------------------------------------------------------------------------------




\chapter{Users and Groups}
\label{chap:ulix:usersgroups}%

\index{user}\index{group}\index{user group|see {group}}%
Unix and all Unix-derived operating systems are multi-user-capable. There are configuration files which contain the information about all known \emph{users}\marginnote{users}, and there is also a list of groups that users can be members of. Each user has a \emph{standard group}\marginnote{standard group} but may---additionally---have the membership of one or more further groups. The [[id]] command lists the user ID, a corresponding user name, the standard group ID and name and a list of all additional group memberships. The following is an example from a Linux\index{Linux} installation:

\begin{Verbatim}
$ id
uid=1000(esser) gid=1000(esser) groups=1000(esser),24(cdrom),25(floppy),29(audio),
30(dip),44(video),46(plugdev)
\end{Verbatim}

Internally, the systems use only the numerical IDs; tools which display user and group names will look them up using functions such as [[getpwnam]] or [[getgrnam]]. The inode of each file stores a user ID and a group ID, the first one expresses file ownership by the specific user who uses this user ID, whereas the second one establishes an additional group ownership. Members of a group may (or may not) have access rights to a file which has the corresponding group ID. The group is sometimes called the \emph{owner group}\marginnote{owner group} or \emph{group owner}, both variants mean the same thing.

Classical Unix systems can associate nine \emph{access permissions}\index{access permissions (files)}\marginnote{access\\ permissions} with every file and every directory: for files, these are the three basic rights to read (\verb#r#), write (\verb#w#) or execute (\verb#x#) a file, for directories the interpretation is listing, modifying and searching/entering a directory (where ``searching'' means getting the inode number of a file in the directory and ``entering'' means setting the \emph{current working directory} to a folder). Each of these three permissions can be granted or denied to the file owner, all members of one specific group of users and all other users. This leads to nine permissions typically represented as a nine-character string of the form \verb#rwxrwxrwx# where missing rights are expressed by exchanging a letter with a minus character. For example, the permission string \verb#rwxr-x---# for a file lets the file owner read, write and execute that file (\verb#rwx#); it lets members of the file's owner group read and execute (but not write) it (\verb#r-x#), and other users (those who neither are the owner nor belong to the owner group) cannot access the file at all (\verb#---#).

There are a few more attributes which can be set for files and directories which have specific effects:

\begin{description}

\item[SUID:] \index{set used ID bit}\index{SUID}If the \emph{Set User ID bit} (\emph{SUID}) is set for an executable file, the \marginnote{effective\\ user ID}\emph{effective user ID} (EUID) is set to the ID of the file owner. For example, the [[passwd]] tool uses this feature: It may be called by any user (who wants to change his own password), but it needs administrator privileges to modify the password file which is non-writeable for ordinary users. In order to allow this, the [[passwd]] program is set to belong to the \verb#root# user and has the SUID bit set. When a regular user starts [[passwd]], the effective user ID of the process is set to 0 (the user ID of \verb#root#), and write access to the password file is granted.

In the directory listing of an executable file with a set SUID bit, the first \verb#x# in the permissions string is replaced with an \verb#s# to show this. It is also possible to set the SUID bit on a non-executable file which will show up with a capital \verb#S#, however this is useless.

\item[SGID:] \index{set group ID bit}\index{SGID}The \emph{Set Group ID bit} (\emph{SGID}) has a function that is similar to the SUID bit's, however it changes the \emph{effective group ID}\marginnote{effective\\ group ID} (EGID). It appears as a capital \verb#S# in the group permissions block.

On some Unix systems, a non-group-executable file which has the SGID bit set is marked for \emph{mandatory locking}\marginnote{mandatory\\ locking} (for the Linux OS\index{Linux!mandatory locking}, see \url{https://www.kernel.org/doc/Documentation/filesystems/mandatory-locking.txt}).

\item[Sticky Bit:] \index{sticky bit (file)}The \emph{sticky bit} appears as a \verb#t# letter in the last position of the permissions string (replacing the \verb#x# which shows the world-executable state). Similar to the difference between \verb#s# and \verb#S#, if a file is set to be sticky but not world-executable, it appears as a capital \verb#T#.

The effect of a set sticky bit depends on the Unix variant. For example, the Linux man page for [[chmod]] says: 
``For directories, it  prevents unprivileged  users  from  removing or renaming a file in the directory unless they  own  the  file  or  the  directory;  this  is  called  the restricted  deletion  flag  for the directory, and is commonly found on world-writable directories like \verb#/tmp#.''

On traditional Unix systems, a sticky bit on an executable file caused the system to keep the program code in memory after termination of a process, with the idea that it did not have to be reloaded when the same program was executed again. That is where the term ``sticky'' comes from.

\end{description}

\noindent
Many modern Unix-like systems provide further access mechanisms through \emph{extended attributes} or \emph{access control lists}\marginnote{access control\\ list (ACL)} (ACLs). This is a feature which was not available in classical Unix, and we will not implement it for \UlixI{}, either.


\section{Users and Groups in \UlixI{}}

\index{Ulix!users and groups}%
\index{user!implementation in Ulix}%
\index{group!implementation in Ulix}%
In order to implement the user and group concepts in \UlixI{}, each thread control block needs four new entries: a user ID ([[uid]]), a group ID ([[gid]]) and effective user and group IDs ([[euid]], [[egid]]) plus a third set called real user ID and real group ID ([[ruid]], [[rgid]]:
\index{user!user ID}\index{group!group ID}%
\index{user!real user ID}\index{group!real group ID}%
\index{user!effective user ID}\index{group!effective group ID}%
\index{real user ID}\index{effective user ID}%
\index{real group ID}\index{effective group ID}%

<<more TCB entries>>=
word uid;   // user ID
word gid;   // group ID
word euid;  // effective user ID
word egid;  // effective group ID
word ruid;  // real user ID
word rgid;  // real group ID
@ %def uid gid euid egid ruid rgid
The purpose of the \emph{real user and group IDs} is to always remember which user started the process: it will (normally) not change over a process' lifetime whereas [[uid]], [[gid]] and the effective IDs can be changed by a running process using [[setuid]], [[setgid]], [[seteuid]] and [[setegid]] functions; we will explain soon why we need to keep track of so many IDs.

0 is a special ID, both for users and groups.\marginnote{user/group ID 0} It belongs to the [[root]] user\index{root user (UID 0)}\index{user!root user (UID 0)} and [[root]] group\index{root group (GID 0)}\index{group!root group (GID 0)}, respectively. The [[root]] user is the \emph{system administrator}\index{system administrator} who can override all permission settings (e.\,g.{} open files for which no read permissions have been set at all). All other IDs have no special meaning, though it is standard on many systems to reserve IDs below 100 (or below 1000) for \emph{system services}\marginnote{system services} with regular user IDs starting at 100 (or 1000).

The default setting of \UlixI{} processes is to run with [[root]] privileges. The function \linebreak[[start_program_from_disk]] sets all four IDs to 0:

<<start program from disk: set uid, gid, euid, egid>>=
thread_table[tid].uid  = 0;  thread_table[tid].gid  = 0;
thread_table[tid].euid = 0;  thread_table[tid].egid = 0;
thread_table[tid].ruid = 0;  thread_table[tid].rgid = 0;
@

The Linux\index{Linux!setreuid man page@\texttt{setreuid} man page} man page for [[setreuid]] states:

\begin{quotation}
``POSIX.1  does not specify all of [the] possible ID changes that are permitted on Linux for an unprivileged process.  For [[setreuid()]], the effective  user  ID  can  be made the same as the real user ID or the save set-user-ID, and it is unspecified whether unprivileged processes may set  the  real user ID to the real user ID, the effective user ID or the saved set-user-ID.  For [[setregid()]], the  real  group  ID  can  be changed  to  the  value  of the saved set-group-ID, and the effective  group ID can be changed to the value of the  real  group  ID  or  the saved  set-group-ID.  The precise details of what ID changes are permitted vary across implementations.''
\end{quotation}

\noindent
For \UlixI{} we will take a simplified approach with the following rules:

\begin{itemize}
\item Processes can invoke the \verb#setuid# and \verb#setgid# system calls to change their user and group IDs ([[uid]], [[gid]]), and this will also set the effective user/group ID to the same value. These functions shall only succeed if the process had an [[uid]] value of 0 or if the desired new ID is identical to either the current user ID or the current effective user ID.

\item Processes can invoke the \verb#seteuid# and \verb#setegid# system calls to change their effective user and group IDs ([[euid]], [[egid]]). This will \emph{not} change the user/group ID ([[uid]], [[gid]]). These functions shall only succeed if the process had an [[uid]] value of 0 or if the desired new effective ID is identical to either the current user ID or the current effective user ID.

\item The \verb#login# system call which expects a user ID and a password allows changing the real and effective user and group IDs as long as the correct password was supplied. \verb#login# is also the only system call which sets the real user and group IDs, thus allowing the system to keep track of which user initially started a process.

\item Whenever file access is checked, the system looks at the effective IDs to establish the permissions of the current process.
\end{itemize}

The consequence of these rules is that changing, for example, the user ID and effective user ID via [[setuid]] is a permanent change which cannot be undone, whereas a modification of only the effective user ID via [[seteuid]] can be followed up with another [[seteuid]] call that sets it back to the original value. Once [[uid]] and [[euid]] have the same non-zero value, there is only one way to go back to a different ID or effective ID: it has to make a \verb#login# system call which reperforms authorization against the password database.

Whenever a process forks, the new process inherits all IDs from its parent.


\subsection{Checking Permissions}
\index{access permissions (files)}%

Before we delve into the implementation of [[login]] and the [[set*id]] functions, let's look at how the [[open]] and [[execv]] functions use the effective IDs to test whether access can be granted or not. 

Checking whether a user may access a file seems to be a simple task: The OS just needs to look up the file's inode and check the file owner, group and permissions stored in the corresponding fields. But this is only half of the work we need to do because there is also the issue of getting into the directory which holds the file---after all, if the directory does not provide sufficient read permissions, it is forbidden to find the inode number that belongs to a filename entry.

The access rules are also different for opening (existing) files and newly creating files.

\begin{itemize}
\item In order to \emph{access} an existing file (either for reading or writing), the user must have read and execute permissions on all directories which are passed on the way to file, starting with the root directory [[/]].
\item In order to \emph{create} a new file, the same permissions are needed, and the user must also have write permission for the last directory (in which the file will be created).
\end{itemize}
\UlixI{} will first check whether the file already exists. It will then follow the path from either the existing file or from the target directory, all the way up to the root directory and test for each directory whether the needed permissions are available. We can do this in a loop which repeatedly uses [[splitpath]] to strip the last element of the current path.

Pseudo code for this loop looks like this:

%nouse
<<pseudo code for checking permissions>>=
curpath = abspath;
step = 0;
for (;;) {
  // check current path
  if (step == 0 && fileexists (abspath)) {  // can we access the (existing) file?
    ok = check (curpath, oflag);            // check requested mode
  } else
  if (step == 1 && !fileexists (abspath)) { // can we create the file, i.\,e. write 
                                            // to the target directory?
    ok = check (curpath, "rwx");
  } else {
    ok = check (curpath, "rx");             // check some intermediate directory
  }
  if (!ok) return false;                    // access denied
  if (curpath == "/") return true;          // end of loop (/), access granted

  // move to upper directory
  lastpath = curpath;
  splitpath (lastpath, curpath, tmp);
  step++;
}
@

Note that it would be more efficient to directly implement the access checks in the loop inside the [[mx_open]] function of the Minix subsystem which traverses the path down from the root to the file, but we did not want to discuss access rights when we presented the code for opening a file. Also, our method is independent of the filesystem (e.\,g. Minix). But it does more than duplicate the efforts of walking down the path, so it would be unacceptable for production systems.

In each step both user, group and world access permissions need to be considered: for example, if user permissions allow access to the first directory, group permissions allow access to the second directory and world permissions allow access to the third directory, then that is an acceptable sequence. Only if none of the directory permissions allow access (somewhere in the path), access must be denied.

\pagebreak

We start with the implementation of

%nouse
<<function prototypes>>=
boolean fileexists (char *abspath);
@ for which we can use the [[u_stat]] function:

<<function implementations>>=
boolean fileexists (char *abspath) {
  struct stat tmp;                        // stat info will not be used
  return (u_stat (abspath, &tmp) != -1);  // -1 means: does not exist
}
@ %def fileexists

For checking the permissions on any level, we write a function

%nouse
<<function prototypes>>=
boolean check_access (char *path, word euid, word egid, word mode);
@ %
which evaluates the owner, group and world access permissions, depending on the provided user and group IDs ([[euid]] and [[egid]]):

<<function implementations>>=
boolean check_access (char *path, word euid, word egid, word mode) {
  struct stat st; 
  int res = u_stat (path, &st);   // get file permissions
  if (res == -1 && (mode & O_CREAT) == 0) {
    set_errno (ENOENT); // file not found
    return false;
  }

  if (res == -1 && (mode & O_CREAT) != 0) {
    <<[[check_access]] special case: create file>>
  }

  if (euid == st.st_uid) {
    // case 1: user owns the file
    res = check_perms (CHECK_USER,  mode, st.st_mode);
  } else if (egid == st.st_gid) {
    // case 2: group matches owner group
    res = check_perms (CHECK_GROUP, mode, st.st_mode);
  } else {
    // case 3: world access?
    res = check_perms (CHECK_WORLD, mode, st.st_mode);
  }
  if (!res) set_errno (EACCES);
  return res;
}
@ %def check_access
(The function [[check_perms]] checks just one possible way of getting access, e.\,g. via the owner permissions. We will describe it soon.)

<<error constants>>=
#define ENOENT          2               // No such file or directory
#define EACCES          13              // Permission denied
@ %def ENOENT EACCES

There's also one special case we need to consider: when we create a new file, it does not yet exist, and so [[u_stat]] will return $-1$. For file creation we have to check the access permissions of the directory in which the new file is to be placed.

<<[[check_access]] special case: create file>>=
char dirname[256], basename[256];
splitpath (path, dirname, basename);
res = u_stat (dirname, &st);   // get directory permissions
if (res == -1) {
  set_errno (ENOENT);          // directory not found
  return false;
}
if (euid == st.st_uid) {
  // case 1: user owns the directory
  res = (((st.st_mode >> CHECK_USER)  & 0x7) == 0x7);   // 7: rwx
} else if (egid == st.st_gid) {
  // case 2: group matches owner group
  res = (((st.st_mode >> CHECK_GROUP) & 0x7) == 0x7);
} else {
  // case 3: world access?
  res = (((st.st_mode >> CHECK_WORLD) & 0x7) == 0x7);
}
if (!res) set_errno (EACCES);
return res;
@

The [[u_open]] function calculates the absolute path of the file it shall open and stores it in [[abspath]]; the requested mode for opening is held in the function's [[oflag]] parameter. It can then call [[u_stat]] to read its access permissions as well as the permissions of the directories involved:

<<[[u_open]]: check permissions>>=
boolean access_ok = false;
word euid = thread_table[current_task].euid;
word egid = thread_table[current_task].egid;
struct stat st;

if (euid == 0) {
  access_ok = true;   // user root can do anything
} else {
  // loop over the directories
  char old_dirname[256]; char dirname[256]; char rest[256];
  strncpy (dirname, abspath, 256);
  for (;;) {
    strncpy (old_dirname, dirname, 256);
    splitpath (old_dirname, dirname, rest);   // ignore rest
    // printf ("DEBUG: checking access to directory %s\n", dirname);  // REMOVE_DEBUGGING_CODE
    u_stat (dirname, &st);
    access_ok = <<[[u_open]]: access to directory is ok>>;
    if (!access_ok) {
      // printf ("DEBUG: access denied at directory %s\n", dirname);  // REMOVE_DEBUGGING_CODE
      set_errno (EACCES);
      return -1;
    }
    if (strlen (dirname) == 1) break;         // reached root directory
  }
  // finally: check file permissions   
  access_ok = check_access (abspath, euid, egid, oflag);
}
if (!access_ok) {
  return -1;  // wrong permissions
}
@ %

A process may only access a directory if it can read and ``execute'' it, and that's possible if one of the following three conditions is fulfilled:

\begin{itemize}
\item the process' effective user (determined by the [[euid]] field) owns the file and the user read and execute bits (\oct{0500}) are set in the access permissions,
\item the process' effective user \emph{does not} own the file, the process' effective group (determined by the [[egid]] field) is the file's owner group and the group read and execute bits (\oct{0050}) are set in the access permissions,
\item or neither the user and group fields of the file match the effective user or group, but the world permissions allow read and execute access (\oct{0005}).
\end{itemize}

Thus, checking whether the process may access a directory (read and execute, $1+4 =5$) can be
done with the following code:

<<[[u_open]]: access to directory is ok>>=
( // user may have access,                         r-x------ ?
  (((euid == st.st_uid) &&                        (st.st_mode & 0500) == 0500)) ||     
  // group may have access (if wrong user),        ---r-x--- ?
  (((euid != st.st_uid) && (egid == st.st_gid) && (st.st_mode & 0050) == 0050)) ||
  // others may have access (wrong user, group),   ------r-x ?
  (((euid != st.st_uid) && (egid != st.st_gid) && (st.st_mode & 0005) == 0005))  )
@

Now we need to provide the function 
\pagebreak

%nouse
<<function prototypes>>=
boolean check_perms (short what, word req_mode, word perms);
@ which accepts one of the three constants

<<constants>>=
#define CHECK_USER  6
#define CHECK_GROUP 3
#define CHECK_WORLD 0
@ %def CHECK_USER CHECK_GROUP CHECK_WORLD
%
and a requested mode [[req_mode]] and the file permissions [[perms]]. The lowest two bits of [[req_mode]] are either \bin{00} (in case of [[O_RDONLY]]), \bin{01} (in case of [[O_WRONLY]]) or \bin{10} (in case of [[O_RDWR]]). We can check them by looking at [[req_mode & 0x3]].

File access permissions can be found in the lowest nine bits of [[perms]]. 

\begin{itemize}
\item If we want to check world permissions (for ``others''), we look at the lowest three bits, [[perms & 0x7]]. 
\item For the group permissions we can first right-shift [[perms]] so that we drop the lowest three bits, that is, we look at [[(perms >> 3) & 0x7]].
\item Finally, for the owner permissions, we need a right-shift of six bits, which gives us [[(perms >> 6) & 0x7]]
\end{itemize}

By setting [[CHECK_USER]], [[CHECK_GROUP]] and [[CHECK_WORLD]] to the necessary amount of shifting (6, 3, 0), we can do this automatically:

<<function implementations>>=
boolean check_perms (short what, word req_mode, word perms) {
  // printf ("DEBUG: check_perms (%d, 0o%o, 0o%o)\n", what, req_mode, perms);  // REMOVE_DEBUGGING_CODE
  boolean req_read  = ((req_mode & 0x3) == O_RDONLY) | ((req_mode & 0x3) == O_RDWR);
  boolean req_write = ((req_mode & 0x3) == O_WRONLY) | ((req_mode & 0x3) == O_RDWR);
  word check = (perms >> what) & 0x7;
  if (req_read  && ((check & 0x4) != 0x4)) return false;  // read_  perm. failure
  if (req_write && ((check & 0x2) != 0x2)) return false;  // write_ perm. failure
  set_errno (0);
  return true;  // both are ok
}
@ %def check_perms

Note that some of this behavior is not obvious: for example, consider a user with user ID 1000 and group ID 1000 who wants to open the following file in [[O_RDWR]] mode:

\begin{Verbatim}
-r--rw-r--   1000  1000  filename
\end{Verbatim}

The file belongs to him and also to his group, but the owner permissions do not contain the right to write to the file. Access will be denied in this case, even though the group permissions would allow writing. In this case it just makes no sense that the owner's write access is not enabled in the permission string. The user would first have to fix this situation via [[chmod]].

The [[u_execv]] function must also check whether it may load an application: this requires that the read and executable flags are set for the owner, group or others. We're leaving this as an exercise to you.

<<[[u_execv]]: check permissions>>=
// TO DO, see "Exercises" section.
@


\subsection{Changing User and Group IDs}

\index{login}%
Now we can deal with the [[login]] and [[set*id]] system calls. As usual we start with the kernel functions which do the real work:

%nouse
<<function prototypes>>=
int u_setuid  (word uid);    // set user ID
int u_setgid  (word gid);    // set group ID
int u_seteuid (word euid);   // set effective user ID
int u_setegid (word egid);   // set effective group ID
int u_login (word uid, char *pass);
@

All of these functions shall return 0 if they were successful and $-1$ otherwise. The implementations are simple, we only have to follow the rules described earlier:

<<function implementations>>=
int u_setuid (word uid) {
  TCB *t = &thread_table[current_task];
  <<begin critical section in kernel>>  // access thread table
  if (t->uid == 0 || uid == t->uid || uid == t->euid) {
    t->uid = uid;                 // set UID
    t->euid = uid;                // and also EUID
    <<end critical section in kernel>>
    return 0;                     // success
  } else {
    <<end critical section in kernel>>
    return -1;                    // failure
  }
}

int u_setgid (word gid) {
  TCB *t = &thread_table[current_task];
  <<begin critical section in kernel>>  // access thread table
  if (t->uid == 0 || gid == t->gid || gid == t->egid) {
    t->gid = gid;                 // set GID
    t->egid = gid;                // and also EGID
    <<end critical section in kernel>>
    return 0;                     // success
  } else {
    <<end critical section in kernel>>
    return -1;                    // failure
  }
}
@ %def u_setuid u_setgid

The implementations of [[u_seteuid]] and [[u_setegid]] are almost identical to the above code, they just skip setting the [[uid]] or [[gid]] elements of the TCB:

<<function implementations>>=
int u_seteuid (word uid) {
  TCB *t = &thread_table[current_task];
  <<begin critical section in kernel>>  // access thread table
  if (t->uid == 0 || uid == t->uid || uid == t->euid) {
    t->euid = uid;                // set the EUID (only!)
    <<end critical section in kernel>>
    return 0;                     // success
  } else {
    <<end critical section in kernel>>
    return -1;                    // failure
  }
}

int u_setegid (word gid) {
  TCB *t = &thread_table[current_task];
  <<begin critical section in kernel>>  // access thread table
  if (t->uid == 0 || gid == t->gid || gid == t->egid) {
    t->egid = gid;                // set the EGID (only!)
    <<end critical section in kernel>>
    return 0;                     // success
  } else {
    <<end critical section in kernel>>
    return -1;                    // failure
  }
}
@ %def u_seteuid u_setegid

The [[u_login]] function is just a little more complicated: In a real Unix system it would look up the \emph{password hash}\marginnote{password hash} stored in \path!/etc/passwd!, \path!/etc/shadow! or some similar file, calculate the hash from the password that was provided as the second argument, compare the two hashes and then decide on setting all user and group IDs (including the real user and group IDs [[ruid]], [[guid]]). Since we don't want to include a hash function in the \UlixI{} source code, we just store the plaintext password in the file. We also restrict the password file\index{password file}\index{user!password file} size to 1024 bytes since the \UlixI{} kernel  has no advanced functions for line reading; we read one block of data and parse it byte by byte.

<<function implementations>>=
int u_login (word uid, char *pass) {
  TCB *t = &thread_table[current_task];
  char passwords[BLOCK_SIZE];
  char *words[128];
  int fd = u_open ("/etc/passwd", O_RDONLY, 0);
  if (fd == -1) return -1;                        // fail: no password database
  int size = u_read (fd, &passwords, BLOCK_SIZE);
  u_close (fd);
  int pos;  int index = 0;                        // position in words array

  words[index++] = (char*)&passwords;             // split 
  for (pos = 1;  pos < size;  pos++) {
    if (passwords[pos] == ':' || passwords[pos] == '\n') {
      passwords[pos] = 0;                         // terminate string
      words[index++] = ((char*)&passwords)+pos+1;
    }
  }
 
  for (int i = 0;  i < index/5;  i++) {           // search
    if ( (atoi (words[5*i+2]) == uid)             // found right entry
          && strequal (words[5*i+1], pass) ) {    // password matches
      // printf ("DEBUG: User %s(%s) authenticated.\n", words[5*i], words[5*i+2]);  // REMOVE_DEBUGGING_CODE
      int gid = atoi (words[5*i+3]);              // get group ID
      u_chdir (words[5*i+4]);                     // make home directory the cwd
      t->uid = t->euid = t->ruid = uid;
      t->gid = t->egid = t->rgid = gid;
      return 0;                                   // success
    }
  }
  
  // printf ("DEBUG: User ID %d, Password: %s, fail!\n", uid, pass);  // REMOVE_DEBUGGING_CODE
  return -1;                                      // fail
}
@ %def u_login

As usual we need to provide system calls for these functions:

\syscallindex{setuid}\syscallindex{setgid}\syscallindex{seteuid}\syscallindex{setegid}\syscallindex{login}%
%nouse
<<syscall prototypes>>=
void syscall_setuid  (context_t *r);
void syscall_setgid  (context_t *r);
void syscall_seteuid (context_t *r);
void syscall_setegid (context_t *r);
void syscall_login   (context_t *r);
@

\pagebreak

<<syscall functions>>=
void syscall_setuid (context_t *r) {
  // ebx: uid
  eax_return ( u_setuid (r->ebx) );
}

void syscall_setgid (context_t *r) {
  // ebx: gid
  eax_return ( u_setgid (r->ebx) );
}

void syscall_seteuid (context_t *r) {
  // ebx: euid
  eax_return ( u_seteuid (r->ebx) );
}

void syscall_setegid (context_t *r) {
  // ebx: egid
  eax_return ( u_setegid (r->ebx) );
}

void syscall_login (context_t *r) {
  // ebx: uid, ecx: password
  eax_return ( u_login (r->ebx, (char*)r->ecx) );
}
@ %def syscall_setuid syscall_setgid syscall_seteuid syscall_setegid syscall_login
%
and enter the new handler function in the system call table:

<<initialize syscalls>>=
install_syscall_handler (__NR_setuid32, syscall_setuid);
install_syscall_handler (__NR_setgid32, syscall_setgid);
install_syscall_handler (__NR_setreuid32, syscall_seteuid);
install_syscall_handler (__NR_setregid32, syscall_setegid);
install_syscall_handler (__NR_login, syscall_login);
@

(Note that the syscall numbers [[__NR_setreuid32]] and [[__NR_setregid32]] do not really match the corresponding functions ([[seteuid]] and [[setegid]]), but they are the closest candidates, so we chose them instead of reserving new numbers. We must, however, declare the system call number [[__NR_login]]:

\pagebreak

<<public constants>>=
#define __NR_login 523
@ %def __NR_login

The user mode library functions just make the system calls:

%nouse
<<ulixlib function prototypes>>=
int setuid  (word uid);    // set user ID
int setgid  (word gid);    // set group ID
int seteuid (word euid);   // set effective user ID
int setegid (word egid);   // set effective group ID
int login   (word uid, char *pass);
@

<<ulixlib function implementations>>=
int setuid (word uid)  { return syscall2 (__NR_setuid32, uid);   }
int setgid (word gid)  { return syscall2 (__NR_setgid32, gid);   }
int seteuid (word uid) { return syscall2 (__NR_setreuid32, uid); }
int setegid (word gid) { return syscall2 (__NR_setregid32, gid); }
int login (word uid, char *pass) {
                         return syscall3 (__NR_login, uid, (unsigned int) pass); }
@ %def setuid setgid seteuid setegid login

In order to let user mode programs look up \path!/etc/passwd! entries, we implement some functions in the library which fill data structures of the following type:

<<ulixlib type definitions>>=
struct passwd {
  char pw_name[32];    // user name
  char pw_passwd[32];  // password
  word pw_uid;         // user ID
  word pw_gid;         // group ID
  char *pw_gecos;      // long name        (ULIX: unused)
  char pw_dir[32];     // home directory
  char *pw_shell;      // shell            (ULIX: unused)
};
@ %def passwd

The functions

%nouse
<<ulixlib function prototypes>>=
int getpwnam_r (const char *name,   struct passwd *pwd, 
                char *buffer, int bufsize, struct passwd **result);
int getpwuid_r (word uid, struct passwd *pwd, 
                char *buffer, int bufsize, struct passwd **result);                
@ %
%
have to read the password file, search it for the username (or user ID) and then fill the supplied data structure. Since both reading the file and storing the data in the structure are the same in both functions, we use two code chunks that deal with these tasks.

\pagebreak

<<ulixlib function implementations>>=
int getpwnam_r (const char *name,   struct passwd *pwd, 
                char *buffer, int bufsize, struct passwd **result) {
  <<get password entry: read password file into [[passwords]] and parse it>>
  int i; for (i = 0;  i < index/5;  i++) {
    if ( strequal (words[5*i], name) ) {        // found right entry
      <<get password entry: fill target buffers>>
      return 0;   // success
    }
  }
  return -1;      // fail
}

int getpwuid_r (word uid, struct passwd *pwd, 
                char *buffer, int bufsize, struct passwd **result) {              
  <<get password entry: read password file into [[passwords]] and parse it>>
  int i; for (i = 0;  i < index/5;  i++) {
    if (atoi (words[5*i+2]) == uid) {           // found right entry
      <<get password entry: fill target buffers>>
      return 0;   // success
    }
  }
  return -1;      // fail
}
@ %def getpwnam_r getpwuid_r

with
<<get password entry: read password file into [[passwords]] and parse it>>=
#define PASSWD_SIZE 1024
char passwords[PASSWD_SIZE] = "passwords";  char *words[128];
int fd = open ("/etc/passwd", O_RDONLY);
if (fd == -1) {
  printf ("Cannot open /etc/passwd\n"); 
  return -1;    // fail: no password database
}
int size = read (fd, (char*)passwords, PASSWD_SIZE);
if (size == -1) {
  printf ("Cannot read /etc/passwd, fd = %d\n", fd); 
  return -1;    // fail: cannot read from password database
} 
close (fd);

int index = 0;   // position in words array
words[index++] = (char*)passwords;
int pos; for (pos = 1;  pos < size;  pos++) {
  if (passwords[pos] == ':' || passwords[pos] == '\n') {
    passwords[pos] = 0;   // terminate string
    words[index++] = ((char*)&passwords)+pos+1;
  }
}
@ and

<<get password entry: fill target buffers>>=
strncpy (pwd->pw_name, words[5*i], 32);     // field 0: username
strncpy (pwd->pw_passwd, words[5*i+1], 32); // field 1: password
pwd->pw_uid = atoi (words[5*i+2]);          // field 2: user ID
pwd->pw_gid = atoi (words[5*i+3]);          // field 3: group ID
strncpy (pwd->pw_dir, words[5*i+4], 32);    // field 4: home directory
@

Once more: With the way we store the plaintext passwords in \path!/etc/passwd!, any user can inspect that file or use the [[getpw*_r]] functions to fetch the password. If we got rid of this property, the system would provide the same security as other Unix implementations do because the decision whether a user will be logged in or may change the user or group ID happens in the kernel's [[u_login]] and [[u_set*id]] functions. A non-\emph{root} user mode process which calls [[setuid (0)]] will be denied.


\subsection{The \texttt{su} Program}
\index{su program@\texttt{su} program}%

Using the [[login]] library function we can create a simple [[su]] implementation which reads in the password and tries to log in as [[root]]. It launches a new shell that runs with root privileges. When that shell is left, control returns to the original shell.

%nouse
<<lib-build/tools/su.c>>=
#include "../ulixlib.h"
int main () {
  char password[32];  printf ("Enter root password: ");
  ureadline ((char*)&password, sizeof(password)-1, false);  // no echo
  printf ("\n");
  if (login (0, password) == -1) { printf ("Login failed\n"); exit (1); }

  // exec shell
  char *args[] = { "/bin/sh", 0 };
  execv (args[0], args);
}
@


\subsection{The \texttt{getuid()} and \texttt{getgid()} Functions}

Processes sometimes need to query the user and group IDs with which they are running. For this purpose they can use the following functions:

\enlargethispage{5mm}
%nouse
<<ulixlib function prototypes>>=
word getuid  ();
word geteuid ();
word getgid  ();
word getegid ();
@ %

\pagebreak

\noindent
Since such functions are never needed in the kernel (where functions can simply look at the thread control block), we provide a simplified mechanism for quick access to these IDs:

<<public constants>>=
#define QUERY_UID  0
#define QUERY_EUID 1
#define QUERY_GID  2
#define QUERY_EGID 3
#define __NR_query_ids 524
@

<<ulixlib function implementations>>=
word getuid  () { return syscall2 (__NR_query_ids, QUERY_UID);  }
word geteuid () { return syscall2 (__NR_query_ids, QUERY_EUID); }
word getgid  () { return syscall2 (__NR_query_ids, QUERY_GID);  }
word getegid () { return syscall2 (__NR_query_ids, QUERY_EGID); }
@

The system call handler in the kernel directly returns the queried value:

\syscallindex{query\_ids}%
<<syscall prototypes>>=
void syscall_query_ids (context_t *r);
@

<<syscall functions>>=
void syscall_query_ids (context_t *r) {
  // ebx: type of ID
  switch (r->ebx) {
    case QUERY_UID:  eax_return (thread_table[current_task].uid);
    case QUERY_EUID: eax_return (thread_table[current_task].euid);
    case QUERY_GID:  eax_return (thread_table[current_task].gid);
    case QUERY_EGID: eax_return (thread_table[current_task].egid); 
    default:         eax_return (-1);
  }
}
@ %def syscall_query_ids

<<initialize syscalls>>=
install_syscall_handler (__NR_query_ids, syscall_query_ids);
@


\subsection{Changing Owner, Group and Permissions}

\index{file!change owner, group or permissions}%
All Unix systems provide system calls and library functions which allow users to change the owner, group and access permissions of any file or directory for which they have write access; \UlixI{} is no different. We start with the kernel-internal functions:

\pagebreak

%nouse
<<function prototypes>>=
int u_chown (const char *path, short owner, short group);
int u_chmod (const char *path, word mode);
@ Note how [[u_chown]] accepts negative arguments for the owner and group: if one or both of them are [[-1]], they are ignored. Thus, 

\begin{itemize}
\item \verb#u_chown(file, 1000, 0)# will set [[file]]'s UID to 1000 and the GID to 0,
\item \verb#u_chown(file, 500, -1)# will only set the UID to 500, 
\item \verb#u_chown(file, -1, 0)# ignores the UID argument and sets the GID to 0 and 
\item \verb#u_chown(file, -1, -1)# does nothing at all.
\end{itemize}

The implementation looks similar to other functions which take a path name as an argument; we start with converting the path into an absolute path and checking which device with which filesystem the file resides on. Then we call filesystem-specific functions. As \UlixI{} only supports the Minix filesystem for disk drives and we do not want [[/dev]] entries to change, the only option is to call [[mx_chown]]:

<<function implementations>>=
int u_chown (const char *path, short owner, short group) {
  char localpath[256], abspath[256];
  short device, fs;

  // only root may change file ownership / group
  if (scheduler_is_active && thread_table[current_task].euid != 0)  return -1;   

  // check relative/absolute path
  if (*path != '/')  relpath_to_abspath (path, abspath);
  else               strncpy (abspath, path, 256);
  get_dev_and_path (abspath, &device, &fs, (char*)&localpath);
  switch (fs) {
    case FS_MINIX: return mx_chown (device, localpath, owner, group);
    case FS_FAT:   return -1;  // not possible (and FAT is not implemented)
    case FS_DEV:   return -1;  // not allowed
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_chown

The implementation of [[u_chmod]] looks almost identical to [[u_chown]], except that the number of arguments taken and passed to [[mx_chown]] or [[mx_chmod]] is different and regular users are allowed to change the access permissions (but not the ownership or owner group), so we don't need the check for the [[root]] user:

\pagebreak

<<function implementations>>=
int u_chmod (const char *path, word mode) {
  char localpath[256], abspath[256];
  short device, fs;

  // check relative/absolute path
  if (*path != '/')  relpath_to_abspath (path, abspath);
  else               strncpy (abspath, path, 256);

  if (scheduler_is_active) {
    <<[[u_chmod]]: check permissions>>   // see user/group chapter
  }
    
  get_dev_and_path (abspath, &device, &fs, (char*)&localpath);
  switch (fs) {
    case FS_MINIX: return mx_chmod (device, localpath, mode);
    case FS_FAT:   return -1;  // not possible, no FAT implementation
    case FS_DEV:   return -1;  // not allowed
    case FS_ERROR: return -1;  // error
    default:       return -1;
  }
}
@ %def u_chmod

We only implement \verb#chown#, \verb#chgrp# and \verb#chmod# for the Minix filesystem. Here are the corresponding [[mx_*]] functions

%nouse
<<function prototypes>>=
int mx_chown (int device, const char *path, short owner, short group);
int mx_chmod (int device, const char *path, word mode);
@ which use a more general function
%nouse
<<function prototypes>>=
int mx_chinode (int device, const char *path, short owner, 
                short group, short mode);
@ that is able to change user ID, group ID and permissions in one step. It is called by both [[mx_chown]] and [[mx_chmod]] and will only modify the fields for which the provided values are $\neq -1$:

\enlargethispage{5mm}

<<function implementations>>=
int mx_chown (int device, const char *path, short owner, short group) {
  return mx_chinode (device, path, owner, group, -1);  // change UID or GID, not mode
}

int mx_chmod (int device, const char *path, word mode) {
  return mx_chinode (device, path, -1, -1, mode);      // change mode, not UID or GID
}

int mx_chinode (int device, const char *path, short owner, 
                short group, short mode) {
  int ext_ino = mx_pathname_to_ino (device, path);
  if (ext_ino == -1) {
    printf ("file not found: %s\n", path);
    return -1;   // file not found
  }
  
  struct minix2_inode inode;
  mx_read_inode (device, ext_ino, &inode);
  if (owner != -1) inode.i_uid  = owner;  // change owner (if != -1)
  if (group != -1) inode.i_gid  = group;  // change group (if != -1)
  if (mode  != -1) 
    // change mode  (if != -1)
    inode.i_mode = (inode.i_mode & ~07777) | (mode & 07777);  
  mx_write_inode (device, ext_ino, &inode);
  return 0;
}
@ %def mx_chown mx_chmod mx_chinode

We provide two system call handlers:

\syscallindex{chown}\syscallindex{chmod}
%nouse
<<syscall prototypes>>=
void syscall_chown (context_t *r);
void syscall_chmod (context_t *r);
@

<<syscall functions>>=
void syscall_chown (context_t *r) {
  // ebx: path, ecx: owner, edx: group
  eax_return ( u_chown ((char *)r->ebx, r->ecx, r->edx) );
}

void syscall_chmod (context_t *r) {
  // ebx: path, ecx: new mode
  eax_return ( u_chmod ((char *)r->ebx, r->ecx) );
}
@ %def syscall_chown syscall_chmod

(which we need to initialize)

<<initialize syscalls>>=
install_syscall_handler (__NR_chown, syscall_chown);
install_syscall_handler (__NR_chmod, syscall_chmod);
@

and also two user mode library functions [[chown]] and [[chmod]] (the [[chgrp]] program will use the [[chown]] function):

%nouse
<<ulixlib function prototypes>>=
int chown (const char *path, short owner, short group);
int chmod (const char *path, short mode);
@

and

<<ulixlib function implementations>>=
int chown (const char *path, short owner, short group) {
  return syscall4 (__NR_chown, (unsigned int)path, owner, group);
}

int chmod (const char *path, short mode) {
  return syscall3 (__NR_chmod, (unsigned int)path, mode);
}
@ %def chown chmod


\section{Exercises}

\begin{enumerate}
% start with ex. 38
\setcounter{enumi}{37}

\item The code chunk [[<<[[u_execv]]: check permissions>>]] is empty: When executing a program, this version of the \UlixI{} kernel does not check whether the user is allowed to run the program. In general, users can run programs if they can read them and also have an execute ...

Implement the empty code chunk and test your checks against some binaries which have or do not have appropriate access permissions.

\item The [[u_chmod]] function also needs to check whether it may change the access permissions. Fill the following code chunk:

<<[[u_chmod]]: check permissions>>=
// TO DO
@ and test that you can only change permissions of files for which you have write access.
\end{enumerate}




%--------------------------------------------------------------------------------




\chapter{Small Standard Library}
\label{chap:ulix:standard-functions}%

Some standard functions which are normally included with an
operating system must be provided by us; here's a list of
functions that are often used. Some of these functions will be part of
both the kernel and the user mode library since features like
formatting and printing a string are needed in both environments.

Looking at the implementations of these functions will add nothing new 
to your understanding of operating system concepts---that is why they
have been moved to this late chapter. Following the literate programming
concept that the document is the program, we decided to include them
here even though they could have been moved to a separate code file.
We will only provide few comments on these functions.

Some of these functions have not been implemented by us but were copied
from online resources. In those cases, the first line after the function
name lists the source.

\section{Strings}
\index{string functions (standard library)}%

Let's start with some string functions which compare, copy and convert strings to numbers:

%nouse
<<public function prototypes>>=
size_t strlen (const char *str);
int    strcmp (const char *str1, const char *str2);
int    strncmp (const char *str1, const char *str2, uint n);
char   *strncpy (char *dest, const char *src, size_t count);
char   *strcpy  (char *dest, const char *src);
int    atoi (char *s);
int    atoi8 (char *s);
@

The function [[strlen]] returns the length of a null"=terminated string, [[strcmp]] and [[strncmp]] compare two strings and return 0 if they are equal and $-1$ or 1 if the first string is lexicographically smaller than the second one or vice versa. The [[strncmp]] variant stops comparing after $n$ characters have been seen.

<<public function implementations>>=
size_t strlen (const char *str) {
    size_t retval;
    for (retval = 0; *str != '\0'; str++) retval++;
    return retval;
}

int strcmp (const char *s1, const char *s2) {
  // source: http://en.wikibooks.org/wiki/C_Programming/Strings
  while (*s1 != '\0' && *s1 == *s2) {
    s1++;  s2++;
  }
  byte b1 = (*(byte *) s1);
  byte b2 = (*(byte *) s2);
  return ((b1 < b2) ? -1 : (b1 > b2));
}

int strncmp (const char *s1, const char *s2, uint n) {
  // source: http://en.wikibooks.org/wiki/C_Programming/Strings
  if (n == 0) { return 0; }                   // nothing to compare? return 0
  while (n-- > 0 && *s1 == *s2) {
    if (n == 0 || *s1 == '\0') { return 0; }  // equality
    s1++;  s2++;
  }
  byte b1 = (*(byte *) s1); 
  byte b2 = (*(byte *) s2);
  return ((b1 < b2) ? -1 : (b1 > b2));
}
@ %def strlen strcmp strncmp

The [[strcmp]] and [[strncmp]] functions copy a null"=terminated string. While the first of the two will potentially go on copying forever if the source string is not terminated, the second function stops copying after [[count]] bytes. Note that if [[strncpy]] fills the whole target string (buffer), that string will not be null"=terminated which can cause problems when correct termination is not checked and otherwise enforced.

<<public function implementations>>=
char *strcpy (char *dest, const char *src) {
  char *ret = dest;
  while ((*dest++ = *src++) != '\0') ;
  return ret;
}

char *strncpy (char *dest, const char *src, size_t count) {
  // like memcpy_ (see next section), but copies only until first \0 character
  const char *sp = (const char *)src;
  char *dp = (char *)dest;
  for (; count != 0; count--) {
    *dp = *sp;
    if (*dp == 0) break;
    dp++; sp++;
  }
  return dest;
}
@ %def strncpy strcpy

[[atoi]] converts a string into an integer value. It goes on reading until the first non-digit occurs, so it can also be used to convert strings like \verb#"123 KByte"# to 123. It does not recognize negative values; for example, trying to convert the string \verb#"-1234"# will lead to a result of 0 as the first character is found to be a non-digit.

<<public function implementations>>=
int atoi (char *s) {
  int res = 0;
  while ( ('0' <= *s) && (*s <= '9') ) {
    res = res*10 + (*s-'0');
    s++;
  }
  return res;
};

int atoi8 (char *s) {   // same as atoi, but with octal numbers
  int res = 0;
  while ( ('0' <= *s) && (*s <= '7') ) {
    res = res*8 + (*s-'0');
    s++;
  }
  return res;
};
@ %def atoi atoi8

[[atoi8]] is not a standard function. It works like [[atoi]] but expects the string to contain an octal number instead of a decimal number.

We define two macros [[strequal]] (strings are equal) and [[strdiff]] (strings are different) which use [[strcmp]]:

\pagebreak

<<public macro definitions>>=
#define strequal(s1,s2) (!strcmp((s1),(s2)))
#define strdiff(s1,s2)  (strcmp((s1),(s2)))
@ %def strequal strdiff
They are more intuitive to use than the standard (in-)equality comparisons via [[strcmp]]. Wherever we need to compare strings in this book, we only use our [[strequal]] and [[strdiff]] functions. However, if you want to integrate other code in \UlixI{} or one of the user mode programs, the default [[strcmp]] function is available.


\section{Memory}

The standard functions [[memcpy]], [[memset]] and [[memsetw]] compare two chunks of memory and fill a memory area with a byte or word constant:
\index{memory functions (standard library)}%

%nouse
<<public function prototypes>>=
void *memcpy  (void *dest, const void *src, size_t count);
void *memset  (void *dest, char val, size_t count);
word *memsetw (word *dest, word val, size_t count);
@

<<public function implementations>>=
void *memcpy (void *dest, const void *src, size_t count) {
  // debug_printf ("DEBUG: memcpy (%x,%x,%x)\n", dest, src, count);    // REMOVE_DEBUGGING_CODE
  const char *sp = (const char *)src;
  char *dp = (char *)dest;
  for (; count != 0; count--) 
    *dp++ = *sp++;
  return dest;
}

void *memset (void *dest, char val, size_t count) {
  char *temp = (char *)dest;
  for ( ; count != 0; count--) *temp++ = val;
  return dest;
}

word *memsetw (word *dest, word val, size_t count) {
  word *temp = (word *)dest;
  for ( ; count != 0; count--) *temp++ = val;
  return dest;
}
@ %def memcpy memset memsetw

Only in the kernel we provide the

<<macro definitions>>=
#define memcpy_debug(dest, src, count) \
  debug_printf ("DEBUG: memcpy() called in line %d\n", __LINE__); \
  memcpy (dest, src, count);
@ %def memcpy_debug
%
macro which creates a debug message and calls [[memcpy]].


\section{Formatted Output}

\index{printf (standard library)@\texttt{printf} (standard library)}%
We use a small implementation of the standard functions [[printf]] and [[sprintf]] 
that is dual-licensed unter the LGPL and the BSD license and available from
\url{http://www.menie.org/georges/embedded/} \cite{Menie:2002:printf}---there is 
no need to reinvent the wheel. We modified the code so that [[printf]] can also
handle the `o' format character for octal numbers and we changed the
code indentation to match the style of the other code in this book. 
There were also some minor modifications that enable the functions to
use the \UlixI{} output functions. (Thankfully the
function already knew how to print numbers to any base; we just copied
the code for `x' and changed the base 16 to 8.)

The code was also changed a bit to make it shorter, and we have turned the leading comments into normal text to make them better readable.\\

\noindent \verb#/*# 
Copyright 2001, 2002 Georges Menie (\url{http://www.menie.org})\\

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU Lesser General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA 
\hspace*{\fill}
\verb#*/#\\

\noindent \verb#/*# 
[[putchar]] is the only external dependency for this file,
if you have a working [[putchar]], just remove the following
define. If the function should be called something else,
replace [[outbyte(c)]] by your own function call.
\hspace*{\fill}
\verb#*/#


\subsection{\texttt{printf} in the Kernel}
\label{sec:ulix:printf:kernel}

\enlargethispage{1cm}
The kernel uses the functions
%nouse
<<public function prototypes>>=
int printf  (const char *format, ...);
int sprintf (char *out, const char *format, ...);
@ %
\pagebreak

\noindent
and we have to define [[putchar]] as [[kputch]] so that [[printf]] will call the right character output function.

<<function implementations>>=
#define putchar(c) kputch (c)

static void printchar (char **str, int c) {
  if ((int)str == -1) {
    // debug output: goes to qemu serial console via uartputc
    if (c == 0x100) {  //  backspace
      uartputc ('\b'); uartputc (' '); uartputc ('\b');
    } else {
      uartputc (c);
    }
  } else if (str) {
    **str = c; ++(*str);
  } else {
    (void)putchar (c);
  }
}
<<public [[printf]] implementation>>
@ %def putchar printchar
The [[printchar]] function uses [[uartputc]] to write output (only) to the serial port for debugging purposes if [[str]] is $-1$. [[kputch]] always writes to the serial port, too.


\subsection{\texttt{printf} in the User Mode Library}

For the library, we use the same [[printf]] code and only need to 
modify the implementation of [[putchar]] and [[printchar]]. That is why 
we can provide most of the code via the [[<<public [[printf]] implementation>>]]
chunk. Here we also define the [[ulixlib_printchar]] function for printing 
single characters that writes to the standard output descriptor (1).
\index{standard output}%

%nouse
<<ulixlib function prototypes>>=
int ulixlib_printchar (byte c);
@

%BREAK BEFORE DEFINES
<<ulixlib function implementations>>=
int ulixlib_printchar (byte c) { write (STDOUT_FILENO, &c, 1); }

#define putchar(c) ulixlib_printchar(c)

static void printchar (char **str, int c) {
  if (str) { **str = c; ++(*str); } 
  else     (void)putchar(c);
}
<<public [[printf]] implementation>>
@ %def ulixlib_printchar putchar printchar


\subsection{The Generic Implementation}

<<public [[printf]] implementation>>=
#define PAD_RIGHT 1
#define PAD_ZERO 2

static int prints (char **out, const char *string, int width, int pad) {
  register int pc = 0, padchar = ' ';
  if (width > 0) {
    register int len = 0; register const char *ptr;
    for (ptr = string; *ptr; ++ptr) ++len;
    if (len >= width) width = 0;
    else width -= len;
    if (pad & PAD_ZERO) padchar = '0';
  }
  if (!(pad & PAD_RIGHT)) {
    for ( ; width > 0; --width) { printchar (out, padchar); ++pc; }
  }
  for ( ; *string ; ++string) { printchar (out, *string); ++pc; }
  for ( ; width > 0; --width) { printchar (out, padchar); ++pc; }
  return pc;
}
@ %def PAD_RIGHT PAD_ZERO prints

The [[printi]] functions deals with 32-bit integers whose textual representation fits inside a 34-byte buffer:

<<public [[printf]] implementation>>=
#define PRINT_BUF_LEN 34

static int printi (char **out, int i, int b, int sg, int width, int pad, int letbase) {
  char print_buf[PRINT_BUF_LEN];
  register char *s; register int t, neg = 0, pc = 0; register unsigned int u = i;
  if (i == 0) {
    print_buf[0] = '0';  print_buf[1] = '\0'; 
    return prints (out, print_buf, width, pad);
  }
  if (sg && b == 10 && i < 0) { neg = 1; u = -i; }
  s = print_buf + PRINT_BUF_LEN-1;  *s = '\0';
  while (u) {
    t = u % b;        if ( t >= 10 )  t += letbase - '0' - 10;
    *--s = t + '0';   u /= b;
  }
  if (neg) {
    if ( width && (pad & PAD_ZERO) ) { printchar (out, '-'); ++pc; --width; } 
    else                             { *--s = '-'; }
  }
  return pc + prints (out, s, width, pad);
}
@ %def PRINT_BUF_LEN printi

We have modified the [[print]] function so that it recognizes the [[%o]]
(octal) and [[%b]] 
(binary) format words and prints numbers with base 8 or base 2, respectively. 

%BREAK BEFORE DEFINES
<<public [[printf]] implementation>>=
static int print (char **out, int *varg) {
  register int width, pad; register int pc = 0;
  register char *format = (char *)(*varg++); register char *s; char scr[2];
  for (; *format != 0; ++format) {
    if (*format == '%') {
      ++format; width = pad = 0;
      if (*format == '\0') break;
      if (*format == '%')  goto outlabel;
      if (*format == '-')  { ++format; pad = PAD_RIGHT; }
      while (*format == '0') { ++format; pad |= PAD_ZERO; }
      for ( ; *format >= '0' && *format <= '9'; ++format) {
        width *= 10;  width += *format - '0';
      }
      switch (*format) {
        case 's': s = *((char **)varg++);
                  pc += prints (out, s?s:"(null)", width, pad);         continue;
        case 'd': pc += printi (out, *varg++, 10, 1, width, pad, 'a');  continue;
        case 'o': pc += printi (out, *varg++,  8, 0, width, pad, 'a');  continue;
        case 'b': pc += printi (out, *varg++,  2, 0, width, pad, 'a');  continue;
        case 'x': pc += printi (out, *varg++, 16, 0, width, pad, 'a');  continue;
        case 'X': pc += printi (out, *varg++, 16, 0, width, pad, 'A');  continue;
        case 'u': pc += printi (out, *varg++, 10, 0, width, pad, 'a');  continue;
        case 'c': // char are converted to int then pushed on the stack
                  scr[0] = *varg++;  scr[1] = '\0';
                  pc += prints (out, scr, width, pad);                  continue;
      }      
    } else {
      outlabel:
      printchar (out, *format);  ++pc;
    }
  }
  if ( (int)out != -1 && out )  **out = '\0';
  return pc;
}
@ %def print

<<public [[printf]] implementation>>=
int printf (const char *format, ...) {
  register int *varg = (int *)(&format); return print (0, varg);
}

int sprintf (char *out, const char *format, ...) {
  register int *varg = (int *)(&format); return print (&out, varg);
}
@ %def printf sprintf


The [[debug_printf]] function 

%nouse
<<function prototypes>>=
int debug_printf (const char *format, ...);
@ %
exists only in the kernel, it is similar to [[printf]] if the [[DEBUG]] macro is set but passes the target argument $-1$ instead of 0 so that output will go \emph{only} to the serial port (and not to the \UlixI{} screen). If [[DEBUG]] is not set, it does nothing.

Since writing many messages makes the system a bit slower, debug output is disabled by default:

<<macro definitions>>=
// #define DEBUG
@

<<function implementations>>=
#ifdef DEBUG
  int debug_printf (const char *format, ...) {
    register int *varg = (int *)(&format); return print ((char**)-1, varg);
  }
#else
  inline int debug_printf (const char *format, ...) { return 0; }  // do nothing
#endif
@ %def debug_printf

\black



%------------------------------------------------------------------------------------------




\chapter{Debugging Help}
\label{chap:ulix:debugging}%
\index{debugging}%
\index{Ulix!debugging help}%

\section{The Kernel Mode Shell}
\index{kernel mode shell}\index{Ulix!kernel mode shell}%

In cases when user mode does not work or when we need to look at
kernel structures that are not accessible from user mode, we can
launch a simple kernel shell [[kernel_shell]] that provides a 
few commands which are helpful for debugging.

This code is even less interesting than the one in the previous chapter
unless you want to modify \UlixI{} and run into problems that require
some debugging.

For most internal commands \verb#CMD# of the kernel shell we provide
corresponding functions named \verb#ksh_command_CMD# which will be executed.

You can enter the kernel shell by pressing [Shift-Escape], and you can
leave it with \verb#exit# which brings you back to user mode. When
the system detects a fault from which it cannot recover it will also
drop you in the kernel mode shell, but in that case returning to user
mode is not possible.

The \verb#test# command displays addresses of the current page
directory and page table and a hexdump of the frame table.

<<function implementations>>=
void ksh_command_test () {
  kputs ("current_pd as INT:              "); 
    printbitsandhex (*(uint*)(current_pd)); kputs ("\n");
  kputs ("current_pd->ptds[0].frame_addr.:"); 
    printbitsandhex (current_pd->ptds[0].frame_addr<<12); kputs ("\n");  
  kputs ("current_pt as INT:              "); 
    printbitsandhex (*(uint*)(current_pt)); kputs ("\n");
  kputs ("address of current_pd:          "); printf ("%08x\n",(uint)current_pd);
  kputs ("address of current_pt:          "); printf ("%08x\n",(uint)current_pt);
  kputs ("size of current_pd:             "); 
    printf ("%08x\n", sizeof (*current_pd));
  kputs ("size of current_pt:             "); 
    printf ("%08x\n", sizeof (*current_pt));
  kputs ("address of frame table:         "); printf ("%08x\n", (uint)ftable);
  kputs ("hexdump ftable\n");
  hexdump ((uint)&place_for_ftable, ((uint)&place_for_ftable) + 1);
};
@ %def ksh_command_test

\verb#mem# displays similar data, but for specific page table entries.

<<global variables>>=
extern memaddress stack_first_address, stack_last_address;
@

<<function implementations>>=
void ksh_command_mem () {
  kputs ("kernel_pd as INT:               "); 
    printbitsandhex (*(int*)(&kernel_pd)); kputs ("\n");
  kputs ("kernel_pd.ptds[0].frame_addr:   "); 
    printbitsandhex (kernel_pd.ptds[0].frame_addr<<12); kputs ("\n");  
  kputs ("kernel_pd.ptds[768].frame_addr: "); 
    printbitsandhex (kernel_pd.ptds[768].frame_addr<<12); kputs ("\n");  
  kputs ("kernel_pd.ptds[831].frame_addr: "); 
    printbitsandhex (kernel_pd.ptds[831].frame_addr<<12); kputs ("\n");  
  kputs ("kernel_pd.ptds[832].frame_addr: "); 
    printbitsandhex (kernel_pd.ptds[832].frame_addr<<12); kputs ("\n");  
  kputs ("kernel_pd.ptds[833].frame_addr: "); 
    printbitsandhex (kernel_pd.ptds[833].frame_addr<<12); kputs ("\n");  
  kputs ("kernel_pt as INT:               "); 
    printbitsandhex (*(int*)(&kernel_pt)); kputs ("\n");
  kputs ("address of kernel_pd:           "); 
    printf ("%08x\n", (uint)&kernel_pd);
  kputs ("address of kernel_pt:           "); 
    printf ("%08x\n", (uint)&kernel_pt);
  kputs ("stack_first_address:            "); 
    printf ("%08x\n", (uint)&stack_first_address);
  kputs ("stack_last_address:             "); 
    printf ("%08x\n", (uint)&stack_last_address);
  kputs ("free_frames:                    "); printf ("%d\n", free_frames);
  uint esp; asm volatile ("mov %%esp, %0": "=r"(esp));
  kputs ("ESP:                            "); printf ("%08x\n", esp);
};
@ %def ksh_command_mem

\verb#time# and \verb#uname# show the current time and the \UlixI{} version string.

<<function implementations>>=
void ksh_command_time () {
  short int hour, min, sec;
    hour = (system_time/60/60)%24; min = (system_time/60)%60; sec = system_time%60;
    printf ("The time is %02d:%02d:%02d.\n", hour, min, sec);
};

void ksh_command_uname () { printf ("%s; Build: %s \n", UNAME, BUILDDATE); };
@ %def ksh_command_time ksh_command_uname

\verb#div0# causes a division by zero fault.

<<function implementations>>=
void ksh_command_div0 () {
  int zero = 0; int i = 10 / zero; kputch (i);  // Test for exception
}
@ %def ksh_command_div0

\verb#hexdump# prints a hex dump of the specified address range. Since kernel shell commands do not take parameters, the addresses have to be changed in the source code in order to show a different range.

<<function implementations>>=
void ksh_command_hexdump () {
  int as = current_as;
  activate_address_space (10);
  hexdump (0xaffffdf8, 0xaffffdf8 + 128);   // modify this to show other regions
  activate_address_space (as);
};
@ %def ksh_command_hexdump

\verb#ps# shows the process list.

<<function implementations>>=
void ksh_command_ps () {  
  int i;
  printf (" TID  PID PPID ESP      EIP      EBP      ESP0     AS  State "
          "Exi Cmdline\n");
  for (i=0;i<MAX_THREADS; i++) {
    if (thread_table[i].used) {
      printf ("%4d %4d %4d %08x %08x %08x %08x %2d  %-5s %3d %s\n",
        thread_table[i].tid,                thread_table[i].pid,
        thread_table[i].ppid,               thread_table[i].regs.esp,
        thread_table[i].regs.eip,           thread_table[i].regs.ebp,
        thread_table[i].esp0,               thread_table[i].addr_space,
        state_names[thread_table[i].state], thread_table[i].exitcode,
        thread_table[i].cmdline);
    }
  }
}
@ %def ksh_command_ps

\verb#queues# shows all blocked queues and the processes or threads on those queues (as well as the ready queue). The [[ksh_command_queues]] function uses the [[ksh_print_queue]] helper function which displays a single queue. Similarly, \verb#locks# shows all processes or threads waiting for a lock.

<<function implementations>>=
void ksh_print_queue (char *name, blocked_queue *bq) {
  printf ("%s: ", name);
  int pid = bq->next;
  while (pid != 0) {
    printf ("%d, ", pid);
    pid = thread_table[pid].next;
  }
  printf ("\n");
}

void ksh_command_queues () {
  printf ("Queues: \n");
  printf ("ready: ");
  int pid = 0;
  while ((pid = thread_table[pid].next) != 0)  printf ("%d, ", pid);
  printf ("\n");
  ksh_print_queue ("keyboard", &keyboard_queue);
  ksh_print_queue ("harddisk", &harddisk_queue);
  ksh_print_queue ("floppy",   &floppy_queue);
  ksh_print_queue ("waitpid",  &waitpid_queue);
  ksh_print_queue ("buffer",   &(buffer_lock->bq));
}

void ksh_command_locks () {
  for (int i = 1;  i < MAX_LOCKS;  i++) {
    if (kernel_locks[i].used) {
      ksh_print_queue (kernel_locks[i].lockname, &kernel_locks[i].bq);
    }
  }
}
@ %def ksh_print_queue ksh_command_queues ksh_command_locks

\verb#inode# displays the hex dump of an inode. The device and number must be set directly in the source code.

<<function implementations>>=
void ksh_command_inode () {
  struct minix2_inode in;
  int dev = DEV_HDA;
  int ino = 79;
  int res = mx_read_inode (dev, ino, &in);
  printf ("mx_read_inode(%d, %d) returns %d\n", dev, ino, res);
  if (res != 0) {
    hexdump ((uint)&in, (uint)&in+sizeof(struct minix2_inode));
    printf ("size: %d, blocks: ", in.i_size);
    for (int i = 0; i < 10; i++) printf ("%d, ", in.i_zone[i]); printf ("\n");
  }
}
@ %def ksh_command_inode

[[lsof]] displayes the list of open Minix files.

<<function implementations>>=
void ksh_command_lsof () {
  for (int i = 0;  i < MX_MAX_FILES;  i++) {
    struct int_minix2_inode *inode = mx_status[i].int_inode;
    if (inode != NULL) {
      printf ("mfd=%d inode-addr=%08x size=%d\n", 
              i, (unsigned int)inode, inode->i_size);
    }
  }
}
@ %def ksh_command_lsof

[[longhelp]] explains (some of) the commands in the kernel shell.

<<function implementations>>=
void ksh_command_longhelp () {
  printf ("ex" "it         return to user mode\n"
          "te" "st\n"
          "pfault, div0 test faults\n"
          "mem          show memory (frames, pages) info\n"
          "st" "at\n"
          "uname        show Ulix version\n"
          "hex" "dump      show hex" "dump of some memory area\n"
          "clear        clear the screen\n"
          "gf, g" "p, gp1k get a frame, a page, 1000 pages\n"
          "rp           release page\n"
          "bdump\n"
          "malloc       test kernel malloc\n"
          "time         show time\n"
          "cloneas <n>  clone address space (argument: size)\n"
          "listas       show address spaces\n"
          "ps           process list\n"
          "disable      disable sche" "duler\n"
          "enable       (re-)enable sche" "duler\n"
  );          
}
@ %def ksh_command_longhelp

The [[ksh_run_command]] function tests whether the command that was entered is known. If so, it executes one of the [[ksh_command_*]] functions (or directly performs some action).

<<constants>>=
#define SHELL_COMMANDS "help, ex" "it, test, div0, mem, stat, uname, "\
  "hexdump, clear, gf, gp, rp, gp1k, bdump, malloc, time, listas, "\
  "init, exec, testdisk, enable, longhelp, ps, queues, lsof"
@ %def SHELL_COMMANDS

<<function implementations>>=
void ksh_run_command (char *s) {
  if      ( strequal (s, "help") )     { printf ("Commands: %s \n", 
                                                 SHELL_COMMANDS); }
  else if ( strequal (s, "uname") )    { ksh_command_uname (); }
  else if ( strequal (s, "test") )     { ksh_command_test (); }
  else if ( strequal (s, "div0") )     { ksh_command_div0 (); }
  else if ( strequal (s, "hexdump") )  { ksh_command_hexdump (); }
  else if ( strequal (s, "clear") )    { vt_clrscr (); }
  else if ( strequal (s, "mem") )      { ksh_print_page_table (); }
  else if ( strequal (s, "mem2") )     { ksh_command_mem (); }
  else if ( strequal (s, "ps") )       { ksh_command_ps (); }
  else if ( strequal (s, "queues") )   { ksh_command_queues (); }
  else if ( strequal (s, "locks") )    { ksh_command_locks (); }
  else if ( strequal (s, "longhelp") ) { ksh_command_longhelp (); }
  else if ( strequal (s, "enable") )   { <<enable scheduler>> }
  else if ( strequal (s, "disable") )  { <<disable scheduler>> }
  else if ( strequal (s, "listas") )   { list_address_spaces (); }
  else if ( strequal (s, "time") )     { ksh_command_time (); }
  else if ( strequal (s, "lsof") )     { ksh_command_lsof (); }
  else if ( strequal (s, "inode") )    { ksh_command_inode ();    
  } else if ( strequal (s, "gf") ) {
    uint newframeid = request_new_frame ();
    printf ("New frame ID: %d\n", newframeid);
  } else if ( strequal (s, "gp") ) {
    /* uint* page = */ request_new_page ();
    // kputs (", Page @ "); printf ("%08x\n", (uint)page);
  } else if ( strequal (s, "rp") ) {
    printf ("releasing page range 0xc03fe..0xc07e6 \n");
    release_page_range (0xc03fe,0xc07e6);
  } else if ( strequal (s, "gp1k") ) {
    char buf[20]; uint *page;
    for (int i = 0;  i < 1024;  i++) {
      sprintf ((char*)&buf, "Create: %d   ", i); set_statusline ((char*)&buf);
      page = request_new_page ();
    }
  } else if ( strequal (s, "gp10k") ) {
    char buf[20]; uint *page;
    for (int i = 0;  i < 10;  i++) {
      sprintf ((char*)&buf, "Create: %d   ", i); set_statusline ((char*)&buf);
      page = request_new_pages (1024);
    }
  } 
  else if ( strequal (s, "") ) { return; } // no command
  else { printf ("Error: >%s< - no such command\n", s); }
}
@ %def ksh_run_command

The two [[statusline_*]] functions change the color of the status line so that it is always obvious whether you are using a regular shell (blue blackground) or the kernel shell (red).

<<function implementations>>=
void statusline_red () {
  // make status line red
  memsetw (textmemptr + 24 * 80, 0x20 | VT_RED_BACKGROUND, 80);
}

void statusline_blue () {
  // make status line blue
  memsetw (textmemptr + 24 * 80, 0x20 | VT_BLUE_BACKGROUND, 80);
  set_statusline (UNAME);
}
@ %def statusline_red statusline_blue

Finally, this is the kernel shell. It reads in a command and calls [[ksh_run_command]].

\pagebreak

<<function implementations>>=
void kernel_shell () {
  <<enable interrupts>>
  statusline_red ();
  char s[101];

  system_kbd_pos = 0;
  system_kbd_lastread = -1;
  system_kbd_count = 0;

  printf ("\nUlix Kernel Shell. Commands: %s\n", SHELL_COMMANDS);
  printf ("Type 'ex" "it' to enter user mode.\n");
  for (;;) {
    set_statusline (UNAME);
    kputs ("kernel@ulix# ");
    kreadline ((char*)&s,sizeof (s)-1);
    if ( strequal ((char*)&s, "ex" "it") ) { 
      statusline_blue ();  // restore normal color
      <<enable scheduler>>
      return; 
    }
    ksh_run_command ((char*)&s);
  };
};
@ %def kernel_shell

%nouse
<<function prototypes>>=
void kernel_shell ();
@


\section{A System Call That Displays an Inode}

For testing the Minix filesystem implementation we provide a system call that reads a Minix inode from the disk and displays it. It also shows the first seven entries of the [[i_zone[]]] array (which contain the direct block numbers).

<<syscall prototypes>>=
void syscall_print_inode (context_t *r);
@

<<syscall functions>>=
void syscall_print_inode (context_t *r) {
  int ino = r->ebx;   // requested inode
  printf ("syscall; ino = %d\n", ino);
  
  struct minix2_inode in;
  mx_read_inode (DEV_HDA, ino, &in);
  printf ("i_mode:   0%o\n", in.i_mode);
  printf ("i_nlinks: %d\n", in.i_nlinks);
  printf ("i_size:   %d\n", in.i_size);
  printf ("i_zone:   [");
  for (int i = 0; i < 7; i++) printf ("%d, ", in.i_zone[i]);  printf ("]\n");
}
@

<<initialize syscalls>>=
install_syscall_handler (777, syscall_print_inode);
@

The system call should not be used for regular programs, instead the [[stat]] function is intended to return information about a file.


\section{Printing the Page Directory}

The following function prints parts of the page directory.

<<function implementations>>=
void print_page_directory () {
  int i;
  kputs ("The Page Directory:\n");
  for ( i = 700 ; i<800 ; i++ ) {
    if ( current_pd->ptds[i].present ) {
      printf ("%04d ", i);
      printf ("%08x\n", current_pd->ptds[i].frame_addr);
    };
  };
  
  unsigned int z=(unsigned int)current_pd;
  printf ("hexdump for %08x\n", z);
  hexdump (z,z+128);
  kputch ('\n');
};
@ %def print_page_directory


\section{Helper Functions for Printing}

Some functions that belong to the kernel mode shell use the following
helper functions to print number in binary and hexadecimal format and to
print a hex dump.

%nouse
<<function prototypes>>=
void printbitsandhex (uint i);
@

<<function implementations>>=
void printbitsandhex (uint i) { printf ("%032b %08X", i, i); };
@ %def printbitsandhex

%nouse
<<function prototypes>>=
void hexdump (uint startval, uint endval);
@

<<function implementations>>=
void hexdump (uint startval, uint endval) {
  for (uint i=startval; i < endval; i+=16) {
    printf ("%08x  ", i);                   // address
    for (int j = i;  j < i+16;  j++) {      // hex values
      printf ("%02x ", (byte)PEEK(j));
      if (j==i+7) printf (" ");
    };
    printf (" ");
    for (int j = i;  j < i+16;  j++) {      // characters
      char z = PEEK(j);
      if ((z>=32) && (z<127)) {
        printf ("%c", PEEK(j));
      } else {
        printf (".");
      };
    };    
    printf ("\n");
  };
};
@ %def hexdump


\section{Printing the Frame Table and Page Table}

Here's a function for displaying the current page tables.

Since we want to output information from the free frame list
(we will use [[test_frame]] to check frame states), we
write a simple function that can print status information for
a memory region (going from [[start]] to [[end]]):

<<function implementations>>=
void ksh_print_page_table_helper (unsigned sta, unsigned end, unsigned used) {
  if (used) { kputs ("Used: "); } 
  else      { kputs ("Free: "); }
  printf ("%05x-%05x    %5d-%5d   (%5d frames)\n", 
          sta, end, sta, end, end-sta+1);
};
@ %def ksh_print_page_table_helper

The following function prints the frame and page tables:

%nouse
<<function prototypes>>=
void ksh_print_page_table ();
@

<<function implementations>>=
void ksh_print_page_table () {
  unsigned int cr3;
  <<print frame table>>
  kputch ('\n');
  <<print page table>>
  __asm__ __volatile__("mov %%cr3, %0": "=r"(cr3));
  printf ("cr3: %08x\n", cr3);
}
@ %def ksh_print_page_table

<<print frame table>>=
kputs ("Current Frame Info:\n");
// set_frame (2047*4096);  // use page 2047, TESTING   // REMOVE_DEBUGGING_CODE
unsigned int frameno = 0;
unsigned int totalfree = NUMBER_OF_FRAMES;  // total number of free frames
unsigned int test = test_frame (frameno);   // check first frame
  
for (unsigned int i = 1;  i < NUMBER_OF_FRAMES;  i++) {
  if (test_frame (i) != test) { 
    ksh_print_page_table_helper (frameno, i-1, test);
    if (test) totalfree -= (i-frameno);
    test = 1-test;
    frameno = i;
  };
};
ksh_print_page_table_helper (frameno, NUMBER_OF_FRAMES-1, test);
if (test) totalfree -= (NUMBER_OF_FRAMES-frameno);
printf ("Total free frames:    %6d\n", totalfree);
printf ("Value of free_frames: %6d\n", free_frames);
@

The output of [[<<print frame table>>]]
looks like this:

\begin{Verbatim}
Current Frame Info:
Used: 0x00000000-0x000003FF    0000000-0001023   (0001024 frames)
Free: 0x00000400-0x000007FE    0001024-0002046   (0001023 frames)
Used: 0x000007FF-0x000007FF    0002047-0002047   (0000001 frames)
Free: 0x00000800-0x00004000    0002048-0016384   (0014337 frames)
Total free frames:   0015359
\end{Verbatim}

The following code for the page table seems overly complicated
because we want to print mappings of ranges and not each single
mapping of a page to a frame in order to save space in the output
(and keep it readable). We use a variable [[started]] to memorize
whether we're right now in a mapped region while skipping through
the page tables.

<<print page table>>=
printf ("Current Paging Info: Address Space #%d\n", current_as);

boolean started=false;
int save_i=0; int save_f=0; 
unsigned int start_i=0; unsigned int start_f=0;
for (unsigned int i = 0;  i < 1024*1024;  i++) {
  frameno = mmu_p (current_as, i);  // get frameno with respect to current AS
  if (frameno == -1) {
    if (started) {                            // frame NOT found
      <<print pages to frames block>>
      started = false;
    }
    continue;  // dont act on non-mapped pages
  } else {                                    // frame found
    if (!started) {
      start_i = i; start_f = frameno;
      save_i  = i; save_f  = frameno;
      started = true;
    } else {
      if (i-start_i != frameno-start_f) {
        // pages continue, but frames are elsewhere
        <<print pages to frames block>>
        start_i=i; start_f=frameno;
      };

      save_i = i; save_f = frameno;
    };
  };    
};
if (started) {  <<print pages to frames block>> }
@

This is just the code for formatting the output:

<<print pages to frames block>>=
printf ("PTEs 0x%05x..0x%05x -> frames 0x%05x..0x%05x  (%5d pages)\n",
  start_i, save_i, start_f, save_f, save_i-start_i+1);
@

The output of [[<<print page table>>]] will look like this:

\begin{Verbatim}
Current Paging Info:
PTEs 0x00000000..0x000003FF -> frames 0x00000000..0x000003FF   (0001024 pages)
PTEs 0x000C0000..0x000C03FF -> frames 0x00000000..0x000003FF   (0001024 pages)
PTEs 0x000D0000..0x000D3FFF -> frames 0x00000000..0x00003FFF   (0016384 pages)
\end{Verbatim}

\black



%--------------------------------------------------------------------------



\chapter{The ULIX Build Process}
\label{chap:ulix:build-process}%
\index{build process}\index{Ulix!build process}%

You have almost reached the end of the book---now we describe the
whole process that is needed in order to turn a literate program
(the \path!ulix-book.nw! file) into a booting operating system disk
image and some other files needed for execution of the system.

\section{Required Software}

If you want to build \UlixI{} yourself, you need several tools which might not be installed on your machine. Check that the following requirements are fulfilled:

\begin{itemize}
\item \textbf{Linux operating system}
\vspace{-1mm}%

Any 32-bit version of Linux\index{Linux!Ulix development}\index{Debian Linux (Ulix development)} will work, provided that you can install the correct version of the C compiler (see next point). There was also one positive report of a developer using FreeBSD\index{FreeBSD operating system!Ulix development}, and \UlixI{} can also be compiled on Mac OS X, but that requires some more work (see Section~\ref{sec:mac-toolchain}). In principle a 64-bit Linux system should work as well, but that would require some extra work because in default 64-bit installations the compiler cannot create 32-bit binaries.

\item \textbf{GNU C compiler, version 4.4}
\vspace{-1mm}%

The \UlixI{} sources can be compiled with older or newer versions of the GNU C compiler\index{GNU C compiler} [[gcc]] (\url{https://gcc.gnu.org/}), but when we experimentally picked a different version than 4.4, the resulting kernel did not work. This is likely caused by different code optimization.
We successfully used GCC 4.4.5 on a 32-bit version of Debian Linux 6.0.1 (Squeeze, \url{https://www.debian.org/releases/squeeze/}).
If it turns out that your compiler version cannot compile \UlixI{} and you do not have the option to install GCC 4.4, then you will need to download the development environment, see Section~\ref{sec:build:download-dev-env}.

\pagebreak
\item \textbf{NASM assembler}
\vspace{-1mm}%

\index{Assembler language!nasm assembler@\texttt{nasm} assembler}\index{nasm assembler}You need the [[nasm]] assembler (\url{http://nasm.us/}). On two development machines \linebreak (Debian Linux 6.0.1 and OS X 10.6.8) [[nasm -v]] displayed the following version strings:
\begin{Verbatim}
Debian: NASM version 2.08.01 compiled on Jun  2 2010
OS X:   NASM version 0.98.40 (Apple Computer, Inc. build 11) compiled on May 18 
        2009
\end{Verbatim}
Both versions worked well, but others should, too, because the assembler must always produce the same object files from the code: Assembler code will not be optimized.

\item \textbf{NoWEB}
\vspace{-1mm}%

You have to install the [[noweb]] package (\url{http://www.cs.tufts.edu/~nr/noweb/}) which can extract the C and assembler source code files and the makefiles from the literate program \path!ulix-book.nw!. On a Debian Linux machine you can type \verb#apt-get install noweb#.

\item \textbf{\LaTeX{}, the \XeLaTeX{} variant}
\vspace{-1mm}%

\pcindex{XeLaTeX}{\XeLaTeX{}}\pcindex{LaTeX}{\LaTeX{}}
In order to reproduce a PDF version of this book, you will need the \XeLaTeX{} variant of the \LaTeX{} document preparation system (\url{http://www.xelatex.org/}, \url{http://www.latex-project.org/}). Depending on your Linux distribution, installing \LaTeX{} might not lead to a full installation (that contains \XeLaTeX{}). On Debian Linux [[apt-get install texlive-xetex]] should fetch and install the required packages. You will also need a \verb#noweb# package for \XeLaTeX{} that is available from the \UlixI{} project website via
\begin{Verbatim}
wget http://ulixos.org/files/0.12/noweb.sty
\end{Verbatim}
You can instead use the default \verb#noweb.sty# file that might be installed on your machine, but then the layout will look a bit different.

\item \textbf{mtools}
\vspace{-1mm}%

Install the \emph{mtools}\pcindex{mtools software}{\texttt{mtools} software} package (\url{http://www.gnu.org/software/mtools/}) if it is not present yet. (You can check by typing [[mtools]] in the shell; if you get a ``Command not found'' error, you need to install it.) On Debian systems [[apt-get install mtools]] finds the right package.

\item \textbf{qemu}
\vspace{-1mm}%

You will also need the [[qemu]]\index{qemu PC emulator@\texttt{qemu} PC emulator} PC emulator (\url{http://www.qemu.org/}). While \UlixI{} might run on other Intel"=x86"=based hardware, we only tested it in the [[qemu]] and Bochs PC emulators\index{Bochs PC emulator}, and of those two only [[qemu]] was able to boot and run it. We also successfully used the Q program on OS~X (\url{http://www.kju-app.org/}) which is a GUI for [[qemu]]; the package contains a [[qemu]] version, so installing Q is enough for running \UlixI{}.

\end{itemize}


\subsection{Toolchain on Mac OS X}
\label{sec:mac-toolchain}%

It is possible to compile \UlixI{} on an Apple Mac, but the information in this section will not be fully applicable if you use a newer version of OS X. However, it might still be helpful for finding the right files for your setup. We used Mac OS X 10.6.8 and started with installing a GCC Cross Compiler as documented in \url{http://www.fanofblitzbasic.de/prettyos/PrettyOSMacOSX.pdf}).
We downloaded the file
\path!http://www.fanofblitzbasic.de/prettyos/! \linebreak \path!i586-elf-binutils-gcc-macos.zip!
and unpacked it.
(Note: When we attempted to re"=download the file during the final preparation stage of 
  this book, the website was offline. We could not find that PDF file or the cross compiler 
  archive elsewhere, but on \url{http://wiki.osdev.org/Talk:GCC_Cross-Compiler#On_Mac_OS_X_Lion}
  the creation of a cross-compiler is discussed, so that site might help you. In the end you
  will need a \texttt{gcc} version called \texttt{i586-elf-gcc} that creates ELF-i386 binaries.)

We also had to install GMP and MPFR which could be automated using the \verb#port# tool (\url{https://www.macports.org/}). (On newer OS X versions \verb#port# is replaced by \verb#brew#; \url{http://brew.sh/}.)

\lstset{language=bash,breaklines=true,basicstyle=\ttfamily}
\begin{lstlisting}
port install gmp
port install mpfr
\end{lstlisting}

Then we set some links:

\begin{lstlisting}
ln -s /opt/local/var/macports/software/mpfr/3.0.0-p8_0/opt/local/lib/libmpfr.4.dylib /usr/local/lib/libmpfr.1.dylib
ln -s /opt/local/var/macports/software/gmp/5.0.1_0/opt/local/lib/libgmp.3.dylib /usr/local/lib/libgmp.3.dylib
\end{lstlisting}

The [[nasm]] assembler was installed by default; it is also available via the MacPorts package collection.


\subsection{Other Useful Tools}

You might find the following tools helpful though we have not used all of them for the development of \UlixI{}.

\begin{itemize}

\item \textbf{All in one boot disk}, \url{http://rescup.winbuilder.net/bootdisk/}
\vspace{-1mm}%

This is a FAT"=formatted GRUB\index{GRUB boot loader} boot disk (with other tools on there, e.\,g.,
a free DOS clone and tools). It is useful because you can use the 
\verb#mtools# utilities to copy a new \UlixI{} kernel to the disk by typing
\begin{Verbatim}
mcopy -i bootdisk.img kernel.img ::kernel.img
\end{Verbatim}
(the first \verb#:# in \verb#::# is a ``drive letter'' used for
talking to the disk image referenced by \verb#-i#).

We modified the boot disk so that it has only one menu entry
to boot \verb#/ulix.bin#, and we removed the contents of the \verb#TOOLS# directory that provided DOS tools such as \verb#fdisk.exe# or \verb#ntfsdos.exe#.

\item \textbf{mfstool}, \url{http://mfstool.sourceforge.net/}
\vspace{-1mm}%

The [[mfstool]] can access Minix filesystem images. It works on Linux, Mac OS and other Unix versions. For example, 
\begin{Verbatim}
mfstool dir minix1.img
\end{Verbatim}
displays the contents of the root directory in the Minix filesystem image \verb#minix1.img#. However, the version we tested had problems with writing files to an image. It was good for reading files or listing directories, though.

\item \textbf{minixfs (MacFUSE)}, \url{http://osxbook.com/software/unixfs/}
\vspace{-1mm}%

[[minixfs]] is a driver that is part of the \marginnote{MacFUSE,\\ UnixFS}MacFUSE"=based UnixFS package and lets OS X users
mount Minix"=formatted volumes---but only in read-only mode. Accessing a mounted volume is simpler than using \verb#mfstool#.

\end{itemize}


\section{Downloading the Development Environment}
\label{sec:build:download-dev-env}%
\index{Ulix!download the development environment}%

If you run into problems with your installed version of the development tools, you can either attempt to fix them or simply download a virtual machine image for the \marginnote{VirtualBox}VirtualBox virtualization program (\url{https://www.virtualbox.org/}) that contains a Debian Linux 6.0.1 installation and the \UlixI{} sources. It is distributed as an \verb#ova# appliance file (Open Virtualization Format) that you can import in VirtualBox using the \emph{File / Import Appliance} menu entry. Visit the \url{http://ulixos.org/files/0.12/ova/} directory and read the instructions in \path!readme.txt! which contain updated information about the installation process.


\section{Bootstrapping: How to Start}
\label{sec:bootstrap-ulix}%
\index{Ulix!bootstrapping}%

Assuming that you have a development environment with all the needed tools installed and the \UlixI{} noweb\index{noweb} source code file [[ulix-book.nw]] in your home directory, you can start by extracting the needed files from the noweb source file.

Create a directory \verb#ulix# somewhere in your home directory and change into it with [[cd]]. The directory must be empty. Move the literate program \path!ulix-book.nw! that you can download with
\begin{Verbatim}
wget http://ulixos.org/files/0.12/ulix-book.nw
\end{Verbatim}
into that folder and execute the command
\begin{Verbatim}
notangle ulix-book.nw | sh
\end{Verbatim}

That command will extract the following root chunk [[<<*>>]] of the document which contains a simple shell script that in turn creates some directories and makefiles. You will also need to download and decompress the disk images and some additional files that help with the PDF file generation. If you don't press [Ctrl-C], the script will do that for you automatically.

The Makefiles are intended to work on a Debian Linux 6.0.1 system that has all the required tools installed. If they do not work, you might want to inspect the \verb#Makefile# files in \path!bin-build/!, \path!lib-build/! and \path!tex-build/! which are extracted from the [[<<bin-build/Makefile>>]], [[<<lib-build/Makefile>>]] and [[<<tex-build/Makefile>>]] code chunks (see below).

%BEGIN NOSYNTAX
%nouse
<<*>>=
#!/bin/bash
echo This is the ULIX source code extractor
litprog=ulix-book.nw
files=$( ls -1 | wc -l )
if [ $files != 1 ]; then
  echo "~/ulix directory is not empty, it must contain only ulix-book.nw. Aborting."
  exit
fi

for dir in bin-build lib-build/tools lib-build/diskfiles/bin mountpoint tex-build
do
  mkdir -p ${dir}
done
for file in Makefile bin-build/Makefile lib-build/Makefile lib-build/process.ld \
lib-build/tools/Makefile lib-build/tools/process.ld tex-build/Makefile \
bin-build/assembler-parser.py tex-build/filter-uses.py module.nw lib-build/init.c
do
  notangle -R${file} -t8 ${litprog} > ${file}
done
chmod a+x bin-build/assembler-parser.py tex-build/filter-uses.py

webroot="http://ulixos.org/files/0.12"
echo "You can download the disk images if you don't have them yet:"
echo "cd to bin-build/ and type:"
echo "  wget ${webroot}/ulix-fd0.img.gz"
echo "  wget ${webroot}/ulix-fd1.img.gz"
echo "  wget ${webroot}/ulix-hda.img.gz"
echo "  wget ${webroot}/ulix-hdb.img.gz"
echo "Then uncompress them with"
echo "  gunzip *.gz"
echo "Similarly, change to tex-build/ and type:"
echo "  wget ${webroot}/noweb.sty.gz"
echo "  wget ${webroot}/grep-patterns.gz"
echo "and uncompress them as well."
echo
echo "This script will download all files for you if you don't press Ctrl-C"
echo -n "in the next eight seconds... "
for (( i=1; i<9; i++ )); do echo -n ${i}...; sleep 1; done
echo ""
echo "Downloading files"
cd bin-build
for image in fd0 fd1 hda hdb; do
  echo wget ${webroot}/ulix-${image}.img.gz
  wget ${webroot}/ulix-${image}.img.gz
  gunzip ulix-${image}.img.gz
done
cd ../tex-build
for file in noweb.sty grep-patterns; do
  echo wget ${webroot}/${file}.gz
  wget ${webroot}/${file}.gz
  gunzip ${file}.gz
done
echo 'Done. Type "make" to build the kernel, type "make run" to run it in qemu.'
@


\subsection{Makefiles}

We start with the makefiles which control the build processes for the kernel, the user mode library, the applications and the PDF document (this book).

The development root folder contains the following makefile that will make kernel, library and tools (when you execute [[make]]) and start \UlixI{} in the [[qemu]] emulator when you type [[make run]]. With [[make pdf]] you can create the PDF file (if \XeLaTeX{} is installed).

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
<<Makefile>>=
all: tools bin

pdf: ulix-book.nw
	make -C tex-build

bin: ulix-book.nw
	make -C bin-build

run:
	make -C bin-build run

runs:
	make -C bin-build runs

tools: ulix-book.nw
	make -C lib-build

clean:
	make -C lib-build clean
	make -C bin-build clean
	make -C tex-build clean
@
\end{multicols}

The \path!bin-build/! directory is used for compiling the kernel source file \path!ulix.c!, assembling the Assembler source file \path!start.asm! and linking the generated object files to create the kernel binary \path!ulix.bin!.

%nouse
<<bin-build/Makefile>>=
OS=Linux
LD=ld
CC=/usr/bin/gcc-4.4
OBJDUMP=objdump
CFLAGS=-O0 -m32 -mstackrealign

HDA_IMG=ulix-hda.img
HDB_IMG=ulix-hdb.img
FD0_IMG=ulix-fd0.img
FD1_IMG=ulix-fd1.img

ASM=nasm
ASMFLAGS=-f elf
TEXSRC_FILE=../ulix-book.nw
TEXSRC_MODULE_FILE=../module.nw
EXTRACT_FILES=ulix.c start.asm ulix.ld

all: build

build:	extract parse asm compile linking objdump mtools

extract: 
	notangle -L -Rulix.c $(TEXSRC_FILE) > ulix.c; true
	notangle -Rstart.asm $(TEXSRC_FILE) > start.asm
	notangle -Rulix.ld $(TEXSRC_FILE) > ulix.ld
	notangle -L -Rmodule.c $(TEXSRC_MODULE_FILE) > module.c
	notangle -L -Rmodule.h $(TEXSRC_MODULE_FILE) > module.h

parse:
	mv ulix.c ulix.c.pre
	./assembler-parser.py ulix.c.pre ulix.c
	sed -ie "s/SCRIPTBUILDDATE/`date`/" ulix.c

asm:
	mv module.c module.c.pre
	./assembler-parser.py module.c.pre module.c
	$(ASM) $(ASMFLAGS) -o start.o start.asm

compile:
	$(CC) $(CFLAGS) -fno-stack-protector -std=c99 -g -nostdlib -nostdinc \
	-fno-builtin -I./include -c -o module.o module.c
	$(CC) $(CFLAGS) -fno-stack-protector -std=c99 -g -nostdlib -nostdinc \
	-fno-builtin -I./include -c -o ulix.o -aux-info ulix.aux ulix.c

linking:
	$(LD) $(LDFLAGS) -T ulix.ld -o ulix.bin *.o 

mtools:
	mcopy -o -i $(FD0_IMG) ulix.bin ::

objdump:
	$(OBJDUMP) -M intel -D ulix.bin > ulix.dump
	cat ulix.dump | grep -e '^[^ ]* <' | sed -e 's/<//' -e 's/>://' > ulix.sym

clean:
	rm -f ./*.o ./*.c ./*.h ./*.pre ./ulix.bin ./ulix.aux ./ulix.ce 
	rm -f ./ulix.dump* ./*asm ./*.objdump ./*sym

run: 
	qemu -m 64 -rtc base=localtime -boot a -fda $(FD0_IMG) -fdb $(FD1_IMG) \
	-hda $(HDA_IMG) -hdb $(HDB_IMG) -d cpu_reset -s -serial mon:stdio | \
	tee ulix.output

nolog: 
	qemu -m 64 -rtc base=localtime -boot a -fda $(FD0_IMG) -fdb $(FD1_IMG) \
	-hda $(HDA_IMG) -hdb $(HDB_IMG) -d cpu_reset
@

The \path!lib-build/! directory is used for compiling the user mode library (from its source files \path!ulixlib.c! and \path!ulixlib.h!) and the user mode applications in \path!lib-build/tools/!. The generated \UlixI{} binaries will be placed in \path!lib-build/diskfiles/! and then copied to the hard disk image file \path!bin-build/ulix-hda.img!.

You might want to set up your Linux system so that you can run \verb#sudo# without entering a password, otherwise making the files in this directory will ask for your password.

%nouse
<<lib-build/Makefile>>=
OS=Linux
LD=ld
CC=/usr/bin/gcc-4.4
OBJDUMP=objdump

NOWEBFILE=../ulix-book.nw
ROOTDISK=../bin-build/ulix-hda.img

CCOPTIONS=-nostdlib -ffreestanding -fforce-addr -fomit-frame-pointer \
-fno-function-cse -nostartfiles -mtune=i386 -momit-leaf-frame-pointer -O0
CCASMOPTIONS=-fverbose-asm -masm=intel
LDOPTIONS=-static -s

all: build

build: extract compile image

extract:
	notangle -L -Rulixlib.c < $(NOWEBFILE) > ulixlib.c  ; true
	notangle -L -Rulixlib.h < $(NOWEBFILE) > ulixlib.h  ; true

compile:
	$(CC) $(CCOPTIONS) -g $(CCTESTOPTIONS) -c ulixlib.c
	$(CC) $(CCOPTIONS) $(CCTESTOPTIONS) -c init.c
	# link it with linker script "process.ld"
	$(LD) $(LDOPTIONS) -T process.ld -o init init.o ulixlib.o
	touch tools/*.c
	make -C tools

image:
	sudo mount -o loop $(ROOTDISK) ../mountpoint
	cp init ../mountpoint/
	sudo umount ../mountpoint

clean:
	rm -f ./*.o
@

We've already shown the [[<<lib-build/tools/Makefile>>]] code chunk when we introduced ELF binaries.

\subsection{Linker Configuration Files}

\index{linker configuration file}%
The two code chunks [[<<lib-build/process.ld>>]] and [[<<lib-build/tools/process.ld>>]] contain \path!process.ld! files which are used to configure the behavior of the GNU linker \verb#ld#. One of those files belongs in the \path!lib-build/! folder and is only used for creating the flat binary file \verb#init#, the other one belongs in \path!lib-build/tools/! and is used for linking all the regular programs which are ELF binaries. (The code chunk [[<<lib-build/process.ld>>]] was already shown in Chapter~\ref{sec:processes:start the first}.)

\columnsep=1cm
\columnseprule=.4pt
\begin{multicols}{2}
%nouse
<<lib-build/tools/process.ld>>=
OUTPUT_FORMAT("elf32-i386")
ENTRY(main)
virt = 0x00000000;
SECTIONS {
  . = virt;
  
  .setup : AT(virt) {
    *(.setup)
  }

  .text : AT(code) {
    code = .;
    *(.text)
    *(.rodata*)
    . = ALIGN(4096);
  }

  .data : AT(data) {
    data = .;
    *(.data)
    . = ALIGN(4096);
  }

  .bss : AT(bss) {
    bss = .;
    *(COMMON*)
    *(.bss*)
    . = ALIGN(4096);
  }
  end = .;
}
@
\end{multicols}

\path!tex-build/! is the folder in which you can recreate the PDF file of this book.

%nouse
<<tex-build/Makefile>>=
TEX=xelatex -8bit -shell-escape

all:
	grep -v "REMOVE_DEBUGGING_CODE" ../ulix-book.nw > tmp.nw
	nodefs -auto cee tmp.nw | sort -u > noweb.defs
	grep -v -f grep-patterns noweb.defs > noweb.filtered.defs
	noweave -indexfrom noweb.filtered.defs -delay tmp.nw > tmp.tex.in
	./filter-uses.py < tmp.tex.in > tmp.tex
	sed -ie "s/SCRIPTBUILDDATE/`LANG=C date`/" tmp.tex
	sed -ie 's/<=/≤/g' tmp.tex
	sed -ie 's/>=/≥/g' tmp.tex
	$(TEX) tmp
	bibtex tmp
	makeindex tmp.idx
	noindex tmp
	$(TEX) tmp
	$(TEX) tmp
	mv tmp.pdf ../ulix-book.pdf

clean:
	rm -f ./tmp.*
@

(Note that the three [[sed]] commands are shown wrong in this code chunk, the first one replaces \verb#SCRIPT#\verb#BUILD# with today's date, the second and third ones replace \verb#<#\verb#=# and \verb#>#\verb#=# with \verb#≤# and \verb#≥# which you cannot see here because the transformation was also applied to those lines. Extracting the Makefile gives you a correct file.)


\subsection{The Assembler Pre-Parser}

\index{Assembler language!pre-processor}The following Python program performs transformations of a simplified inline assembler syntax to the regular syntax (as expected by the GNU C compiler).

\label{code:assembler parser}
%nouse
<<bin-build/assembler-parser.py>>=
#!/usr/bin/python

"""
This Parser replaces code of the following form:
    asm {
      starta: mov eax, 0x1001   // comment
      mov ebx, 'A'              // more comment
      int 0x80
    }
with code that looks like this:
    asm ("\
      .intel_syntax noprefix; \
      starta: mov eax, 0x1001; \
      mov ebx, 'A'; \
      int 0x80; \
      .att_syntax; \
    ");
It also understands asm volatile. What it cannot cope with is variable / register 
usage. Note that it does not change the number or position of code lines.
"""

from sys import argv, exit
if len(argv)<3:
  print ("Error: give input and output filenames")
  exit (1)
infilename = argv[1]
outfilename = argv[2]

global ReplaceMode
ReplaceMode = False

def count_leading_blanks (line):
  counter = 0
  while line and (line[0] == " "):
    counter+=1
    line = line[1:]
  return counter

def remove_trailing_blanks (line):
  if (line == ""): return line
  while (line != "") and (line[-1] == " "):
    line = line[:-1]
  return line
def transform (line):
  global ReplaceMode
  if ReplaceMode:
    if "}" in line:
      # reached the end; skip this line
      blanks = count_leading_blanks (line)
      line = (blanks+2) * " " + '.att_syntax; ");'
      ReplaceMode = False
      return line
    else:  
      # do something to the line
      if '//' in line:
        # remove comment
        pos = line.find ("//")
        line = line[:pos]
        line = remove_trailing_blanks (line)
      line = line + "; \\"
      return line

def process (line):
  global ReplaceMode
  line = line[:-1]
  if ReplaceMode:
    # we're already in ReplaceMode, working on assembler
    line = transform (line)
  else:
    # we're in normal C mode, check for asm {
    if ("asm volatile{" in line) or ("asm volatile {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm volatile (".intel_syntax noprefix; \\'
      ReplaceMode = True
    elif ("asm{" in line) or ("asm {" in line):
      blanks = count_leading_blanks (line)
      line = blanks * " " + 'asm (".intel_syntax noprefix; \\'
      ReplaceMode = True    
  return line

infile  = file (infilename,  "r")
outfile = file (outfilename, "w");

EndOfLoop = False

for line in infile:
  line = process (line)
  outfile.write (line+"\n")

infile.close()
outfile.close()
@


\subsection{Creating Modules with \texttt{module.nw}}

\index{Ulix!module}%
The file \path!module.nw! is intended for students who want to work on a \UlixI{}"=related project but create their own literate program document. From the file two code chunks are extracted, resulting in \path!bin-build/module.c! and \path!bin-build/module.h!. The C file will also be compiled, and the resulting object file \path!module.o! is linked with the other kernel object files.

%nouse
<<module.nw>>=
@<<module.c@>>=
#include "module.h"
void initialize_module () {}
@@
@<<module.h@>>=
void initialize_module ();
extern int printf(const char *format, ...);
@@
@

The \path!module.c! function must provide an [[initialize_module]] function which will be called during kernel initialization.


\subsection{Pretty Printing for the Book}

The \path!filter-uses.py! script enables the limited pretty-printing that we have used in this book. It replaces brackets (\verb#()[]{}#), exclamation marks, \verb!#include! and \verb!#define! statements and C and Assembler comments with highlighted versions.

%nouse
<<tex-build/filter-uses.py>>=
#!/usr/bin/env python

import fileinput
from re import sub

deletemode = False
codemode = False
asmmode = False
breakmode = False
nosyntaxmode = False

for line in fileinput.input():
  line = line[:-1]   # remove \n
  if line == "%nouse":
    deletemode = True
    # print "% DELETE MODE ON"

  if "%BEGIN ASM CHUNK" in line:
    asmmode = True
  
  if "%END ASM CHUNK" in line:
    asmmode = False

  if "%BEGIN NOSYNTAX" in line:
    nosyntaxmode = True
  
  if "%END NOSYNTAX" in line:
    nosyntaxmode = False

  if "%BREAK BEFORE DEFINES" in line:
    breakmode = True

  if "nwendcode" in line:
    codemode = False

  if breakmode and "nwindexdefn" in line:
    line = sub (r"\\nwindexdefn", r"\\pagebreak\\nwindexdefn", line)
    breakmode = False

  if not nosyntaxmode:

    if codemode == True:
      if asmmode == False:
        # highlight C comments
        line = sub (r"(//.*)$", r"{\\green\\emph{\1}}", line)
        line = sub (r"/\*", r"{\\green\\emph{/*", line)
        line = sub (r"\*/", r"*/}}", line)
      else:
        # highlight ASM comments
        line = sub (r"(;.*)$", r"{\\green\\emph{\1}}", line)
      line = sub (r"\(", r"{\\lightblue{}(}", line)
      line = sub (r"\)", r"{\\lightblue{})}", line)
      line = sub (r"\[", r"{\\red{}[}", line)
      line = sub (r"\]", r"{\\red{}]}", line)
      line = sub (r"!", r"{\\red{}!}", line)
      line = sub (r"\\\{", r"{\\orange{}\\{}", line)
      line = sub (r"\\\}", r"{\\orange{}\\}}", line)
      for keyword in (r"#define", r"#include"):
        line = sub (keyword, r"\\emph{"+keyword+r"}", line)
  
  if "nwenddeflinemarkup" in line:
    codemode = True
      
  if deletemode and "nwidentuses" in line:
    line = sub (r"nwidentuses.*nwindexuse", r"nwindexuse", line)
    deletemode = False
  
  print line
@ %
%END NOSYNTAX

\pagebreak

For those readers who might want to modify the build process, we give some more details in the following sections.


\section{Directory Hierarchy and Makefiles}

In the [[ulix/]] directory you find several files and directories after the initial build process:

\begin{itemize}
\item \verb#ulix.pdf# is a PDF version of this book. It will only be generated if you have \XeLaTeX{} installed (which is not a requirement for simply testing \UlixI{}).
\item \verb#bin-build/# contains the kernel source files \verb#ulix.c# and \verb#start.asm# which are compiled and linked into the kernel binary with [[gcc]], [[nasm]] and [[ld]]. 
\item \verb#lib-build/# holds the user mode library source files [[ulixlib.c]] and [[ulixlib.h]] as well as a sub-directory for the user mode applications.
\item \verb#lib-build/tools/# is the place where the application source files reside. All of those are C programs.
\item \verb#lib-build/tools/diskfiles/# collects files which shall be placed in the \UlixI{} root disk image file (that is located in \verb#bin-build/minixdata.img#). 

The image \verb#bin-build/ulix-fd0.img# only contains the boot loader GRUB and the \UlixI{} kernel (and no other data).
\item \verb#tex-build/# is used for generating the PDF documentation. It also contains some extra \LaTeX{} files which are not part of a standard \LaTeX{} distribution, such as the noweb package ([[noweb.sty]]).
\item The \Ulix{} source root directory (where you placed \verb#ulix-book.nw#) and all \verb#*-build# directories contain makefiles which can be executed by simply changing to the directory and calling [[make]]. They do also provide some options for partial builds or cleanup operations (see next section).
\end{itemize}


\section{Making and Booting}

In this section we provide some further details about the build process and the ways to execute \UlixI{}.


\subsection{User Mode Applications}

\index{application}%
In order to compile a user mode program, place its source code file in the \path!lib-build/tools! folder. We assume that the source file is called \path!myprogram.c!. If you simply want to check whether it compiles, type [[make myprogram]] (while in the \path!lib-build/tools! directory), that will generate a \path!myprogram! binary. For installing it in the disk image, change the directory to \path!lib-build! and type \verb#make#. You can then test the program by entering the \UlixI{} development root directory and typing \verb#make run#.

Note that each user mode program must start with the line
\begin{Verbatim}
#include "../ulixlib.h"
\end{Verbatim}
which includes the \UlixI{} library headers.

If you also made changes to the library (by modifying the \path!ulix-book.nw! file) you need to call [[make]] twice in \path!lib-build!.


\subsection{The Disk Images}

\index{Ulix!disk images}%
\UlixI{} uses four disk image files:

\begin{itemize}
\item \path!ulix-fd0.img!: This file is FAT-formatted and contains the boot loader GRUB and the \UlixI{} kernel file \path!ulix.bin!. It is updated whenever you rebuild the kernel.
\item \path!ulix-fd1.img!: This is a Minix"=formatted floppy image that is mounted on the \path!/mnt! directory when \UlixI{} boots. It does not contain any relevant files, so you can reformat it with [[mkfs.minix -2 ulix-fd1.img]].
\item \path!ulix-hda.img!: This disk image is used as the first hard disk, even though it has the layout of a 1.44 MB floppy disk. It is the root disk, i.\,e., it is mounted to \path!/!. You can reformat it, but then you need to reinstall the \path!init! program and the other applications (via \verb#make# in the \path!lib-build! directory).
\item \path!ulix-hdb.img!: The 100~MByte hard disk image is mounted on the \path!/tmp! directory and holds the 64~MByte swap file \path!/tmp/swap! that \UlixI{} uses for paging out page frames. It is required, but you can also add other files to it.
\end{itemize}


\subsection{Alternative Boot Options}

If you look at the \path!Makefile! in \path!bin-build!, you will notice that there is another make target besides \verb#run# which also starts the PC emulator: By typing [[make nolog]] you can start [[qemu]] without the option that gathers the serial line output, displays it in the terminal and also writes it to the log file \path!ulix.output!.

For experiments, you can add further make targets which use modified options.


\subsection{Informative Files}

When you compile the kernel, the files \path!ulix.sym! and \path!ulix.dump! are created. The first one contains a listing of symbols with their addresses, and the second one contains the generated assembler\index{Assembler language!generated code (from C)} code, also with addresses. When you modify \UlixI{} and the system hangs because of invalid memory access or some other fault, the fault handler will display the faulting address. You can then use these files to check where the error occurred.


\subsection{Manually Inspecting the C Files}

If you want to have a look at the C files which are extracted from \path!ulix-book.nw! because you prefer to see functions in a complete version (instead of the chunk-based presentation in this book), you will notice that the files are garbled with hundreds of source line modifiers of the form
\begin{Verbatim}
#line 19651 "../ulix-book.nw"
\end{Verbatim}
They allow the C compiler to show the line number in \path!ulix-book.nw! (instead of the line number in the current C file) when printing error messages. In order to get rid, [[untangle]] the C file without the [[-L]] option, i.\,e., run
\begin{Verbatim}
notangle -Rulix.c ../ulix-book.nw > ulix.c
\end{Verbatim}
instead of 
\begin{Verbatim}
notangle -L -Rulix.c ../ulix-book.nw > ulix.c
\end{Verbatim}


\subsection{Other Emulators}

Early versions of \UlixI{} were also compatible with the Bochs PC emulator which has a comfortable graphical debugger (if you install the right version of Bochs). However, the current version does not boot on the Bochs machine.

You could also try to use \UlixI{} with virtualization software (such as VirtualBox or VMware Workstation), but we have not tested that.


\section{Online Resources: the \texttt{ulixos.org} Website}

We already mentioned the website as the download resource for all the files we have discussed above. You may find updated information in a \path!readme.txt! file in the \url{http://ulixos.org/files/0.12/} directory. Also check the start page, \url{http://ulixos.org/}, for information about new \UlixI{} releases.


\section{Tools}

The last section is not strictly related to the build process. Here we merely present the [[bindump]] tool that was mentioned in the Minix implementation chapter (Chapter~\ref{sec:fs:minix-overview}).

\subsection{bindump}
\label{tools:bindump}%
\tindex{bindump}%

Similar to \verb#hexdump#, here's an implementation of [[bindump]]. The tool has an option [[-r]] which reverses the output order of 8-bit-strings (bytes; e.\,g.\ \verb#10100000# instead of \verb#00000101#). [[bindump]] accepts no filename, you must use it as a filter (e.\,g.\ [[bindump -r < image.img]]).

The tool was helpful during the early implementation phase of the Minix filesystem since it allowed to print the inode and zone bitmaps in a readable form. It is not automatically extracted from the book sources, but you can copy and paste its code from \path!ulix-book.nw! if you want to use it, too.

\pagebreak

%nouse
<<bindump source code>>=
// bindump.c

// use as filter:
//   bindump < image.img      (for regular output, lower bits on the right)
//   bindump -r < image.img   (for reversed output, lower bits on the left)
//   cat image.img | bindump

#include <stdio.h>

int rev;  // reverse output?

void binwrite (byte c) {
  unsigned int v = (unsigned int)c;
  int i;
  for (i = 7;  i > -1;  i--) {
    if (rev == 0)  printf ("%d", (v>>i)%2);       // regular output
    else           printf ("%d", (v>>(7-i))%2);   // reversed output
  };
  printf (" ");
}

void bindump (byte *bytes, int offset, int num) {
  int i; byte c;
  printf ("%08x  ", offset);
  for (i = 0;  i < num;  i++)  binwrite (bytes[i]);
  printf (" ");
  for (i = 0;  i < num;  i++) {
    c = bytes[i];
    if ((c > 31) && (c < 128))  printf ("%c",c);
    else                        printf (".");
  };
  printf ("\n");
};

int main (int argc, char *argv[]) {
  byte buf[8]; int count; int pos = 0;
  rev = 0;                                                 // reverse?
  // Test if option -r is set:
  if ((argc > 1) && (strequal (argv[1], "-r")))  rev = 1;  // reverse!
  do {
    count = read (0, &buf, 8);
    if (count > 0)  bindump ((byte*)&buf, pos, count);
    pos += 8;
  } while (count > 0);
  return 0;
}
@



%----------------------------------------------------------------------------------------



\chapter{Where to Go Now?}

You've done it: you finished the book (unless you skipped to this chapter early), and that means you've seen the whole source code of the \UlixI{} operating system. Now you know how a Unix-like system works internally, and that tells you a lot about how most other systems function. Of course, \UlixI{} differs a lot from Linux\index{Linux} or Windows\index{Windows operating system}, but many of the differences are about hardware support (systems intended for practical purposes need lots of drivers for all sorts of devices), performance, stability, failure handling and of course the list of provided features.

However, there is one important topic that you have not seen in this book at all: Operating systems for multi-core (or multi-processor) architectures are more complex since they have to handle a lot more parallelism; after all, on such systems several cores or CPUs execute instructions at the same time, and it may happen that two or more processes simultaneously make a system call or run a faulting instruction. Similarly the scheduler may be required to pick a new process on several cores at the same time. This has many consequences for the operating system code which needs to be protected better against the typical problems that parallelism causes.

So if you want to understand why Linux or Windows\index{Windows operating system} is able to use your quad-core machine so efficiently, you need to go on reading. 

Herlihy and Shavit's book ``The Art of Multiprocessor Programming'' \cite{Herlihy:2012:AMP} discusses synchronization problems on multiprocessor platforms in detail, and Schimmel's ``UNIX Systems for Modern Architectures'' \cite{Schimmel:1994:Unix-Modern} also deals with this topic, but focuses on Unix.

Looking at the Linux\index{Linux!source code} sources (or those of one of the free BSD versions) could be a next step, though that would require lots of time. If you're more interested in Windows\index{Windows operating system}, Microsoft used to provide a stripped-down but very well-documented version of the Windows 2003 Server kernel, called the ``Windows Research Kernel''\index{Windows operating system!Windows research kernel (WRK)} (WRK) which was available to instructors via Microsoft's Academic Alliance website and was later moved to \url{http://www.microsoft.com/resources/sharedsource/Licensing/researchkernel.mspx}, however that section of the website has been moved once more and we are currently unaware of any WRK download resources---perhaps someone in your faculty still has a copy of it.

If you want to test your understanding of the \UlixI{} code (and have already worked on the exercises) you might want to continue with a bigger project. Here are some suggestions for improvements of the \UlixI{} kernel:

\begin{itemize}
\item Enable partition support: Currently \UlixI{} treats hard disks like floppies, i.\,e., unpartitioned. Understanding either the classical MBR or the new GUID partition tables (GPT) and adding code to \UlixI{} so that partitions can be accessed via \path!/dev/hda1!, \path!/dev/hda2! etc.\ is not too complicated but will still require some time to get it right.
\item Add network support: \UlixI{} would get closer to being a proper Unix system if it could access the network. The task would be twofold: a) Write a hardware driver for a standard network adapter (e.\,g.\ the one that is provided as a virtual network card by [[qemu]]), and b) Write or port a TCP/IP stack to \UlixI{}.
\item Port some interesting user mode applications to \UlixI{}. For example, there is a simple implementation of a \verb#vi# clone which can do very limited editing of text files that are no longer than 23 lines (because it does not support scrolling). You could take this code and build it into a proper editor.
\end{itemize}

If you're able to read the German language, you can also have a look at the publication list on the \UlixI{} website: There are links to several Bachelor's theses which describe the implementations of various \UlixI{} components.

As a closing remark, we'd like to rephrase what we wrote in the foreword: We hope that you've found this book interesting and helpful for gaining some understanding of operating system concepts. We believe that our approach of presenting the whole source code of a simplified Unix system in the literate programming style is unique and worthwhile. If you agree (or disagree), then please drop us a note and tell us how the \UlixI{} book worked for you.



%----------------------------------------------------------------------------------------




\appendix

\chapter{Introduction to C}
\label{chap:intro-to-c}%

\index{C programming language!introduction}%
In this chapter we give you a very short introduction to programming with C---and we expect that you have some previous knowledge of one of the object-oriented successors of C, such as C++ or C\#.


\section{No Classes, no Objects}

The most important difference between C and the other languages is that C is no object-oriented language. It knows neither classes nor objects. This means that you have to change your way of conceptually thinking of code: Where you have been used to define a \emph{class}\marginnote{class, method} and implement \emph{methods} that can manipulate objects of that class, this is not possible with C. Instead you need to write \emph{functions}\marginnote{function}, and these functions are independent of specific ``data objects''. If you want to store data, you declare \emph{variables}, and you must provide a function with that variable (while calling it).

Imagine a string class that has a reverse function. If you have an object \verb#s#, you might put the statement \verb#s.reverse();# in your code and expect that this changes the order of the characters in the string \verb#s#. In C, you could implement a function \verb#reverse()# which has the following prototype:

%nouse
<<example function>>=
void reverse (char *arg);
@

You would then call the function by using the statement \verb#reverse (s);#. (We will explain why the argument is written [[char *arg]] in the next section.) 

C is a \emph{typed language}, and it does not allow you to \emph{overload}\marginnote{overloading} its functions. So, by continuing the above example, if you also had a list class in an object-oriented language, you might find that that list class also provides a \verb#reverse()# method, using the same name. Then, if you had a string \verb#s# and a list \verb#l#, you could use the syntactically identical method invocations \verb#s.reverse();# and \verb#l.reverse();# to have both objects reversed---even though the technical details of the methods' implementations might differ a lot.

It is not possible to have two C functions of the same name, so in this situation the best solution would be to write two functions with appropriate names, such as \verb#reverse_string()# and \verb#reverse_list()#.


\section{Data Types, Arrays and Pointers}

\index{C programming language!data type}%
\index{C programming language!array}%
Since classes are not available, C needs to provide an alternative for declaring user-defined complex data types (which have several simpler elements, similar to member fields of an object). The C keyword \verb#struct# is used for defining a \emph{structure}\marginnote{structure}. For example, the following definition declares a complex number that consists of two real numbers:

%nouse
<<example structure 1>>=
struct complex {
  float re;
  float im;
};
@

After you have defined this structure, you can declare variables of that new type, for example by writing \verb#struct complex c;#. The \verb#struct# keyword is required, though it is possible to get rid of it: instead of the above code, you can also write

%nouse
<<example structure 2>>=
typedef struct {
  float re;
  float im;
} complex;
@

This creates the same kind of structure, but via the \verb#typedef#\marginnote{[[typedef]]} keyword you assign the name \verb#complex# to that structure. Then, you can declare variables by simply stating \verb#complex c;#.

In both cases, you can access the fields of the variable \verb#c# with a syntax that is similar to the one that C++ and Java use for member access: the \emph{dot notation}\marginnote{dot notation}. Typing \verb#c.re# will give you the real component of the number, and \verb#c.im# is the imaginary component.

Often several instances of a variable are needed, and for this purpose C provides \emph{arrays}\marginnote{array}. If you want \verb#cnumbers[]# to be an array that can hold 20 complex numbers, you would write

%nouse
<<example array 1>>=
struct complex cnumbers[20];
@ or
%nouse
<<example array 2>>=
complex cnumbers[20];
@ (depending on whether you chose the first or second method of defining the new type). You can then access the 20 individual entries of the array by putting the index in square brackets. Note that C starts counting at 0, thus valid index numbers for the example array range from 0 to 19: \verb#cnumbers[0]# is the first number, and \verb#cnumbers[19]# is the last. Getting the real and imaginary parts is done via the dot notation again, so \verb#cnumbers[0].re# is the real part of the first complex number.

If you want to add all the complex numbers in the \verb#cnumbers[]# array and store the sum in the \verb#sum# variable, you could write the following loop:

%nouse
<<summing up the complex numbers>>=
complex sum = { 0, 0 };        // set sum.re = sum.im = 0
int i;
for (i = 0;  i < 20;  i++) {
  sum.re += cnumbers[i].re;
  sum.im += cnumbers[i].im;
}
@ (\verb#x += y;# is a short form for \verb#x = x + y;#, and the first line shows how you can initialize a structure without using the field names.)

It is impossible to directly add two complex numbers, because you cannot create your own version of the \verb#+# or \verb#+=# operator---the following loop cannot be expressed in C:

%nouse
<<impossible way to build the sum>>=
complex sum = { 0, 0 };        // set sum.re = sum.im = 0
int i;
for (i = 0;  i < 20;  i++) {
  sum += cnumbers[i];          // !  cannot do that
}
@

You could, however, write a function \verb#addto()# that takes two complex numbers and adds the second one to the first one:

%nouse
<<function for adding>>=
void addto (complex *c1, complex *c2) {
  *c1.re += *c2.re;
  *c1.im += *c2.im;
}
@ and then rewrite the add loop as
%nouse
<<summing up the complex numbers with [[addto]]>>=
complex sum = { 0, 0 };        // set sum.re = sum.im = 0
int i;
for (i = 0;  i < 20;  i++) {
  addto (&sum, &cnumbers[i]);
}
@

What's happening here or, more specifically, what are the \verb#*# and \verb#&# operators doing?

Let's start with the \verb#&# operator which is called the \emph{address-of operator}\marginnote{address-of\\ operator}: It ``gets'' the memory address of the variable, i.\,e., a numerical value that says where in memory the variable is stored. In the above loop this happens with both \verb#sum# and \verb#cnumbers[i]#. The two addresses are then provided to the \verb#addto# function.

When you look at the functions's prototype, you see that \verb#addto()# does not expect two complex \emph{values} but something else, namely, two addresses of complex variables. These are just 32-bit integers (if you're working on a 32-bit machine), but the function knows to expect complex numbers (and not something else) at those addresses. Inside the function you cannot directly access the numbers by writing \verb#c1# or \verb#c2#, because those two arguments are not complex numbers, but addresses. In order to access the contents, you have to \emph{dereference} the address, and that is what the \verb#*# operator is for. It is called the \marginnote{dereference\\ operator}\emph{dereference operator}.

\index{C programming language!pointer}%
\verb#c1# and \verb#c2# are what C calls \emph{pointers}\marginnote{pointer}: internally they store the addresses of two complex variables, and practically that turns them into pointers to those variables. Prefixing them with the \verb#*# operator turns them into the (wanted) complex variables. Thus, \verb#*c1# and \verb#*c2# are of type \verb#complex#. You already know how to access the real and imaginary parts of a complex variable, so it should be obvious why \verb#*c1.re# and \verb#*c2.re# deliver the intended values.

Why can we use \verb#addto()# to actually change the value of the first operand? That's because the memory addresses of the real variables are provided. Using pointers as function arguments is a form of \emph{call-by-reference}\marginnote{call-by-reference} (as opposed to \emph{call-by-value} where a function gets to work with a copy of the values).

Since expressions of the form \verb#*var.element# are often needed, there is a different way to write them which is better readable and also makes it clearer that we deal with a pointer: that alternative is \verb#var->element#\marginnote{[[->]] notation}. The \verb#-># combination looks like an arrow (it points). The prettier way to write the \verb#addto# function is this:

%nouse
<<function for adding, with pointer syntax>>=
void addto (complex *c1, complex *c2) {
  c1->re += c2->re;
  c1->im += c2->im;
}
@


\section{Strings? There is no String}
\index{C programming language!string}%

One of the properties of C is that there is no built-in \emph{string type}\marginnote{no string type}. But obviously, strings are much needed. What C does have, is an elementary \emph{character type} \marginnote{[[char]]}(\verb#char#) that simply is a signed byte, storing values between -128 and 127; the ASCII table holds only 128 values, so the positive numbers of this range are sufficient to store any ASCII character. You can also use the \marginnote{unsigned char}\verb#unsigned char# type which ranges from 0 to 255.

The simplest way to introduce a string in your program is using a \emph{character array}:

%nouse
<<string definition as [[char]] array>>=
char my_string[128];
@ (or with \verb#unsigned char# instead of \verb#char#).

This defines a character array of length 128. All functions in the standard C libraries use a \emph{null character}\marginnote{[[\0]]} (ASCII value 0) to mark the end of such a string, so the above definition actually provides a string that can hold no more than 127 characters: The last position cannot be used other than to store a 0 value (to indicate that this string consists of 127 characters). This is a popular source of programming errors, where a developer thinks ``my password string can consist of 16 characters'' and then proceeds to write \verb#char password[16]# which lets him store only 15 characters.

An alternative way to think of a string is as just a consecutive chunk of memory (where a character is stored at each of its addresses). Then it is enough to simply store the starting address of the string. A pointer can do just that, and in case of strings, a pointer to \verb#char# makes the most sense. So typing

%nouse
<<string definition as [[char*]] pointer>>=
char *my_string;
@ does also declare a string. However, there's an important difference: The first example (with the array) reserves a defined amount of memory where the string can be stored---the new version does not do so. It simply says: [[my_string]] points to a chunk of memory which is interpreted as a string. That address may or may not be initialized to 0. In any case, just declaring the string does nothing that helps us store a string.

How can we use such a pointer? First of all, if you already have a string (say, one declared as an array), you can assign its address to the pointer. Consider the following code:

%nouse
<<char pointer assignment>>=
char array_string[12] = "Hello World";   // declares and assigns
char *pointer_string;
pointer_string = array_string;
@

The first line shows how strings can be filled with content at the time of declaration. The \emph{string literal}\marginnote{string literal} [["Hello World"]] is just a shorthand for [[{ 'H', 'e', 'l', 'l', 'o', ' ', 'W', 'o', 'r', 'l', 'd', '\0' }]] which is the standard way to initialize arrays during declaration. When you type a string in [["..."]] signs, the string-terminating [['\0']] character is automatically added. The second line declares a pointer to [[char]]. The interesting instruction is in the last line: it assigns [[array_string]] to [[pointer_string]]. When you use just the name of an array, that is automatically interpreted as the (starting) address of the array. Thus, [[array_string]] is a pointer to [[char]], and this address is assigned to [[pointer_string]] by the instruction. Afterwards, both [[pointer_string]] and [[array_string]] reference \emph{the same} memory address. You can check that by changing a single character in one string and then printing the other one:

%nouse
<<char pointer assignment>>=
array_string[5] = '_';                            // replace blank with '_'
printf ("array_string:   %s\n", array_string);    // print the first string
printf ("pointer_string: %s\n", pointer_string);  // print the second string
@

The output will be identical ([[Hello_World]] with an underscore). The assignment does not work vice versa, i.\,e., you cannot have an instruction [[array_string = pointer_string]] in the same situation: the compiler knows that the [[array_string]] variable points to a fixed memory address, whereas [[pointer_string]] is truly a variable. What is changeable in an array variable, are the elements, not the position and size of the array.

If you have no array-type strings, then how to get a free memory location? You can use the \verb#malloc()# function (memory allocation) to request space. If you want to store a string with 100 characters (plus the terminating zero), you could type

%nouse
<<char pointer memory allocation>>=
pointer_string = (char*) malloc (101);
@ The \verb#malloc(101);# call will reserve memory and return its start address which is then stored in the variable. The new memory may or may not be initialized. The extra [[(char*)]] part before \verb#malloc# performs a type conversion: the return value of \verb#malloc# is [[(void*)]], a pointer to data of unknown type. Placing the desired type ([[char*]]) in round brackets in front of it changes the type to [[char*]]. This kind of conversion is called a \emph{type cast}\marginnote{type cast} or simply a \emph{cast}. You can always convert pointers to something into pointers to something else, though some conversions make no sense. A conversion in the C program does not translate into the execution of any code (in the generated assembler language): a pointer is an address, and all addresses have the same type when looked at at the machine level; on a 32-bit machine every address is a 32-bit integer. But the C compiler keeps track of how you define your pointers and issues warnings when you assign a pointer to a pointer of a different type without adding the explicit cast.


\section{String Operations}

Once you have the memory that is necessary to store a string (either via a direct array declaration of via \verb#malloc#), you want to work with the string.
As C has no string type and no methods, you cannot write \verb#s1 = s1+s2;# or \verb#s1.append(s2);# in order to append a string \verb#s2# to another string \verb#s1#. Instead you need to use a function that does just that. The same holds for copying: You cannot assign a string to another one (and expect that to result in a copy), so even \verb#s1 = s2;# is illegal for character arrays. It is legal when \verb#s1# is a pointer, but does not duplicate the string: It copies the address. The standard functions for copying a string and appending a string (to another one) are

%nouse
<<standard string functions>>=
char *strcpy (char *dest, char *src);
char *strcat (char *dest, char *src);
@

Instead of \verb#s1 = s2;# you would write \verb#strcpy (s1, s2);# and instead of \verb#s1 = s1 + s2;# you need \verb#strcat (s1, s2);#. However, these functions may not always have the intended effect, and that is the source of many security holes in applications.

You can find our implementation of [[strcpy]] in the book: \UlixI{} provides its own version since it cannot use the functions which are available on the development (Linux) system.

The functions \verb#strcpy# and \verb#strcat# should be used very carefully because they can write beyond the end of the memory area that was reserved for the string. Typing

\index{C programming language!buffer overflow}%
%nouse
<<string buffer overflow>>=
char s1[10];
char s2[25] = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
strcpy (s1, s2);   // copy long string s2 into s1
@ is perfectly legal C code, but \verb#strcpy()# will not stop when it reaches the end of \verb#s1#. Instead it will just fill the following bytes as well, and that may result in a number of things, for example \verb#s2# being destroyed (if it is located directly behind \verb#s1#) or an application crashing if the addresses behind \verb#s1# are not available.

That is why it is best to replace all uses of \verb#strcpy# and \verb#strcat# with their safe variants which are called \verb#strncpy# and \verb#strncat#: they have a third argument via which you can limit the number of bytes that are actually written:

%nouse
<<standard string functions>>=
char *strncpy (char *dest, char *src, size_t n);
char *strncat (char *dest, char *src, size_t n);
@ Using them (and using the right value for \verb#n#) the following code causes no problems (though it still cannot achieve what can't be done, i.\,e., copying a large string into a small one:

%nouse
<<no string buffer overflow>>=
char s1[10];
char s2[25] = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
strncpy (s1, s2, 10);   // copy up to 10 characters of s2 into s1
@ This code will not write beyond the end of \verb#s1#, but it will also leave \verb#s1# in a bad state: the string will not be null-terminated, but instead contain the first ten characters of \verb#s1# without termination. The only way to avoid this (if the size limit cannot be helped) is this:

%nouse
<<truly creating a string>>=
char s1[10];
char s2[25] = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";
strncpy (s1, s2, 9);   // copy 9 characters...
s1[9] = '\0';          // and manually terminate the string
@

Of course there are other ways that let you avoid such situations. For example, when you want to copy a string you can first use the function

%nouse
<<standard string functions>>=
size_t strlen (const char *s);
@ to discover the length of a string, then reserve the appropriate amount of memory for a copy (using \verb#malloc()#) and then create the copy.

For comparing two strings you need yet another function since a simple comparison like \verb#(s1==s2)# will only compare the strings' starting addresses.

%nouse
<<standard string functions>>=
int strcmp  (const char *s1, const char *s2);
int strncmp (const char *s1, const char *s2, size_t n);
@ compare \verb#s1# and \verb#s2# character-by-character and return 0 if the strings are equal. If \verb#s1# $<$ \verb#s2# (lexicographically), they return a negative number, and if \verb#s1# $>$ \verb#s2#, they return a positive number. So test for \verb#(strcmp(s1,s2)==0)# to check whether two strings are identical. For both functions the comparison ends when the null-termination occurs in one of the strings, the safe ``n'' version also stops after \verb#n# characters have been read.


\pagebreak

\section{Pointer Arithmetic}
\label{appendix:c:pointerarithmetic}%
\index{C programming language!pointer arithmetic}%
\index{pointer arithmetic}%

Consider the following, naive implementation of a \verb#strcpy()# function:

%nouse
<<simple [[strcpy]] implementation>>=
char *strcpy (char *dest, char *src) {
  int i;
  for (i = 0; i < strlen(src); i++) {
    dest[i] = src[i];     // copy i'th character
  dest[i] = '\0';         // terminate dest
  return dest;
}
@ It works because \verb#dest# and \verb#src# can be treated like arrays (though the parameters are declared as pointers). However it is neither necessary to use a counter variable nor the \verb#strlen()# function. Instead the following version is preferred in the realm of C programmers:

%nouse
<<typical [[strcpy]] implementation>>=
char *strcpy (char *dest, char *src) {
  char *tmp = dest;
  while ( (*dest++ = *src++) != '\0' ) 
    ;
  return tmp;
}
@ For most people who are new to C, this looks like garbage though it's perfectly correct C (and does what you want). Let's explain the code in detail.

\begin{itemize}
\item First of all \verb#*dest++ = *src++# is C shorthand for the three commands \verb#*dest = *src;# \verb#dest++; src++;#, and the value of the whole expression is the value of \verb#*dest# or \verb#*src# \emph{before} the two increment commands. (\verb#x++# is another shorthand, meaning \verb#x = x+1#.)

\item Adding 1 to a \verb#char# pointer increases the memory address by 1 (as would be expected). At the beginning \verb#dest# points to the first character of the destination string, \verb#dest[0]#. After the increment it points to what was previously \verb#dest[1]#, the second character.

\item The \verb#while# loop continues the byte-wise copying until a null character is found (and copied). The destination string is now complete (null-terminated), but \verb#dest# no longer points to the beginning of the target string since mutiple \verb#++# operations have increased its value. That is why we kept the initial value in \verb#tmp#.

\item That saved value is then returned. (The \verb#strcpy()# function must always return a pointer to the new string.)

\end{itemize}

\noindent
Now why is this section titled \emph{Pointer Arithmetic}? If we were to work with integer arrays (instead of character arrays), we might also be interested in a copy function, let's call it \verb#intarrcpy()# (integer array copy). Its implementation looks almost identical to the second \verb#strcpy()# version, with all occurrences of ``\verb#char#'' replaced with ``\verb#int#'':

\pagebreak

%nouse
<<copying a 0-terminated integer array>>=
int *intarrcpy (int *dest, int *src) {
  int *tmp = dest;
  while ( (*dest++ = *src++) != 0 ) 
    ;
  return tmp;
}
@ But let's look at the \verb#++# operator again: If it also increased the values of \verb#dest# and \verb#src# by 1, the function would have to fail since a 32-bit integer needs four bytes for storage, not just one. So what we want is to add 4 to the addresses in every step of the loop. The surprising news is: This is exactly what \verb#++# does, and that is why it is called pointer arithmetic. The \verb#++# operator (as well as \verb#--# and the regular addition and subtraction) consider the size of the base type that the pointer points to. For an [[int]] pointer \verb#ptr#, the \verb#ptr++# commands actually increases \verb#ptr#'s address by \verb#sizeof(int)# (which is 4). 

Pointer arithmetic is not restricted to base types. If you define a \verb#struct something# structure that contains a lot of data, totaling in 2604 bytes of data for each such variable, and declare a pointer of that type (via [[struct something *ptr;]]), then each [[ptr++;]] command will modify the address by adding 2604. This makes it easy to walk through array-like structures even when they were never declared as arrays.

There is one problem with pointer arithmetic that sometimes leads to wrong code. We already mentioned that you can cast pointer types to different pointer types. Look at the following example to see what can go wrong:

%nouse
<<cast and pointer arithmetic gone bad>>=
char s[10] = "ABCDEFGHI";
char *charptr;
int  *intptr;

charptr = s;              // points to the 'A' in s
intptr = (int*) charptr;  // same address
intptr++;                 // pointer arithmetic!
charptr = (char*) intptr; // cast/copy it back
@ If you expect \verb#charptr# to point to the \verb#'B'# in \verb#s#, then you've made the mistake that we want to explain. It actually points to the \verb#'E'# because the pointer arithmetic was performed on an [[int]] pointer, so addresses are always modified in multiples of 4.


\section{C Pre-Processor}
\index{C programming language!pre-processor}%

The C compiler runs a pre-processor before actually compiling the code. That pre"=processor looks for commands that begin with \verb!#! and acts on them. These can be used for including other source files, for conditional compilation and for macro definitions. Since we use some of these features, we give a short explanation of each of these three possibilities but only discuss the details which are relevant for reading and/or modifying the \UlixI{} code.

\begin{itemize}
\item Including files: Using the command
\begin{Verbatim}
#include "path/to/file.h"
\end{Verbatim}
you can include other files in the source file. Typically those are header files (ending in \verb#.h#), but you can include any file you want. If the path name starts with a slash, it is treated as an absolute path, otherwise as a relative one. So you can include the file \verb#xyz.h# from the upper directory by writing
\begin{Verbatim}
#include "../xyz.h"
\end{Verbatim}
---regardless of where the files are placed absolutely.

\index{C programming language!macro}\index{macro (C)}%
\item Macro definition: The \verb!#define! command declares a macro. In its simplest version that leads to a simple search-and-replace. For example,
\begin{Verbatim}
#define BLOCK_SIZE 1024
\end{Verbatim}
lets the compiler search the source file for the string \verb#BLOCK_SIZE# and replace every occurrence with \verb#1024#.

A more advanced version of macros uses parameters\marginnote{macros with\\ parameters}, so macros provide an alternative method to writing (simple) functions. A typical example is finding the smaller of two values:
\begin{Verbatim}
#define MIN(x,y) ((x<y) ? x : y)
\end{Verbatim}
The expression \verb#(x<y) ? x : y# evaluates to \verb#x# if \verb#x<y# is true and to \verb#y# otherwise. Using \verb#MIN(x,y)# in the code makes it more readable. However, this must be used with care, as the following example shows which attempts to increase two variables while picking their minimum:
\verb#MIN(v1++,v2++)# does not do what is expected because the macro is expanded to
\verb#((v1++ < v2++) ? v1++ : v2++)#. Here, \verb#v1# and \verb#v2# are compared. Let's assume that \verb#v1# is the smaller one. Then both variables are incremented (as expected). However, in the next step \verb#v1# is increased again: The condition is true, so \verb#v1++# is evaluated. The total result is that the value of \verb#MIN(v1++,v2++)# is the old value of \verb#v1# $+1$, and \verb#v1# gets incremented twice (while \verb#v2# is incremented only once).

When you work with macros, use them only with constant arguments or arguments which have no \emph{side effects}\marginnote{side effect}. (In the example, \verb#MIN(f(x1),f(x2))# with some function \verb#f()# would also call \verb#f(x1)# twice, not once, if \verb#(f(x1)<f(x2))# evaluates as true.)

\item Conditional Compilation:\index{C programming language!conditional compilation}%
 You can create simple if-then-else constructions which can remove parts of the code before compilation. This is often used for inserting debug code during the development which is then removed for the final release of the software. As an example consider the following code block:
\begin{Verbatim}
#define DEBUG
int somefunc (int x) {
  int res;
  #ifdef DEBUG
    printf ("DEBUG: somefunc() called with argument %d\n", x);
    res = x / 3;
    printf ("DEBUG: somefunc() going to return %d\n", res);
  #else
    res = x / 3;
  #endif
  return res;
}     
\end{Verbatim}
When you compile this code it will contain the debug output because the \verb#DEBUG# macro is defined. (Note that it has no specific value, it is just defined, so \verb!#ifdef! will evaluate it as true.) Simply remove that \verb!#define DEBUG! line and recompile to get the version which contains only the ``else'' case: the lines between \verb!#else! and \verb!#endif!.

Of course, the same effect could be achieved without a macro (by using a \verb#DEBUG# variable and a regular \verb#if# expression), but then all of the code would be compiled. With the macro, the pre"=processor removes the unwanted lines from the source code before the compiler runs.
\end{itemize}

\noindent
The pre"=processor does not touch occurrences of a macro name inside a string literal: the arguments of \verb#printf()# in the example contain \verb#DEBUG# in the string argument, and they remain intact.

You can check the effect of pre"=processor commands by calling the \verb#gcc# compiler with the \verb#-E# option: \verb#gcc -E file.c -o file.i# creates a new file \verb#file.i# where all pre"=processor commands have been executed. That file is now free of pre"=processor commands.
An interesting alternative to the \verb#-E# option is the \verb#-save-temps# option which performs all compilation steps, but keeps the intermediate files which are normally deleted. When you run the command
\begin{Verbatim}
gcc -save-temps testprog.c -o testprog
\end{Verbatim}
you can find four new files: \path!testprog.i! is the pre"=processor"=modified version of the source file, \path!testprog.s! is the compiled assembler version (with readable assembler source code), \path!testprog.o! is the assembled object file, and finally \path!testprog! is the binary executable file which contains library code or links to dynamically loaded libraries. Figure~\ref{fig:gcc-keep-intermediate} shows an example of the created files.

\begin{figure}[t]
\begin{centering}
\fboxsep 4.5mm
\begin{boxedminipage}{\textwidth}
\centering
\begin{Verbatim}
$ cat testprog.c       $ cat testprog.i          $ cat testprog.s
#define TEST 1024      # 1 "test.c"                      .cstring
                       # 1 "<built-in>"          LC0:
int main () {          # 1 "<command-line>"              .ascii "%d\0"
  printf ("%d",        # 1 "test.c"                      .text
          TEST);                                 .globl _main
}                                                _main:
                       int main () {             LFB2:
                         printf ("%d",                   pushq   %rbp
                                 1024);          LCFI0:
                       }                                 movq    %rsp, %rbp
                                                 LCFI1:
                                                         movl    $1024, %esi
                                                         leaq    LC0(%rip), %rdi
                                                         movl    $0, %eax
                                                         call    _printf
                                                         leave
                                                         ret
                                                 ...
\end{Verbatim}
\end{boxedminipage}
\end{centering}
\caption[\hgepolylof{Intermediate code files generated by the \texttt{gcc} compiler.}]{When called with the [[-save-temps]] option, [[gcc]] keeps the intermediate files.}
\label{fig:gcc-keep-intermediate}
\end{figure}


\section{Further Reading}

Since pointers seem to be a crucial topic for most students who are new to C programming, we suggest reading a whole book about pointers: ``Pointers on C'' \cite{reek1998pointers} by Kenneth Reek is an excellent read and comes with many exercises, both practical and theoretical. The author uses diagrams to show what points where and what content is stored in which memory locations.

For those who truly want to delve into the language, the description of the C compiler in David Hanson and Christopher Fraser's LCC book \cite{Fraser-Hanson:1995:lcc-compiler} offers deep insight. If you understand the workings of a C compiler, you've also mastered the language. Plus: the book is another literate programming example which in itself makes it worth reading---provided that you like this style.

Another interesting book about C is Peter van der Linden's ``Expert C Programming: Deep C Secrets'' \cite{linden1994expert-c-prog}. The author looks at some obscure details and explains unexpected phenomena with direct quotations from the ANSI C standard definition \cite{ANSI:1989:PLC}. There are many comparisons of language features in C and C++ which are especially helpful if you're used to writing C++ code. The publisher's website has a 60-page sample.

Many good C books are rather old as the language was created in the eighties. Some of them are still available in print. If you want to have some fun with C programs, look at the International Obfuscated C Code Contest website, \url{http://www.ioccc.org/}.


%----------------------------------------------------------------------------------------


\addtocontents{toc}{\protect\parttocpagebreak}


\chapter{Introduction to Intel x86 Assembler}
\label{chap:intro-to-asm}
\index{Assembler language!introduction}%

Most of the \UlixI{} code is written in C, but some small parts had to be done in Assembler since C cannot directly access the CPU's registers or execute specific CPU instructions such as the ones that enable or disable interrupts. In many cases it is sufficient to use [[gcc]]'s inline assembler feature that lets you drop a few lines of assembler in the middle of a C function (see Section~\ref{sec:assembler:inline}), but we also needed a separate assembler source file for the early steps in the system initialization. In this chapter we give a very short introduction to some of the features available on Intel i386 and higher CPUs and the syntax of the commands.

When you use assembly language, you are somewhat limited in the way you can structure the code. For example, where C has several types of loops (\verb#for#, \verb#while#, \verb#do#) and nestable if-then-else expressions, assembler does not. Instead, you can make comparisons and jump elsewhere in the code (depending on the result of that comparison). That is closer to early Basic dialects where branching worked via ``IF \emph{condition} GOTO \emph{line number}'' statements. However, there's no need to learn the assembler ways of expressing \verb#for# and \verb#while# loops, because we don't want to write \emph{all} our code in assembler.


\section{CPU Registers}

\index{Assembler language!registers}%
\index{register!Assembler language}%
Just like a C program that accesses a variable (which is stored somewhere in RAM), assembler code often works with memory, too. For example, the CPU provides instructions that inspect the contents of two memory cells, add or substract them and store the result in the first of the two cells. That is basically what the C compiler creates when it compiles a C command like \verb#var1 += var2;# or \verb#var1 -= var2;#. But memory access is expensive: it takes some time to translate a virtual address into a physical address and fetch the memory contents via the memory bus. It is too slow to perform all operations that way. Every CPU has a set of faster memory cells: the CPU-internal \emph{registers}\marginnote{registers}. They are even faster than the first level cache which is embedded in the same chip as the CPU's core: they provide instant access.

Intel's CPUs (like many other processors) have a set of \emph{general purpose registers} which can be used to hold arbitrary data and perform calculations on them, and then there's also a set of \emph{special purpose registers} which is what we're really interested in, because we need to read or write some of those registers to influence and control paging, interrupt handling and other critical tasks.

There are eight \emph{general registers}\marginnote{general registers} \cite[p.~29]{intel80386}: \register{EAX}, \register{EBX}, \register{ECX}, \register{EDX}, \register{EBP}, \register{ESP}, \register{ESI}, and \register{EDI}. You can use them to hold values and perform calculations and comparisons. Each of these registers is 32 bits wide, and you can also access the lower 16 bits of them by using a different name (\register{AX}, \register{BX}, \register{CX}, \register{DX}, \register{BP}, \register{SP}, \register{SI}, and \register{DI}; all without the leading ``E''). The first four registers can be separated even further into higher and lower halves which are only eight bits wide (and hold a byte): \register{AH}, \register{BH}, \register{CH} and \register{DH} are the higher halves, \register{AL}, \register{BL}, \register{CL} and \register{DL} are the lower halves (see Figure~\ref{fig:eax-ax-al-ASMCHAP}) which are sometimes needed for I/O when data is read from or written to a \emph{port}\marginnote{I/O port} that grants the CPU access to the internal 8-bit register of some chip, e.\,g. a disk controller.

\begin{figure}[ht]
\centering
\includegraphics[width=9cm]{pics/eax-ax-al.pdf}
\caption[Accessing parts of \register{EAX} as \register{AX}, \register{AH} and \register{AL} (identical to Figure~\ref{fig:eax-ax-al}).]{The lower half of \register{EAX} is \register{AX} which in turn is split into \register{AH} (high) and \register{AL} (low).}
\label{fig:eax-ax-al-ASMCHAP}
\end{figure}

For example, in order to add the contents of \register{EBX} to \register{EAX} you could use the assembler instruction \verb#add eax, ebx#. The \verb#mov# instruction copies (not: moves) a value from one register to another, so \verb#mov eax, ebx# performs an \verb#eax := ebx# action. You can also access memory locations with these commands: \verb#mov eax, [ebx]# will load a 32-bit value from the memory addresses pointed to by \register{EBX} and copy it to \register{EAX}---the C equivalent would be \verb#eax := *ebx# (with \verb#ebx# interpreted as an \verb#int*# pointer).

The registers \register{ESP} (extended stack pointer) and \register{EBP} (extended base pointer) are used for working with stacks\marginnote{stack}. \register{ESP} points to the top of the stack and is changed whenever a subroutine is called or it exits and when a value is pushed onto or popped from the stack. The base pointer helps with staying oriented on the stack: While a subroutine executes, it may often modify the stack (thus changing \register{ESP}). But the stack also holds the arguments which were provided to the subroutine as well as its local variables, and by letting \register{EBP} point to the address between arguments and local variables, it is possible to access them without a need to consider changes to \register{ESP}. For example, \register{EBP}+8, \register{EBP}+12, \register{EBP}+16 store the first, second and third argument, and \register{EBP}--4, \register{EBP}--8 and \register{EBP}--12 store the first, second and third local variable (assuming that all those values are 32-bit integers). Between those two areas there is still some room: address \register{EBP}+4 holds the return address, and at the address that \register{EBP} points directly to you find the ``old value'' of \register{EBP} that was used for the previous subroutine call (in a setting where subroutines call other subroutines). 


\section{A Few Standard Commands}

We will not give a detailed introduction to the instructions that the Intel x86 CPU provides, but here is a short overview of some of the most important ones. For the Intel processor platform, two ``dialects'' exist, the Intel and the AT\&T one. The GNU C compiler supports both but defaults to the AT\&T variant. We have decided to use the Intel syntax, because it is closer to C's syntax: For example, you can load the \register{EAX} register with the value 0 via the command [[mov eax, 0]] (in Intel syntax). So the target of the [[mov]] command comes first which resembles the C command [[eax = 0]]. In AT\&T syntax, the operands are reversed, with the target coming last and extra syntactical elements being needed ([[mov $0, %eax]]).
In the following examples we will show the Intel syntax on the left hand side, and the AT\&T syntax on the right.


\subsection{Moving Data Around}

\index{Assembler language!mov instruction@\texttt{mov} instruction}
The simplest way of filling a register is loading an \emph{immediate}\marginnote{immediate} value. The [[mov]] instruction does that. In Intel syntax, the register name comes first, followed by the number expressed as in the following examples. In the AT\&T syntax the order of arguments is reversed, and immediate values are prefixed with a dollar sign, whereas register names have a percent sign as prefix. Also, AT\&T syntax appends a size identifier to the [[mov]] instruction, so instead of [[mov]] it is called [[movb]] (byte, 8 bits), [[movw]] (word, 16 bits) or [[movl]] (long, 32 bits).

If you want to copy the contents of a memory location, you can load the address in one of the registers and tell [[mov]] to look at the memory cell(s) that it points to. The last two examples in the following table show how this is done, once without an offset and once with an offset.

%%% mov ecx, 10101b            movl $0b10101,  %ecx        direct load, binary
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Intel Syntax} & \textbf{AT\&T Syntax} & \textbf{Description} \\
\hline
\verb#mov eax, 0xABCD    # & \verb#movl $0xABCD,    %eax# & direct load, hexadecimal \\
\verb#mov ebx, 1         # & \verb#movl $1,         %ebx# & direct load, decimal \\
\verb#mov eax, [ebx]     # & \verb#movl (%ebx),     %eax# & copy memory at \register{EBX} to \register{EAX} \\
\verb#mov eax, [ebx+0xF0]# & \verb#movl 0xF0(%ebx), %eax# & with offset 0xF0 \\
\hline
\end{tabular}
\end{center}

In those last two lines, if \register{EBX} holds the value \hex{ABCD0000}, then the first line will read the 32-bit integer stored at address \hex{ABCD0000}, wheras the second one reads address \hex{ABCD00F0}. In both cases the found value is written to the \register{EAX} register.

The original Intel syntax for hexadecimal numbers is \verb#0ABCDh# with a \verb#h# suffix (and a required \verb#0# prefix if the number starts with a letter digit), but [[nasm]] supports both variants in Intel mode, so we have chosen to use the \hex{ABCD} notation that is also C's way of expressing hexadecimal numbers.


\subsection{Different Integer Sizes}

In the register overview you have already seen that some registers can be accessed in ways which only use the lowest eight or 16 bits. For using these smaller versions, use the alternative names (e.\,g., \register{ax} for the 16-bit version and \register{al} for the 8-bit version). In the AT\&T version you need to use a suffix again for expressing that you want to move a byte, word or long.

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Intel Syntax} & \textbf{AT\&T Syntax} & \textbf{Description} \\
\hline
\verb#mov al,  bl             # & \verb#movb %bl,    %al  # & move a byte \\
\verb#mov ax,  bx             # & \verb#movw %bx,    %ax  # & move a word \\
\verb#mov eax, ebx            # & \verb#movl %ebx,   %eax # & move a long (32 bits) \\
\verb#mov al,  byte ptr [ebx] # & \verb#movb (%ebx), %al  # & move byte from memory \\
\verb#mov ax,  word ptr [ebx] # & \verb#movw (%ebx), %ax  # & move word from memory \\
\verb#mov eax, dword ptr [ebx]# & \verb#movl (%ebx), %eax # & move long from memory \\
\hline
\end{tabular}
\end{center}

Making the value size explicit makes even more sense when you access memory: Copying a byte is not the same as copying a long integer. In the Intel syntax explicit \verb#byte ptr#, \verb#word ptr# and \verb#long ptr# keywords are used to state that a byte, word or long integer shall be read from memory, as shown in the last three lines. The equivalent AT\&T commands don't need this since the [[mov]] suffix already makes the length explicit.


\subsection{Arithmetic Operations}
\index{Assembler language!arithmetic operations}%

When talking about arithmetic operations, we only consider integer operations. The Intel CPUs also provides floating point operations, but we do not need them for \UlixI{}.

For adding and subtracting you can use the \verb#add# and \verb#sub# instructions which take two arguments and add the source to the target; multiplication and integer division are handled by \verb#mul# and \verb#div#, but they don't take two arguments but only one and use the \register{EAX} register as \emph{accumulator}\marginnote{accumulator} (i.\,e., \register{EAX} is implicitly both one of the source operands and the target):

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Intel Syntax} & \textbf{AT\&T Syntax} & \textbf{Description} \\
\hline
\verb#add eax, ebx  # & \verb#addl %ebx,   eax# & add \register{EBX} to \register{EAX}, \verb#eax += ebx# \\
\verb#add eax, [ebx]# & \verb#addl (%ebx), eax# & add (long) memory contents at \register{EBX} to \register{EAX} \\
\verb#sub eax, ebx  # & \verb#subl %ebx,   eax# & subtract \register{EBX} from \register{EAX}, \verb#eax -= ebx# \\
\verb#sub eax, [ebx]# & \verb#subl (%ebx), eax# & subtract (long) memory contents at \register{EBX} from \register{EAX} \\
\verb#mul ebx#        & \verb#mull %ebx#        & multiply \register{EAX} with \register{EBX}, result in \register{EAX}, \verb#eax *= ebx# \\
\verb#div ebx#        & \verb#divl %ebx#        & divide \register{EAX} by \register{EBX}, result in \register{EAX}, \verb#eax /= ebx# \\
\hline
\end{tabular}
\end{center}


\subsection{Jumps, Calls, Comparisons and Conditional Jumps}

\index{Assembler language!jumps and calls}
Sometimes you want to jump to a specific program address in order to continue execution elsewhere. For those cases the [[jmp]] instruction can be used. When creating an assembler source file (for use with [[nasm]]) you will normally assign a label to an instruction that you want to jump to and then use it in the [[jmp]] instruction, like this:
\begin{Verbatim}
  infinite_loop: mov  al,  byte ptr [eax]
                 call printchar
                 add  eax, 1
                 jmp  infinite_loop
\end{Verbatim}
This example shows a further instruction for jumping to a new address: \verb#call# also jumps to the supplied address, but before that it pushes the address of the following instruction (in the example: of \verb#add eax, 1#) onto the stack. The assembler code at \verb#printchar# can then execute the [[ret]] instruction which will pop that address from the stack and continue execution inside the above loop. To summarize the difference: When you [[jmp]], there's no easy way to get back; when you [[call]], you can return with [[ret]].

Simply jumping (or calling) unconditionally does not allow for any case distinctions: Code that only uses [[jmp]] and [[call]] will always execute the same commands in the same sequence. For a distinction of cases we need comparison operations and based on the result we want to decide whether we jump elsewhere or not.

The [[cmp]] instruction takes two arguments and compares them. They are either identical or one value is bigger than the other. The [[j*]] instructions in the following table jump if a certain condition (such as: first value is smaller than the second one) is met.

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Intel Syntax} & \textbf{AT\&T Syntax} & \textbf{Description} \\
\hline
\verb#cmp eax, ebx# & \verb#cmpl %ebx, eax# & compare \register{EAX} and \register{EBX}, then: \\
\hline
\verb#jl  label# & \verb#jl  label# & jump to \verb#label# if \register{EAX} $<$    \register{EBX} \\
\verb#jle label# & \verb#jle label# & jump to \verb#label# if \register{EAX} $\leq$ \register{EBX} \\
\verb#je  label# & \verb#je  label# & jump to \verb#label# if \register{EAX} $=$    \register{EBX} \\
\verb#jge label# & \verb#jge label# & jump to \verb#label# if \register{EAX} $\geq$ \register{EBX} \\
\verb#jg  label# & \verb#jg  label# & jump to \verb#label# if \register{EAX} $>$    \register{EBX} \\
\verb#jne label# & \verb#jne label# & jump to \verb#label# if \register{EAX} $\ne$  \register{EBX} \\
\hline
\verb#sub eax, ebx# & \verb#subl %ebx, eax# & subtract \register{EBX} from \register{EAX}, then: \\
\hline
\verb#jz  label# & \verb#jz  label# & jump to \verb#label# if result of last arith.\ operation $= 0$ \\
\verb#jnz label# & \verb#jnz label# & jump to \verb#label# if result of last arith.\ operation $\ne 0$ \\
\hline
\end{tabular}
\end{center}

The last three commands show that there are also conditional jumps that depend on the last arithmetic operation (instead of the last comparision). [[jz]] jumps if the \marginnote{zero flag}\emph{zero flag} is set which is the case if the last arithmetic operation resulted in a zero value. Similarly you can jump if the \emph{overflow flag}\marginnote{overflow flag} is set which happens when the last operation caused an overflow, e.\,g., after adding 100 to \hex{FFFFFFF0}.


\subsection{Pushing and Popping With the Stack}

\index{Assembler language!stack usage}%
\index{stack!Assembler language}%
We already mentioned the stack which is used by the [[call]] instruction for storing the return address. Using [[push]] and [[pop]] you can also push data on the stack and pop it back. If you want to call an assembler function with arguments, first [[push]] the values and then [[call]] the function. The function can then either [[pop]] all values from the stack into registers (though it has to remember the return address and restore the stack later) or it can access the stack contents directly via \verb#[ebp+8]#, \verb#[ebp+12]# etc.\ if it saves the original \register{ESP} in the base pointer \register{EBP}. \verb#push# and \verb#pop# also accept memory locations, so you can push the value stored at the memory address that \register{EAX} points to by executing \verb#push [EAX]#.

In AT\&T syntax, [[push]] and [[pop]] need a suffix to indicate how large the data are which must be pushed or popped, so you get [[pushw]], [[pushl]], [[popw]] and [[popl]]. (You cannot push or pop a single byte, see \cite[p.~137]{hyde2010art-of-assembly-language}.) 
% also: p.251 of books.google.de/books?id=WLgCBAAAQBAJ  (first edition??)
Some assemblers support a [[pushb]] or [[push byte]] instruction, but that will actually turn a byte into a word (by filling it with zero bits) and then push that.


\section{Special Commands}
\label{appendix:assembler:special-commands}%

\index{Assembler language!db, dw, dd (data storage)@\texttt{db}, \texttt{dw}, \texttt{dd} (data storage)}%
There are three kinds of special commands that we'll introduce in this section: You can define constants (which are similar to C-\verb#define#d macro constants), you can use macros (similar to C's macros that look like functions), and you can store data bytes for creating data structures.

All of these require using the [[nasm]] assembler. If you want to work with another assembler, it is likely that the same features are available, but they might use a different syntax.


\subsection{Data Storage (\texttt{db}, \texttt{dw}, \texttt{dd})}

Assembler code contains instructions and data. Since you cannot define data types (like in C), your only option is to \emph{know} what a data structure should look like and then directly encode data in the binary (and later refer to the address where the data are located).

There are three commands which can store data:

\begin{itemize}
\item [[db]] is used to store individual bytes (or sequences of bytes). For example, [[dd 0x32, 0x38, 0x3b]] will store the three bytes \hex{32}, \hex{38} and \hex{3b} (in this order). If you place a label before that command you can later reference the address where those three bytes can be found. Instead of hexadecimal (or regular) numbers, you can only provide a single character or a string: [[db 'xyz']] will store the three bytes whose character representations are x, y and z. Note that such a string will not be null"=terminated.
\item [[dw]] does the same as [[db]], but stores a double byte (a word), and
\item [[dd]] stores a double word (or quad byte, consisting of four bytes). You need to use [[dd]] to store 32-bit addresses.
\end{itemize}

[[dw]] and [[dd]] get the order of the bytes right so that they are stored in memory according to the \emph{endianness}\marginnote{endianness} of your platform, for example, [[dd 0x12345678]] will write bytes \hex{78}, \hex{56}, \hex{34} and \hex{12} because Intel x86 machines are of the \emph{little-endian}\marginnote{little-endian} type where the smaller bit blocks come first.

There are also commands for storing floating-point numbers ([[dq]], [[dt]]), but we do not need them for \UlixI{} which uses only integers.


\subsection{Constants (\texttt{equ})}

\index{Assembler language!equ (constants)@\texttt{equ} (constants)}
With [[equ]] statements you can define identifiers which you can use in later code lines instead of the constants or expressions that you provided in the identifier definition. The syntax is always of the form

\begin{Verbatim}
  IDENTIFIER  equ  EXPRESSION
\end{Verbatim}

\noindent
For example, the \UlixI{} assembler file \path!start.asm! contains the following lines:
\begin{Verbatim}
  MB_HEADER_MAGIC   equ 0x1BADB002
  MB_HEADER_FLAGS   equ 11b
  MB_CHECKSUM       equ - (MB_HEADER_MAGIC + MB_HEADER_FLAGS)
\end{Verbatim}

\noindent
They define three local identifiers \verb#MB_HEADER_MAGIC#, \verb#MB_HEADER_FLAGS# and \verb#MB_CHECKSUM# that are used to create the multiboot header:
\begin{Verbatim}
  ; GRUB Multiboot header, boot signature
  dd MB_HEADER_MAGIC   ; 00..03: magic string
  dd MB_HEADER_FLAGS   ; 04..07: flags
  dd MB_CHECKSUM       ; 08..11: checksum
\end{Verbatim}


\subsection{Macros (\texttt{\%macro})}

\index{Assembler language!macros}\index{macro (Assembler)}%
If your code contains repetitive sequences that you would turn into a function (when programming in C), you can use a \emph{macro} to keep the level of repetitions down. We show you the macro that we used in \path!start.asm! to write the assembler functions [[irq0]], [[irq1]], \dots

The macro definition looked like this:
\begin{Verbatim}
  %macro irq_macro 1 
         push byte 0          ; error code (none)
         push byte %1         ; interrupt number
         jmp irq_common_stub  ; rest is identical for all handlers
  %endmacro
\end{Verbatim}
and we called the macro this way:
\begin{Verbatim}
  ...
  irq12: irq_macro 44
  irq13: irq_macro 45
  irq14: irq_macro 46
  ...
\end{Verbatim}
which the assembler expands to the following lines:
\begin{Verbatim}
  irq12: push byte 0          ; error code (none)
         push byte 44         ; interrupt number
         jmp irq_common_stub  ; rest is identical for all handlers
  
  irq13: push byte 0          ; error code (none)
         push byte 45         ; interrupt number
         jmp irq_common_stub  ; rest is identical for all handlers
  
  irq14: push byte 0          ; error code (none)
         push byte 46         ; interrupt number
         jmp irq_common_stub  ; rest is identical for all handlers
%endmacro
\end{Verbatim}

In the macro's definition, the parameter \verb#1# in the first line states that the macro can be used with one argument. That argument can be referred to via \verb#%1#.
So, while expanding the macro, every occurrence of \verb#%1#
is replaced with the argument. In the above examples we called the macro with arguments \verb#44#, \verb#45# and \verb#46#.

If you need more than one argument (say: three), you set a different number, e.\,g. with [[%macro name 3]]. 
Then you access those arguments via \verb#%1#, \verb#%2# and \verb#%3#.


\section{\texttt{gcc} Inline Assembler}
\label{sec:assembler:inline}%

\index{Assembler language!inline assembler}\index{inline assembler}
The GNU C compiler [[gcc]] lets developers write inline assembler statements in the middle of C code. That is very helpful if only a few lines of assembler code are required---storing them in a separate assembler source file and making sure that both the C and the assembler code can see the variables which are needed in both places is laborious, and it also costs (a little) CPU time because an external assembler routine must be called via the function call mechanism whereas inline assembler code is just inserted between the translations of the preceding and successive C code.

You can find the best example for a quick line of assembler code in the book: Whenever we need to disable or enable the interrupts, we do this via the [[<<disable interrupts>>]] and [[<<ensable interrupts>>]] code chunks which use the inline assembler instructions
\begin{Verbatim}
  asm ("cli");    // disable interrupts (clear interrupt flag)
\end{Verbatim}
or
\begin{Verbatim}
  asm ("sti");    // enable interrupts (set interrupt flag)
\end{Verbatim}
to execute the [[cli]] and [[sti]] instructions.

However, this is the simple case. It is more typical that values (which are stored in C variables) have to be used as a parameter of the assembler instruction. In a pure assembler file you can write
\begin{Verbatim}
  mov eax, some_label
\end{Verbatim}
to load the address of [[some_label]] in the \register{EAX} register, but you cannot similarly write an inline assembler statement like
\begin{Verbatim}
  asm ("mov eax, &some_C_variable")
\end{Verbatim}
to do the same for the address of [[some_C_variable]]. Instead, values or addresses must be passed by preparing registers before the assembler instructions are executed (and fetching possible result values via registers as well). [[gcc]] defines a special syntax to provide \marginnote{input/output\\ operands}\emph{input operands} and \emph{output operands}; the general instruction format is this:
\begin{Verbatim}
  asm ("assembler instructions",
       :    // optional output operands
       :    // optional input  operands
       :    // optional "clobber" list
      )
\end{Verbatim}
Operands are always written in the \verb#"reg" (variable)# form; if there is more than one register that we want to use, we use several such expressions and put commas between them. The following registers can be used:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Register} & \textbf{Reading} & \textbf{Writing} \\
\hline
\register{EAX} & \verb#"a"# & \verb#"=a"# \\
\register{EBX} & \verb#"b"# & \verb#"=b"# \\
\register{ECX} & \verb#"c"# & \verb#"=c"# \\
\register{EDX} & \verb#"d"# & \verb#"=d"# \\
\register{ESI} & \verb#"S"# & \verb#"=S"# \\
\register{EDI} & \verb#"D"# & \verb#"=D"# \\
any            & \verb#"r"# & \verb#"=r"# \\
\hline
\end{tabular}
\end{center}

We use that syntax in the [[syscall*]] functions of the user mode library: as an example, here is the code for [[syscall3]] which takes three parameters, stores them in \register{EAX}, \register{EBX} and \register{ECX}, raises the interrupt \hex{80} and returns a result from \register{EAX}:
\begin{Verbatim}
  inline int syscall3 (int eax, int ebx, int ecx) {
    int result;
    asm ( "int $0x80"       : "=a" (result)     : "a" (eax), "b" (ebx), "c" (ecx) );
    //    |- instruction -|   |- output regs -|   |- input registers           -|
    return result;
  }
\end{Verbatim}
The instruction explicitly copies the variables [[eax]], [[ebx]] and [[ecx]] into the corresponding registers and then, after [[int 0x80]], explicitly copies the contents of \register{EAX} into the [[result]] variable.

\verb#"r"# (or \verb#"=r"# for output) can be used for an arbitrary register, i.\,e., the compiler will choose a register as it sees fit. But then we don't know which register will hold the value. We can reference the variables by observing the order in which they appear in the output and input operand lists, and then address them as \verb#%0#, \verb#%1#, \dots\ in the assembler code.

For example, in order to add two variables [[var1]] and [[var2]] and store the sum in [[sum]], we could write
\begin{Verbatim}
  asm ("movl %1, %%eax \n"
       "addl %2, %%eax \n"
       "movl %%eax, %0"
       : "=r" (sum)               // output
       : "r" (var1), "r" (var2)   // input
       : "%eax"                   // "clobber" list
      );
\end{Verbatim}
We don't know what registers will hold the values of [[var1]] and [[var2]], but we simply move or add them to \register{EAX} and finally write the sum (which is in \register{EAX} after the [[addl]] instruction) back to register 0. That is then copied to [[sum]].

We do not want the compiler to use \register{EAX} for one of the variable values, and that it where the \emph{clobber list}\marginnote{clobber list} comes in: With it we can tell the compiler which registers it must not use, so in the case of the above addition we put \register{EAX} on that list. Note that the syntax for the register name is different in the instructions (\verb#%%eax#) and in the clobber list (\verb#%eax#)! In the clobber list you could also write \verb#eax# instead of \verb#%eax#, but not \verb#%%eax#.


\section{Further Reading}

A freely downloadable introductory text is Paul Carter's ``PC Assembly Language Book'' \cite{carter:2006:pc-assembly-language}. It is available in English and a few other languages via the author's website, \url{http://www.drpaulcarter.com/pcasm/}.

If you're more interested in concepts of assembler programming than in the actual syntax, ``The Art of Assembly Language'' \cite{hyde2010art-of-assembly-language} is a good alternative introduction: The author, Randall Hyde, has created his own dialect of Intel 32-bit assembler called HLA (High Level Assembler) which looks more natural since it has commands for conditional loops and standard input/output. HLA programs have more similarity with C programs than normal assembler code, but writing programs in HLA still teaches all the basic principles of assembler.

``Linux Assembly Language Programming'' \cite{neveln:2000:0130879401:assembly} by Bob Neveln focuses on Linux\index{Linux!Assembler}; for example there is a description of the ELF binary format used by Linux (and \UlixI{}).

For [[gcc]] inline assembler the ``GCC Inline Assembly How-to'' \cite{sandeep:2003:gcc-inline-assembly} is available online at
\url{http://www.ibiblio.org/gferg/ldp/GCC-Inline-Assembly-HOWTO.html}.


%------------------------------------------------------------------



\chapter{Other Educational Operating Systems} % Appendix C
\label{appendix:more related work}%

As mentioned in the introduction chapter, we have assembled a list of other educational operating systems. We already discussed Minix and Xinu (see page~\pageref{minix-and-xinu}) and suggested having a look at these two systems. But there are many more:

\begin{itemize}

\item One of the oldest instructional texts in this area is the Lions' commentary \cite{persons/Lions1996}, originally written by John Lions\index{Lions, John} in 1976 but only published 20 years later. Its roughly 100 pages of code documentation are intended to be read side-by-side with a specially enumerated printout of the source code of Unix Version 6. Each section of the commentary explains a specific code section that is identified by its first line number.

\item Xv6\index{xv6 operating system} is a simple Unix-like teaching OS \cite{xv6Draft} originally developed in the summer of 2006 for MIT's OS course, and its documentation mimics the Lions' commentary in that the source code is available in a document with full line numbering (throughout all source files) and a descriptive document refers to those line numbers.

Our \Ulix{} implementation has borrowed some code from Xv6, for example for dealing with the hard disk controller and with serial ports.

\item Topsy\index{Topsy (Teachable operating system)} (Teachable Operating System) was developed at ETH Zurich \cite{Fankhauser:1996:Topsy}, the original version runs on the MIPS architecture. Later it was ported to Intel i386 \cite{Ruf:1998:Topsy-i386} and to the Pentium 4 \cite{Ryffel:2007:Topsy-P4} by students of the same university.

\item Thix\index{Thix operating system} is a Unix-like operating system developed by Tudor Hulubei and documented in a technical report \cite{Hulubei:1995:Thix}. While the author's goal was not to create an educational resource but ``to learn about operating systems design and architecture, kernel algorithms, resource allocation, process scheduling, memory management policies, etc.'', the resulting code and report make an interesting read.

The \Ulix{} implementation uses parts of the floppy driver code from Thix.

\item Nachos\index{Nachos operating system} (Not another completely heuristic operating system) \cite{nachos:paper,nachos:code} was originally developed in Berkeley and is currently supported at University of Washington. It was written in C++ and the sources were well-commented, though classically (i.\,e., directly in the source files). The system has to be run on a specific MIPS hardware emulator (also provided by the authors). Development of the original code was stopped, but there is a Java version \cite{nachos:java} now used in Berkeley. The concept of the authors is to provide a system with only the most basic properties which is then extended by students during a course. Another successor to Nachos is Pintos.

\item The goal of the Pintos\index{Pintos operating system} \cite{pintos,pintos:code} developers was to replace Nachos. It differs from it in several aspects: it runs on 32-bit Intel x86 hardware (the authors suggest to execute it in the Bochs \cite{BOCHS} or [[qemu]] \cite{QEMU} PC emulators), and it uses the C programming language instead of C++. Its feature set is similar to the one of \Ulix{}. Pintos is also similar to Unix systems, but does not provide a \verb#fork# function. It is currently used for teaching at Stanford and other universities.

\item OS/161\index{OS/161 operating system} is a kernel that was written in C for classes at Harvard University. It runs on an emulator for a machine called System/161 and is available for download at \url{http://www.eecs.harvard.edu/~syrah/os161/}. The authors have described their experiences with using OS/161 in class in a short conference paper \cite{Holland:2002:NIO:563340.563383}. 

\item iPoƨix\index{iPoƨix operating system} (spelled iPosix) is a small Unix-like kernel for 32-bit Intel machines that was written in C++ by two students of Oldenburg University \cite{iPosix:kernel}. Later a practical course with exercises based on iPoƨix was designed by another student \cite{iPosix:teaching}.

\item L4\index{L4 kernel} is a family of micro-kernels that is sometimes used for educational purposes, for example at Technical University of Dresden (in the ``Building Microkernel-Based Operating Systems'' course). Reference manuals for the x86 \cite{L4:Liedtke:ReferenceManualX86} and MIPS architectures \cite{L4:Liedtke:ReferenceManualMIPS} describe the system.

\item FreeDOS\index{FreeDOS operating system} is a clone of Microsoft's MS-DOS\index{MS-DOS operating system}, and its author has documented the development in a book \cite{pat1996freedos}. When he created FreeDOS, sources of MS-DOS were not available, so at that time studying FreeDOS was an alternative to reverse engineering the MS-DOS binaries. (In 2014 Microsoft published the source code of MS-DOS \cite{msdos-source-released-2014,msdos-11-source}.)

\item MicroC-OS II\index{MicroC-OS II real-time kernel} by Jean J. Labrosse is a real-time kernel that is described in a freely available book \cite{micro-c-os-2}. The author states that the intended audience of the book includes ``students interested in real-time operating systems''. There is also a newer version (MicroC-OS III) that runs on several platforms.

\item OOStuBS\index{OOStuBS operating system} and MPStuBS\index{MPStuBS operating system} are object-oriented operating systems for the Intel x86 platform which are used for classes at Friedrich Alexander University Erlangen"=Nuremberg \cite{mpstubs}. MPStuBS is a version of OOStuBS that supports multiprocessor systems. Students taking the Operating Systems course can decide which system they want to work with throughout the semester.

\end{itemize}

The following entries do not refer to educational operating systems, but to books which describe ``real world'' systems. However, they do it so thoroughly that these texts can also be used as learning materials.

\begin{itemize}

\item Marshall Kirk McKusick and George V. Neville-Neil give a very detailed description of the FreeBSD\index{FreeBSD operating system!kernel} kernel in their book ``The Design and Implementation of the FreeBSD Operating System'' \cite{McKusick:2005:DIF}. There is a lot of code mixed with explanations and figures, but the code is only pseudo code that leaves out the details.

\item The original Unix\index{Unix} system is described in Bach's book ``The Design of the Unix Operating System'' \cite{Bach:1986:DUO}. It is based on Unix System V, Release 2 (from 1984) and describes the internal data structures and algorithms in a similar way as the FreeBSD book does: Real code is replaced with more accessible descriptions of what needs to be done.

\item Lixiang et al.\ have written ``The Art of Linux Kernel Design'' \cite{Yang:2014:ArtOfLinuxDesign}. Even though it was published in 2014, it is based on Linux\index{Linux} version 0.11 which was released in December 1991. The old code is not as complex as that of current versions, and the authors use it for in-depth descriptions of the internal data structures and algorithms. 

\end{itemize}




%%%%%%%%%%%%%%


\cleardoublepage
\addcontentsline{toc}{chapter}{Appendices}

\clearpage
\addcontentsline{toc}{section}{Chunk Index}
%\pagestyle{useheadings}
%\markboth{Chunk Index}{Chunk Index}
\pagestyle{scrheadings}
\ihead{Chunk Index}

\begin{adjmulticols}{1}{-2.5cm}{-2.97cm}
\chapter*{Chunk Index}
\end{adjmulticols}
\begin{adjmulticols}{2}{0cm}{-2.97cm}
%\begin{multicols}{2}
\small
\nowebchunks
\end{adjmulticols}
%\end{multicols}

% how can this be merged with normal latex index?
\cleardoublepage
%\changetext{⟨text height⟩}{⟨text width⟩}{⟨even-side margin⟩} {⟨odd-side margin⟩}{⟨column sep.⟩}
%\changetext{-2cm}{}{}{}{}

\addcontentsline{toc}{section}{Identifier Index}
%\pagestyle{useheadings}
%\markboth{Identifier Index}{Identifier Index}
\pagestyle{scrheadings}
\ihead{Identifier Index}
\begin{adjmulticols}{1}{-2.5cm}{-2.97cm}
\chapter*{Identifier Index}
\end{adjmulticols}
\begin{adjmulticols}{3}{0cm}{-2.92cm}
%\begin{multicols}{2}
\small
\nowebindex
\end{adjmulticols}
%\end{multicols}


\renewenvironment{theindex}
  {{\huge\indexname}\par%
   %\parindent\z@
   %\parskip\z@ \@plus .3\p@\relax
   %\let\item\@idxitem
   \parindent 0in%
   \let\item\par%
   \begin{adjmulticols}{2}{0cm}{-2.92cm}}
  {\end{adjmulticols}}
  
\cleardoublepage
\addcontentsline{toc}{section}{Index}
\normalsize
\pagestyle{scrheadings}
\thispagestyle{empty}%
%\begin{adjmulticols}{2}{0cm}{-2.97cm}
\ihead{Index}
\begin{adjmulticols}{1}{-2.5cm}{-2.97cm}
\chapter*{Index}
\end{adjmulticols}


%%% remove page number from 
\let\originalstyle=\thispagestyle            % Store the command for later reuse.
%\def\thispagestyle#1{\fancyfoot[C]{}}       % This clears footer in the center if fancyhdr is in use.
%\def\thispagestyle#1{\originalstyle{empty}} % Use this to get blank header+footer, TeXnically it is only \thispagestyle{empty}.
\def\thispagestyle#1{}                       % This line completely ignores the content of the \thispagestyle command.
\renewcommand{\indexname}{}

\printindex                                  % Typeset the actual Index.
\let\thispagestyle=\originalstyle

%\end{adjmulticols}
%\end{adjmulticols}

\cleardoublepage
\addcontentsline{toc}{section}{Bibliography}
\columnseprule=0pt%
\bibliographystyle{hge-is-alpha}
\raggedright
\pagestyle{scrheadings}
\ihead{Bibliography}
\begin{adjmulticols}{1}{0cm}{-2.92cm}

\let\OLDurl\url%
\newcommand\myQ[1]{\href{#1}{\Q{#1}}}
\renewcommand\url[1]{\href{#1}{\Q{#1}}}
\newcommand\showURL{}

\bibliography{ulix-book}

\let\url\OLDurl%

\section*{Image Credits}
\addcontentsline{toc}{section}{Image Credits}

``UNIX-Licence-Plate'' (title page of book) by KHanger - Own work. Licensed under Creative Commons Attribution 3.0 via Wikimedia Commons, \path!http://commons.wikimedia.org/wiki/File:UNIX-Licence-Plate.JPG#mediaviewer/File:UNIX-Licence-Plate.JPG!
\vspace{2mm}

Hard disk icon (Figure~\ref{fig:translation:table}):
Oxygen Team, LGPL-licensed, 
\url{http://www.iconarchive.com/show/oxygen-icons-by-oxygen-icons.org/Devices-drive-harddisk-icon.html}
\vspace{2mm}

Punch card image (Figure~\ref{img:punchcard}):
Wikimedia Commons, \url{http://commons.wikimedia.org/wiki/File:Blue-punch-card-front-horiz.png}
% pics/Blue-punch-card-front-horiz.jpg
\vspace{2mm}

DVD logo (Figures~\ref{fig:fs-windows}, \ref{fig:fs-unix}): \\
Wikipedia, \url{http://de.wikipedia.org/wiki/Datei:DVD-ROM-Logo.svg}
\vspace{2mm}

Other hard disk icon (Figures~\ref{fig:fs-windows}, \ref{fig:fs-unix}): \\
Wikimedia Commons, \url{http://commons.wikimedia.org/wiki/File:Harddisk.svg}
\vspace{2mm}

The font used for Figure~\ref{fig:keyboard-us} and Figure~\ref{fig:keyboard-de} is ``Aa Qwertz-Tasten'' and was designed by Anke Arnold, 
\url{http://www.anke-art.de/}. \quad \quad .

\end{adjmulticols}


\cleardoublepage\phantomsection
\pagestyle{scrheadings}
\ihead{GNU General Public License}

\begin{adjmulticols}{1}{-2.5cm}{-2.97cm}
\chapter*{GNU General Public License}
\addcontentsline{toc}{section}{GNU General Public License}
\end{adjmulticols}

\begin{adjmulticols}{2}{0cm}{-2.92cm}

\fontsize{8pt}{9.2pt}\selectfont

Version 3, 29 June 2007


\begin{center}
{\parindent 0in

Copyright \copyright\  2007 Free Software Foundation, Inc. \texttt{http://fsf.org/}

\bigskip
Everyone is permitted to copy and distribute verbatim copies of this

license document, but changing it is not allowed.}

\end{center}

\parskip 2mm
\subsubsection*{Preamble}
The GNU General Public License is a free, copyleft license for
software and other kinds of works.

The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

The precise terms and conditions for copying, distribution and
modification follow.

%\clearpage


\subsubsection*{Terms and Conditions}

\setlist[enumerate]{leftmargin=12pt,topsep=5pt,parsep=5pt,itemsep=-2pt}

\begin{enumerate}

\addtocounter{enumi}{-1}

\item Definitions.

``This License'' refers to version 3 of the GNU General Public License.

``Copyright'' also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

``The Program'' refers to any copyrightable work licensed under this
License.  Each licensee is addressed as ``you''.  ``Licensees'' and
``recipients'' may be individuals or organizations.

To ``modify'' a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a ``modified version'' of the
earlier work or a work ``based on'' the earlier work.

A ``covered work'' means either the unmodified Program or a work based
on the Program.

To ``propagate'' a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

To ``convey'' a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

An interactive user interface displays ``Appropriate Legal Notices''
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

\item Source Code.

The ``source code'' for a work means the preferred form of the work
for making modifications to it.  ``Object code'' means any non-source
form of a work.

A ``Standard Interface'' means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

The ``System Libraries'' of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
``Major Component'', in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

The ``Corresponding Source'' for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

The Corresponding Source for a work in source code form is that
same work.

\item Basic Permissions.

All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

\item Protecting Users' Legal Rights From Anti-Circumvention Law.

No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

\item Conveying Verbatim Copies.

You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

\item Conveying Modified Source Versions.

You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:
  \begin{enumerate}
  \item The work must carry prominent notices stating that you modified
  it, and giving a relevant date.

  \item The work must carry prominent notices stating that it is
  released under this License and any conditions added under section
  7.  This requirement modifies the requirement in section 4 to
  ``keep intact all notices''.

  \item You must license the entire work, as a whole, under this
  License to anyone who comes into possession of a copy.  This
  License will therefore apply, along with any applicable section 7
  additional terms, to the whole of the work, and all its parts,
  regardless of how they are packaged.  This License gives no
  permission to license the work in any other way, but it does not
  invalidate such permission if you have separately received it.

  \item If the work has interactive user interfaces, each must display
  Appropriate Legal Notices; however, if the Program has interactive
  interfaces that do not display Appropriate Legal Notices, your
  work need not make them do so.
\end{enumerate}
A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
``aggregate'' if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

\item Conveying Non-Source Forms.

You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:
  \begin{enumerate}
  \item Convey the object code in, or embodied in, a physical product
  (including a physical distribution medium), accompanied by the
  Corresponding Source fixed on a durable physical medium
  customarily used for software interchange.

  \item Convey the object code in, or embodied in, a physical product
  (including a physical distribution medium), accompanied by a
  written offer, valid for at least three years and valid for as
  long as you offer spare parts or customer support for that product
  model, to give anyone who possesses the object code either (1) a
  copy of the Corresponding Source for all the software in the
  product that is covered by this License, on a durable physical
  medium customarily used for software interchange, for a price no
  more than your reasonable cost of physically performing this
  conveying of source, or (2) access to copy the
  Corresponding Source from a network server at no charge.

  \item Convey individual copies of the object code with a copy of the
  written offer to provide the Corresponding Source.  This
  alternative is allowed only occasionally and noncommercially, and
  only if you received the object code with such an offer, in accord
  with subsection 6b.

  \item Convey the object code by offering access from a designated
  place (gratis or for a charge), and offer equivalent access to the
  Corresponding Source in the same way through the same place at no
  further charge.  You need not require recipients to copy the
  Corresponding Source along with the object code.  If the place to
  copy the object code is a network server, the Corresponding Source
  may be on a different server (operated by you or a third party)
  that supports equivalent copying facilities, provided you maintain
  clear directions next to the object code saying where to find the
  Corresponding Source.  Regardless of what server hosts the
  Corresponding Source, you remain obligated to ensure that it is
  available for as long as needed to satisfy these requirements.

  \item Convey the object code using peer-to-peer transmission, provided
  you inform other peers where the object code and Corresponding
  Source of the work are being offered to the general public at no
  charge under subsection 6d.
  \end{enumerate}

A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

A ``User Product'' is either (1) a ``consumer product'', which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, ``normally used'' refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

``Installation Information'' for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

\item Additional Terms.

``Additional permissions'' are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:
  \begin{enumerate}
  \item Disclaiming warranty or limiting liability differently from the
  terms of sections 15 and 16 of this License; or

  \item Requiring preservation of specified reasonable legal notices or
  author attributions in that material or in the Appropriate Legal
  Notices displayed by works containing it; or

  \item Prohibiting misrepresentation of the origin of that material, or
  requiring that modified versions of such material be marked in
  reasonable ways as different from the original version; or

  \item Limiting the use for publicity purposes of names of licensors or
  authors of the material; or

  \item Declining to grant rights under trademark law for use of some
  trade names, trademarks, or service marks; or

  \item Requiring indemnification of licensors and authors of that
  material by anyone who conveys the material (or modified versions of
  it) with contractual assumptions of liability to the recipient, for
  any liability that these contractual assumptions directly impose on
  those licensors and authors.
  \end{enumerate}

All other non-permissive additional terms are considered ``further
restrictions'' within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

\item Termination.

You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

\item Acceptance Not Required for Having Copies.

You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

\item Automatic Licensing of Downstream Recipients.

Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

An ``entity transaction'' is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

\item Patents.

A ``contributor'' is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's ``contributor version''.

A contributor's ``essential patent claims'' are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, ``control'' includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

In the following three paragraphs, a ``patent license'' is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To ``grant'' such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  ``Knowingly relying'' means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

A patent license is ``discriminatory'' if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

\item No Surrender of Others' Freedom.

If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

\item Use with the GNU Affero General Public License.

Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

\item Revised Versions of this License.

The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License ``or any later version'' applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

\item Disclaimer of Warranty.

\begin{sloppypar}
 THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
 APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE
 COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM ``AS IS''
 WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED,
 INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
 MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE
 RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.
 SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL
 NECESSARY SERVICING, REPAIR OR CORRECTION.
\end{sloppypar}

\item Limitation of Liability.

 IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN
 WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES
 AND/OR CONVEYS THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR
 DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL
 DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE PROGRAM
 (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING RENDERED
 INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE
 OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS), EVEN IF SUCH
 HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
 DAMAGES.

\item Interpretation of Sections 15 and 16.

If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

\end{enumerate}

\begin{center}
{\large\sc End of Terms and Conditions}
\end{center}

\subsubsection*{How to Apply These Terms to Your New Programs}


If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the ``copyright'' line and a pointer to where the full notice is found.

{\fontsize{7.4pt}{8.4pt}\selectfont
\begin{verbatim}
<one line to give the program's name and a brief idea of what it does.>

Copyright (C) <textyear>  <name of author>

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
\end{verbatim}
}

Also add information on how to contact you by electronic and paper mail.

If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

{\fontsize{7.4pt}{8.4pt}\selectfont
\begin{verbatim}
<program>  Copyright (C) <year>  <name of author>

This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
This is free software, and you are welcome to redistribute it
under certain conditions; type `show c' for details.
\end{verbatim}
}

The hypothetical commands {\tt show w} and {\tt show c} should show
the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an ``about box''.

You should also get your employer (if you work as a programmer) or
school, if any, to sign a ``copyright disclaimer'' for the program, if
necessary.  For more information on this, and how to apply and follow
the GNU GPL, see \texttt{http://www.gnu.org/licenses/}.

The GNU General Public License does not permit incorporating your
program into proprietary programs.  If your program is a subroutine
library, you may consider it more useful to permit linking proprietary
applications with the library.  If this is what you want to do, use
the GNU Lesser General Public License instead of this License.  But
first, please read \texttt{http://www.gnu.org/philosophy/why-not-lgpl.html}.

\end{adjmulticols}

\end{document}

